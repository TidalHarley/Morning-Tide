{
  "date": "2026-02-15",
  "generatedAt": "2026-02-15T23:53:22.006592",
  "introduction": "今日AI领域聚焦三大方向：智能体、安全与生成控制。OpenClaw创始人加入OpenAI，预示AI代理技术将加速整合进主流平台；Anthropic与五角大楼就Claude军事用途产生分歧，凸显AI伦理边界争议。论文方面，RISE提出具身智能新范式，PISCO实现视频实例的精准插入，DeepSight构建统一安全工具包，而T3D和Think Longer等研究则推动推理效率与个性化对齐。值得关注的是，印度ChatGPT用户破亿，反映全球AI普及加速；同时，大模型“快模式”技术细节曝光，揭示推理速度与模型保真度之间的权衡。",
  "introductionZh": "今日AI领域聚焦三大方向：智能体、安全与生成控制。OpenClaw创始人加入OpenAI，预示AI代理技术将加速整合进主流平台；Anthropic与五角大楼就Claude军事用途产生分歧，凸显AI伦理边界争议。论文方面，RISE提出具身智能新范式，PISCO实现视频实例的精准插入，DeepSight构建统一安全工具包，而T3D和Think Longer等研究则推动推理效率与个性化对齐。值得关注的是，印度ChatGPT用户破亿，反映全球AI普及加速；同时，大模型“快模式”技术细节曝光，揭示推理速度与模型保真度之间的权衡。",
  "introductionEn": "Today’s AI developments spotlight agents, safety, and controllable generation. OpenClaw’s founder joining OpenAI signals a push toward mainstream AI agent integration, while Anthropic’s reported clash with the Pentagon over Claude’s military use highlights urgent ethical boundaries. Key papers include RISE for self-improving robot policies, PISCO for precise video editing, and DeepSight—a unified safety toolkit for LLMs. Efficiency breakthroughs like T3D and Think Longer advance fast, verifiable reasoning. Meanwhile, India surpasses 100M weekly ChatGPT users, underscoring global adoption, and technical details of Anthropic’s vs. OpenAI’s “fast mode” reveal trade-offs between speed and model fidelity.",
  "longformScript": "今天AI领域有几件事情值得你留意：一边是顶尖开发者正加速把智能体带进主流平台，另一边，大模型在速度、安全和伦理上的边界争议也愈发尖锐。技术跑得很快，但规则和共识似乎还在原地追赶。\n\n先说一个关键人事变动：OpenClaw的创始人Peter Steinberger正式加入OpenAI。如果你关注过开源社区，可能知道OpenClaw是个强调本地运行、用户掌控数据的个人AI助手项目，它的设计哲学甚至有个名字——“龙虾方式”，意思是像龙虾一样，外壳坚硬、内核自主。Steinberger自己说，他接下来的目标是做出“连他母亲都能用的AI代理”。这听起来很朴素，但背后其实指向一个更大的趋势：AI代理正在从极客玩具转向大众工具。更值得注意的是，他承诺将OpenClaw移交独立基金会继续维护，并获得OpenAI的赞助支持多模型生态。这意味着，即便被大厂吸纳，这个项目仍试图保持开源中立。对普通用户来说，未来或许真能用上既易用又尊重隐私的AI助手，但也要留心：当开源项目与商业巨头深度绑定，它的独立性还能维持多久？\n\n与此同时，AI的速度竞赛也在分化出两条截然不同的路径。Anthropic和OpenAI最近都推出了各自的“快模式”来加速大模型推理，但策略完全不同。Anthropic选择降低批处理规模，让完整的Opus 4.6模型以2.5倍速度响应，牺牲的是系统吞吐量，换来了低延迟下的能力完整性；而OpenAI则走了一条更激进的路——借助Cerebras的超大芯片，部署一个精简版的GPT-5.3-Codex-Spark模型，速度提升高达15倍，但能力明显缩水。这种差异不只是技术选型问题，它直接关系到你我使用AI时的体验：如果你依赖AI调用工具、执行关键任务，高速模式下错误率可能悄然上升。开发者现在必须在“快”和“准”之间做取舍，而作为用户，我们也该意识到：不是所有“快”都值得追求。\n\n当然，速度之外，AI的伦理边界正在被现实狠狠拉扯。Anthropic最近和五角大楼杠上了——美国国防部希望授权使用Claude大模型用于“所有合法用途”，包括大规模国内监控和自主武器系统。Anthropic明确拒绝这两类应用，哪怕可能因此失去一份2亿美元的合同。这场冲突表面看是商业与原则的博弈，实则暴露了一个更深层的问题：当政府用“合法”二字定义AI用途时，谁来界定“合法”的边界？尤其在军事和监控这类高风险场景，技术一旦脱缰，后果难以挽回。这件事提醒我们，作为公众，不能只把AI当作便利工具，还得持续追问：它被用在了哪里？由谁控制？是否透明？\n\n技术演进的同时，内容生态也在经历阵痛。老牌科技媒体Ars Technica最近撤回了一篇包含AI伪造引述的文章，向被错误引用的当事人公开道歉。他们承认违反了自家“禁用未标注AI生成内容”的编辑政策。连这样以严谨著称的媒体都栽了跟头，说明AI滥用的风险无处不在。更早前，前NPR主播David Greene起诉Google，称其NotebookLM中的播客语音高度模仿他的语调、节奏甚至口头禅。Google辩称那是专业配音演员录制的，但相似度之高已引发广泛质疑。这些案例共同指向一个事实：生成式AI正在模糊真实与合成的界限，而法律和行业规范还没跟上。我们在享受AI生成内容便利的同时，也得保持一份警惕——尤其是涉及声音、图像或直接引语时，真实性不该是默认选项。\n\n最后，别忘了那些看似边缘却可能改变未来的探索。比如GitHub上突然蹿红的Moonshine项目，专为手机和IoT设备打造轻量级语音识别系统，能在离线状态下实现低延迟、高准确率的语音转文本。这类边缘AI技术，或许才是让AI真正融入日常生活的关键。还有天文学家首次观测到一颗恒星未经超新星爆发就直接坍缩成黑洞——虽然和AI无关，但它提醒我们：世界远比我们想象的复杂，而技术的意义，终究是帮我们更好地理解它，而不是简化它。\n\n今天的种种迹象表明，AI正处在从“能做什么”转向“该做什么”的拐点。技术突破固然令人兴奋，但真正决定未来走向的，可能是那些关于边界、责任和信任的艰难选择。作为使用者，我们不必成为专家，但至少可以保持清醒：在拥抱便利的同时，别忘了问一句——这真的是我们想要的吗？",
  "longformScriptZh": "今天AI领域有几件事情值得你留意：一边是顶尖开发者正加速把智能体带进主流平台，另一边，大模型在速度、安全和伦理上的边界争议也愈发尖锐。技术跑得很快，但规则和共识似乎还在原地追赶。\n\n先说一个关键人事变动：OpenClaw的创始人Peter Steinberger正式加入OpenAI。如果你关注过开源社区，可能知道OpenClaw是个强调本地运行、用户掌控数据的个人AI助手项目，它的设计哲学甚至有个名字——“龙虾方式”，意思是像龙虾一样，外壳坚硬、内核自主。Steinberger自己说，他接下来的目标是做出“连他母亲都能用的AI代理”。这听起来很朴素，但背后其实指向一个更大的趋势：AI代理正在从极客玩具转向大众工具。更值得注意的是，他承诺将OpenClaw移交独立基金会继续维护，并获得OpenAI的赞助支持多模型生态。这意味着，即便被大厂吸纳，这个项目仍试图保持开源中立。对普通用户来说，未来或许真能用上既易用又尊重隐私的AI助手，但也要留心：当开源项目与商业巨头深度绑定，它的独立性还能维持多久？\n\n与此同时，AI的速度竞赛也在分化出两条截然不同的路径。Anthropic和OpenAI最近都推出了各自的“快模式”来加速大模型推理，但策略完全不同。Anthropic选择降低批处理规模，让完整的Opus 4.6模型以2.5倍速度响应，牺牲的是系统吞吐量，换来了低延迟下的能力完整性；而OpenAI则走了一条更激进的路——借助Cerebras的超大芯片，部署一个精简版的GPT-5.3-Codex-Spark模型，速度提升高达15倍，但能力明显缩水。这种差异不只是技术选型问题，它直接关系到你我使用AI时的体验：如果你依赖AI调用工具、执行关键任务，高速模式下错误率可能悄然上升。开发者现在必须在“快”和“准”之间做取舍，而作为用户，我们也该意识到：不是所有“快”都值得追求。\n\n当然，速度之外，AI的伦理边界正在被现实狠狠拉扯。Anthropic最近和五角大楼杠上了——美国国防部希望授权使用Claude大模型用于“所有合法用途”，包括大规模国内监控和自主武器系统。Anthropic明确拒绝这两类应用，哪怕可能因此失去一份2亿美元的合同。这场冲突表面看是商业与原则的博弈，实则暴露了一个更深层的问题：当政府用“合法”二字定义AI用途时，谁来界定“合法”的边界？尤其在军事和监控这类高风险场景，技术一旦脱缰，后果难以挽回。这件事提醒我们，作为公众，不能只把AI当作便利工具，还得持续追问：它被用在了哪里？由谁控制？是否透明？\n\n技术演进的同时，内容生态也在经历阵痛。老牌科技媒体Ars Technica最近撤回了一篇包含AI伪造引述的文章，向被错误引用的当事人公开道歉。他们承认违反了自家“禁用未标注AI生成内容”的编辑政策。连这样以严谨著称的媒体都栽了跟头，说明AI滥用的风险无处不在。更早前，前NPR主播David Greene起诉Google，称其NotebookLM中的播客语音高度模仿他的语调、节奏甚至口头禅。Google辩称那是专业配音演员录制的，但相似度之高已引发广泛质疑。这些案例共同指向一个事实：生成式AI正在模糊真实与合成的界限，而法律和行业规范还没跟上。我们在享受AI生成内容便利的同时，也得保持一份警惕——尤其是涉及声音、图像或直接引语时，真实性不该是默认选项。\n\n最后，别忘了那些看似边缘却可能改变未来的探索。比如GitHub上突然蹿红的Moonshine项目，专为手机和IoT设备打造轻量级语音识别系统，能在离线状态下实现低延迟、高准确率的语音转文本。这类边缘AI技术，或许才是让AI真正融入日常生活的关键。还有天文学家首次观测到一颗恒星未经超新星爆发就直接坍缩成黑洞——虽然和AI无关，但它提醒我们：世界远比我们想象的复杂，而技术的意义，终究是帮我们更好地理解它，而不是简化它。\n\n今天的种种迹象表明，AI正处在从“能做什么”转向“该做什么”的拐点。技术突破固然令人兴奋，但真正决定未来走向的，可能是那些关于边界、责任和信任的艰难选择。作为使用者，我们不必成为专家，但至少可以保持清醒：在拥抱便利的同时，别忘了问一句——这真的是我们想要的吗？",
  "longformScriptEn": "Today’s AI landscape is defined by a pivotal tension: the race to embed intelligent agents into everyday life versus the urgent need to govern their use with ethical guardrails. As major players consolidate talent and capabilities, questions about control, transparency, and accountability are moving from academic debates to real-world consequences—whether in military contracts, courtroom battles over voice rights, or retractions from respected newsrooms. The direction we’re heading isn’t just about faster models or smarter assistants; it’s about who gets to decide what AI should—and shouldn’t—do.\n\nOne of the clearest signals of this shift comes from OpenAI’s latest hire: Peter Steinberger, the creator of OpenClaw, a rising open-source AI agent designed to run locally across devices while prioritizing user data ownership. Steinberger announced he’s joining OpenAI to help build “accessible AI agents—even for my mother”—a telling phrase that underscores the industry’s push toward mainstream usability. Importantly, OpenClaw will continue as an independent open-source project under a new foundation, with OpenAI pledging ongoing sponsorship. This move reflects a broader trend: top builders are aligning with well-resourced labs to scale their visions, but the community is watching closely to see whether such projects retain their original ethos of decentralization and user sovereignty once corporate interests are involved.\n\nMeanwhile, the ethical fault lines are deepening. Anthropic is reportedly refusing a $200 million Pentagon contract over demands that its Claude model be authorized for “all lawful purposes”—a phrase that, according to Axios, includes mass domestic surveillance and autonomous weapons systems. Anthropic has drawn a hard line: no to both. This standoff isn’t just about one company’s principles; it’s a litmus test for how AI developers navigate national security pressures without normalizing dangerous applications. The ambiguity around what governments deem “lawful” makes this especially fraught. If AI systems become tools of unchecked state power, even under legal pretenses, the public loses a critical check on technological overreach. Anthropic’s stance may cost them short-term revenue, but it could set a precedent for responsible boundaries in dual-use AI.\n\nOn the technical front, speed is becoming a battleground—with trade-offs that users rarely see. Both Anthropic and OpenAI have rolled out “fast mode” inference options, but their approaches diverge sharply. Anthropic achieves a 2.5x speedup by running its full Opus 4.6 model with smaller batch sizes, preserving reasoning fidelity at the cost of throughput. OpenAI, meanwhile, uses Cerebras’ specialized hardware to run a distilled version of GPT-5.3—called Codex-Spark—that’s 15x faster but demonstrably less capable. For developers building AI agents that handle sensitive tasks—like medical triage or financial advice—this distinction matters deeply. High-speed modes may feel snappier, but they can introduce subtle errors or hallucinations that compound in autonomous workflows. The lesson here is clear: when latency drops, scrutiny must rise.\n\nBeyond infrastructure and ethics, generative AI is also triggering legal and journalistic reckoning. Ars Technica recently retracted an article containing AI-fabricated quotes attributed to a real person, violating its own policy against unlabeled AI content. The outlet apologized and reaffirmed its ban on such practices—a sobering reminder that even seasoned tech publications aren’t immune to the seductive efficiency of synthetic text. At the same time, former NPR host David Greene is suing Google, claiming its NotebookLM tool cloned his distinctive voice—including his verbal tics like “uh”—without consent. Google denies using his recordings, insisting the voice came from a professional actor, but the resemblance has alarmed listeners and raised unresolved questions about personality rights in the age of voice synthesis. These cases highlight a growing gap between what AI can mimic and what it’s legally or ethically permitted to replicate.\n\nSo where do we go from here? Keep an eye on three things. First, watch how OpenClaw evolves under OpenAI’s stewardship—will it remain a truly neutral, user-controlled agent, or gradually align with OpenAI’s ecosystem? Second, monitor the fallout from Anthropic’s Pentagon standoff; if they hold firm, it could inspire other firms to codify red lines around military AI. Third, demand transparency on voice and content provenance: if platforms won’t disclose training data sources or voice origins, users should treat synthetic media with healthy skepticism. The opportunities are immense—local AI agents, efficient edge ASR systems like Moonshine, faster reasoning—but so are the risks of eroded trust, legal gray zones, and unchecked automation.\n\nIn sum, today’s developments reveal AI at a crossroads. On one path, we get seamless, safe, and sovereign agents that augment human capability without compromising autonomy. On the other, we risk systems optimized for speed over truth, deployed in contexts that blur moral lines, and trained on data that sidesteps consent. The choices made by companies, regulators, and even individual users in the coming months will shape which path dominates. For now, stay curious—but stay critical.",
  "audioUrl": "",
  "papers": [
    {
      "id": "hf_2602.11075",
      "title": "RISE: Self-Improving Robot Policy with Compositional World Model",
      "titleZh": "RISE: Self-Improving Robot Policy with Compositional World Model",
      "titleEn": "RISE: Self-Improving Robot Policy with Compositional World Model",
      "url": "https://huggingface.co/papers/2602.11075",
      "type": "paper",
      "source": "HuggingFace Daily Papers",
      "summary": "主要内容：Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle...；关键点：RISE: Self-Improving Robot Policy with Compositional World M；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle...；关键点：RISE: Self-Improving Robot Policy with Compositional World M；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic m.... Key takeaway: RISE: Self-Improving Robot Policy with Compositional World Model. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Robotics"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：通过组合式世界模型实现机器人策略自我进化，显著提升复杂动态任务中的鲁棒性，是当前VLA模型迈向真实世界应用的关键突破。",
        "热度：0 / 评论 2"
      ],
      "score": 7.4,
      "publishedAt": "2026-02-11T17:43:36+00:00",
      "authors": [
        "Jiazhi Yang",
        "Kunyang Lin",
        "Jinwei Li",
        "Wencong Zhang",
        "Tianwei Lin",
        "Longyan Wu",
        "Zhizhong Su",
        "Hao Zhao",
        "Ya-Qin Zhang",
        "Li Chen",
        "Ping Luo",
        "Xiangyu Yue",
        "Hongyang Li"
      ]
    },
    {
      "id": "hf_2602.12092",
      "title": "DeepSight: An All-in-One LM Safety Toolkit",
      "titleZh": "DeepSight: An All-in-One LM Safety Toolkit",
      "titleEn": "DeepSight: An All-in-One LM Safety Toolkit",
      "url": "https://huggingface.co/papers/2602.12092",
      "type": "paper",
      "source": "HuggingFace Daily Papers",
      "summary": "主要内容：As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language ...；关键点：DeepSight: An All-in-One LM Safety Toolkit；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language ...；关键点：DeepSight: An All-in-One LM Safety Toolkit；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal L.... Key takeaway: DeepSight: An All-in-One LM Safety Toolkit. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Multimodal",
        "Open Source",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：推出一站式大模型安全工具包DeepSight，整合评估、诊断与对齐流程，响应全球对LLM/MLLM安全监管的迫切需求，具备产业级影响力。",
        "热度：0 / 评论 3"
      ],
      "score": 7.4,
      "publishedAt": "2026-02-12T15:43:14+00:00",
      "authors": [
        "Bo Zhang",
        "Jiaxuan Guo",
        "Lijun Li",
        "Dongrui Liu",
        "Sujin Chen",
        "Guanxu Chen",
        "Zhijie Zheng",
        "Qihao Lin",
        "Lewen Yan",
        "Chen Qian",
        "Yijin Zhou",
        "Yuyao Wu",
        "Shaoxiong Guo",
        "Tianyi Du",
        "Jingyi Yang",
        "Xuhao Hu",
        "Ziqi Miao",
        "Xiaoya Lu",
        "Jing Shao",
        "Xia Hu"
      ]
    },
    {
      "id": "hf_2602.12205",
      "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "titleZh": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "titleEn": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "url": "https://huggingface.co/papers/2602.12205",
      "type": "paper",
      "source": "HuggingFace Daily Papers",
      "summary": "主要内容：Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10...；关键点：DeepGen 1.0: A Lightweight Unified Multimodal Model for Adva；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10...；关键点：DeepGen 1.0: A Lightweight Unified Multimodal Model for Adva；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive trai.... Key takeaway: DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generati. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Training",
        "RAG"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：发布轻量级5B统一多模态模型DeepGen 1.0，以极低参数量实现全面图像生成与编辑能力，打破算力壁垒，推动AI内容创作普惠化。",
        "热度：0 / 评论 3"
      ],
      "score": 7.4,
      "publishedAt": "2026-02-12T17:44:24+00:00",
      "authors": [
        "Dianyi Wang",
        "Ruihang Li",
        "Feng Han",
        "Chaofan Ma",
        "Wei Song",
        "Siyuan Wang",
        "Yibin Wang",
        "Yi Xin",
        "Hongjian Liu",
        "Zhixiong Zhang",
        "Shengyuan Ding",
        "Tianhang Wang",
        "Zhenglin Cheng",
        "Tao Lin",
        "Cheng Jin",
        "Kaicheng Yu",
        "Jingjing Chen",
        "Wenjie Wang",
        "Zhongyu Wei",
        "Jiaqi Wang"
      ]
    },
    {
      "id": "hf_2602.08277",
      "title": "PISCO: Precise Video Instance Insertion with Sparse Control",
      "titleZh": "PISCO: Precise Video Instance Insertion with Sparse Control",
      "titleEn": "PISCO: Precise Video Instance Insertion with Sparse Control",
      "url": "https://huggingface.co/papers/2602.08277",
      "type": "paper",
      "source": "HuggingFace Daily Papers",
      "summary": "主要内容：The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on e...；关键点：PISCO: Precise Video Instance Insertion with Sparse Control；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on e...；关键点：PISCO: Precise Video Instance Insertion with Sparse Control；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering a.... Key takeaway: PISCO: Precise Video Instance Insertion with Sparse Control. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Diffusion",
        "Research",
        "Open Source",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：实现高保真、细粒度视频实例插入，突破传统生成依赖提示工程的局限，代表AI影视制作从“生成”迈向“可控编辑”的重大跃迁。",
        "热度：0 / 评论 2"
      ],
      "score": 7.4,
      "publishedAt": "2026-02-09T05:15:39+00:00",
      "authors": [
        "Xiangbo Gao",
        "Renjie Li",
        "Xinghao Chen",
        "Yuheng Wu",
        "Suofei Feng",
        "Qing Yin",
        "Zhengzhong Tu"
      ]
    },
    {
      "id": "hf_2602.09891",
      "title": "Stemphonic: All-at-once Flexible Multi-stem Music Generation",
      "titleZh": "Stemphonic: All-at-once Flexible Multi-stem Music Generation",
      "titleEn": "Stemphonic: All-at-once Flexible Multi-stem Music Generation",
      "url": "https://huggingface.co/papers/2602.09891",
      "type": "paper",
      "source": "HuggingFace Daily Papers",
      "summary": "主要内容：Music stem generation, the task of producing musically-synchronized and isolated instrument audio clips, offers the pote...；关键点：Stemphonic: All-at-once Flexible Multi-stem Music Generation；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Music stem generation, the task of producing musically-synchronized and isolated instrument audio clips, offers the pote...；关键点：Stemphonic: All-at-once Flexible Multi-stem Music Generation；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Music stem generation, the task of producing musically-synchronized and isolated instrument audio clips, offers the potential of greater user control .... Key takeaway: Stemphonic: All-at-once Flexible Multi-stem Music Generation. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Diffusion",
        "Audio",
        "Training",
        "Inference"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出一次性生成多音轨音乐的新范式，突破传统文本到音乐生成局限，显著提升创作灵活性与工业应用潜力，具备主流媒体关注价值。",
        "热度：0 / 评论 3"
      ],
      "score": 6.8,
      "publishedAt": "2026-02-10T15:30:12+00:00",
      "authors": [
        "Shih-Lun Wu",
        "Ge Zhu",
        "Juan-Pablo Caceres",
        "Cheng-Zhi Anna Huang",
        "Nicholas J. Bryan"
      ]
    },
    {
      "id": "hf_2602.05827",
      "title": "Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation",
      "titleZh": "Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation",
      "titleEn": "Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation",
      "url": "https://huggingface.co/papers/2602.05827",
      "type": "paper",
      "source": "HuggingFace Daily Papers",
      "summary": "主要内容：Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease deci...；关键点：Sparse Video Generation Propels Real-World Beyond-the-View V；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease deci...；关键点：Sparse Video Generation Propels Real-World Beyond-the-View V；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease decision-making, they fundamentall.... Key takeaway: Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navig. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Agent"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：推动视觉语言导航向更轻量化、自主化方向演进，打破对详细指令的依赖，对真实世界机器人部署具有变革意义。",
        "热度：0 / 评论 2"
      ],
      "score": 6.8,
      "publishedAt": "2026-02-05T16:16:13+00:00",
      "authors": [
        "Hai Zhang",
        "Siqi Liang",
        "Li Chen",
        "Yuxian Li",
        "Yukuan Xu",
        "Yichao Zhong",
        "Fu Zhang",
        "Hongyang Li"
      ]
    }
  ],
  "news": [
    {
      "id": "rss_1551240715",
      "title": "OpenClaw founder Peter Steinberger is joining OpenAI",
      "titleZh": "OpenClaw founder Peter Steinberger is joining OpenAI",
      "titleEn": "OpenClaw founder Peter Steinberger is joining OpenAI",
      "url": "https://www.theverge.com/ai-artificial-intelligence/879623/openclaw-founder-peter-steinberger-joins-openai",
      "type": "news",
      "source": "The Verge AI",
      "summary": "Sam Altman announced on X that Peter Steinberger, the man behind the trendy AI a，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "Sam Altman announced on X that Peter Steinberger, the man behind the trendy AI a，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "Sam Altman announced on X that Peter Steinberger, the man behind the trendy AI agent OpenClaw, was joining OpenAI. He sa. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "OpenClaw founder Peter Steinberger is joining OpenAI | The Verge Skip to main content The homepage The Verge The Verge logo. The Verge The Verge logo. Tech Reviews Science Entertainment AI Policy Hamburger Navigation Button The homepage The Verge The Verge logo. Hamburger Navigation Button Navigation Drawer The Verge The Verge logo. Login / Sign Up close Close Search Tech Expand Amazon Apple Facebook Google Microsoft Samsung Business See all tech Reviews Expand Smart Home Reviews Phone Reviews Tablet Reviews Headphone Reviews See all reviews Science Expand Space Energy Environment Health See all science Entertainment Expand TV Shows Movies Audio See all entertainment AI Expand OpenAI Anthropic See all AI Policy Expand Antitrust Politics Law Security See all policy Gadgets Expand Laptops Phones TVs Headphones Speakers Wearables See all gadgets Verge Shopping Expand Buying Guides Deals Gift Guides See all shopping Gaming Expand Xbox PlayStation Nintendo See all gaming Streaming Expand Disney HBO Netflix YouTube Creators See all streaming Transportation Expand Electric Cars Autonomous Cars Ride-sharing Scooters See all transportation Features Verge Video Expand TikTok YouTube Instagram Podcasts Expand Decoder The Vergecast Version History Newsletters Expand The Verge Daily Installer Verge Deals Notepad Optimizer Regulator The Stepback Archives Store Verge Product Updates Subscribe Facebook Threads Instagram Youtube RSS The Verge The Verge logo. OpenClaw founder Peter Steinberger is joining OpenAI Comments Drawer Comments Loading comments Getting the conversation ready... AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI News Close News Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All News Tech Close Tech Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Tech OpenClaw founder Peter Steinberger is joining OpenAI OpenClaw will live on as an open-source project. OpenClaw will live on as an open-source project. by Terrence O'Brien Close Terrence O'Brien Weekend Editor Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Terrence O'Brien Feb 15, 2026, 10:56 PM UTC Link Share Gift Image: The Verge Part Of OpenClaw: all the news about the trending AI agent see all updates Terrence O'Brien Close Terrence O'Brien Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Terrence O'Brien is the Verge’s weekend editor. He has over 18 years of experience, including 10 years as managing editor at Engadget. Sam Altman announced on X that Peter Steinberger, the man behind the trendy AI agent OpenClaw , was joining OpenAI. He said that Steinberger has “a lot of amazing ideas” about getting AI agents to interact with each other, saying “the future is going to be extremely multi-agent.” He also said that this ability for agents to work together will “quickly become core to our product offerings.” OpenClaw, previously known as Moltbot and Clawdbot, exploded on the scene earlier this year and became the darling of the tech world . Its rise was swift, but not without its bumps along the way. Earlier this month, researchers found over 400 malicious skills uploaded to ClawHub . It also launched MoltBook , a social network where AI agents went to complain about their humans, debate the provability of consciousness, and discuss the need for a private place to exchange ideas. And then it was immediately infiltrated by humans . In a post on his personal site, Steinberger said that joining OpenAI would allow him to achieve his goal of bringing AI agents to the masses, without the headaches of running a company. He explained: I could totally see how OpenClaw could become a huge company. And no, it’s not really exciting for me. I’m a builder at heart. I did the whole creating-a-company game already, poured 13 years of my life into it and learned a lot. What I want is to change the world, not build a large company and teaming up with OpenAI is the fastest way to bring this to everyone. For OpenAI, this is a high-profile hire after several big names were poached by Meta or left to form a rival . It also had a public falling-out with Elon Musk. Details of the deal aren’t public. It’s not clear how much Steinberger is getting paid or what his title might be. But Altman said that OpenClaw will continue as an open-source project in a foundation supported by OpenAI. Update February 15th : Added statement from Peter Steinberger’s blog. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Terrence O'Brien Close Terrence O'Brien Weekend Editor Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Terrence O'Brien AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI News Close News Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All News OpenAI Close OpenAI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All OpenAI Tech Close Tech Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Tech More in: OpenClaw: all the news about the trending AI agent OpenClaw is scanning AI skills after hundreds of malicious add-ons were found on ClawHub. Terrence O'Brien Feb 7 OpenClaw’s AI ‘skill’ extensions are a security nightmare Emma Roth Feb 4 Humans are infiltrating the social network for AI bots Hayden Field Feb 3 Most Popular Most Popular Jikipedia turns Epstein’s emails into an encyclopedia of his powerful friends The Pocket Taco is the best way to turn your phone into a Game Boy Anker’s USB-C cable that lets you charge two gadgets at once is 20 percent off The DJI Romo robovac had security so poor, this man remotely accessed thousands of them Why are Epstein’s emails full of equals signs? The Verge Daily A free daily digest of the news that matters most. Email (required) Sign Up By submitting your email, you agree to our Terms and Privacy Notice . This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Advertiser Content From This is the title for the native ad More in AI I hate my AI pet with every fiber of my being AI can’t make good video game worlds yet, and it might never be able to My uncanny AI valentines What’s behind the mass exodus at xAI? Ring’s adorable surveillance hellscape Meta reportedly wants to add face recognition to smart glasses while privacy advocates are distracted I hate my AI pet with every fiber of my being Robert Hart 3:00 PM UTC AI can’t make good video game worlds yet, and it might never be able to Jay Peters 1:00 PM UTC My uncanny AI valentines Victoria Song Feb 14 What’s behind the mass exodus at xAI? Hayden Field Feb 13 Ring’s adorable surveillance hellscape David Pierce Feb 13 Meta reportedly wants to add face recognition to smart glasses while privacy advocates are distracted Emma Roth Feb 13 Advertiser Content From This is the title for the native ad Top Stories 1:00 PM UTC Why are Epstein’s emails full of equals signs? 3:00 PM UTC I hate my AI pet with every fiber of my being 5:30 PM UTC You need to watch the intensely surreal cult classic Possession 1:00 PM UTC AI can’t make good video game worlds yet, and it might never be able to 3:00 PM UTC Logitech’s new Superstrike is a faster, more customizable gaming mouse Feb 14 A powerful tool of resistance is already in your hands The Verge The Verge logo. Facebook Threads Instagram Youtube RSS Contact Tip Us Community Guidelines Archives About Ethics Statement How We Rate and Review Products Cookie Settings Terms of Use Privacy Notice Cookie Policy Licensing FAQ Accessibility Platform Status © 2026 Vox Media , LLC. All Rights Reserved",
      "imageUrl": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/STKB382_OPEN_CLAW_D.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200",
      "tags": [
        "Agent",
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：The Verge AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：OpenClaw创始人加入OpenAI并被高层公开认可，预示多智能体系统重大战略方向，具全球产业影响力",
        "热度：0 / 评论 0"
      ],
      "score": 6.4,
      "publishedAt": "2026-02-15T22:56:16+00:00",
      "authors": [
        "Terrence O’Brien"
      ]
    },
    {
      "id": "rss_3268542495",
      "title": "OpenClaw creator Peter Steinberger joins OpenAI",
      "titleZh": "OpenClaw creator Peter Steinberger joins OpenAI",
      "titleEn": "OpenClaw creator Peter Steinberger joins OpenAI",
      "url": "https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/",
      "type": "news",
      "source": "TechCrunch AI",
      "summary": "OpenAI said OpenClaw will live on as an open source project.，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "OpenAI said OpenClaw will live on as an open source project.，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "OpenAI said OpenClaw will live on as an open source project.. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "OpenClaw creator Peter Steinberger joins OpenAI | TechCrunch TechCrunch Desktop Logo TechCrunch Mobile Logo Latest Startups Venture Apple Security AI Apps Events Podcasts Newsletters Search Submit Site Search Toggle Mega Menu Toggle Topics Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture More from TechCrunch Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us In Brief Posted: 2:28 PM PST · February 15, 2026 Image Credits: Getty Images Anthony Ha OpenClaw creator Peter Steinberger joins OpenAI Peter Steinberger, who created the AI personal assistant now known as OpenClaw , has joined OpenAI. Previously known as Clawdbot, then Moltbot, OpenClaw achieved viral popularity over the past few weeks with its promise to be the “AI that actually does things,” whether that’s managing your calendar, booking flights, or even joining a social network full of other AI assistants . (The name changed the first time after Anthropic threatened legal action over its similarity to Claude, then changed again because Steinberger liked the new name better.) In a blog post announcing his decision to join OpenAI, the Austrian developer said that while he might have been able to turn OpenClaw into a huge company, “It’s not really exciting for me.” “What I want is to change the world, not build a large company[,] and teaming up with OpenAI is the fastest way to bring this to everyone,” Steinberger said. OpenAI CEO Sam Altman posted on X that in his new role, Steinberger will “drive the next generation of personal agents.” As for OpenClaw, Altman said it will “live in a foundation as an open source project that OpenAI will continue to support” Topics AI , Startups October 13-15 San Francisco, CA Tickets are live at the lowest rates of the year. Save up to $680 on your pass now. Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders , dive into 200+ sessions , and explore 300+ startups building what’s next. Don’t miss these one-time savings. REGISTER NOW Newsletters See More Subscribe for the industry’s biggest tech news TechCrunch Daily News Every weekday and Sunday, you can get the best of TechCrunch’s coverage. TechCrunch Mobility TechCrunch Mobility is your destination for transportation news and insight. Startups Weekly Startups are the core of TechCrunch, so get our best coverage delivered weekly. StrictlyVC Provides movers and shakers with the info they need to start their day. No newsletters selected. Subscribe By submitting your email, you agree to our Terms and Privacy Notice . Related AI India has 100M weekly active ChatGPT users, Sam Altman says Jagmeet Singh 5 hours ago AI The enterprise AI land grab is on. Glean is building the layer beneath the interface. Rebecca Bellan 6 hours ago Startups India doubles down on state-backed venture capital, approving $1.1B fund Jagmeet Singh 1 day ago Latest in AI In Brief OpenClaw creator Peter Steinberger joins OpenAI Anthony Ha 50 minutes ago In Brief Longtime NPR host David Greene sues Google over NotebookLM voice Anthony Ha 1 hour ago In Brief Anthropic and the Pentagon are reportedly arguing over Claude usage Anthony Ha 2 hours ago X LinkedIn Facebook Instagram youTube Mastodon Threads Bluesky TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Terms of Service Privacy Policy RSS Terms of Use Code of Conduct Epstein Kindle Scribe Reddit TikTok GPT-4o Tech Layoffs ChatGPT © 2025 TechCrunch Media LLC.",
      "imageUrl": "https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-1396827010.jpg?resize=1200%2C630",
      "tags": [
        "Industry",
        "Open Source"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：TechCrunch AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：OpenClaw核心人物加盟OpenAI并确认项目开源，标志多智能体生态布局关键一步，具有战略级影响",
        "热度：0 / 评论 0"
      ],
      "score": 6.4,
      "publishedAt": "2026-02-15T22:28:02+00:00",
      "authors": [
        "Anthony Ha"
      ]
    },
    {
      "id": "rss_7326201001",
      "title": "Anthropic拒让Claude用于监控与自主武器，或失五角大楼2亿美元合同",
      "titleZh": "Anthropic拒让Claude用于监控与自主武器，或失五角大楼2亿美元合同",
      "titleEn": "Anthropic Resists Pentagon’s Push to Use Claude for Surveillance and Autonomous Weapons, Risks $200M Contract",
      "url": "https://techcrunch.com/2026/02/15/anthropic-and-the-pentagon-are-reportedly-arguing-over-claude-usage/",
      "type": "news",
      "source": "TechCrunch AI",
      "summary": "据Axios报道，**Anthropic与美国国防部就其Claude大模型的使用范围产生严重分歧**：五角大楼要求AI公司授权其“所有合法用途”，包括大规模国内监控和自主武器系统，而Anthropic明确拒绝这两类应用，并可能因此失去一份价值2亿美元的合同；这一冲突凸显了AI伦理边界在国家安全场景下的紧张博弈，也提醒公众关注政府如何界定“合法”使用AI技术，普通用户可借此审视自身对AI军事化应用的立场并支持透明治理。",
      "summaryZh": "据Axios报道，**Anthropic与美国国防部就其Claude大模型的使用范围产生严重分歧**：五角大楼要求AI公司授权其“所有合法用途”，包括大规模国内监控和自主武器系统，而Anthropic明确拒绝这两类应用，并可能因此失去一份价值2亿美元的合同；这一冲突凸显了AI伦理边界在国家安全场景下的紧张博弈，也提醒公众关注政府如何界定“合法”使用AI技术，普通用户可借此审视自身对AI军事化应用的立场并支持透明治理。",
      "summaryEn": "According to Axios, Anthropic and the U.S. Department of Defense are in sharp disagreement over the permissible uses of its Claude AI model: the Pentagon demands authorization for 'all lawful purposes,' including mass domestic surveillance and autonomous weapons, while Anthropic explicitly refuses both applications and risks losing a $200 million contract. This clash highlights the tension between national security imperatives and ethical AI boundaries, urging public scrutiny of how governments define 'lawful' AI use and prompting individuals to consider their stance on AI militarization.",
      "fullText": "Anthropic and the Pentagon are reportedly arguing over Claude usage | TechCrunch TechCrunch Desktop Logo TechCrunch Mobile Logo Latest Startups Venture Apple Security AI Apps Events Podcasts Newsletters Search Submit Site Search Toggle Mega Menu Toggle Topics Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture More from TechCrunch Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us In Brief Posted: 1:11 PM PST · February 15, 2026 Image Credits: Tom Brenner/Bloomberg via Getty Images Anthony Ha Anthropic and the Pentagon are reportedly arguing over Claude usage The Pentagon is pushing AI companies to allow the U.S. military to use their technology for “all lawful purposes,” but Anthropic is pushing back, according to a new report in Axios . The government is reportedly making the same demand to OpenAI, Google, and xAI. An anonymous Trump administration official told Axios that one of those companies has agreed, while the other two have supposedly shown some flexibility. Anthropic, meanwhile, has reportedly been the most resistant. In response, the Pentagon is apparently threatening to pull the plug on its $200 million contract with the AI company. In January, the Wall Street Journal reported that there was significant disagreement between Anthropic and Defense Department officials over how its Claude models could be used. The WSJ subsequently said that Claude was used in the U.S. military’s operation to capture then-Venezuelan President Nicolás Maduro. Anthropic did not immediately respond to TechCrunch’s request for comment. A company spokesperson told Axios that the company has “not discussed the use of Claude for specific operations with the Department of War” but is instead “focused on a specific set of Usage Policy questions — namely, our hard limits around fully autonomous weapons and mass domestic surveillance.” Topics AI , Anthropic , department of defense , Government & Policy , pentagon October 13-15 San Francisco, CA Tickets are live at the lowest rates of the year. Save up to $680 on your pass now. Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders , dive into 200+ sessions , and explore 300+ startups building what’s next. Don’t miss these one-time savings. REGISTER NOW Newsletters See More Subscribe for the industry’s biggest tech news TechCrunch Daily News Every weekday and Sunday, you can get the best of TechCrunch’s coverage. TechCrunch Mobility TechCrunch Mobility is your destination for transportation news and insight. Startups Weekly Startups are the core of TechCrunch, so get our best coverage delivered weekly. StrictlyVC Provides movers and shakers with the info they need to start their day. No newsletters selected. Subscribe By submitting your email, you agree to our Terms and Privacy Notice . Related AI The enterprise AI land grab is on. Glean is building the layer beneath the interface. Rebecca Bellan 6 hours ago Media & Entertainment Hollywood isn’t happy about the new Seedance 2.0 video generator Anthony Ha 8 hours ago Startups India doubles down on state-backed venture capital, approving $1.1B fund Jagmeet Singh 1 day ago Latest in Government & Policy In Brief Anthropic and the Pentagon are reportedly arguing over Claude usage Anthony Ha 2 hours ago In Brief Homeland Security reportedly sent hundreds of subpoenas seeking to unmask anti-ICE accounts Anthony Ha 1 day ago Government & Policy India partners with Alibaba.com for export push despite past China tech bans Jagmeet Singh 2 days ago X LinkedIn Facebook Instagram youTube Mastodon Threads Bluesky TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Terms of Service Privacy Policy RSS Terms of Use Code of Conduct Epstein Kindle Scribe Reddit TikTok GPT-4o Tech Layoffs ChatGPT © 2025 TechCrunch Media LLC.",
      "imageUrl": "https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1252170580.jpg?resize=1200%2C630",
      "tags": [
        "LLM",
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：TechCrunch AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：涉及美国国防部与顶级AI公司Anthropic在军事伦理与技术使用上的公开争议，触及AI治理核心议题，具有全球政策与产业影响，符合战略级事件标准。",
        "热度：0 / 评论 0"
      ],
      "score": 6.4,
      "publishedAt": "2026-02-15T21:11:28+00:00",
      "authors": [
        "Anthony Ha"
      ]
    },
    {
      "id": "hn_47022329",
      "title": "Anthropic与OpenAI推LLM“快模式”，技术路线与能力取舍迥异",
      "titleZh": "Anthropic与OpenAI推LLM“快模式”，技术路线与能力取舍迥异",
      "titleEn": "Anthropic and OpenAI Roll Out Fast LLM Inference with Divergent Trade-offs",
      "url": "https://www.seangoedecke.com/fast-llm-inference/",
      "type": "news",
      "source": "Hacker News",
      "summary": "Anthropic与OpenAI近期分别推出“快速模式”以加速LLM推理，但技术路径截然不同：**Anthropic通过降低批处理规模实现2.5倍提速，仍运行完整Opus 4.6模型；OpenAI则借助Cerebras超大芯片部署精简版GPT-5.3-Codex-Spark模型，速度提升15倍但能力明显下降**。这一对比揭示了当前AI推理优化的两种策略——牺牲吞吐换低延迟 vs. 硬件定制+模型蒸馏换极致速度，对开发者而言意味着需在响应速度与任务可靠性间权衡，普通用户若依赖AI代理执行关键操作（如工具调用），应警惕高速模式下错误率上升的风险。",
      "summaryZh": "Anthropic与OpenAI近期分别推出“快速模式”以加速LLM推理，但技术路径截然不同：**Anthropic通过降低批处理规模实现2.5倍提速，仍运行完整Opus 4.6模型；OpenAI则借助Cerebras超大芯片部署精简版GPT-5.3-Codex-Spark模型，速度提升15倍但能力明显下降**。这一对比揭示了当前AI推理优化的两种策略——牺牲吞吐换低延迟 vs. 硬件定制+模型蒸馏换极致速度，对开发者而言意味着需在响应速度与任务可靠性间权衡，普通用户若依赖AI代理执行关键操作（如工具调用），应警惕高速模式下错误率上升的风险。",
      "summaryEn": "Anthropic and OpenAI have launched 'fast mode' LLM inference with divergent approaches: Anthropic achieves 2.5x speedup by reducing batch size while running the full Opus 4.6 model, whereas OpenAI leverages Cerebras’ giant chips to run a distilled, less capable GPT-5.3-Codex-Spark model at 15x speed. This contrast reveals two optimization strategies—low-latency via reduced batching versus hardware-accelerated speed with model distillation—forcing developers to balance responsiveness against reliability. End users relying on AI agents for critical tasks should be wary of increased error rates in high-speed modes.",
      "fullText": "Two different tricks for fast LLM inference sean goedecke February 15, 2026 │ ai Two different tricks for fast LLM inference Anthropic and OpenAI both recently announced “fast mode”: a way to interact with their best coding model at significantly higher speeds. These two versions of fast mode are very different. Anthropic’s offers up to 2.5x tokens per second (so around 170, up from Opus 4.6’s 65). OpenAI’s offers more than 1000 tokens per second (up from GPT-5.3-Codex’s 65 tokens per second, so 15x). So OpenAI’s fast mode is six times faster than Anthropic’s 1 . However, Anthropic’s big advantage is that they’re serving their actual model. When you use their fast mode, you get real Opus 4.6, while when you use OpenAI’s fast mode you get GPT-5.3-Codex-Spark, not the real GPT-5.3-Codex. Spark is indeed much faster, but is a notably less capable model: good enough for many tasks, but it gets confused and messes up tool calls in ways that vanilla GPT-5.3-Codex would never do. Why the differences? The AI labs aren’t advertising the details of how their fast modes work, but I’m pretty confident it’s something like this: Anthropic’s fast mode is backed by low-batch-size inference, while OpenAI’s fast mode is backed by special monster Cerebras chips . Let me unpack that a bit. How Anthropic’s fast mode works The tradeoff at the heart of AI inference economics is batching , because the main bottleneck is memory . GPUs are very fast, but moving data onto a GPU is not. Every inference operation requires copying all the tokens of the user’s prompt 2 onto the GPU before inference can start. Batching multiple users up thus increases overall throughput at the cost of making users wait for the batch to be full. A good analogy is a bus system. If you had zero batching for passengers - if, whenever someone got on a bus, the bus departed immediately - commutes would be much faster for the people who managed to get on a bus . But obviously overall throughput would be much lower, because people would be waiting at the bus stop for hours until they managed to actually get on one. Anthropic’s fast mode offering is basically a bus pass that guarantees that the bus immediately leaves as soon as you get on. It’s six times the cost, because you’re effectively paying for all the other people who could have got on the bus with you, but it’s way faster 3 because you spend zero time waiting for the bus to leave. edit: I want to thank a reader for emailing me to point out that the “waiting for the bus” cost is really only paid for the first token, so that won’t affect streaming latency (just latency per turn or tool call). It’s thus better to think of the performance impact of batch size being mainly that smaller batches require fewer flops and thus execute more quickly. In my analogy, maybe it’s “lighter buses drive faster”, or something. Obviously I can’t be fully certain this is right. Maybe they have access to some new ultra-fast compute that they’re running this on, or they’re doing some algorithmic trick nobody else has thought of. But I’m pretty sure this is it. Brand new compute or algorithmic tricks would likely require changes to the model (see below for OpenAI’s system), and “six times more expensive for 2.5x faster” is right in the ballpark for the kind of improvement you’d expect when switching to a low-batch-size regime. How OpenAI’s fast mode works OpenAI’s fast mode does not work anything like this. You can tell that simply because they’re introducing a new, worse model for it. There would be absolutely no reason to do that if they were simply tweaking batch sizes. Also, they told us in the announcement blog post exactly what’s backing their fast mode: Cerebras. OpenAI announced their Cerebras partnership a month ago in January. What’s Cerebras? They build “ultra low-latency compute”. What this means in practice is that they build giant chips . A H100 chip (fairly close to the frontier of inference chips) is just over a square inch in size. A Cerebras chip is 70 square inches. You can see from pictures that the Cerebras chip has a grid-and-holes pattern all over it. That’s because silicon wafers this big are supposed to be broken into dozens of chips. Instead, Cerebras etches a giant chip over the entire thing. The larger the chip, the more internal memory it can have. The idea is to have a chip with SRAM large enough to fit the entire model , so inference can happen entirely in-memory. Typically GPU SRAM is measured in the tens of megabytes . That means that a lot of inference time is spent streaming portions of the model weights from outside of SRAM into the GPU compute 4 . If you could stream all of that from the (much faster) SRAM, inference would a big speedup: fifteen times faster, as it turns out! So how much internal memory does the latest Cerebras chip have? 44GB . This puts OpenAI in kind of an awkward position. 44GB is enough to fit a small model (~20B params at fp16, ~40B params at int8 quantization), but clearly not enough to fit GPT-5.3-Codex. That’s why they’re offering a brand new model, and why the Spark model has a bit of “small model smell” to it: it’s a smaller distil of the much larger GPT-5.3-Codex model 5 . edit: I was wrong about this - the Codex model is almost certainly larger than this, and doesn’t need to fit entirely in one chip’s SRAM (if it did, we’d be seeing faster speeds). Thanks to the Hacker News commenters for correcting me. But I think there’s still a good chance that Spark is SRAM-resident (split across a few Cerebras chips) which is what’s driving the speedup. OpenAI’s version is much more technically impressive It’s interesting that the two major labs have two very different approaches to building fast AI inference. If I had to guess at a conspiracy theory, it would go something like this: OpenAI partner with Cerebras in mid-January, obviously to work on putting an OpenAI model on a fast Cerebras chip Anthropic have no similar play available, but they know OpenAI will announce some kind of blazing-fast inference in February, and they want to have something in the news cycle to compete with that Anthropic thus hustles to put together the kind of fast inference they can provide: simply lowering the batch size on their existing inference stack Anthropic (probably) waits until a few days before OpenAI are done with their much more complex Cerebras implementation to announce it, so it looks like OpenAI copied them Obviously OpenAI’s achievement here is more technically impressive. Getting a model running on Cerebras chips is not trivial, because they’re so weird. Training a 20B or 40B param distil of GPT-5.3-Codex that is still kind-of-good-enough is not trivial. But I commend Anthropic for finding a sneaky way to get ahead of the announcement that will be largely opaque to non-technical people. It reminds me of OpenAI’s mid-2025 sneaky introduction of the Responses API to help them conceal their reasoning tokens . Is fast AI inference the next big thing? Seeing the two major labs put out this feature might make you think that fast AI inference is the new major goal they’re chasing. I don’t think it is. If my theory above is right, Anthropic don’t care that much about fast inference, they just didn’t want to appear behind OpenAI. And OpenAI are mainly just exploring the capabilities of their new Cerebras partnership. It’s still largely an open question what kind of models can fit on these giant chips, how useful those models will be, and if the economics will make any sense. I personally don’t find “fast, less-capable inference” particularly useful. I’ve been playing around with it in Codex and I don’t like it. The usefulness of AI agents is dominated by how few mistakes they make , not by their raw speed. Buying 6x the speed at the cost of 20% more mistakes is a bad bargain, because most of the user’s time is spent handling mistakes instead of waiting for the model 6 . However, it’s certainly possible that fast, less-capable inference becomes a core lower-level primitive in AI systems. Claude Code already uses Haiku for some operations. Maybe OpenAI will end up using Spark in a similar way. edit: there are some good comments about this post on Hacker News . First, a good correction : Cerebras offers a ~355B model, GLM-4.7, at 1000 tokens per second already, so I’m wrong about Spark living in a single chip’s SRAM. Presumably they’re sharding Spark across multiple chips, like they’re doing with GLM-4.7. Many commenters disagreed with me (and each other) about the performance characteristics of batching. Some said that continuous batching means nobody ever waits for a bus, or that the volume of requests for Anthropic models means batch wait time is negligible. Other users disagreed about whether chip-to-chip communication is a bottleneck at inference time, or whether chaining chips together affects throughput. I only have a layman’s understanding of continuous batching, but it seems to me that you still have to wait for a slot to become available (even if you’re not waiting for the entire previous batch to finish), so the batch size throughput/latency tradeoff still applies. Overall, I think the takeaway is that this stuff is really complicated and hard to form a good, simple mental model around. This isn’t even factoring in latency. Anthropic explicitly warns that time to first token might still be slow (or even slower), while OpenAI thinks the Spark latency is fast enough to warrant switching to a persistent websocket (i.e. they think the 50-200ms round trip time for the handshake is a significant chunk of time to first token). ↩ Either in the form of the KV-cache for previous tokens, or as some big tensor of intermediate activations if inference is being pipelined through multiple GPUs. I write a lot more about this in Why DeepSeek is cheap at scale but expensive to run locally , since it explains why DeepSeek can be offered at such cheap prices (massive batches allow an economy of scale on giant expensive GPUs, but individual consumers can’t access that at all). ↩ Is it a contradiction that low-batch-size means low throughput, but this fast pass system gives users much greater throughput? No. The overall throughput of the GPU is much lower when some users are using “fast mode”, but those user’s throughput is much higher. ↩ Remember, GPUs are fast, but copying data onto them is not. Each “copy these weights to GPU” step is a meaningful part of the overall inference time. ↩ Or a smaller distil of whatever more powerful base model GPT-5.3-Codex was itself distilled from. I don’t know how AI labs do it exactly, and they keep it very secret. More on that here . ↩ On this note, it’s interesting to point out that Cursor’s hype dropped away basically at the same time they released their own “much faster, a little less-capable” agent model. Of course, much of this is due to Claude Code sucking up all the oxygen in the room, but having a very fast model certainly didn’t help . ↩ If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News . Here's a preview of a related post that shares tags with this one. How does AI impact skill formation? Two days ago, the Anthropic Fellows program released a paper called How AI Impacts Skill Formation . Like other papers on AI before it, this one is being treated as proof that AI makes you slower and dumber. Does it prove that? The structure of the paper is sort of similar to the 2025 MIT study Your Brain on ChatGPT . They got a group of people to perform a cognitive task that required learning a new skill: in this case, the Python Trio library. Half of those people were required to use AI and half were forbidden from using it. The researchers then quizzed those people to see how much information they retained about Trio. Continue reading... subscribe │ about │ podcasts │ popular │ tags │ rss Search seangoedecke.com Search",
      "imageUrl": "https://www.seangoedecke.com/og-image.jpg",
      "tags": [
        "LLM",
        "Inference"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：揭示Anthropic与OpenAI在LLM推理加速上的差异化策略，揭示行业核心优化路径，直接影响模型服务演进方向。",
        "热度：155 / 评论 63"
      ],
      "score": 5.64,
      "publishedAt": "2026-02-15T09:27:33+00:00",
      "authors": [
        "swah"
      ]
    },
    {
      "id": "github_openclaw_openclaw",
      "title": "openclaw/openclaw",
      "titleZh": "openclaw/openclaw",
      "titleEn": "openclaw/openclaw",
      "url": "https://github.com/openclaw/openclaw",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "OpenClaw是一个开源项目，旨在打造一个跨操作系统、跨平台的个人AI助手，强调用户数据主权与本地化运行，采用“龙虾方式”（The lobster way）作为其设计哲学，目前尚未披露具体技术细节或性能指标，但其愿景呼应了社区对去中心化、可审计AI代理日益增长的需求。",
      "summaryZh": "OpenClaw是一个开源项目，旨在打造一个跨操作系统、跨平台的个人AI助手，强调用户数据主权与本地化运行，采用“龙虾方式”（The lobster way）作为其设计哲学，目前尚未披露具体技术细节或性能指标，但其愿景呼应了社区对去中心化、可审计AI代理日益增长的需求。",
      "summaryEn": "OpenClaw is an open-source project aiming to build a personal AI assistant that runs across any OS and platform, emphasizing user data ownership and local execution under its 'lobster way' design philosophy. While technical specifics and performance metrics remain undisclosed, its vision aligns with growing community demand for decentralized, auditable AI agents.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/6bf70f0755da83fe87a474b35498316318cb0f8a47b72ee41bb8ce301f70c65f/openclaw/openclaw",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：AI代理项目在开发者社区引发热潮，具备显著技术示范意义，推动多智能体系统讨论",
        "热度：197024 / 评论 0"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-15T23:37:49.818062+00:00",
      "authors": []
    },
    {
      "id": "github_moonshine-ai_moonshine",
      "title": "moonshine-ai/moonshine",
      "titleZh": "moonshine-ai/moonshine",
      "titleEn": "moonshine-ai/moonshine",
      "url": "https://github.com/moonshine-ai/moonshine",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "Moonshine是面向边缘设备的自动语音识别（ASR）系统，主打在资源受限环境下实现高准确率与低延迟的语音转文本能力，适用于手机、IoT设备等场景，其核心优势在于模型轻量化与推理效率的平衡，为离线语音交互提供了可行方案。",
      "summaryZh": "Moonshine是面向边缘设备的自动语音识别（ASR）系统，主打在资源受限环境下实现高准确率与低延迟的语音转文本能力，适用于手机、IoT设备等场景，其核心优势在于模型轻量化与推理效率的平衡，为离线语音交互提供了可行方案。",
      "summaryEn": "Moonshine is an automatic speech recognition (ASR) system designed for edge devices, offering high accuracy and low latency in resource-constrained environments like smartphones and IoT gadgets. Its core strength lies in balancing model compactness with inference efficiency, enabling practical offline voice interaction.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/04b000d5a41ee215c48ca8957dee56464f1fc58577beb0da51c95ccf9cf6be8e/moonshine-ai/moonshine",
      "tags": [
        "Audio"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：6/10，理由：边缘设备语音识别优化项目，实用性强但属于细分领域改进，尚未形成广泛影响",
        "热度：3791 / 评论 0"
      ],
      "score": 6.6,
      "publishedAt": "2026-02-15T23:37:51.587879+00:00",
      "authors": []
    },
    {
      "id": "hn_47026071",
      "title": "Ars Technica撤回含AI伪造引述文章，重申禁用未标注AI内容政策",
      "titleZh": "Ars Technica撤回含AI伪造引述文章，重申禁用未标注AI内容政策",
      "titleEn": "Ars Technica Retracts Article with AI-Fabricated Quotes, Reaffirms Ban on Unlabeled AI Content",
      "url": "https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/",
      "type": "news",
      "source": "Hacker News",
      "summary": "Ars Technica因一篇使用AI生成虚假引述的文章而发布撤稿声明，承认违反其禁止未标注AI生成内容的编辑政策，并向被错误引用的Scott Shambaugh道歉；**该事件凸显即使资深科技媒体也面临AI滥用风险，警示所有内容创作者必须严格验证直接引语的真实性，普通读者应保持对AI辅助内容的批判性意识**。",
      "summaryZh": "Ars Technica因一篇使用AI生成虚假引述的文章而发布撤稿声明，承认违反其禁止未标注AI生成内容的编辑政策，并向被错误引用的Scott Shambaugh道歉；**该事件凸显即使资深科技媒体也面临AI滥用风险，警示所有内容创作者必须严格验证直接引语的真实性，普通读者应保持对AI辅助内容的批判性意识**。",
      "summaryEn": "Ars Technica retracted an article containing AI-generated fabricated quotes, admitting it violated its policy against publishing unlabeled AI content and apologizing to falsely quoted source Scott Shambaugh. The incident underscores that even established tech outlets are vulnerable to AI misuse, warning all creators to rigorously verify direct quotations and urging readers to maintain critical awareness of AI-assisted content.",
      "fullText": "Editor’s Note: Retraction of article containing fabricated quotations - Ars Technica Skip to content Ars Technica home Sections Forum Subscribe Search AI Biz & IT Cars Culture Gaming Health Policy Science Security Space Tech Feature Reviews AI Biz & IT Cars Culture Gaming Health Policy Science Security Space Tech Forum Subscribe Story text Size Small Standard Large Width * Standard Wide Links Standard Orange * Subscribers only Learn more Pin to story Theme HyperLight Day & Night Dark System Sign In Retraction Editor’s Note: Retraction of article containing fabricated quotations We are reinforcing our editorial standards following this incident. Ken Fisher – Feb 15, 2026 1:09 pm | 336 Text settings Story text Size Small Standard Large Width * Standard Wide Links Standard Orange * Subscribers only Learn more Minimize to nav On Friday afternoon, Ars Technica published an article containing fabricated quotations generated by an AI tool and attributed to a source who did not say them. That is a serious failure of our standards. Direct quotations must always reflect what a source actually said. That this happened at Ars is especially distressing. We have covered the risks of overreliance on AI tools for years, and our written policy reflects those concerns. In this case, fabricated quotations were published in a manner inconsistent with that policy. We have reviewed recent work and have not identified additional issues. At this time, this appears to be an isolated incident. Ars Technica does not permit the publication of AI-generated material unless it is clearly labeled and presented for demonstration purposes. That rule is not optional, and it was not followed here. We regret this failure and apologize to our readers. We have also apologized to Mr. Scott Shambaugh, who was falsely quoted. Ken Fisher Editor in Chief Ken Fisher Editor in Chief Ken is the founder & Editor-in-Chief of Ars Technica. A veteran of the IT industry and a scholar of antiquity, Ken studies the emergence of intellectual property regimes and their effects on culture and innovation. 336 Comments Comments Forum view Loading comments... Prev story Next story Most Read 1. Verizon imposes new roadblock on users trying to unlock paid-off phones 2. NASA has a new problem to fix before the next Artemis II countdown test 3. Editor’s Note: Retraction of article containing fabricated quotations 4. Why is Bezos trolling Musk on X with turtle pics? Because he has a new Moon plan. 5. Retraction: After a routine code rejection, an AI agent published a hit piece on someone by name Customize Ars Technica has been separating the signal from the noise for over 25 years. With our unique combination of technical savvy and wide-ranging interest in the technological arts and sciences, Ars is the trusted source in a sea of information. After all, you don’t need to know everything, only what’s important. More from Ars About Us Staff Directory Ars Newsletters General FAQ Posting Guidelines RSS Feeds Contact Contact us Advertise with us Reprints Manage Preferences © 2026 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Ars Technica Addendum and Your California Privacy Rights . Ars Technica may earn compensation on sales from links on this site. Read our affiliate link policy . The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices",
      "imageUrl": "https://tse1.mm.bing.net/th/id/OIP.tG7cRASM3-4Uoa_awL9ulQHaEK?w=1200&h=630&c=7&r=0&o=5&pid=1.7",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：Ars Technica因使用AI伪造引述而撤稿，暴露生成式AI在新闻伦理中的重大风险，是全球媒体信任体系的关键警示事件。",
        "热度：112 / 评论 95"
      ],
      "score": 5.9,
      "publishedAt": "2026-02-15T18:29:54+00:00",
      "authors": [
        "bikenaga"
      ]
    },
    {
      "id": "hn_47019633",
      "title": "Star collapse into a black hole without a supernova",
      "titleZh": "Star collapse into a black hole without a supernova",
      "titleEn": "Star collapse into a black hole without a supernova",
      "url": "https://www.sciencedaily.com/releases/2026/02/260213223855.htm",
      "type": "news",
      "source": "Hacker News",
      "summary": "天文学家首次详细观测到一颗位于仙女座星系的超大质量恒星（M31-2014-DS1）未经历超新星爆发而直接坍缩成黑洞的过程：**该恒星自2014年起红外增亮，2016年可见光骤暗，至2023年几乎完全消失，仅剩中红外余辉；研究证实其外层物质因对流作用缓慢抛射形成尘埃壳，而非剧烈爆炸，这为理解大质量恒星死亡机制提供了关键证据，并表明“失败超新星”可能是黑洞形成的常见路径之一**。",
      "summaryZh": "天文学家首次详细观测到一颗位于仙女座星系的超大质量恒星（M31-2014-DS1）未经历超新星爆发而直接坍缩成黑洞的过程：**该恒星自2014年起红外增亮，2016年可见光骤暗，至2023年几乎完全消失，仅剩中红外余辉；研究证实其外层物质因对流作用缓慢抛射形成尘埃壳，而非剧烈爆炸，这为理解大质量恒星死亡机制提供了关键证据，并表明“失败超新星”可能是黑洞形成的常见路径之一**。",
      "summaryEn": "Astronomers have directly observed a massive star (M31-2014-DS1) in the Andromeda Galaxy collapse into a black hole without a supernova—the first detailed case of its kind. The star brightened in infrared from 2014, dimmed sharply in visible light by 2016, and nearly vanished by 2023, leaving only a mid-infrared glow. Researchers attribute this to convective motions pushing outer layers outward to form dust, rather than a violent explosion, providing key evidence that 'failed supernovae' may be a common pathway to black hole formation.",
      "fullText": "Astronomers watch a massive star collapse into a black hole without a supernova | ScienceDaily Skip to main content Your source for the latest research news Follow: Facebook X/Twitter Subscribe: RSS Feeds Newsletter New! Sign up for our free email newsletter . Science News from research organizations Astronomers watch a massive star collapse into a black hole without a supernova A massive star in Andromeda just vanished â and left behind a newborn black hole glowing in the dark. Date: February 14, 2026 Source: Simons Foundation Summary: A massive star 2.5 million light-years away simply vanished â and astronomers now know why. Instead of exploding in a supernova, it quietly collapsed into a black hole, shedding its outer layers in a slow-motion cosmic fade-out. The leftover debris continues to glow in infrared light, offering a long-lasting signal of the black holeâs birth. The finding reshapes our understanding of how some of the universeâs biggest stars meet their end. Share: Facebook Twitter Pinterest LinkedIN Email FULL STORY An illustration of a star that collapsed, forming a black hole. The black hole is at the center, unseen. Surrounding it is a dust shell moving away from the black hole and gas being pulled toward it. Credit: Keith Miller, Caltech/IPAC - SELab Astronomers have directly observed a massive dying star skip a supernova explosion and instead collapse into a black hole. This event provides the most detailed set of observations ever assembled of a star making that transition, giving researchers an unusually complete view of how stellar black holes form. By combining fresh telescope data with more than a decade of archived observations, scientists were able to test and refine long standing theories about how the most massive stars end their lives. Rather than exploding outward in a brilliant supernova, this star's core gave way under gravity and formed a black hole. In the process, its unstable outer layers were gradually pushed outward. The findings, published February 12 in Science , are drawing attention because they offer a rare look at the birth of a black hole. The results may help explain why some massive stars explode dramatically at the end of their lives, while others collapse quietly. \"This is just the beginning of the story,\" says Kishalay De, an associate research scientist at the Simons Foundation's Flatiron Institute and lead author on the new study. Light from dusty debris surrounding the newborn black hole, he says, \"is going to be visible for decades at the sensitivity level of telescopes like the James Webb Space Telescope, because it's going to continue to fade very slowly. And this may end up being a benchmark for understanding how stellar black holes form in the universe.\" The Disappearance of M31-2014-DS1 in Andromeda The star, known as M31-2014-DS1, was located about 2.5 million light-years away in the Andromeda Galaxy. De and colleagues examined data collected between 2005 and 2023 from NASA's NEOWISE mission along with other ground and space telescopes. They discovered that the star began brightening in infrared light in 2014. Then in 2016, its brightness dropped sharply in less than a year. By 2022 and 2023, the star had nearly vanished in visible and near-infrared wavelengths, fading to just one ten-thousandth of its former brightness in those bands. What remains can now only be detected in mid-infrared light, where it glows at roughly one-tenth of its original intensity. De says, \"This star used to be one of the most luminous stars in the Andromeda Galaxy, and now it was nowhere to be seen. Imagine if the star Betelgeuse suddenly disappeared. Everybody would lose their minds! The same kind of thing [was] happening with this star in the Andromeda Galaxy.\" When the team compared the observations with theoretical predictions, they concluded that such an extreme drop in brightness strongly indicates that the star's core collapsed and formed a black hole. Why Some Massive Stars Fail to Explode Stars shine because nuclear fusion in their cores converts hydrogen into helium, creating outward pressure that counteracts gravity. In stars at least 10 times more massive than our sun, this balance eventually breaks down when nuclear fuel runs low. Gravity then overwhelms the outward pressure, causing the core to collapse and form a dense neutron star. In many cases, a flood of neutrinos released during this collapse generates a powerful shock wave that tears the star apart in a supernova. But if that shock wave is too weak to eject the surrounding material, much of the star can fall back inward. Theoretical models have long suggested that this fallback can turn the neutron star into a black hole. \"We've known for almost 50 years now that black holes exist,\" says De, \"yet we are barely scratching the surface of understanding which stars turn into black holes and how they do it.\" The Key Role of Convection The detailed study of M31-2014-DS1 also helped researchers revisit a similar object, NGC 6946-BH1, which had been identified a decade earlier. Reanalyzing both cases revealed a crucial missing ingredient in understanding what happens to a star's outer layers after a failed supernova. The answer lies in convection. Convection arises from large temperature differences inside a star. The core is extremely hot, while the outer layers are much cooler. This contrast drives gas to circulate between hotter and cooler regions. When the core collapses, the outer gas is still in motion because of this churning process. According to models developed at the Flatiron Institute, that motion prevents most of the outer material from plunging straight into the black hole. Instead, some inner layers circle the black hole, while the outermost layers are pushed outward. As the expelled material travels away, it cools. At lower temperatures, atoms and molecules combine to form dust. That dust blocks light from the hotter gas closer to the black hole, absorbs energy, and reemits it in infrared wavelengths. The result is a lingering reddish glow that can last for decades after the original star has disappeared. Co-author and Flatiron Research Fellow Andrea Antoni developed the theoretical framework behind these convection models. Drawing on the new observations, she says, \"the accretion rate -- the rate of material falling in -- is much slower than if the star imploded directly in. This convective material has angular momentum, so it circularizes around the black hole. Instead of taking months or a year to fall in, it's taking decades. And because of all this, it becomes a brighter source than it would be otherwise, and we observe a long delay in the dimming of the original star.\" Much like water spiraling down a drain rather than dropping straight through, gas continues orbiting the newly formed black hole as gravity gradually pulls it inward. This delayed infall means the entire star does not collapse all at once. Even after the core quickly gives way, some material falls back slowly over many decades. Researchers estimate that only about one percent of the star's original outer envelope ultimately feeds the black hole, producing the faint light still observed today. Building a Bigger Picture of Black Hole Formation As they analyzed M31-2014-DS1, the team also reexamined NGC 6946-BH1. The new study provides strong evidence that both stars followed a similar path. What first seemed like an unusual case now appears to be part of a broader category of failed supernovae that quietly produce black holes. M31-2014-DS1 initially stood out as an \"oddball,\" De says, but it now seems to be one of several examples, including NGC 6946-BH1. \"It's only with these individual jewels of discovery that we start putting together a picture like this,\" De says. RELATED TOPICS Space & Time Space Exploration NASA Space Telescopes Galaxies Stars Black Holes Astrophysics Space Missions RELATED TERMS Big Bang Supernova Astronomy Edwin Hubble Cosmic microwave background radiation Large-scale structure of the cosmos Star Trek Spitzer space telescope Story Source: Materials provided by Simons Foundation . Note: Content may be edited for style and length. Related Multimedia : Star Collapse Black Hole Animation Journal Reference : Kishalay De, Morgan MacLeod, Jacob E. Jencson, Elizabeth Lovegrove, Andrea Antoni, Erin Kara, Mansi M. Kasliwal, Ryan M. Lau, Abraham Loeb, Megan Masterson, Aaron M. Meisner, Christos Panagiotou, Eliot Quataert, Robert Simcoe. Disappearance of a massive star in the Andromeda Galaxy due to formation of a black hole . Science , 2026; 391 (6786): 689 DOI: 10.1126/science.adt4853 Cite This Page : MLA APA Chicago Simons Foundation. \"Astronomers watch a massive star collapse into a black hole without a supernova.\" ScienceDaily. ScienceDaily, 14 February 2026. <www.sciencedaily.com / releases / 2026 / 02 / 260213223855.htm>. Simons Foundation. (2026, February 14). Astronomers watch a massive star collapse into a black hole without a supernova. ScienceDaily . Retrieved February 15, 2026 from www.sciencedaily.com / releases / 2026 / 02 / 260213223855.htm Simons Foundation. \"Astronomers watch a massive star collapse into a black hole without a supernova.\" ScienceDaily. www.sciencedaily.com / releases / 2026 / 02 / 260213223855.htm (accessed February 15, 2026). Explore More from ScienceDaily RELATED STORIES Fresh Wind Blows from Historical Supernova July 5, 2024 Â A mysterious remnant from a rare type of supernova recorded in 1181 has been explained for the first time. Two white dwarf stars collided, creating a temporary 'guest star,' now labeled ... Webb Finds Evidence for Neutron Star at Heart of Young Supernova Remnant Feb. 22, 2024 Â NASA's James Webb Space Telescope has found the best evidence yet for emission from a neutron star at the site of a recently observed supernova. The supernova, known as SN 1987A, was a ... Dwarf Galaxies Use 10-Million-Year Quiet Period to Churn out Stars Nov. 21, 2023 Â If you look at massive galaxies teeming with stars, you might be forgiven in thinking they are star factories, churning out brilliant balls of gas. But actually, less evolved dwarf galaxies have ... A Star's Unexpected Survival Jan. 13, 2023 Â Hundreds of millions of light-years away in a distant galaxy, a star orbiting a supermassive black hole is being violently ripped apart under the black hole's immense gravitational pull. As the ... Hubble Finds Spiraling Stars, Providing Window Into Early Universe Sep. 8, 2022 Â Stars are the machines that sculpt the universe, yet scientists don't fully know how they form. To understand the frenzied 'baby boom' of star birth that occurred early in the ... Hubble Reveals Surviving Companion Star in Aftermath of Supernova May 5, 2022 Â It's not unheard of to find a surviving star at the scene of a titanic supernova explosion, which would be expected to obliterate everything around it, but new research has provided a ... TRENDING AT SCITECHDAILY.com Golden Experiment Reveals the Invisible Forces Holding the Universe Together This Surprising High-Fat Diet Helped Brains Heal From Stress Before Birth AI-Designed Obesity Drug Delivers Over 31% Weight Loss in Preclinical Tests Scientists Finally Solve the Mystery Behind Rare COVID Vaccine Blood Clots Â Print Â Email Â Share Breaking this hour Why Some Kids Struggle With Math AI Maps Gene Networks in Alzheimerâs Nerves Actively Fuel Pancreatic Cancer Scientists Can Trace Where Rain Comes From Scientists Found a Way to Plant Ideas in Dreams How Psychedelics Trigger Hallucinations Most Statin Side Effects Not Proven Male Birth Control Breakthrough Pets Are Helping an Invasive Flatworm Spread Couples Who Savor Stay Together Trending Topics this week SPACE & TIME Space Telescopes NASA Galaxies MATTER & ENERGY Graphene Spintronics Energy and Resources COMPUTERS & MATH Computer Modeling Computer Programming Neural Interfaces Strange & Offbeat Â SPACE & TIME Ramanujanâs 100-Year-Old",
      "imageUrl": "https://www.sciencedaily.com/images/1920/star-collapse-black-hole.webp",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：首次观测到恒星无超新星爆发直接坍缩成黑洞，改写天体物理认知，具有重大科学突破意义。",
        "热度：42 / 评论 3"
      ],
      "score": 5.64,
      "publishedAt": "2026-02-14T23:49:09+00:00",
      "authors": [
        "wglb"
      ]
    },
    {
      "id": "hn_47028013",
      "title": "OpenClaw创始人加入OpenAI，推动易用AI代理开发",
      "titleZh": "OpenClaw创始人加入OpenAI，推动易用AI代理开发",
      "titleEn": "OpenClaw Creator Joins OpenAI to Build Accessible AI Agents",
      "url": "https://steipete.me/posts/2026/openclaw",
      "type": "news",
      "source": "Hacker News",
      "summary": "OpenClaw项目创始人Peter Steinberger宣布加入OpenAI，将致力于开发“连他母亲都能使用的AI代理”；**他同时承诺将OpenClaw移交至独立基金会以保持开源与中立，并获得OpenAI赞助继续支持多模型生态**。此举反映顶尖开发者正通过与大模型实验室合作加速通用AI代理落地，普通用户未来或能更便捷地使用安全、易用的个人AI助手，但也需关注开源项目在商业合作中的独立性维护。",
      "summaryZh": "OpenClaw项目创始人Peter Steinberger宣布加入OpenAI，将致力于开发“连他母亲都能使用的AI代理”；**他同时承诺将OpenClaw移交至独立基金会以保持开源与中立，并获得OpenAI赞助继续支持多模型生态**。此举反映顶尖开发者正通过与大模型实验室合作加速通用AI代理落地，普通用户未来或能更便捷地使用安全、易用的个人AI助手，但也需关注开源项目在商业合作中的独立性维护。",
      "summaryEn": "Peter Steinberger, creator of the OpenClaw AI assistant project, announced he is joining OpenAI to build universally accessible AI agents—even for his mother—while transitioning OpenClaw to an independent foundation to preserve its open-source and neutral nature, with continued sponsorship from OpenAI. This move reflects how top builders are partnering with leading labs to accelerate practical AI agent deployment, potentially giving everyday users easier access to safe, user-friendly assistants, though vigilance is needed to ensure open projects retain independence amid corporate backing.",
      "fullText": "OpenClaw, OpenAI and the future | Peter Steinberger Skip to content Peter Steinberger Posts About Search OpenClaw, OpenAI and the future Published: 14 Feb, 2026 • 3 min read | Edit on GitHub tl;dr: I’m joining OpenAI to work on bringing agents to everyone. OpenClaw will move to a foundation and stay open and independent. The last month was a whirlwind, never would I have expected that my playground project would create such waves. The internet got weird again, and it’s been incredibly fun to see how my work inspired so many people around the world. There’s an endless array of possibilities that opened up for me, countless people trying to push me into various directions, giving me advice, asking how they can invest or what I will do. Saying it’s overwhelming is an understatement. When I started exploring AI, my goal was to have fun and inspire people. And here we are, the lobster is taking over the world. My next mission is to build an agent that even my mum can use. That’ll need a much broader change, a lot more thought on how to do it safely, and access to the very latest models and research. Yes, I could totally see how OpenClaw could become a huge company. And no, it’s not really exciting for me. I’m a builder at heart. I did the whole creating-a-company game already, poured 13 years of my life into it and learned a lot. What I want is to change the world, not build a large company and teaming up with OpenAI is the fastest way to bring this to everyone. I spent last week in San Francisco talking with the major labs, getting access to people and unreleased research, and it’s been inspiring on all fronts. I want to thank all the folks I talked to this week and am thankful for the opportunities. It’s always been important to me that OpenClaw stays open source and given the freedom to flourish. Ultimately, I felt OpenAI was the best place to continue pushing on my vision and expand its reach. The more I talked with the people there, the clearer it became that we both share the same vision. The community around OpenClaw is something magical and OpenAI has made strong commitments to enable me to dedicate my time to it and already sponsors the project. To get this into a proper structure I’m working on making it a foundation. It will stay a place for thinkers, hackers and people that want a way to own their data, with the goal of supporting even more models and companies. Personally I’m super excited to join OpenAI, be part of the frontier of AI research and development, and continue building with all of you. The claw is the law. New posts, shipping stories, and nerdy links straight to your inbox. Subscribe 2× per month, pure signal, zero fluff. | Edit on GitHub ai openai openclaw agents Share this post on: Share this post on X Share this post on BlueSky Share this post on LinkedIn Share this post via WhatsApp Share this post on Facebook Share this post via Telegram Share this post on Pinterest Share this post via email Back to Top Next Post Shipping at Inference-Speed Peter Steinberger on Github Peter Steinberger on X Peter Steinberger on BlueSky Peter Steinberger on LinkedIn Send an email to Peter Steinberger Steal this post ➜ CC BY 4.0 · Code MIT",
      "imageUrl": "https://steipete.me/posts/2026/openclaw/index.png",
      "tags": [
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：作者为知名AI开源项目OpenClaw创始人，宣布加入OpenAI并聚焦通用智能体开发，具有显著行业影响力和未来技术方向指引意义。",
        "热度：291 / 评论 204"
      ],
      "score": 5.53,
      "publishedAt": "2026-02-15T21:54:15+00:00",
      "authors": [
        "mfiguiere"
      ]
    },
    {
      "id": "hn_47025188",
      "title": "Palantir起诉瑞士《Republik》杂志，要求强制更正涉其游说活动报道",
      "titleZh": "Palantir起诉瑞士《Republik》杂志，要求强制更正涉其游说活动报道",
      "titleEn": "Palantir Sues Swiss Magazine Republik Over Reporting on Its Government Lobbying",
      "url": "https://www.heise.de/en/news/Palantir-vs-the-Republik-US-analytics-firm-takes-magazine-to-court-11176508.html",
      "type": "news",
      "source": "Hacker News",
      "summary": "美国数据分析公司Palantir因不满瑞士杂志《Republik》对其在瑞士军警及卫生部门游说活动的报道，向苏黎世商事法院提起诉讼，要求强制发布更正声明；**尽管Palantir称报道含“重大不实信息”，但未公开具体细节，而《Republik》坚称其基于政府文件进行严谨调查，事件已引发欧洲公众对科技巨头利用法律手段压制批评的担忧，并凸显Palantir在拓展欧洲市场时面临的信任挑战**。",
      "summaryZh": "美国数据分析公司Palantir因不满瑞士杂志《Republik》对其在瑞士军警及卫生部门游说活动的报道，向苏黎世商事法院提起诉讼，要求强制发布更正声明；**尽管Palantir称报道含“重大不实信息”，但未公开具体细节，而《Republik》坚称其基于政府文件进行严谨调查，事件已引发欧洲公众对科技巨头利用法律手段压制批评的担忧，并凸显Palantir在拓展欧洲市场时面临的信任挑战**。",
      "summaryEn": "U.S. analytics firm Palantir has sued Swiss magazine Republik in Zurich’s Commercial Court, demanding a legally mandated correction statement over reports detailing its lobbying efforts with Swiss military, police, and health authorities. While Palantir claims 'significant inaccuracies' without specifying them, Republik defends its reporting as based on official government documents. The case has sparked concerns in Europe about tech giants using legal pressure to silence criticism and highlights Palantir’s ongoing trust challenges in expanding its European footprint.",
      "fullText": "Palantir vs. the \"Republik\": US analytics firm takes magazine to court | heise online heise+ entdecken Suchen Abo Suchen Alle Magazine im Browser lesen IT News Newsticker Hintergründe Ratgeber Testberichte Meinungen Online-Magazine heise + Telepolis heise autos bestenlisten tipps+tricks Services heise shop heise jobs heise academy heise download heise preisvergleich Tarifrechner heise compaliate Abo bestellen Mein Abo Netzwerktools iMonitor Loseblattwerke Spiele Über uns heise medien heise regioconcept heise business services Sponsoring Mediadaten Karriere Presse Anzeige Special: Zusammen das Datacenter weiterentwickeln Secure IT für Unternehmen Newsletter heise-Bot Push -Nachrichten Newsticker Security IT & Tech Developer KI Entertainment Wissenschaft Bestenlisten Digital Health Foren Alle Themen Anzeige Special: Zusammen das Datacenter weiterentwickeln Secure IT für Unternehmen Advertisement Palantir vs. the \"Republik\": US analytics firm takes magazine to court Data analysis provider Palantir wants to obtain a counterstatement in court – and triggers a wave of solidarity for a small Swiss magazine. listen Print view Palantir objects to \"significant inaccuracies\" in the reporting of the magazine \"Republik\". (Image: Screenhot/heise medien) Feb 13, 2026 at 9:49 pm CET 7 min. read By Falk Steiner Advertisement Contents Palantir vs. the \"Republik\": US analytics firm takes magazine to court Streisand Effect Swiss Counterstatements Difficult Terrain Europe \"Borderline Conspiracy Theories\" Palantir Rejects Accusation of Intimidation Palantir Technologies, the US provider of analytics software, finds itself directly affected by two reports from the Swiss online magazine \"Republik\". After the company unsuccessfully demanded a counterstatement from the magazine, it now wants to enforce one through legal action. It's about a factual comparison, says the software provider. The \"Republik\" creators appear surprised. Continue after ad Streisand Effect With the step to court, Palantir has generated more attention for the \"Republik\" reporting than the objected articles themselves could have caused – 23 years after Barbra Streisand triggered the effect named after her . And yet, there are reasons why Palantir is acting this way. While in Germany the provider of data linking and data analysis software for authorities with surveillance powers is successful with at least some state customers. The company has so far had – as far as is known – little state clientele in Switzerland. In December, \"Republik\" extensively quoted from Swiss administration files . According to this, Palantir repeatedly sought contact with Swiss authorities – and found it. In some cases, it originated from Palantir, in others, likely from public bodies. The matters concerned the military, police, and health authorities. However, no business deal was apparently concluded. Palantir feels unfairly treated by the reporting on this. \"We can confirm that an application for a counterstatement has been filed with the Commercial Court in this matter,\" the communications officer of the Cantonal High Court told heise online on Friday upon request. Swiss Counterstatements Swiss law provides for counterstatements, meaning that as soon as a request for a counterstatement has been rejected by a medium, a civil court can examine the matter and hear both sides. The Commercial Court of Zurich is responsible here. The Commercial Court of Zurich is responsible here. Continue after ad Palantir says it had to sue to uphold its legal claim. \"Palantir fully respects press freedom and the essential role of independent media in public debate,\" said a company spokeswoman. The right to a counterstatement is a \"correction instrument intended to provide the public with balanced information.\" For Palantir, the \"Republik\" reporting came at an inopportune time. This is because important procurement decisions are currently being made in several business areas in many European countries: the modernization and expansion of military, intelligence, and secret services, as well as police authorities, would be a promising business for Palantir and its software, which is also helpful for official surveillance. In its home market, the USA, the company does business with US federal authorities for about a quarter of a billion US dollars, according to transparency data approximately a quarter of a billion US dollars . Customers include the US Department of Defense, the Army, and the FBI. The company reports nearly 4.5 billion US dollars in revenue for 2025, about a tenth of SAP's annual revenue. And yet, Palantir is valued on the stock market at around 300 billion euros, while SAP comes in at around 200 billion. Difficult Terrain Europe The European market remains difficult terrain for Palantir. The connection to the Immigration and Customs Enforcement agency (ICE), which is supposed to track down illegal migrants with brutal methods and a lot of high-tech , causes consternation in Europe. As a US company, Palantir is subject to US law, which increasingly questions international cooperation in security matters – this is unlikely to be conducive to sales for Palantir. Meanwhile, the uproar had just subsided elsewhere: Palantir was criticized for its involvement in Israel. Founders Peter Thiel and Alex Karp had agreed to a strategic partnership with the Israeli Ministry of Defense in January 2024, Bloomberg reported at the time. The report on this is publicly available on the Palantir website . The small medium from Switzerland is hardly comparable to industry giants like Bloomberg. It has been published ad-free and exclusively online since 2018. It is primarily supported by a good 30,000 subscribers, a majority of whom are also cooperative members with voting rights. Not a media behemoth with a large publisher behind it. \"Borderline Conspiracy Theories\" Shortly after the publication of the two articles now being heard in court, Courtney Bowman, head of Palantir's \"Privacy and Civil Liberties\" department, had already set the course on LinkedIn: The reports from \"Republik\" were \"full of distortions, insinuations, and borderline conspiracy theories.\" Bowman accuses the authors of having reproduced a report from the Swiss Army Staff too uncritically – whose authors, unfortunately, had \"relied on a limited set of search engine hit sources.\" The Palantir representative, in turn, provided no evidence for his claims. \"I believe we have done excellent research and documented it very comprehensively,\" says Daniel Binswanger, co-editor-in-chief of \"Republik,\" in an interview with heise online. Research based on Swiss government documents is one of the \"best foundations for reporting.\" He is very confident about the outcome of the proceedings. Videos by heise mehr Videos c't 3003 heise & ct Peertube Palantir Rejects Accusation of Intimidation Palantir strongly rejects the impression that a multi-billion dollar company is flexing its muscles against a small magazine: Any accusation that this is a strategic attempt to intimidate unfavorable reporting through legal action is unfounded, the company spokeswoman emphasizes: \"Palantir merely seeks the publication of a concise and appropriate counterstatement to correct significant inaccuracies.\" However, the company does not disclose what specific \"significant inaccuracies\" Palantir wants to see corrected. Palantir did not respond to a request to send the \"corrections\" specifically demanded by \"Republik\" by Friday afternoon. Whether the company will achieve at least partial success with its approach in court is hardly predictable. The Swiss right to a counterstatement involves no examination by the court whether a statement was actually correct. This is why it is a frequently used form in the Swiss media world when companies feel they have been misrepresented. \"The right to a counterstatement is not about whether something is true or false,\" explains \"Republik\" co-editor-in-chief Daniel Binswanger. \"It's about whether another version of the facts could also be possible.\" However, this only concerns factual representation. Opinions, on the other hand, are not challengeable in Switzerland either. For the Swiss online magazine, however, the effect is noticeable and measurable. \"We are overwhelmed,\" says Daniel Binswanger in an interview with heise online. \"The offers of donations, expressions of solidarity – it's gigantic,\" he says. \"We've never experienced a story triggering this.\" Ms. Streisand sends her regards. ( vbr ) Don't miss any news – follow us on Facebook , LinkedIn or Mastodon . This article was originally published in German . It was translated with technical assistance and editorially reviewed before publication. Dieser Link ist leider nicht mehr gültig. Links zu verschenkten Artikeln werden ungültig, wenn diese älter als 7 Tage sind oder zu oft aufgerufen wurden. Sie benötigen ein heise+ Paket, um diesen Artikel zu lesen. Jetzt eine Woche unverbindlich testen – ohne Verpflichtung! Wochenpass bestellen Sie haben heise+ bereits abonniert? Hier anmelden. Oder benötigen Sie mehr Informationen zum heise+ Abo Home Anzeige Advertisement Welches Tool passt zu meiner Webanalyse? Sichere Arbeitsumgebung direkt im Browser Themenspecial: Digitale Souveränität Als WiFi-Dienstleister zur eigenen Marke werden Souveräne Kontrolle bei Endgeräten behalten Special: Zusammen das Datacenter weiterentwickeln Bezahlbare Cyber-Sicherheit für den Mittelstand Share this article Shortlink: https://heise.de/-11176508 Beliebte Bestenlisten Alle bestenlisten Top 10: Wärmebildkamera für das Handy im Test bestenlisten Top 10: Die beste Gaming-Tastatur im Test bestenlisten Top 10: Das beste E-Bike für Damen & Herren im Test bestenlisten Alle bestenlisten Advertisement Advertisement Alle Angebote IT News Newsticker Hintergründe Ratgeber Tests Meinungen Online-Magazine heise + Telepolis heise autos bestenlisten tipps+tricks Services heise shop heise jobs heise academy heise download heise preisvergleich Tarifrechner heise compaliate Abo bestellen Mein Abo Netzwerktools iMonitor Loseblattwerke Spiele Über Uns heise medien heise regioconcept heise business services Sponsoring Mediadaten Karriere Presse Newsletter heise-Bot heise-Bot Push Nachrichten Push Push-Nachrichten Back to top Kontakt Impressum Barriere melden Verträge kündigen Cookies & Tracking Datenschutz Mediadaten 5027771 Content Management by InterRed Hosted by Plus.line Copyright © 2025 heise medien heise Logo Eine Antwort weiter kopieren",
      "imageUrl": "https://heise.cloudimg.io/bound/1200x1200/q85.png-lossy-85.webp-lossy-85.foil1/_www-heise-de_/imgs/18/5/0/2/7/7/7/1/Screenshot_2026-02-13_at_19.57.24-85c7b3432095e315.png",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：Palantir起诉瑞士杂志引发关于数据公司法律边界与媒体独立性的全球关注，反映AI企业权力扩张带来的制度挑战。",
        "热度：188 / 评论 62"
      ],
      "score": 5.3,
      "publishedAt": "2026-02-15T16:51:17+00:00",
      "authors": [
        "cdrnsf"
      ]
    },
    {
      "id": "rss_3662304309",
      "title": "NPR前主播David Greene起诉Google NotebookLM语音侵权",
      "titleZh": "NPR前主播David Greene起诉Google NotebookLM语音侵权",
      "titleEn": "Former NPR Host David Greene Sues Google Over NotebookLM Voice Clone",
      "url": "https://techcrunch.com/2026/02/15/longtime-npr-host-david-greene-sues-google-over-notebooklm-voice/",
      "type": "news",
      "source": "TechCrunch AI",
      "summary": "前NPR《Morning Edition》长期主持人David Greene起诉Google，指控其AI工具NotebookLM中的男性播客语音高度模仿其语调、节奏及口头禅（如“uh”），在亲友多次指出相似性后，Greene认为该声音侵犯其声音权；Google回应称该语音由公司聘请的专业配音演员录制，与Greene无关。此案延续了AI语音模仿真实人物引发的法律争议（如Scarlett Johansson诉OpenAI事件），凸显生成式AI在训练数据来源与人格权保护上的模糊边界，普通用户在使用AI生成内容时应警惕潜在侵权风险，并关注平台对声音来源的透明度说明。",
      "summaryZh": "前NPR《Morning Edition》长期主持人David Greene起诉Google，指控其AI工具NotebookLM中的男性播客语音高度模仿其语调、节奏及口头禅（如“uh”），在亲友多次指出相似性后，Greene认为该声音侵犯其声音权；Google回应称该语音由公司聘请的专业配音演员录制，与Greene无关。此案延续了AI语音模仿真实人物引发的法律争议（如Scarlett Johansson诉OpenAI事件），凸显生成式AI在训练数据来源与人格权保护上的模糊边界，普通用户在使用AI生成内容时应警惕潜在侵权风险，并关注平台对声音来源的透明度说明。",
      "summaryEn": "David Greene, longtime host of NPR’s “Morning Edition,” is suing Google, alleging that the male podcast voice in its NotebookLM AI tool closely mimics his speech patterns, cadence, and filler words like “uh”—a resemblance first flagged by friends and colleagues. Google denies the claim, stating the voice was performed by a paid professional actor. This case follows similar disputes, such as Scarlett Johansson’s complaint against OpenAI, highlighting ongoing legal uncertainties around voice cloning, data sourcing, and personality rights in generative AI. Users should remain cautious about potential copyright or likeness violations when using AI-generated audio and demand clearer transparency from platforms on voice origins.",
      "fullText": "Longtime NPR host David Greene sues Google over NotebookLM voice | TechCrunch TechCrunch Desktop Logo TechCrunch Mobile Logo Latest Startups Venture Apple Security AI Apps Events Podcasts Newsletters Search Submit Site Search Toggle Mega Menu Toggle Topics Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture More from TechCrunch Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us In Brief Posted: 2:07 PM PST · February 15, 2026 Image Credits: RamKay (opens in a new window) / Getty Images Anthony Ha Longtime NPR host David Greene sues Google over NotebookLM voice David Greene, the longtime host of NPR’s “Morning Edition,” is suing Google, alleging that the male podcast voice in the company’s NotebookLM tool is based on Greene, according to The Washington Post . Greene said that after friends, family members, and coworkers began emailing him about the resemblance, he became convinced that the voice was replicating his cadence, intonation, and use of filler words like “uh.” “My voice is, like, the most important part of who I am,” said Greene, who currently hosts the KCRW show “Left, Right, & Center.” Among other features, Google’s NotebookLM allows users to generate a podcast with AI hosts . A company spokesperson told the Post that the voice used in this product is unrelated to Greene’s: “The sound of the male voice in NotebookLM’s Audio Overviews is based on a paid professional actor Google hired.” This isn’t the first dispute over AI voices resembling real people. In one notable example, OpenAI removed a ChatGPT voice after actress Scarlett Johansson complained that it was an imitation of her own. Topics AI , david greene , Media & Entertainment , notebooklm October 13-15 San Francisco, CA Tickets are live at the lowest rates of the year. Save up to $680 on your pass now. Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders , dive into 200+ sessions , and explore 300+ startups building what’s next. Don’t miss these one-time savings. REGISTER NOW Newsletters See More Subscribe for the industry’s biggest tech news TechCrunch Daily News Every weekday and Sunday, you can get the best of TechCrunch’s coverage. TechCrunch Mobility TechCrunch Mobility is your destination for transportation news and insight. Startups Weekly Startups are the core of TechCrunch, so get our best coverage delivered weekly. StrictlyVC Provides movers and shakers with the info they need to start their day. No newsletters selected. Subscribe By submitting your email, you agree to our Terms and Privacy Notice . Related Startups What the Epstein files reveal about EV startups and Silicon Valley Anthony Ha 7 hours ago Media & Entertainment Hollywood isn’t happy about the new Seedance 2.0 video generator Anthony Ha 8 hours ago Apps Airbnb plans to bake in AI features for search, discovery and support Ivan Mehta 2 days ago Latest in AI In Brief OpenClaw creator Peter Steinberger joins OpenAI Anthony Ha 1 hour ago In Brief Longtime NPR host David Greene sues Google over NotebookLM voice Anthony Ha 2 hours ago In Brief Anthropic and the Pentagon are reportedly arguing over Claude usage Anthony Ha 2 hours ago X LinkedIn Facebook Instagram youTube Mastodon Threads Bluesky TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Terms of Service Privacy Policy RSS Terms of Use Code of Conduct Epstein Kindle Scribe Reddit TikTok GPT-4o Tech Layoffs ChatGPT © 2025 TechCrunch Media LLC.",
      "imageUrl": "https://techcrunch.com/wp-content/uploads/2020/05/GettyImages-837551280.jpg?resize=1200%2C630",
      "tags": [
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：TechCrunch AI",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：知名主持人起诉Google声音克隆侵权，引发AI生成内容伦理与法律边界讨论，具有广泛行业警示意义",
        "热度：0 / 评论 0"
      ],
      "score": 5.3,
      "publishedAt": "2026-02-15T22:07:51+00:00",
      "authors": [
        "Anthony Ha"
      ]
    }
  ],
  "stats": {
    "total_papers_ingested": 20,
    "total_news_ingested": 39,
    "l1_papers_passed": 20,
    "l1_news_passed": 34,
    "l2_papers_scored": 18,
    "l2_news_scored": 19,
    "l3_papers_selected": 6,
    "l3_news_selected": 11,
    "news_source_counts": {
      "Hacker News": 22,
      "GitHub Trending": 7,
      "TechCrunch AI": 7,
      "The Verge AI": 3
    },
    "rss_source_counts": {
      "TechCrunch AI": 7,
      "The Verge AI": 3
    },
    "news_title_source_counts": {
      "i m joining openai": 1,
      "radio host david greene says google s notebooklm tool stole his voice": 1,
      "show hn microgpt is a gpt you can visualize in the browser": 1,
      "show hn klaw sh kubernetes for ai agents": 1,
      "gwtar a static efficient single file html format": 1,
      "two different tricks for fast llm inference": 1,
      "editor s note retraction of article containing fabricated quotations": 1,
      "oat ultra lightweight zero dependency semantic html css js ui library": 1,
      "palantir vs the republik us analytics firm takes magazine to court": 1,
      "i need ai that scans every pr and issue and de dupes": 1,
      "i love the work of the archwiki maintainers": 1,
      "ai is going to kill app subscriptions": 1,
      "openclaw clawdbot joins openai": 1,
      "openai acquires openclaw": 1,
      "state attorneys general want to tie online access to id": 1,
      "guitars of the ussr and the jolana special in azerbaijani music 2012": 1,
      "scientists observe a 300m year old brain rhythm in several animal species": 1,
      "western digital sells out 2026 hdd capacity as ai demand pushes prices higher": 1,
      "michael abrash doubled quake framerste": 1,
      "dutch defence secretary boldly claims f 35 software could be jailbroken": 1,
      "star collapse into a black hole without a supernova": 1,
      "linear representations and superposition": 1,
      "steipete gogcli": 1,
      "rowboatlabs rowboat": 1,
      "github gh aw": 1,
      "chromedevtools chrome devtools mcp": 1,
      "openclaw openclaw": 1,
      "moonshine ai moonshine": 1,
      "synkraai aios core": 1,
      "openclaw founder peter steinberger is joining openai": 1,
      "i hate my ai pet with every fiber of my being": 1,
      "ai can t make good video game worlds yet and it might never be able to": 1,
      "openclaw creator peter steinberger joins openai": 1,
      "longtime npr host david greene sues google over notebooklm voice": 1,
      "anthropic and the pentagon are reportedly arguing over claude usage": 1,
      "india has 100m weekly active chatgpt users sam altman says": 1,
      "the enterprise ai land grab is on glean is building the layer beneath the interface": 1,
      "hollywood isn t happy about the new seedance 2 0 video generator": 1,
      "the great computer science exodus and where students are going instead": 1
    },
    "total_papers_deduped": 20,
    "total_news_deduped": 39,
    "news_recent_filtered": 39
  }
}