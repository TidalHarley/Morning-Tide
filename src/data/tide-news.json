{
  "date": "2026-02-20",
  "generatedAt": "2026-02-20T23:48:00.127412",
  "introduction": "今日AI领域迎来多项关键突破：谷歌发布时序基础模型TimesFM，显著提升预测能力；OpenAI首次公开其在高难度数学证明挑战中的尝试，展现前沿推理水平。论文方面，EA-Swin为Sora等生成视频提供高效检测方案，M2F实现大规模数学文献自动形式化，AutoNumerics构建PDE无关的多智能体科学计算框架。安全研究揭示AI代理在工具调用中的新型风险，而医疗AI则通过颈动脉超声精准识别血管损伤。此外，印度AI生态获巨额投资，但AI硬件落地与能源消耗问题也引发关注。",
  "introductionZh": "今日AI领域迎来多项关键突破：谷歌发布时序基础模型TimesFM，显著提升预测能力；OpenAI首次公开其在高难度数学证明挑战中的尝试，展现前沿推理水平。论文方面，EA-Swin为Sora等生成视频提供高效检测方案，M2F实现大规模数学文献自动形式化，AutoNumerics构建PDE无关的多智能体科学计算框架。安全研究揭示AI代理在工具调用中的新型风险，而医疗AI则通过颈动脉超声精准识别血管损伤。此外，印度AI生态获巨额投资，但AI硬件落地与能源消耗问题也引发关注。",
  "introductionEn": "Today’s AI breakthroughs span foundational models, safety, and real-world impact. Google released TimesFM, a time-series foundation model for forecasting; OpenAI shared its first attempts at expert-level mathematical proofs. Key papers include EA-Swin for detecting Sora-like AI videos, M2F for large-scale math formalization, and AutoNumerics for PDE-agnostic scientific computing. New research exposes critical gaps in agent safety during tool use, while medical AI demonstrates life-saving potential via carotid ultrasound analysis. Meanwhile, major investments flow into India’s AI ecosystem, even as hardware rollouts and energy demands raise sustainability concerns.",
  "longformScript": "今天，AI 领域的进展呈现出一种微妙的张力：一边是模型能力、工具生态和应用场景的快速扩张，另一边则是对能源消耗、安全边界和隐私风险的持续拷问。从基础模型到终端硬件，从开源协作到政策博弈，技术正在加速落地，但代价与责任也愈发清晰。\n\n首先，大模型的能力边界正在被系统性地拓展。Google 今天发布了 TimesFM，一个专为时间序列预测设计的基础模型。这听起来可能有些抽象，但它意味着未来无论是天气预报、电网负荷，还是电商库存需求，都可能由一个统一的 AI 架构来预测——不再需要为每个场景单独训练模型。与此同时，Google 的 Gemini 3.1 Pro 也在专业任务榜单上刷新纪录，尤其在多步推理和复杂工作流处理上表现突出。这些进展共同指向一个趋势：大模型正从“能聊天”转向“能干活”，成为真正嵌入业务流程的智能代理。而 OpenAI 也在探索更硬核的领域——他们首次公开了参与 First Proof 数学挑战的尝试，虽然尚未完全解决专家级定理，但这种将形式化推理作为测试场的做法，为评估 AI 的科研潜力提供了新标尺。\n\n如果说模型是大脑，那么工具和基础设施就是手脚。今天，多个项目正在让 AI 智能体变得更“能干”。Composio 发布了一个支持上千种工具集成的开发平台，开发者可以像搭积木一样，把日历、邮件、数据库甚至支付接口接入 AI 代理，让它真正执行用户指令。Databricks 则推出了专为编码智能体设计的开发工具包，帮助企业快速构建能自主写代码、调试和部署的 AI 工程师。更值得关注的是，llama.cpp 的创始团队正式加入 Hugging Face，承诺保持项目完全开源，并与 Transformers 库深度整合。这意味着本地运行大模型将变得更简单、更高效——你未来或许能在笔记本上流畅运行一个私有、低延迟的 AI 助手，而无需依赖云端。Hugging Face 还联合 Unsloth 推出了免费微调服务，用更少显存、更快的速度训练小模型，进一步降低定制化 AI 的门槛。\n\n然而，能力越强，风险也越具体。一个名为 Pentagi 的开源项目展示了 AI 在网络安全领域的双刃剑效应：它是一个完全自主的渗透测试智能体，能自动探测系统漏洞。这对企业防御是利好，但也意味着攻击者可能用类似技术发起更复杂的自动化攻击。更隐蔽的风险来自工具调用本身——当 AI 代理被赋予操作真实世界 API 的权限时，如何确保它不会误操作、越权访问，甚至被恶意诱导？这不仅是技术问题，更是系统设计哲学的问题。与此同时，OpenAI 被曝计划在 2027 年推出带摄像头的 ChatGPT 智能音箱，不仅能识别桌面物品，还集成面部识别用于支付。这无疑会带来更自然的人机交互，但也将语音、视觉、身份、支付等敏感数据全部汇聚到一个设备上，隐私保护的挑战前所未有。\n\n而所有这些计算密集型进展的背后，还有一个常被忽视的现实：能源与环境成本。就在今天，有报道指出，美国可能废除针对燃煤电厂汞排放的严格限制，而这一政策变动恰逢 AI 数据中心用电需求激增。AI 训练和推理的能耗早已不是秘密，但当算力扩张遇上化石能源回潮，问题就从“效率优化”升级为“公共健康风险”。燃煤电厂是美国汞污染的主要来源，而汞对儿童神经发育的危害已被充分证实。技术狂奔的同时，如果能源结构不向清洁化转型，我们可能在用下一代的健康为今天的智能买单。\n\n面对这样的图景，普通用户或许不必深究模型架构或工具链细节，但值得保持一种清醒：AI 正在从“功能”走向“代理”，从“响应”走向“行动”。这意味着它能为你做的事越来越多，但你也需要更主动地思考——哪些数据愿意交出？哪些权限可以授予？哪些便利值得以环境为代价？对开发者而言，机会在于利用日益成熟的开源生态快速构建垂直应用，但也要警惕“工具丰富”不等于“系统可靠”，安全与可解释性必须前置。而对整个社会来说，技术演进不能脱离制度约束，尤其是在能源、隐私和安全这些底层议题上。\n\n今天的 AI 世界，既令人兴奋，也令人警醒。它不再是实验室里的概念，而是正在重塑我们工作、生活甚至呼吸的空气。理解它的进展，不只是为了跟上潮流，更是为了在变革中守住底线。",
  "longformScriptZh": "今天，AI 领域的进展呈现出一种微妙的张力：一边是模型能力、工具生态和应用场景的快速扩张，另一边则是对能源消耗、安全边界和隐私风险的持续拷问。从基础模型到终端硬件，从开源协作到政策博弈，技术正在加速落地，但代价与责任也愈发清晰。\n\n首先，大模型的能力边界正在被系统性地拓展。Google 今天发布了 TimesFM，一个专为时间序列预测设计的基础模型。这听起来可能有些抽象，但它意味着未来无论是天气预报、电网负荷，还是电商库存需求，都可能由一个统一的 AI 架构来预测——不再需要为每个场景单独训练模型。与此同时，Google 的 Gemini 3.1 Pro 也在专业任务榜单上刷新纪录，尤其在多步推理和复杂工作流处理上表现突出。这些进展共同指向一个趋势：大模型正从“能聊天”转向“能干活”，成为真正嵌入业务流程的智能代理。而 OpenAI 也在探索更硬核的领域——他们首次公开了参与 First Proof 数学挑战的尝试，虽然尚未完全解决专家级定理，但这种将形式化推理作为测试场的做法，为评估 AI 的科研潜力提供了新标尺。\n\n如果说模型是大脑，那么工具和基础设施就是手脚。今天，多个项目正在让 AI 智能体变得更“能干”。Composio 发布了一个支持上千种工具集成的开发平台，开发者可以像搭积木一样，把日历、邮件、数据库甚至支付接口接入 AI 代理，让它真正执行用户指令。Databricks 则推出了专为编码智能体设计的开发工具包，帮助企业快速构建能自主写代码、调试和部署的 AI 工程师。更值得关注的是，llama.cpp 的创始团队正式加入 Hugging Face，承诺保持项目完全开源，并与 Transformers 库深度整合。这意味着本地运行大模型将变得更简单、更高效——你未来或许能在笔记本上流畅运行一个私有、低延迟的 AI 助手，而无需依赖云端。Hugging Face 还联合 Unsloth 推出了免费微调服务，用更少显存、更快的速度训练小模型，进一步降低定制化 AI 的门槛。\n\n然而，能力越强，风险也越具体。一个名为 Pentagi 的开源项目展示了 AI 在网络安全领域的双刃剑效应：它是一个完全自主的渗透测试智能体，能自动探测系统漏洞。这对企业防御是利好，但也意味着攻击者可能用类似技术发起更复杂的自动化攻击。更隐蔽的风险来自工具调用本身——当 AI 代理被赋予操作真实世界 API 的权限时，如何确保它不会误操作、越权访问，甚至被恶意诱导？这不仅是技术问题，更是系统设计哲学的问题。与此同时，OpenAI 被曝计划在 2027 年推出带摄像头的 ChatGPT 智能音箱，不仅能识别桌面物品，还集成面部识别用于支付。这无疑会带来更自然的人机交互，但也将语音、视觉、身份、支付等敏感数据全部汇聚到一个设备上，隐私保护的挑战前所未有。\n\n而所有这些计算密集型进展的背后，还有一个常被忽视的现实：能源与环境成本。就在今天，有报道指出，美国可能废除针对燃煤电厂汞排放的严格限制，而这一政策变动恰逢 AI 数据中心用电需求激增。AI 训练和推理的能耗早已不是秘密，但当算力扩张遇上化石能源回潮，问题就从“效率优化”升级为“公共健康风险”。燃煤电厂是美国汞污染的主要来源，而汞对儿童神经发育的危害已被充分证实。技术狂奔的同时，如果能源结构不向清洁化转型，我们可能在用下一代的健康为今天的智能买单。\n\n面对这样的图景，普通用户或许不必深究模型架构或工具链细节，但值得保持一种清醒：AI 正在从“功能”走向“代理”，从“响应”走向“行动”。这意味着它能为你做的事越来越多，但你也需要更主动地思考——哪些数据愿意交出？哪些权限可以授予？哪些便利值得以环境为代价？对开发者而言，机会在于利用日益成熟的开源生态快速构建垂直应用，但也要警惕“工具丰富”不等于“系统可靠”，安全与可解释性必须前置。而对整个社会来说，技术演进不能脱离制度约束，尤其是在能源、隐私和安全这些底层议题上。\n\n今天的 AI 世界，既令人兴奋，也令人警醒。它不再是实验室里的概念，而是正在重塑我们工作、生活甚至呼吸的空气。理解它的进展，不只是为了跟上潮流，更是为了在变革中守住底线。",
  "longformScriptEn": "Today’s AI landscape is defined by a powerful convergence: foundational models are maturing, autonomous agents are gaining real-world utility, and the infrastructure to run them—both in the cloud and on our personal devices—is rapidly democratizing. But this acceleration comes with trade-offs. As AI systems grow more capable, they also demand more energy, raise new safety questions, and blur the lines between software and physical interfaces. In just the past week, we’ve seen breakthroughs that could reshape everything from mathematical research to home security—and policy decisions that threaten to undermine the environmental sustainability of this very progress.\n\nLet’s start with forecasting. Google Research has unveiled TimesFM, a true foundation model for time series data. Unlike traditional forecasting tools that require task-specific tuning, TimesFM is pretrained on vast historical datasets and can generalize across domains—whether predicting energy demand, retail inventory needs, or traffic patterns. What makes this significant isn’t just its accuracy, but its accessibility: developers can already tap into it via API, and soon, everyday applications—from weather apps to supply chain dashboards—could embed far more reliable predictions without building custom models from scratch. This marks a shift toward “forecasting as a service,” powered by large-scale pretraining rather than narrow statistical methods.\n\nMeanwhile, the push to bring powerful AI onto personal devices is accelerating. The team behind llama.cpp—the lightweight engine that lets you run LLMs on a laptop or even a smartphone—has officially joined Hugging Face. Crucially, the project remains open-source and community-driven, but now with sustainable backing and tighter integration into Hugging Face’s Transformers library. Paired with a new free fine-tuning program from Hugging Face and Unsloth—which slashes training time and memory use by up to 60%—this creates a compelling pipeline: developers can now customize small models quickly, then deploy them locally with minimal friction. The result? Truly private, low-latency AI assistants that don’t rely on constant cloud connectivity, putting personalized intelligence directly in users’ hands.\n\nOn the frontier of reasoning, OpenAI has taken a bold step into formal mathematics. Its model recently submitted proof attempts for the First Proof challenge—a set of unsolved, expert-level math problems designed to test genuine theorem-proving ability. While these submissions aren’t yet correct or complete, they represent a critical benchmark: for the first time, we can empirically measure how close AI is to replicating the kind of abstract, deductive reasoning that underpins scientific discovery. This isn’t about chatbots solving homework; it’s about laying groundwork for future AI collaborators in fields like physics or cryptography, where logical rigor is non-negotiable.\n\nAt the same time, AI agents are becoming more action-oriented. Composio has launched a platform integrating over 1,000 real-world tools—from Slack and GitHub to financial APIs—into a unified framework for agent development. Combined with specialized toolkits like Databricks’ new AI Dev Kit for coding agents or Pentagi’s autonomous penetration testing system, we’re seeing a move away from “chatty” assistants toward agents that *do* things: secure networks, write production code, manage workflows. Even Google’s new Gemini 3.1 Pro, which just topped professional task benchmarks, demonstrates how multi-step reasoning is enabling agents to handle complex, real-world assignments—like legal document analysis or technical troubleshooting—with unprecedented fidelity.\n\nBut this momentum isn’t without friction. OpenAI’s rumored entry into hardware—a $200–$300 smart speaker with a camera and facial recognition for payments—signals a strategic pivot toward ambient, multimodal AI in the home. While convenient, such devices amplify longstanding privacy concerns, especially when combined with always-on sensing and identity verification. More urgently, the environmental cost of AI’s growth is coming into sharp focus. Just as data centers consume record amounts of electricity to power these models, the Trump administration has rolled back key emissions regulations on coal plants—repealing the Mercury and Air Toxics Standards that protected communities from neurotoxic pollutants. With coal still responsible for half of U.S. mercury emissions, this deregulation directly pits AI’s energy hunger against public health, particularly for children in vulnerable areas. It’s a stark reminder that technological progress cannot be decoupled from its societal and ecological footprint.\n\nSo what should you watch next? Keep an eye on the tension between agent capability and safety—especially as tools like Pentagi and Composio lower the barrier to deploying autonomous systems. Misuse or unintended behavior in high-stakes domains like cybersecurity or finance could have cascading consequences. On the upside, the open ecosystem around local AI (thanks to Hugging Face, Unsloth, and llama.cpp) is creating unprecedented opportunities for developers to build tailored, privacy-preserving applications without corporate gatekeeping. And while hardware plays like OpenAI’s speaker may dominate headlines, the real revolution might be quieter: models running efficiently on your own device, trained on your data, acting only on your behalf.\n\nIn sum, this week underscores a pivotal moment: AI is transitioning from impressive demos to embedded infrastructure. Whether it’s forecasting supply chains, proving theorems, or securing networks, the technology is becoming operational. But with that operationalization comes responsibility—not just in how we design these systems, but in how we power them and who gets to shape their future. The choices we make now, both as builders and citizens, will determine whether this wave of innovation lifts all boats—or leaves some behind in its wake.",
  "audioUrl": "",
  "papers": [
    {
      "id": "arxiv_2602_17260v1",
      "title": "EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection",
      "titleZh": "EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection",
      "titleEn": "EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection",
      "url": "https://arxiv.org/abs/2602.17260v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对当前AI生成视频（如Sora2、Veo3）日益逼真导致传统检测方法失效的问题，研究者提出EA-Swin——一种嵌入无关的Swin Transformer模型，通过因子化窗口注意力机制直接在预训练视频嵌入上建模时空依赖，兼容通用ViT风格编码器；同时构建包含13万视频的EA-Video基准数据集，涵盖多种商用与开源生成器并设置未见生成器划分以评估泛化能力。实验表明，EA-Swin在主流生成器上达到0.97–0.99准确率，较现有最先进方法（通常0.8–0.9）提升5–20%，且在跨分布场景下保持强泛化性，为AI生成视频检测提供了可扩展且鲁棒的解决方案。",
      "summaryZh": "针对当前AI生成视频（如Sora2、Veo3）日益逼真导致传统检测方法失效的问题，研究者提出EA-Swin——一种嵌入无关的Swin Transformer模型，通过因子化窗口注意力机制直接在预训练视频嵌入上建模时空依赖，兼容通用ViT风格编码器；同时构建包含13万视频的EA-Video基准数据集，涵盖多种商用与开源生成器并设置未见生成器划分以评估泛化能力。实验表明，EA-Swin在主流生成器上达到0.97–0.99准确率，较现有最先进方法（通常0.8–0.9）提升5–20%，且在跨分布场景下保持强泛化性，为AI生成视频检测提供了可扩展且鲁棒的解决方案。",
      "summaryEn": "To address the limitations of existing detectors against highly realistic AI-generated videos from systems like Sora2 and Veo3, researchers propose EA-Swin—an Embedding-Agnostic Swin Transformer that models spatiotemporal dependencies directly on pretrained video embeddings via a factorized windowed attention mechanism, compatible with generic ViT-style encoders. They also introduce EA-Video, a benchmark dataset of 130K videos integrating new and curated samples across diverse commercial and open-source generators, including unseen-generator splits for rigorous cross-distribution evaluation. Experiments show EA-Swin achieves 0.97–0.99 accuracy across major generators—outperforming prior state-of-the-art methods (typically 0.8–0.9) by 5–20%—while maintaining strong generalization to unseen distributions, offering a scalable and robust solution for modern AI-generated video detection.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Benchmark"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：针对Sora等生成视频的检测难题提出嵌入无关的新型检测框架，是应对深度伪造泛滥的关键技术突破，可能重塑数字内容监管格局。",
        "热度：14 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-19T11:04:20+00:00",
      "authors": [
        "Hung Mai",
        "Loi Dinh",
        "Duc Hai Nguyen"
      ]
    },
    {
      "id": "arxiv_2602_17217v1",
      "title": "Continual learning and refinement of causal models through dynamic predicate invention",
      "titleZh": "Continual learning and refinement of causal models through dynamic predicate invention",
      "titleEn": "Continual learning and refinement of causal models through dynamic predicate invention",
      "url": "https://arxiv.org/abs/2602.17217v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为克服传统世界模型在样本效率、可解释性和可扩展性方面的不足，研究者提出一种基于动态谓词发明的在线符号因果建模框架，将连续学习与修复融入智能体决策循环，利用元解释学习（Meta-Interpretive Learning）自动发现语义清晰且可复用的抽象概念，构建解耦的高质量概念层次。该方法在具有复杂关系动态的环境中实现高效推理，避免了命题方法的组合爆炸问题，样本效率比PPO神经网络基线高出数个数量级，显著提升了智能体对环境逻辑结构的理解能力。",
      "summaryZh": "为克服传统世界模型在样本效率、可解释性和可扩展性方面的不足，研究者提出一种基于动态谓词发明的在线符号因果建模框架，将连续学习与修复融入智能体决策循环，利用元解释学习（Meta-Interpretive Learning）自动发现语义清晰且可复用的抽象概念，构建解耦的高质量概念层次。该方法在具有复杂关系动态的环境中实现高效推理，避免了命题方法的组合爆炸问题，样本效率比PPO神经网络基线高出数个数量级，显著提升了智能体对环境逻辑结构的理解能力。",
      "summaryEn": "To overcome the sample inefficiency, lack of transparency, and poor scalability of standard world models, researchers propose an online symbolic causal modeling framework that integrates continuous learning and repair into the agent’s decision loop using Meta-Interpretive Learning and dynamic predicate invention to discover semantically meaningful, reusable abstractions and build a hierarchy of disentangled, high-quality concepts. Their lifted inference approach scales to domains with complex relational dynamics—avoiding the combinatorial explosion of propositional methods—and achieves sample efficiency orders of magnitude higher than the PPO neural-network baseline, significantly enhancing agents’ ability to internalize environmental logic.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent",
        "Inference",
        "RAG",
        "Industry"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出动态谓词发明机制实现因果模型持续学习，是迈向可解释、可演化智能体的关键一步，具备战略级影响力。",
        "热度：12 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T10:08:31+00:00",
      "authors": [
        "Enrique Crespo-Fernandez",
        "Oliver Ray",
        "Telmo de Menezes e Silva Filho"
      ]
    },
    {
      "id": "arxiv_2602_17016v1",
      "title": "M2F: Automated Formalization of Mathematical Literature at Scale",
      "titleZh": "M2F: Automated Formalization of Mathematical Literature at Scale",
      "titleEn": "M2F: Automated Formalization of Mathematical Literature at Scale",
      "url": "https://arxiv.org/abs/2602.17016v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为实现数学文献的大规模自动化形式化，研究者提出M2F（Math-to-Formal）——首个支持端到端项目级自动形式化的智能体框架，专用于Lean语言。该框架分两阶段工作：先通过依赖排序和声明骨架修复完成语句编译（允许证明占位符），再通过目标条件局部编辑闭合证明空洞，并全程将验证器纳入反馈循环以确保每步修改有效。在约三周内，M2F成功将479页实分析与凸分析教材转化为153,853行完整Lean代码，形式化速度远超专家人工所需数月甚至数年；在FATE-H基准上达到96%证明成功率（强基线为80%），首次证明大规模数学文献自动形式化已切实可行。",
      "summaryZh": "为实现数学文献的大规模自动化形式化，研究者提出M2F（Math-to-Formal）——首个支持端到端项目级自动形式化的智能体框架，专用于Lean语言。该框架分两阶段工作：先通过依赖排序和声明骨架修复完成语句编译（允许证明占位符），再通过目标条件局部编辑闭合证明空洞，并全程将验证器纳入反馈循环以确保每步修改有效。在约三周内，M2F成功将479页实分析与凸分析教材转化为153,853行完整Lean代码，形式化速度远超专家人工所需数月甚至数年；在FATE-H基准上达到96%证明成功率（强基线为80%），首次证明大规模数学文献自动形式化已切实可行。",
      "summaryEn": "To enable large-scale automated formalization of mathematical literature, researchers present M2F (Math-to-Formal)—the first agentic framework for end-to-end, project-scale autoformalization in Lean. Operating in two stages, M2F first compiles statements by splitting documents into atomic blocks, ordering them via inferred dependencies, and repairing declaration skeletons until the project compiles (allowing proof placeholders); it then closes proof holes using goal-conditioned local edits under fixed signatures. Crucially, the verifier remains in the loop throughout, accepting only edits confirmed by toolchain feedback. In approximately three weeks, M2F converted 479 pages of real and convex analysis textbooks into a 153,853-line Lean library—achieving what would typically require months or years of expert effort—and attained 96% proof success on FATE-H versus 80% for a strong baseline, demonstrating that practical, large-scale autoformalization is now within reach.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent",
        "Research",
        "Open Source"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：实现数学文献规模化形式化，突破自动化验证瓶颈，有望重塑学术研究可信性与知识可计算性，具备战略级影响力。",
        "热度：9 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T02:25:23+00:00",
      "authors": [
        "Zichen Wang",
        "Wanli Ma",
        "Zhenyu Ming"
      ]
    },
    {
      "id": "arxiv_2602_17017v1",
      "title": "Sales Research Agent and Sales Research Bench",
      "titleZh": "Sales Research Agent and Sales Research Bench",
      "titleEn": "Sales Research Agent and Sales Research Bench",
      "url": "https://arxiv.org/abs/2602.17017v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "微软Dynamics 365 Sales推出的Sales Research Agent能连接企业实时CRM数据，理解复杂数据库结构，并生成文本与图表形式的决策就绪洞察；为量化其性能，团队同步开发了Sales Research Bench基准，从文本与图表的接地性、相关性、可解释性、模式准确性等八个客户加权维度评估系统。在2025年10月19日对定制企业架构的200题测试中，该智能体以13分优势超越Claude Sonnet 4.5、24.1分领先ChatGPT-5（满分100），为企业用户提供了一种可重复、透明的AI销售分析工具比较标准。",
      "summaryZh": "微软Dynamics 365 Sales推出的Sales Research Agent能连接企业实时CRM数据，理解复杂数据库结构，并生成文本与图表形式的决策就绪洞察；为量化其性能，团队同步开发了Sales Research Bench基准，从文本与图表的接地性、相关性、可解释性、模式准确性等八个客户加权维度评估系统。在2025年10月19日对定制企业架构的200题测试中，该智能体以13分优势超越Claude Sonnet 4.5、24.1分领先ChatGPT-5（满分100），为企业用户提供了一种可重复、透明的AI销售分析工具比较标准。",
      "summaryEn": "Microsoft’s Dynamics 365 Sales introduces the Sales Research Agent—an AI system that connects to live CRM data, reasons over complex schemas, and delivers decision-ready insights via text and charts. To objectively evaluate its quality, the team developed the Sales Research Bench, a purpose-built benchmark scoring systems across eight customer-weighted dimensions: text and chart groundedness, relevance, explainability, schema accuracy, and chart quality. In a 200-question evaluation on a customized enterprise schema on October 19, 2025, the agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on a 100-point composite score, providing enterprises with a transparent, repeatable method to compare AI-powered sales analytics solutions.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "Industry",
        "Research"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：微软发布企业级销售研究代理及基准，标志着AI深度嵌入CRM生态，推动企业智能化转型，具备全球产业级示范效应。",
        "热度：11 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2025-12-01T19:44:04+00:00",
      "authors": [
        "Deepanjan Bhol"
      ]
    },
    {
      "id": "arxiv_2602_17607v1",
      "title": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
      "titleZh": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
      "titleEn": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
      "url": "https://arxiv.org/abs/2602.17607v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对偏微分方程（PDE）数值求解依赖专家经验且神经网络方法可解释性差的问题，研究者提出AutoNumerics——一个无需预设PDE类型的多智能体自主管道，能直接从自然语言描述出发，自动设计、实现、调试并验证经典数值格式的求解器。该框架采用由粗到精的执行策略与残差自验证机制，生成透明、基于传统数值分析的解法。在24个经典及真实PDE问题上的实验表明，AutoNumerics在精度上媲美或优于现有神经与大模型基线，并能根据PDE结构特性正确选择数值方案，为科学计算提供了一种可解释、低门槛的自动化范式。",
      "summaryZh": "针对偏微分方程（PDE）数值求解依赖专家经验且神经网络方法可解释性差的问题，研究者提出AutoNumerics——一个无需预设PDE类型的多智能体自主管道，能直接从自然语言描述出发，自动设计、实现、调试并验证经典数值格式的求解器。该框架采用由粗到精的执行策略与残差自验证机制，生成透明、基于传统数值分析的解法。在24个经典及真实PDE问题上的实验表明，AutoNumerics在精度上媲美或优于现有神经与大模型基线，并能根据PDE结构特性正确选择数值方案，为科学计算提供了一种可解释、低门槛的自动化范式。",
      "summaryEn": "Addressing the reliance on expert knowledge in PDE solver design and the poor interpretability of neural approaches, researchers introduce AutoNumerics—a multi-agent, PDE-agnostic pipeline that autonomously designs, implements, debugs, and verifies classical numerical solvers directly from natural language descriptions. Unlike black-box neural solvers, AutoNumerics generates transparent, numerically grounded methods using a coarse-to-fine execution strategy and a residual-based self-verification mechanism. Experiments on 24 canonical and real-world PDE problems show it achieves competitive or superior accuracy compared to neural and LLM-based baselines and correctly selects numerical schemes based on PDE structural properties, establishing an interpretable, accessible paradigm for automated scientific computing.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：构建无偏PDE求解的多智能体自动流水线，突破科学计算领域专家依赖瓶颈，可能重塑工程仿真与科研范式。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T18:31:52+00:00",
      "authors": [
        "Jianda Du",
        "Youran Sun",
        "Haizhao Yang"
      ]
    },
    {
      "id": "arxiv_2602_17598v1",
      "title": "The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?",
      "titleZh": "The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?",
      "titleEn": "The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?",
      "url": "https://arxiv.org/abs/2602.17598v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究发现，当前多数语音大模型（如Ultravox）在可从转录文本解决的任务上，其行为与Whisper→LLM级联管道几乎等效：通过匹配主干模型控制变量实验，Ultravox与对应级联系统的Cohen’s κ达0.93；隐藏层中可检测到显式文本表征，且擦除该表征会使两类架构性能均崩溃至接近零。仅Qwen2-Audio表现出真实差异，表明级联等效性取决于架构而非普遍规律。这意味着多数部署中的语音大模型实质是昂贵的级联系统，在噪声环境下表现更差——干净条件下最多7.6%的优势在0 dB信噪比时完全逆转。",
      "summaryZh": "研究发现，当前多数语音大模型（如Ultravox）在可从转录文本解决的任务上，其行为与Whisper→LLM级联管道几乎等效：通过匹配主干模型控制变量实验，Ultravox与对应级联系统的Cohen’s κ达0.93；隐藏层中可检测到显式文本表征，且擦除该表征会使两类架构性能均崩溃至接近零。仅Qwen2-Audio表现出真实差异，表明级联等效性取决于架构而非普遍规律。这意味着多数部署中的语音大模型实质是昂贵的级联系统，在噪声环境下表现更差——干净条件下最多7.6%的优势在0 dB信噪比时完全逆转。",
      "summaryEn": "A study reveals that most current speech LLMs (e.g., Ultravox) behave nearly identically to simple Whisper→LLM cascade pipelines on tasks solvable from transcripts: matched-backbone experiments show Ultravox is statistically indistinguishable from its cascade counterpart (κ=0.93), logit lens uncovers literal text emerging in hidden states, and erasing these representations collapses accuracy to near-zero in both architectures. Only Qwen2-Audio genuinely diverges, indicating cascade equivalence is architecture-dependent, not universal. This implies most deployed speech LLMs are effectively expensive cascades—and under noise, worse ones, as their clean-condition advantage (up to 7.6%) reverses at 0 dB SNR.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Audio"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：揭示语音大模型与ASR+LLM流水线行为等价性，深刻影响模型设计与评估范式，具备战略级行业洞察力。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T18:22:39+00:00",
      "authors": [
        "Jayadev Billa"
      ]
    },
    {
      "id": "arxiv_2602_17345v1",
      "title": "What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?",
      "titleZh": "What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?",
      "titleEn": "What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?",
      "url": "https://arxiv.org/abs/2602.17345v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对具身AI（如自动驾驶汽车、服务机器人）在现实部署中面临的安全挑战，该综述指出，仅从大语言模型漏洞或传统信息物理系统（CPS）缺陷角度分析是不足的；真正关键的风险源于“具身引发的系统级不匹配”：语言层面的语义正确性无法保证物理安全（因忽略几何、动力学与接触约束）；相同动作在不同物理状态下因非线性动态产生迥异结果；感知-决策-行动环路中的微小误差会放大传播；局部安全决策随时间累积可能导致全局不安全。因此，保障具身AI安全需超越组件级防御，转向对物理风险、不确定性与故障传播的系统级建模。",
      "summaryZh": "针对具身AI（如自动驾驶汽车、服务机器人）在现实部署中面临的安全挑战，该综述指出，仅从大语言模型漏洞或传统信息物理系统（CPS）缺陷角度分析是不足的；真正关键的风险源于“具身引发的系统级不匹配”：语言层面的语义正确性无法保证物理安全（因忽略几何、动力学与接触约束）；相同动作在不同物理状态下因非线性动态产生迥异结果；感知-决策-行动环路中的微小误差会放大传播；局部安全决策随时间累积可能导致全局不安全。因此，保障具身AI安全需超越组件级防御，转向对物理风险、不确定性与故障传播的系统级建模。",
      "summaryEn": "This survey argues that analyzing embodied AI security solely through LLM vulnerabilities or traditional Cyber-Physical System (CPS) flaws is insufficient. Instead, a critical class of failures stems from embodiment-induced system-level mismatches: semantic correctness does not guarantee physical safety (as language reasoning abstracts away geometry, dynamics, and contact); identical actions yield divergent outcomes due to nonlinear dynamics and state uncertainty; small errors amplify across tightly coupled perception-decision-action loops; and locally safe decisions can accumulate into globally unsafe behavior over time. Securing embodied AI thus requires moving beyond component-level defenses toward system-level reasoning about physical risk, uncertainty, and failure propagation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "Robotics",
        "Reasoning"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：系统性分析具身AI安全瓶颈，涵盖LLM与物理系统双重风险，推动全球对智能体安全标准的讨论，影响深远。",
        "热度：14 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T13:29:00+00:00",
      "authors": [
        "Boyang Ma",
        "Hechuan Guo",
        "Peizhuo Lv"
      ]
    },
    {
      "id": "arxiv_2602_17168v1",
      "title": "BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning",
      "titleZh": "BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning",
      "titleEn": "BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning",
      "url": "https://arxiv.org/abs/2602.17168v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对多模态对比学习模型中的后门攻击难以兼顾隐蔽性与持久性的问题，研究者提出BadCLIP++框架：通过语义融合QR微触发器将不可感知图案嵌入任务相关区域以维持干净数据统计特性，并结合目标对齐子集选择增强低投毒率下的攻击信号；为提升持久性，采用半径收缩与质心对齐稳定触发嵌入，并通过曲率控制与弹性权重巩固使模型参数驻留在抗微调的宽平坦损失盆地中。理论分析首次证明，在信任区域内干净微调与后门目标的梯度方向一致，攻击成功率衰减存在非增上界。实验显示，仅0.3%投毒率下，BadCLIP++在数字攻击中达成99.99%成功率（超基线11.4点），在19种防御下仍保持>99.90%成功率且干净准确率下降<0.8%，并在物理攻击中取得65.03%成功率，对水印移除防御亦具鲁棒性。",
      "summaryZh": "针对多模态对比学习模型中的后门攻击难以兼顾隐蔽性与持久性的问题，研究者提出BadCLIP++框架：通过语义融合QR微触发器将不可感知图案嵌入任务相关区域以维持干净数据统计特性，并结合目标对齐子集选择增强低投毒率下的攻击信号；为提升持久性，采用半径收缩与质心对齐稳定触发嵌入，并通过曲率控制与弹性权重巩固使模型参数驻留在抗微调的宽平坦损失盆地中。理论分析首次证明，在信任区域内干净微调与后门目标的梯度方向一致，攻击成功率衰减存在非增上界。实验显示，仅0.3%投毒率下，BadCLIP++在数字攻击中达成99.99%成功率（超基线11.4点），在19种防御下仍保持>99.90%成功率且干净准确率下降<0.8%，并在物理攻击中取得65.03%成功率，对水印移除防御亦具鲁棒性。",
      "summaryEn": "To address the dual challenges of stealthiness and persistence in backdoor attacks against multimodal contrastive learning models, researchers propose BadCLIP++. For stealth, it embeds imperceptible semantic-fusion QR micro-triggers near task-relevant regions to preserve clean-data statistics and uses target-aligned subset selection to strengthen signals at low poisoning rates. For persistence, it stabilizes trigger embeddings via radius shrinkage and centroid alignment, and model parameters through curvature control and elastic weight consolidation—keeping solutions in a wide, low-curvature loss basin resistant to fine-tuning. The work provides the first theoretical analysis showing co-directional gradients between clean fine-tuning and backdoor objectives within a trust region, yielding a non-increasing upper bound on attack degradation. Experiments show BadCLIP++ achieves 99.99% attack success rate (ASR) with only 0.3% poisoning—surpassing baselines by 11.4 points—maintains >99.90% ASR across 19 defenses with <0.8% clean accuracy drop, attains 65.03% success in physical attacks, and resists watermark removal defenses.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Multimodal",
        "Audio",
        "Training",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：揭示多模态对比学习中的隐蔽后门攻击新范式，直接威胁AI系统安全，引发全球对生成内容可信性的深度反思，推动安全标准升级。",
        "热度：16 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T08:31:16+00:00",
      "authors": [
        "Siyuan Liang",
        "Yongcheng Jing",
        "Yingjie Wang"
      ]
    },
    {
      "id": "arxiv_2602_17601v1",
      "title": "Graph Neural Model Predictive Control for High-Dimensional Systems",
      "titleZh": "Graph Neural Model Predictive Control for High-Dimensional Systems",
      "titleEn": "Graph Neural Model Predictive Control for High-Dimensional Systems",
      "url": "https://arxiv.org/abs/2602.17601v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：The control of high-dimensional systems, such as soft robots, requires models that faithfully capture complex dynamics w...；关键点：Graph Neural Model Predictive Control for High-Dimensional S；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：The control of high-dimensional systems, such as soft robots, requires models that faithfully capture complex dynamics w...；关键点：Graph Neural Model Predictive Control for High-Dimensional S；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: The control of high-dimensional systems, such as soft robots, requires models that faithfully capture complex dynamics while remaining computationally.... Key takeaway: Graph Neural Model Predictive Control for High-Dimensional Systems. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "RAG"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：将图神经网络与模型预测控制结合，为高维系统（如软体机器人）提供高效可扩展的控制框架，具备推动先进机器人系统落地的战略意义。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T18:26:42+00:00",
      "authors": [
        "Patrick Benito Eberhard",
        "Luis Pabon",
        "Daniele Gammelli"
      ]
    },
    {
      "id": "arxiv_2602_16872v1",
      "title": "DODO: Discrete OCR Diffusion Models",
      "titleZh": "DODO: Discrete OCR Diffusion Models",
      "titleEn": "DODO: Discrete OCR Diffusion Models",
      "url": "https://arxiv.org/abs/2602.16872v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge betwe...；关键点：DODO: Discrete OCR Diffusion Models；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge betwe...；关键点：DODO: Discrete OCR Diffusion Models；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge between visual data and textual und.... Key takeaway: DODO: Discrete OCR Diffusion Models. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Diffusion"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出离散OCR扩散模型，突破传统自回归解码瓶颈，有望重塑文档理解与信息提取范式，对通用视觉语言模型发展具有战略影响。",
        "热度：16 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T20:59:22+00:00",
      "authors": [
        "Sean Man",
        "Roy Ganz",
        "Roi Ronen"
      ]
    },
    {
      "id": "arxiv_2602_17124v1",
      "title": "3D Scene Rendering with Multimodal Gaussian Splatting",
      "titleZh": "3D Scene Rendering with Multimodal Gaussian Splatting",
      "titleEn": "3D Scene Rendering with Multimodal Gaussian Splatting",
      "url": "https://arxiv.org/abs/2602.17124v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：3D scene reconstruction and rendering are core tasks in computer vision, with applications spanning industrial monitorin...；关键点：3D Scene Rendering with Multimodal Gaussian Splatting；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：3D scene reconstruction and rendering are core tasks in computer vision, with applications spanning industrial monitorin...；关键点：3D Scene Rendering with Multimodal Gaussian Splatting；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: 3D scene reconstruction and rendering are core tasks in computer vision, with applications spanning industrial monitoring, robotics, and autonomous dr.... Key takeaway: 3D Scene Rendering with Multimodal Gaussian Splatting. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Robotics",
        "3D"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：将多模态高斯点云渲染推向新高度，为工业监控、自动驾驶等关键领域提供高效高保真3D重建方案，具备显著产业转化潜力。",
        "热度：13 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-19T06:49:53+00:00",
      "authors": [
        "Chi-Shiang Gau",
        "Konstantinos D. Polyzos",
        "Athanasios Bacharis"
      ]
    },
    {
      "id": "arxiv_2602_17196v1",
      "title": "EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models",
      "titleZh": "EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models",
      "titleEn": "EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models",
      "url": "https://arxiv.org/abs/2602.17196v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：Multimodal large language models (MLLMs) incur substantial inference cost due to the processing of hundreds of visual to...；关键点：EntropyPrune: Matrix Entropy Guided Visual Token Pruning for；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Multimodal large language models (MLLMs) incur substantial inference cost due to the processing of hundreds of visual to...；关键点：EntropyPrune: Matrix Entropy Guided Visual Token Pruning for；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Multimodal large language models (MLLMs) incur substantial inference cost due to the processing of hundreds of visual tokens per image. Although token.... Key takeaway: EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large La. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Inference"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出基于矩阵熵的视觉令牌剪枝方法，有效降低多模态大模型推理开销，对边缘设备部署和实时应用具有重要推动作用。",
        "热度：17 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-19T09:29:43+00:00",
      "authors": [
        "Yahong Wang",
        "Juncheng Wu",
        "Zhangkai Ni"
      ]
    },
    {
      "id": "arxiv_2602_17182v1",
      "title": "NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting",
      "titleZh": "NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting",
      "titleEn": "NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting",
      "url": "https://arxiv.org/abs/2602.17182v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：Visual simultaneous localization and mapping (V-SLAM) is a fundamental capability for autonomous perception and navigati...；关键点：NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deform；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Visual simultaneous localization and mapping (V-SLAM) is a fundamental capability for autonomous perception and navigati...；关键点：NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deform；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Visual simultaneous localization and mapping (V-SLAM) is a fundamental capability for autonomous perception and navigation. However, endoscopic scenes.... Key takeaway: NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gauss. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "3D",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：解决内窥镜场景下非刚性SLAM的核心难题，结合变形感知的3D高斯溅射，对医疗机器人与精准手术导航具有变革性意义。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-19T09:03:47+00:00",
      "authors": [
        "Jiwei Shan",
        "Zeyu Cai",
        "Yirui Li"
      ]
    },
    {
      "id": "arxiv_2602_16764v1",
      "title": "Machine Learning Argument of Latitude Error Model for LEO Satellite Orbit and Covariance Correction",
      "titleZh": "Machine Learning Argument of Latitude Error Model for LEO Satellite Orbit and Covariance Correction",
      "titleEn": "Machine Learning Argument of Latitude Error Model for LEO Satellite Orbit and Covariance Correction",
      "url": "https://arxiv.org/abs/2602.16764v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：Low Earth orbit (LEO) satellites are leveraged to support new position, navigation, and timing (PNT) service alternative...；关键点：Machine Learning Argument of Latitude Error Model for LEO Sa；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Low Earth orbit (LEO) satellites are leveraged to support new position, navigation, and timing (PNT) service alternative...；关键点：Machine Learning Argument of Latitude Error Model for LEO Sa；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Low Earth orbit (LEO) satellites are leveraged to support new position, navigation, and timing (PNT) service alternatives to GNSS. These alternatives .... Key takeaway: Machine Learning Argument of Latitude Error Model for LEO Satellite Orbit and Co. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "3D",
        "RAG",
        "Open Source"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：面向LEO卫星轨道误差建模与协方差修正，对下一代非GNSS导航系统（如星链PNT）有关键支撑作用，影响全球定位基础设施演进。",
        "热度：9 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T17:23:14+00:00",
      "authors": [
        "Alex Moody",
        "Penina Axelrad",
        "Rebecca Russell"
      ]
    },
    {
      "id": "arxiv_2602_16870v1",
      "title": "Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads",
      "titleZh": "Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads",
      "titleEn": "Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads",
      "url": "https://arxiv.org/abs/2602.16870v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose ...；关键点：Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset ；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose ...；关键点：Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset ；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose challenges for modern autonomo.... Key takeaway: Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Benchmark"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：发布大规模多传感器自动驾驶数据集Boreas-RT，覆盖复杂道路场景，将显著推动自动驾驶算法在极端条件下的训练与评估。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T20:53:59+00:00",
      "authors": [
        "Daniil Lisus",
        "Katya M. Papais",
        "Cedric Le Gentil"
      ]
    },
    {
      "id": "arxiv_2602_16825v1",
      "title": "RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness",
      "titleZh": "RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness",
      "titleEn": "RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness",
      "url": "https://arxiv.org/abs/2602.16825v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-di...；关键点：RRT$^η$: Sampling-based Motion Planning and Control from STL；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-di...；关键点：RRT$^η$: Sampling-based Motion Planning and Control from STL；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-dimensional configuration spaces.... Key takeaway: RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications usin. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Robotics",
        "RAG",
        "Reasoning"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：基于算术-几何平均鲁棒性改进采样运动规划，使形式化任务指令在复杂环境中更可靠执行，推动可信自主机器人系统发展。",
        "热度：15 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T19:45:43+00:00",
      "authors": [
        "Ahmad Ahmad",
        "Shuo Liu",
        "Roberto Tron"
      ]
    },
    {
      "id": "arxiv_2602_16898v1",
      "title": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
      "titleZh": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
      "titleEn": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
      "url": "https://arxiv.org/abs/2602.16898v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "MALLVi 是一个基于多智能体架构的闭环机器人操作框架，利用大语言模型（LLM）与视觉语言模型（VLM）协同实现自然语言指令到原子动作的生成，并通过环境反馈动态调整执行流程；其核心由 Decomposer、Localizer、Thinker 和 Reflector 四个专用智能体分别处理任务分解、目标定位、推理规划与错误恢复，Reflector 还能选择性重激活相关智能体以避免全局重规划；在仿真与真实环境中，该方法显著提升了零样本操作任务的成功率与泛化能力。",
      "summaryZh": "MALLVi 是一个基于多智能体架构的闭环机器人操作框架，利用大语言模型（LLM）与视觉语言模型（VLM）协同实现自然语言指令到原子动作的生成，并通过环境反馈动态调整执行流程；其核心由 Decomposer、Localizer、Thinker 和 Reflector 四个专用智能体分别处理任务分解、目标定位、推理规划与错误恢复，Reflector 还能选择性重激活相关智能体以避免全局重规划；在仿真与真实环境中，该方法显著提升了零样本操作任务的成功率与泛化能力。",
      "summaryEn": "MALLVi is a multi-agent, closed-loop robotic manipulation framework that leverages large language models (LLMs) and vision-language models (VLMs) to translate natural language instructions into executable atomic actions, with environmental feedback dynamically guiding execution. It coordinates four specialized agents—Decomposer, Localizer, Thinker, and Reflector—to handle task decomposition, object localization, reasoning, and error recovery, where the Reflector enables targeted recovery by reactivating only relevant agents instead of full replanning. Experiments in simulation and real-world settings demonstrate significantly improved generalization and success rates on zero-shot manipulation tasks.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Agent"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：提出多智能体框架用于通用机器人操作，结合LLM与环境反馈，具备显著技术突破性，对AI+ robotics 领域有实际推动作用。",
        "热度：20 / 评论 0"
      ],
      "score": 7.0,
      "publishedAt": "2026-02-18T21:28:56+00:00",
      "authors": [
        "Iman Ahmadi",
        "Mehrshad Taji",
        "Arad Mahdinezhad Kashani"
      ]
    },
    {
      "id": "arxiv_2602_17407v1",
      "title": "Bluetooth Phased-array Aided Inertial Navigation Using Factor Graphs: Experimental Verification",
      "titleZh": "Bluetooth Phased-array Aided Inertial Navigation Using Factor Graphs: Experimental Verification",
      "titleEn": "Bluetooth Phased-array Aided Inertial Navigation Using Factor Graphs: Experimental Verification",
      "url": "https://arxiv.org/abs/2602.17407v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "该研究验证了基于相控阵蓝牙的低成本惯性导航系统在GNSS拒止环境（如仓库物流或无人机着陆）中的可行性，通过因子图优化融合蓝牙角度测量、距离或气压数据，在多旋翼无人机实飞实验中评估了不同鲁棒估计策略的性能，结果表明尽管商用现成组件带来更高噪声和较短作用距离，但合理设计的因子图仍可有效提升导航精度。",
      "summaryZh": "该研究验证了基于相控阵蓝牙的低成本惯性导航系统在GNSS拒止环境（如仓库物流或无人机着陆）中的可行性，通过因子图优化融合蓝牙角度测量、距离或气压数据，在多旋翼无人机实飞实验中评估了不同鲁棒估计策略的性能，结果表明尽管商用现成组件带来更高噪声和较短作用距离，但合理设计的因子图仍可有效提升导航精度。",
      "summaryEn": "This paper experimentally validates a low-cost inertial navigation system aided by phased-array Bluetooth in GNSS-denied scenarios such as warehouse logistics or drone landings. Using factor graph optimization, it fuses Bluetooth angular measurements with range or barometric pressure data and evaluates robust estimation strategies on real multirotor drone flight data. Results show that despite noisier measurements and limited range from commercial off-the-shelf components, well-designed factor graph estimators can still significantly enhance navigation accuracy.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Research"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：利用蓝牙相控阵实现低成本惯性导航，在仓储物流、无人机等场景具实际部署价值，是边缘智能与定位融合的重要进展。",
        "热度：6 / 评论 0"
      ],
      "score": 7.0,
      "publishedAt": "2026-02-19T14:34:04+00:00",
      "authors": [
        "Glen Hjelmerud Mørkbak Sørensen",
        "Torleiv H. Bryne",
        "Kristoffer Gryte"
      ]
    }
  ],
  "news": [
    {
      "id": "github_google-research_timesfm",
      "title": "Google Research 发布时间序列基础模型 TimesFM",
      "titleZh": "Google Research 发布时间序列基础模型 TimesFM",
      "titleEn": "Google Research Launches TimesFM, a Foundation Model for Time Series Forecasting",
      "url": "https://github.com/google-research/timesfm",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Google Research 发布了 TimesFM（Time Series Foundation Model）**，这是一个预训练的时间序列基础模型，专为通用时间序列预测任务设计；该模型的重要性在于将大模型范式引入时序领域，有望提升金融、能源、供应链等场景的预测能力；对开发者而言，可通过公开接口快速集成先进预测功能，普通用户未来可能受益于更精准的天气、交通或需求预测服务。",
      "summaryZh": "**Google Research 发布了 TimesFM（Time Series Foundation Model）**，这是一个预训练的时间序列基础模型，专为通用时间序列预测任务设计；该模型的重要性在于将大模型范式引入时序领域，有望提升金融、能源、供应链等场景的预测能力；对开发者而言，可通过公开接口快速集成先进预测功能，普通用户未来可能受益于更精准的天气、交通或需求预测服务。",
      "summaryEn": "Google Research has released TimesFM (Time Series Foundation Model), a pretrained foundation model designed for general-purpose time series forecasting. Its significance lies in bringing the large-model paradigm to time series analysis, potentially enhancing prediction accuracy in finance, energy, and supply chain applications. Developers can integrate its capabilities via public APIs, while end users may eventually benefit from more accurate forecasts in areas like weather, traffic, or demand planning.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/5e58b122f68d398c344a61705a184c4cb2a30691870e2a3ddbce6ee1bf342cba/google-research/timesfm",
      "tags": [
        "Industry",
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Google Research推出的Time Series Foundation Model是时间序列预测领域的里程碑式进展，具备全球产业级影响力。",
        "热度：8835 / 评论 0"
      ],
      "score": 9.9,
      "publishedAt": "2026-02-20T23:36:16.847762+00:00",
      "authors": []
    },
    {
      "id": "rss_0725894001",
      "title": "llama.cpp 创始团队加入 Hugging Face 共推本地 AI",
      "titleZh": "llama.cpp 创始团队加入 Hugging Face 共推本地 AI",
      "titleEn": "llama.cpp Creators Join Hugging Face to Advance Local AI",
      "url": "https://huggingface.co/blog/ggml-joins-hf",
      "type": "news",
      "source": "Hugging Face Blog",
      "summary": "**GGML 团队（llama.cpp 创始者）正式加入 Hugging Face**，旨在长期推动本地 AI 生态发展；此举确保 llama.cpp 项目维持 100% 开源与社区自治，同时获得可持续资源支持，并将与 Transformers 库深度集成以实现“一键部署”新模型；对 AI 领域而言，这强化了本地推理基础设施的开放性；普通用户未来将更容易在手机、笔记本等设备上运行高效、私有的 AI 模型。",
      "summaryZh": "**GGML 团队（llama.cpp 创始者）正式加入 Hugging Face**，旨在长期推动本地 AI 生态发展；此举确保 llama.cpp 项目维持 100% 开源与社区自治，同时获得可持续资源支持，并将与 Transformers 库深度集成以实现“一键部署”新模型；对 AI 领域而言，这强化了本地推理基础设施的开放性；普通用户未来将更容易在手机、笔记本等设备上运行高效、私有的 AI 模型。",
      "summaryEn": "The GGML team, creators of llama.cpp, has officially joined Hugging Face to ensure the long-term advancement of local AI. The project remains fully open-source and community-driven, with full technical autonomy, while gaining sustainable resources and deeper integration with the Transformers library to enable near “one-click” deployment of new models. This move strengthens the open infrastructure for on-device inference, making it easier for everyday users to run efficient, private AI models on phones, laptops, and other personal devices.",
      "fullText": "GGML and llama.cpp join HF to ensure the long-term progress of Local AI Hugging Face Models Datasets Spaces Community Docs Enterprise Pricing Log In Sign Up Back to Articles GGML and llama.cpp join HF to ensure the long-term progress of Local AI Published February 20, 2026 Update on GitHub Upvote 159 +153 Georgi Gerganov ggerganov Follow Xuan-Son Nguyen ngxson Follow Aleksander Grygier allozaur Follow Lysandre lysandre Follow Victor Mustar victor Follow Julien Chaumond julien-c Follow What will change for llama.cpp, the open source project and the community? Technical focus Our long term vision We are super happy to announce that GGML, creators of Llama.cpp, are joining HF in order to keep future AI open. 🔥 Georgi Gerganov and team are joining HF with the goal of scaling and supporting the community behind ggml and llama.cpp as Local AI continues to make exponential progress in the coming years. We've been working with Georgi and team for quite some time (we even have awesome core contributors to llama.cpp like Son and Alek in the team already) so this has been a very natural process. llama.cpp is the fundamental building block for local inference, and transformers is the fundamental building block for model definition, so this is basically a match made in heaven. ❤️ What will change for llama.cpp, the open source project and the community? Not much – Georgi and team still dedicate 100% of their time maintaining llama.cpp and have full autonomy and leadership on the technical directions and the community. HF is providing the project with long-term sustainable resources, improving the chances of the project to grow and thrive. The project will continue to be 100% open-source and community driven as it is now. Technical focus llama.cpp is the fundamental building block for local inference, and transformers is the fundamental building block for definition of models and architectures, so we’ll work on making sure it’s as seamless as possible in the future (almost “single-click”) to ship new models in llama.cpp from the transformers library ‘source of truth’ for model definitions. Additionally, we will improve packaging and user experience of ggml-based software. As we enter the phase in which local inference becomes a meaningful and competitive alternative to cloud inference, it is crucial to improve and simplify the way in which casual users deploy and access local models. We will work towards making llama.cpp ubiquitous and readily available everywhere. Our long term vision Our shared goal is to provide the community with the building blocks to make open-source superintelligence accessible to the world over the coming years. We will achieve this together with the growing Local AI community, as we continue to build the ultimate inference stack that runs as efficiently as possible on our devices. More Articles from our Blog llm fine-tuning open-source Codex is Open Sourcing AI models 72 December 11, 2025 llm fine-tuning open-source Hot We Got Claude to Fine-Tune an Open Source LLM 597 December 4, 2025 Community Bright8192 about 8 hours ago Big congrats to GGML and Hugging Face! Great news for the Local AI community. Excited to see llama.cpp grow stronger and make local AI easier for everyone! See translation Reply Room64 about 7 hours ago LLama.cpp is the best AI project by far, super reactive to bug solve, very competent team, love you guys, you desserve it See translation Reply Xenova about 7 hours ago Our shared goal is to provide the community with the building blocks to make open-source superintelligence accessible to the world over the coming years. See translation 🔥 9 9 + Reply Trilogix1 about 4 hours ago Hugging Face smart moves never ending. Are you guys using AI for advice? I wonder which of 2 million AI models you are using 😄 See translation Reply joshnur about 4 hours ago Great news. Serving with llama.cpp using HF-hosted models, including unsloth's on AMD Strix Halo and OpenCode here. See translation Reply raphaelamorim about 3 hours ago • edited about 3 hours ago Congrats to both teams. Well deserved. Wonderful news for wonderful teams and community. See translation Reply iyanello about 3 hours ago Congratulations to Georgi Gerganov and team! So happy for you guys, this is huge success! See translation Reply Tugay31 about 1 hour ago Great news. congrats to GGML and HF. . always LocalAI. See translation Reply Edit Preview Upload images, audio, and videos by dragging in the text input, pasting, or clicking here . Tap or paste here to upload images Comment · Sign up or log in to comment Upvote 159 +147 System theme Company TOS Privacy About Careers Website Models Datasets Spaces Pricing Docs",
      "imageUrl": "https://huggingface.co/blog/assets/ggml-joins-hf/ggml-joins-hf.png",
      "tags": [
        "LLM"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：GGML 与 llama.cpp 加入 Hugging Face 是推动本地化 AI 可持续发展的关键举措，强化了开源生态，对全球 AI 自主可控格局产生深远影响，符合战略性突破标准。",
        "热度：0 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-20T00:00:00+00:00",
      "authors": []
    },
    {
      "id": "rss_6763406561",
      "title": "AI 模型首次提交 First Proof 数学挑战证明尝试",
      "titleZh": "AI 模型首次提交 First Proof 数学挑战证明尝试",
      "titleEn": "AI Model Submits First Proof Attempts in Expert-Level Math Challenge",
      "url": "https://openai.com/index/first-proof-submissions",
      "type": "news",
      "source": "OpenAI Blog",
      "summary": "**研究团队公开了其 AI 模型参与 First Proof 数学挑战的证明尝试**，该挑战聚焦专家级数学问题，旨在测试模型的研究级推理能力；这一举措为评估当前 AI 在形式化数学推理上的边界提供了实证基准；对科研社区而言，有助于推动自动定理证明技术发展；普通用户虽不直接使用，但长期看可能促进更可靠的 AI 助手在科学发现中的应用。",
      "summaryZh": "**研究团队公开了其 AI 模型参与 First Proof 数学挑战的证明尝试**，该挑战聚焦专家级数学问题，旨在测试模型的研究级推理能力；这一举措为评估当前 AI 在形式化数学推理上的边界提供了实证基准；对科研社区而言，有助于推动自动定理证明技术发展；普通用户虽不直接使用，但长期看可能促进更可靠的 AI 助手在科学发现中的应用。",
      "summaryEn": "A research team has released its AI model’s proof attempts for the First Proof math challenge, which tests research-grade reasoning on expert-level mathematical problems. This provides an empirical benchmark for evaluating the current limits of AI in formal mathematical reasoning. For the scientific community, it advances progress in automated theorem proving; while not directly impacting end users now, it may eventually enable more reliable AI assistants in scientific discovery.",
      "fullText": "We share our AI model’s proof attempts for the First Proof math challenge, testing research-grade reasoning on expert-level problems.",
      "imageUrl": "https://tse1.mm.bing.net/th?q=Openai&w=1200&h=630&c=7&rs=1&p=0&o=5&pid=1.7&mkt=en-US&cc=US&setlang=en&adlt=moderate&t=1",
      "tags": [
        "Reasoning",
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：OpenAI 公布其模型在 First Proof 数学挑战中的推理尝试，展示了 AI 在专家级逻辑推理上的进步，具有研究价值和行业参考意义，属 relevant 但未达战略高度。",
        "热度：0 / 评论 0"
      ],
      "score": 8.8,
      "publishedAt": "2026-02-20T14:30:00+00:00",
      "authors": []
    },
    {
      "id": "github_vxcontrol_pentagi",
      "title": "Pentagi：全自主 AI 渗透测试智能体系统发布",
      "titleZh": "Pentagi：全自主 AI 渗透测试智能体系统发布",
      "titleEn": "Pentagi: Fully Autonomous AI Agents for Penetration Testing Released",
      "url": "https://github.com/vxcontrol/pentagi",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Pentagi 是一个完全自主的 AI 智能体系统，专为执行复杂渗透测试任务而设计**；其重要性在于将自动化安全测试推向更高自主水平，减少人工干预；对网络安全领域而言，可加速漏洞发现并提升红队效率；安全研究人员和企业可利用该开源工具增强系统防御能力，普通用户则间接受益于更健壮的数字基础设施。",
      "summaryZh": "**Pentagi 是一个完全自主的 AI 智能体系统，专为执行复杂渗透测试任务而设计**；其重要性在于将自动化安全测试推向更高自主水平，减少人工干预；对网络安全领域而言，可加速漏洞发现并提升红队效率；安全研究人员和企业可利用该开源工具增强系统防御能力，普通用户则间接受益于更健壮的数字基础设施。",
      "summaryEn": "Pentagi is a fully autonomous AI agent system designed to perform complex penetration testing tasks. Its significance lies in advancing automated security testing toward higher autonomy, reducing manual effort. For the cybersecurity field, it accelerates vulnerability discovery and enhances red team efficiency. Security researchers and organizations can leverage this open-source tool to strengthen defenses, indirectly benefiting end users through more resilient digital infrastructure.",
      "fullText": "",
      "imageUrl": "https://repository-images.githubusercontent.com/913030762/c8502908-380f-4897-aaba-87cfa16d67b4",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：全自主AI代理系统完成复杂渗透测试任务，代表AI Agent在安全领域的重大突破，具备行业变革潜力。",
        "热度：3795 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-20T23:36:08.557884+00:00",
      "authors": []
    },
    {
      "id": "github_ComposioHQ_composio",
      "title": "Composio 发布支持千级工具的 AI 智能体开发平台",
      "titleZh": "Composio 发布支持千级工具的 AI 智能体开发平台",
      "titleEn": "Composio Launches AI Agent Platform with 1,000+ Integrated Tools",
      "url": "https://github.com/ComposioHQ/composio",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Composio 提供超 1000 种工具集成、工具搜索、上下文管理、认证及沙盒工作台**，帮助开发者构建能将用户意图转化为具体行动的 AI 智能体；其重要性在于解决了智能体开发中的工具碎片化与集成复杂性问题；对 AI 领域而言，降低了构建多功能智能体的门槛；开发者可快速接入真实世界 API，普通用户未来将体验到更强大、可操作的 AI 助手。",
      "summaryZh": "**Composio 提供超 1000 种工具集成、工具搜索、上下文管理、认证及沙盒工作台**，帮助开发者构建能将用户意图转化为具体行动的 AI 智能体；其重要性在于解决了智能体开发中的工具碎片化与集成复杂性问题；对 AI 领域而言，降低了构建多功能智能体的门槛；开发者可快速接入真实世界 API，普通用户未来将体验到更强大、可操作的 AI 助手。",
      "summaryEn": "Composio offers over 1,000 integrated tools, tool search, context management, authentication, and a sandboxed workbench to help developers build AI agents that turn user intent into actionable outcomes. It addresses the fragmentation and complexity of tool integration in agent development, lowering the barrier to creating capable, multi-functional AI agents. Developers can rapidly connect to real-world APIs, enabling end users to interact with more powerful and actionable AI assistants in the future.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/7bea0e49bdc3a876139315220ecc5bd8e5ed1548292dd993f05b3d26fc372a1a/ComposioHQ/composio",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：Composio整合工具链、上下文管理与沙箱环境，显著降低构建AI Agent门槛，推动Agent生态发展，具备广泛行业应用前景。",
        "热度：27008 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-20T23:36:20.556480+00:00",
      "authors": []
    },
    {
      "id": "rss_0151227448",
      "title": "Hugging Face 联合 Unsloth 推出免费 LLM 微调服务",
      "titleZh": "Hugging Face 联合 Unsloth 推出免费 LLM 微调服务",
      "titleEn": "Hugging Face and Unsloth Offer Free LLM Fine-Tuning with Accelerated Training",
      "url": "https://huggingface.co/blog/unsloth-jobs",
      "type": "news",
      "source": "Hugging Face Blog",
      "summary": "**Hugging Face 与 Unsloth 联合推出免费 LLM 微调计划**，用户可通过 Hugging Face Jobs 使用 Unsloth 技术以约 2 倍速度和 60% 更少显存训练小模型（如 LFM2.5-1.2B-Instruct），并获赠免费算力额度；此举大幅降低高质量微调门槛，推动小模型在端侧部署；开发者可快速迭代定制模型，普通用户未来能在手机或电脑上运行个性化、低延迟的本地 AI 应用。",
      "summaryZh": "**Hugging Face 与 Unsloth 联合推出免费 LLM 微调计划**，用户可通过 Hugging Face Jobs 使用 Unsloth 技术以约 2 倍速度和 60% 更少显存训练小模型（如 LFM2.5-1.2B-Instruct），并获赠免费算力额度；此举大幅降低高质量微调门槛，推动小模型在端侧部署；开发者可快速迭代定制模型，普通用户未来能在手机或电脑上运行个性化、低延迟的本地 AI 应用。",
      "summaryEn": "Hugging Face and Unsloth have launched a free LLM fine-tuning program, offering users free credits to train small models like LFM2.5-1.2B-Instruct on Hugging Face Jobs using Unsloth’s technology—which delivers ~2x faster training and ~60% less VRAM usage. This significantly lowers the barrier to high-quality fine-tuning and accelerates on-device deployment. Developers can rapidly iterate custom models, while everyday users will eventually run personalized, low-latency AI applications directly on phones or laptops.",
      "fullText": "Train AI models with Unsloth and Hugging Face Jobs for FREE Hugging Face Models Datasets Spaces Community Docs Enterprise Pricing Log In Sign Up Back to Articles Train AI models with Unsloth and Hugging Face Jobs for FREE Published February 20, 2026 Update on GitHub Upvote 45 +39 ben burtenshaw burtenshaw Follow Daniel (Unsloth) danielhanchen Follow unsloth Michael Han shimmyshimmer Follow unsloth Maxime Labonne mlabonne Follow LiquidAI Daniel van Strien davanstrien Follow shaun smith evalstate Follow You will need Run the Job Installing the Skill Claude Code Codex Anything else Quick Start How It Works Example Training Script Tips for Working with Coding Agents Resources This blog post covers how to use Unsloth and Hugging Face Jobs for fast LLM fine-tuning (specifically LiquidAI/LFM2.5-1.2B-Instruct ) through coding agents like Claude Code and Codex. Unsloth provides ~2x faster training and ~60% less VRAM usage compared to standard methods, so training small models can cost just a few dollars. Why a small model? Small language models like LFM2.5-1.2B-Instruct are ideal candidates for fine-tuning. They are cheap to train, fast to iterate on, and increasingly competitive with much larger models on focused tasks. LFM2.5-1.2B-Instruct runs under 1GB of memory and is optimized for on-device deployment, so what you fine-tune can be served on CPUs, phones, and laptops. You will need We are giving away free credits to fine-tune models on Hugging Face Jobs. Join the Unsloth Jobs Explorers organization to claim your free credits and one-month Pro subscription. A Hugging Face account (required for HF Jobs) Billing setup (for verification, you can monitor your usage and manage your billing in your billing page ). A Hugging Face token with write permissions (optional) A coding agent ( Open Code , Claude Code , or Codex ) Run the Job If you want to train a model using HF Jobs and Unsloth, you can simply use the hf jobs CLI to submit a job. First, you need to install the hf CLI. You can do this by running the following command: # mac or linux curl -LsSf https://hf.co/cli/install.sh | bash Next you can run the following command to submit a job: hf jobs uv run https://huggingface.co/datasets/unsloth/jobs/resolve/main/sft-lfm2.5.py \\ --flavor a10g-small \\ --secrets HF_TOKEN \\ -- timeout 4h \\ --dataset mlabonne/FineTome-100k \\ --num-epochs 1 \\ --eval-split 0.2 \\ --output-repo your-username/lfm-finetuned Check out the training script and Hugging Face Jobs documentation for more details. Installing the Skill Hugging Face model training skill lowers barrier of entry to train a model by simply prompting. First, install the skill with your coding agent. Claude Code Claude Code discovers skills through its plugin system , so we need to install the Hugging Face skills first. To do so: Add the marketplace: /plugin marketplace add huggingface/skills Browse available skills in the Discover tab: /plugin Install the model trainer skill: /plugin install hugging-face-model-trainer@huggingface-skills For more details, see the documentation on using the hub with skills or the Claude Code Skills docs . Codex Codex discovers skills through AGENTS.md files and .agents/skills/ directories. Install individual skills with $skill-installer : $skill-installer install https://github.com/huggingface/skills/tree/main/skills/hugging-face-model-trainer For more details, see the Codex Skills docs and the AGENTS.md guide . Anything else A generic install method is simply to clone the skills repository and copy the skill to your agent's skills directory. git clone https://github.com/huggingface/skills.git mkdir -p ~/.agents/skills && cp -R skills/skills/hugging-face-model-trainer ~/.agents/skills/ Quick Start Once the skill is installed, ask your coding agent to train a model: Train LiquidAI/LFM2.5-1.2B-Instruct on mlabonne/FineTome-100k using Unsloth on HF Jobs The agent will generate a training script based on an example in the skill , submit the training to HF Jobs, and provide a monitoring link via Trackio. How It Works Training jobs run on Hugging Face Jobs , fully managed cloud GPUs. The agent: Generates a UV script with inline dependencies Submits it to HF Jobs via the hf CLI Reports the job ID and monitoring URL Pushes the trained model to your Hugging Face Hub repository Example Training Script The skill generates scripts like this based on the example in the skill . # /// script # dependencies = [\"unsloth\", \"trl>=0.12.0\", \"datasets\", \"trackio\"] # /// from unsloth import FastLanguageModel from trl import SFTTrainer, SFTConfig from datasets import load_dataset model, tokenizer = FastLanguageModel.from_pretrained( \"LiquidAI/LFM2.5-1.2B-Instruct\" , load_in_4bit= True , max_seq_length= 2048 , ) model = FastLanguageModel.get_peft_model( model, r= 16 , lora_alpha= 32 , lora_dropout= 0 , target_modules=[ \"q_proj\" , \"k_proj\" , \"v_proj\" , \"out_proj\" , \"in_proj\" , \"w1\" , \"w2\" , \"w3\" , ], ) dataset = load_dataset( \"trl-lib/Capybara\" , split= \"train\" ) trainer = SFTTrainer( model=model, tokenizer=tokenizer, train_dataset=dataset, args=SFTConfig( output_dir= \"./output\" , push_to_hub= True , hub_model_id= \"username/my-model\" , per_device_train_batch_size= 4 , gradient_accumulation_steps= 4 , num_train_epochs= 1 , learning_rate= 2e-4 , report_to= \"trackio\" , ), ) trainer.train() trainer.push_to_hub() Model Size Recommended GPU Approx Cost/hr <1B params t4-small ~$0.40 1-3B params t4-medium ~$0.60 3-7B params a10g-small ~$1.00 7-13B params a10g-large ~$3.00 For a full overview of Hugging Face Spaces pricing, check out the guide here . Tips for Working with Coding Agents Be specific about the model and dataset to use, and include Hub IDs (for example, Qwen/Qwen2.5-0.5B and trl-lib/Capybara ). Agents will search for and validate those combinations. Mention Unsloth explicitly if you want it used. Otherwise, the agent will choose a framework based on the model and budget. Ask for cost estimates before launching large jobs. Request Trackio monitoring for real-time loss curves. Check job status by asking the agent to inspect logs after submission. Resources Hugging Face Skills Repository Free credits for Unsloth Jobs Explorers Unsloth Tutorial on Hugging Face Jobs Example Unsloth Jobs scripts More Articles from our Blog llm fine-tuning open-source Codex is Open Sourcing AI models 72 December 11, 2025 llm fine-tuning open-source Hot We Got Claude to Fine-Tune an Open Source LLM 597 December 4, 2025 Community ApertureQA about 11 hours ago • edited about 11 hours ago postingonediting Reply ApertureQA about 11 hours ago See translation Reply ApertureQA about 11 hours ago See translation Reply Edit Preview Upload images, audio, and videos by dragging in the text input, pasting, or clicking here . Tap or paste here to upload images Comment · Sign up or log in to comment Upvote 45 +33 System theme Company TOS Privacy About Careers Website Models Datasets Spaces Pricing Docs",
      "imageUrl": "https://huggingface.co/blog/assets/unsloth-jobs/thumbnail.png",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：Unsloth 与 Hugging Face 合作提供免费高效微调服务，显著降低小模型训练门槛，推动开发者生态发展，属于实用性强、具广泛影响力的行业进展。",
        "热度：0 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-20T00:00:00+00:00",
      "authors": []
    },
    {
      "id": "github_obra_superpowers",
      "title": "obra/superpowers",
      "titleZh": "obra/superpowers",
      "titleEn": "obra/superpowers",
      "url": "https://github.com/obra/superpowers",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "obra/superpowers 是一个面向智能体（agentic）的技能框架与软件开发方法论，旨在提升 AI 驱动系统的工程化能力，其核心价值在于将抽象的智能体能力转化为可复用、可组合的开发模块，为构建复杂 AI 应用提供结构化路径。",
      "summaryZh": "obra/superpowers 是一个面向智能体（agentic）的技能框架与软件开发方法论，旨在提升 AI 驱动系统的工程化能力，其核心价值在于将抽象的智能体能力转化为可复用、可组合的开发模块，为构建复杂 AI 应用提供结构化路径。",
      "summaryEn": "obra/superpowers is an agentic skills framework and software development methodology designed to enhance the engineering of AI-driven systems by translating abstract agent capabilities into reusable, composable development modules, offering a structured approach for building complex AI applications.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/3ac95a0b4da1047cd02967b7b7374e230820dacc0dc5e54dd2c9e45ad918f0d0/obra/superpowers",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：提出面向软件开发的智能体技能框架，具有构建可执行AI Agent的方法论价值，对开发者生态具实用意义。",
        "热度：56209 / 评论 0"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-20T23:36:11.998375+00:00",
      "authors": []
    },
    {
      "id": "rss_5905994954",
      "title": "OpenAI 首款硬件曝光：带摄像头的 ChatGPT 智能音箱",
      "titleZh": "OpenAI 首款硬件曝光：带摄像头的 ChatGPT 智能音箱",
      "titleEn": "OpenAI’s First Hardware: A ChatGPT-Powered Smart Speaker with Camera",
      "url": "https://www.theverge.com/ai-artificial-intelligence/882077/openai-chatgpt-smart-speaker-camera-glasses-lamp",
      "type": "news",
      "source": "The Verge AI",
      "summary": "**OpenAI 计划于 2027 年 3 月后推出首款硬件产品——一款售价约 200 至 300 美元的带摄像头智能音箱**，该设备能识别附近桌面上的物品和周围对话，并集成类似 Face ID 的面部识别系统用于支付；此举标志着 OpenAI 正式从纯软件公司向 AI 物理交互入口拓展，可能重塑家庭智能设备生态，普通用户未来或可通过语音与视觉指令直接调用 ChatGPT 能力完成日常任务，但需关注隐私与数据安全风险。",
      "summaryZh": "**OpenAI 计划于 2027 年 3 月后推出首款硬件产品——一款售价约 200 至 300 美元的带摄像头智能音箱**，该设备能识别附近桌面上的物品和周围对话，并集成类似 Face ID 的面部识别系统用于支付；此举标志着 OpenAI 正式从纯软件公司向 AI 物理交互入口拓展，可能重塑家庭智能设备生态，普通用户未来或可通过语音与视觉指令直接调用 ChatGPT 能力完成日常任务，但需关注隐私与数据安全风险。",
      "summaryEn": "OpenAI plans to launch its first hardware product—a smart speaker with a camera priced between $200 and $300—no earlier than March 2027; the device will recognize nearby objects and conversations and feature Face ID-like facial recognition for payments, marking OpenAI’s strategic move from pure software into physical AI interfaces that could redefine home smart ecosystems, enabling users to interact with ChatGPT via voice and vision while raising important privacy considerations.",
      "fullText": "OpenAI’s first ChatGPT gadget could be a smart speaker with a camera | The Verge Skip to main content The homepage The Verge The Verge logo. The Verge The Verge logo. Tech Reviews Science Entertainment AI Policy Hamburger Navigation Button The homepage The Verge The Verge logo. Hamburger Navigation Button Navigation Drawer The Verge The Verge logo. Login / Sign Up close Close Search Tech Expand Amazon Apple Facebook Google Microsoft Samsung Business See all tech Reviews Expand Smart Home Reviews Phone Reviews Tablet Reviews Headphone Reviews See all reviews Science Expand Space Energy Environment Health See all science Entertainment Expand TV Shows Movies Audio See all entertainment AI Expand OpenAI Anthropic See all AI Policy Expand Antitrust Politics Law Security See all policy Gadgets Expand Laptops Phones TVs Headphones Speakers Wearables See all gadgets Verge Shopping Expand Buying Guides Deals Gift Guides See all shopping Gaming Expand Xbox PlayStation Nintendo See all gaming Streaming Expand Disney HBO Netflix YouTube Creators See all streaming Transportation Expand Electric Cars Autonomous Cars Ride-sharing Scooters See all transportation Features Verge Video Expand TikTok YouTube Instagram Podcasts Expand Decoder The Vergecast Version History Newsletters Archives Store Verge Product Updates Subscribe Facebook Threads Instagram Youtube RSS The Verge The Verge logo. OpenAI’s first ChatGPT gadget could be a smart speaker with a camera Comments Drawer Comments Loading comments Getting the conversation ready... AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI Gadgets Close Gadgets Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Gadgets News Close News Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All News OpenAI’s first ChatGPT gadget could be a smart speaker with a camera The company might be developing smart glasses and a smart lamp, too. The company might be developing smart glasses and a smart lamp, too. by Jay Peters Close Jay Peters Senior Reporter Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Jay Peters Feb 20, 2026, 4:52 PM UTC Link Share Gift Image: The Verge Jay Peters Close Jay Peters Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Jay Peters is a senior reporter covering technology, gaming, and more. He joined The Verge in 2019 after nearly two years at Techmeme. OpenAI’s first hardware release will be a smart speaker with a camera that will probably cost between $200 and $300, according to The Information . The device will be able to recognize things like “items on a nearby table or conversations people are having in the vicinity,” The Information says, and it will have a Face ID-like facial recognition system so that people can purchase things. OpenAI acquired Jony Ive’s hardware company last May in a deal worth nearly $6.5 billion. Details about their hardware products have been trickling out since then, including that the first device won’t be a wearable and that it won’t be released to customers earlier than March 2027 . Other hardware companies are making a big push into AI gadgets, too — including Apple, Ive’s former employer, which is reportedly making its own smart glasses, an AI-powered pendant, and AirPods with cameras. In addition to the smart speaker, OpenAI is “possibly” working on smart glasses and a smart lamp, The Information reports. (Apple may also be working on a smart lamp .) But OpenAI’s glasses might not hit mass production until 2028, and while OpenAI has made prototypes of gadgets like the smart lamp, The Information says it’s “unclear” if they’ll be released and that OpenAI’s devices plans are in early stages. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Jay Peters Close Jay Peters Senior Reporter Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Jay Peters AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI Gadgets Close Gadgets Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Gadgets News Close News Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All News OpenAI Close OpenAI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All OpenAI Speakers Close Speakers Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Speakers Tech Close Tech Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Tech Most Popular Most Popular The RAM shortage is coming for everything you care about A $10K+ bounty is waiting for anyone who can unplug Ring doorbells from Amazon’s cloud Xbox chief Phil Spencer is leaving Microsoft Read new Microsoft gaming CEO Asha Sharma’s memo on the future of Xbox Meta’s VR metaverse is ditching VR The Verge Daily A free daily digest of the news that matters most. Email (required) Sign Up By submitting your email, you agree to our Terms and Privacy Notice . This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Advertiser Content From This is the title for the native ad More in AI Trump is making coal plants even dirtier as AI demands more energy Amazon blames human employees for an AI coding agent’s mistake The Pitt has a sharp take on AI The AI security nightmare is here and it looks suspiciously like lobster The speech police came for Colbert Play Money no longer matters to AI’s top talent Trump is making coal plants even dirtier as AI demands more energy Justine Calma 8:18 PM UTC Amazon blames human employees for an AI coding agent’s mistake Robert Hart 4:52 PM UTC The Pitt has a sharp take on AI Charles Pulliam-Moore Feb 19 The AI security nightmare is here and it looks suspiciously like lobster Robert Hart Feb 19 The speech police came for Colbert David Pierce Feb 19 Play Money no longer matters to AI’s top talent Nilay Patel Feb 19 Advertiser Content From This is the title for the native ad Top Stories Two hours ago Xbox chief Phil Spencer is leaving Microsoft 4:15 PM UTC Prediction markets want to eat the news Two hours ago SCOTUS rules Trump’s tariffs are illegal — but the fight is far from over 6:17 PM UTC Trump Mobile is just Liberty Mobile in gold foil 3:00 PM UTC The latest skincare fad is rubbing salmon sperm on your face 11:00 AM UTC Will Stancil is agitating in Minneapolis The Verge The Verge logo. Facebook Threads Instagram Youtube RSS Contact Tip Us Community Guidelines Archives About Ethics Statement How We Rate and Review Products Cookie Settings Terms of Use Privacy Notice Cookie Policy Licensing FAQ Accessibility Platform Status © 2026 Vox Media , LLC. All Rights Reserved",
      "imageUrl": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/STK155_OPEN_AI_4_CVirginia_A.png?quality=90&strip=all&crop=0%2C10.742221417566%2C100%2C78.515557164868&w=1200",
      "tags": [
        "LLM",
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：The Verge AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：OpenAI首款硬件产品可能为带摄像头的智能音箱，标志着其从纯软件向端侧AI设备的战略跃迁，具有深远行业影响。",
        "热度：0 / 评论 0"
      ],
      "score": 6.4,
      "publishedAt": "2026-02-20T16:52:03+00:00",
      "authors": [
        "Jay Peters"
      ]
    },
    {
      "id": "rss_4356582031",
      "title": "特朗普废除燃煤电厂排污限制，AI 耗电激增加剧污染风险",
      "titleZh": "特朗普废除燃煤电厂排污限制，AI 耗电激增加剧污染风险",
      "titleEn": "Trump Rolls Back Coal Plant Emission Rules as AI Energy Demand Soars",
      "url": "https://www.theverge.com/science/882288/trump-ai-data-center-power-plant-pollution-mercury-mats",
      "type": "news",
      "source": "The Verge AI",
      "summary": "**特朗普政府废除了拜登时期针对燃煤电厂汞及其他有毒污染物的《汞和空气毒物标准》（MATS）**，此举恰逢美国因新建 AI 数据中心而电力需求激增，可能导致燃煤电厂排放反弹；由于燃煤电厂贡献了美国约一半的汞排放（一种可致儿童神经发育损伤的神经毒素），该政策逆转不仅加剧公共健康风险，也凸显 AI 算力扩张与能源环境政策之间的深层矛盾，普通民众应关注本地空气质量变化并支持清洁能源转型。",
      "summaryZh": "**特朗普政府废除了拜登时期针对燃煤电厂汞及其他有毒污染物的《汞和空气毒物标准》（MATS）**，此举恰逢美国因新建 AI 数据中心而电力需求激增，可能导致燃煤电厂排放反弹；由于燃煤电厂贡献了美国约一半的汞排放（一种可致儿童神经发育损伤的神经毒素），该政策逆转不仅加剧公共健康风险，也凸显 AI 算力扩张与能源环境政策之间的深层矛盾，普通民众应关注本地空气质量变化并支持清洁能源转型。",
      "summaryEn": "The Trump administration has repealed the Biden-era Mercury and Air Toxics Standards (MATS), which regulated toxic emissions from coal-fired power plants—just as U.S. electricity demand surges due to new AI data centers; since coal plants account for roughly half of U.S. mercury emissions—a neurotoxin linked to birth defects and cognitive impairments in children—this deregulation heightens public health risks and exposes the tension between AI’s energy appetite and environmental safeguards, urging citizens to monitor local air quality and advocate for cleaner energy alternatives.",
      "fullText": "Kingston Fossil Plant, a 1.4-gigawatt coal-fired power plant located in Roane County, just outside Kingston, Tennessee on the shore of Watts Bar Lake. | Photo: Getty Images The Trump administration just tossed out Biden-era restrictions on mercury and other toxic pollutants from power plants. It's repealing Mercury and Air Toxics Standards (MATS) just as electricity demand in the US ticks up with the buildout of new AI data centers. Those standards are particularly impactful when it comes to pollution from coal plants responsible for around half of mercury emissions in the US. Mercury is a neurotoxin; high exposure has been linked to birth defects and learning disabilities in children. Exposure can also impact the kidneys and nervous system. Trump's deregulation spree aims to make it easier to quickly constr … Read the full story at The Verge.",
      "imageUrl": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/gettyimages-1140674387.jpg?quality=90&strip=all&crop=0%2C8.6662992559934%2C100%2C82.667401488013&w=1200",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：The Verge AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：特朗普政府撤销AI数据中心关键环保标准，反映全球能源政策与AI扩张之间的深层矛盾，具有重大战略与政策影响力。",
        "热度：0 / 评论 0"
      ],
      "score": 5.9,
      "publishedAt": "2026-02-20T20:18:34+00:00",
      "authors": [
        "Justine Calma"
      ]
    },
    {
      "id": "github_databricks-solutions_ai-dev-kit",
      "title": "databricks-solutions/ai-dev-kit",
      "titleZh": "databricks-solutions/ai-dev-kit",
      "titleEn": "databricks-solutions/ai-dev-kit",
      "url": "https://github.com/databricks-solutions/ai-dev-kit",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "Databricks 推出由现场工程团队开发的 AI 开发工具包（ai-dev-kit），专为构建编码智能体（coding agents）设计，提供标准化组件与最佳实践，帮助开发者在 Databricks 平台上高效构建、测试和部署具备自主编程能力的 AI 代理，加速企业级 AI 工程落地。",
      "summaryZh": "Databricks 推出由现场工程团队开发的 AI 开发工具包（ai-dev-kit），专为构建编码智能体（coding agents）设计，提供标准化组件与最佳实践，帮助开发者在 Databricks 平台上高效构建、测试和部署具备自主编程能力的 AI 代理，加速企业级 AI 工程落地。",
      "summaryEn": "Databricks has released an AI Development Kit (ai-dev-kit) by its Field Engineering team, specifically designed for building coding agents; it offers standardized components and best practices to help developers efficiently construct, test, and deploy autonomous programming-capable AI agents on the Databricks platform, accelerating enterprise AI engineering adoption.",
      "fullText": "",
      "imageUrl": "https://tse3.mm.bing.net/th/id/OIP.6MTAE9GcLykQZBRIwF9jYgAAAA?w=1200&h=630&c=7&r=0&o=5&pid=1.7",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：6/10，理由：Databricks AI开发工具包为编码代理提供支持，属于实用型工程工具，有一定行业相关性但非颠覆性创新。",
        "热度：535 / 评论 0"
      ],
      "score": 6.6,
      "publishedAt": "2026-02-20T23:36:18.351006+00:00",
      "authors": []
    },
    {
      "id": "rss_6314636106",
      "title": "Gemini 3.1 Pro 登顶专业任务榜单，Google 再推强大多模态模型",
      "titleZh": "Gemini 3.1 Pro 登顶专业任务榜单，Google 再推强大多模态模型",
      "titleEn": "Google’s Gemini 3.1 Pro Tops Professional Task Benchmarks with New Capabilities",
      "url": "https://techcrunch.com/2026/02/19/googles-new-gemini-pro-model-has-record-benchmark-scores-again/",
      "type": "news",
      "source": "TechCrunch AI",
      "summary": "**Google 发布 Gemini 3.1 Pro 预览版，在多项权威基准测试中创下新高**，包括专为评估 AI 执行专业任务能力设计的 APEX-Agents 榜单；该模型显著超越前代 Gemini 3，展现出更强的多步推理与知识工作处理能力，标志着大模型正快速向“能干活的智能体”演进，开发者可借此构建更复杂的自动化工作流，普通用户未来将体验到更精准、上下文感知更强的 AI 助手服务。",
      "summaryZh": "**Google 发布 Gemini 3.1 Pro 预览版，在多项权威基准测试中创下新高**，包括专为评估 AI 执行专业任务能力设计的 APEX-Agents 榜单；该模型显著超越前代 Gemini 3，展现出更强的多步推理与知识工作处理能力，标志着大模型正快速向“能干活的智能体”演进，开发者可借此构建更复杂的自动化工作流，普通用户未来将体验到更精准、上下文感知更强的 AI 助手服务。",
      "summaryEn": "Google has released a preview of Gemini 3.1 Pro, which achieves record scores on key benchmarks—including the APEX-Agents leaderboard that evaluates AI performance on real professional tasks—demonstrating significant improvements over Gemini 3 in multi-step reasoning and knowledge work; this advancement accelerates the shift toward capable AI agents, enabling developers to build sophisticated automation workflows and promising end users more accurate, context-aware AI assistance.",
      "fullText": "Google's new Gemini Pro model has record benchmark scores — again | TechCrunch –:–:–:– Save up to $680 on your pass with Super Early Bird rates. REGISTER NOW . Save up to $680 on your Disrupt 2026 pass. Ends February 27. REGISTER NOW . Close TechCrunch Desktop Logo TechCrunch Mobile Logo Latest Startups Venture Apple Security AI Apps Events Podcasts Newsletters Search Submit Site Search Toggle Mega Menu Toggle Topics Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture More from TechCrunch Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us In Brief Posted: 4:55 PM PST · February 19, 2026 Image Credits: Jagmeet Singh / TechCrunch Lucas Ropek Google’s new Gemini Pro model has record benchmark scores — again On Thursday, Google released the newest version of Gemini Pro, its powerful LLM. The model, 3.1, is currently available as a preview and will be generally released soon, the company said. Google’s new model may be one of the most powerful LLMs yet. Onlookers have noted that Gemini 3.1 Pro appears to be a big step up from its predecessor, Gemini 3 — which, upon its release in November, was already considered a highly capable AI tool. On Thursday, Google also shared statistics from independent benchmarks — such as one called Humanity’s Last Exam — that showed it performing significantly better than its previous version. Gemini 3.1 Pro was also praised by Brendan Foody, the CEO of AI startup Mercor, whose benchmarking system, APEX, is designed to measure how well new AI models perform real professional tasks. “Gemini 3.1 Pro is now at the top of the APEX-Agents leaderboard,” Foody said in a social media post , adding that the model’s impressive results show “how quickly agents are improving at real knowledge work.” The release comes as the AI model wars are heating up , and tech companies continue to release increasingly powerful LLMs designed for agentic work and multi-step reasoning. Other major names — including OpenAI and Anthropic — have recently released new models as well. Techcrunch event Save up to $300 or 30% to TechCrunch Founder Summit 1,000+ founders and investors come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately. Offer ends March 13. Save up to $300 or 30% to TechCrunch Founder Summit 1,000+ founders and investors come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately Offer ends March 13. Boston, MA | June 9, 2026 REGISTER NOW Topics AI , AI , Gemini Pro 3.1 , Google , In Brief , Mercor , TC October 13-15 San Francisco, CA Save up to $680 on your pass before February 27. Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders , dive into 200+ sessions , and explore 300+ startups building what’s next. Don’t miss these one-time savings. REGISTER NOW Newsletters See More Subscribe for the industry’s biggest tech news TechCrunch Daily News Every weekday and Sunday, you can get the best of TechCrunch’s coverage. TechCrunch Mobility TechCrunch Mobility is your destination for transportation news and insight. Startups Weekly Startups are the core of TechCrunch, so get our best coverage delivered weekly. StrictlyVC Provides movers and shakers with the info they need to start their day. No newsletters selected. Subscribe By submitting your email, you agree to our Terms and Privacy Notice . Related AI Great news for xAI: Grok is now pretty good at answering questions about Baldur’s Gate Russell Brandom 5 hours ago AI All the important news from the ongoing India AI Impact Summit Ivan Mehta 1 day ago AI OpenAI, Reliance partner to add AI search to JioHotstar Jagmeet Singh 1 day ago Latest in AI Startups The creator economy’s ad revenue problem and India’s AI ambitions Theresa Loconsolo 37 minutes ago Startups Why creators are ditching ad revenue for chocolate bars and fintech acquisitions Theresa Loconsolo Anthony Ha Rebecca Bellan Kirsten Korosec 1 hour ago In Brief Anthropic-funded group backs candidate attacked by rival AI super PAC Rebecca Bellan 3 hours ago X LinkedIn Facebook Instagram youTube Mastodon Threads Bluesky TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Terms of Service Privacy Policy RSS Terms of Use Code of Conduct OpenClaw AI Memory Anthropic WordPress Cohere Tech Layoffs ChatGPT © 2025 TechCrunch Media LLC.",
      "imageUrl": "https://techcrunch.com/wp-content/uploads/2026/01/google-gemini-jagmeet-singh-techcrunch.jpg?resize=1200%2C630",
      "tags": [
        "LLM",
        "Industry",
        "Benchmark"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：TechCrunch AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Gemini 3.1 Pro在基准测试中再次刷新纪录，体现Google在大模型性能上的持续领先，对全球AI技术演进和产业应用具有重大战略影响。",
        "热度：0 / 评论 0"
      ],
      "score": 5.9,
      "publishedAt": "2026-02-20T00:55:22+00:00",
      "authors": [
        "Lucas Ropek"
      ]
    }
  ],
  "stats": {
    "total_papers_ingested": 258,
    "total_news_ingested": 34,
    "l1_papers_passed": 121,
    "l1_news_passed": 27,
    "l2_papers_scored": 50,
    "l2_news_scored": 20,
    "l3_papers_selected": 18,
    "l3_news_selected": 11,
    "news_source_counts": {
      "TechCrunch AI": 14,
      "GitHub Trending": 8,
      "Hacker News": 3,
      "The Verge AI": 3,
      "AWS Machine Learning Blog": 3,
      "Hugging Face Blog": 2,
      "OpenAI Blog": 1
    },
    "rss_source_counts": {
      "TechCrunch AI": 14,
      "The Verge AI": 3,
      "AWS Machine Learning Blog": 3,
      "Hugging Face Blog": 2,
      "OpenAI Blog": 1
    },
    "news_title_source_counts": {
      "making frontier cybersecurity capabilities available to defenders": 1,
      "consistency diffusion language models up to 14x faster no quality loss": 1,
      "nvidia and openai abandon unfinished 100b deal in favour of 30b investment": 1,
      "vxcontrol pentagi": 1,
      "hailtododongo pyrite64": 1,
      "obra superpowers": 1,
      "aquasecurity trivy": 1,
      "posthog posthog": 1,
      "google research timesfm": 1,
      "databricks solutions ai dev kit": 1,
      "composiohq composio": 1,
      "our first proof submissions": 1,
      "trump is making coal plants even dirtier as ai demands more energy": 1,
      "amazon blames human employees for an ai coding agent 8217 s mistake": 1,
      "openai 8217 s first chatgpt gadget could be a smart speaker with a camera": 1,
      "the creator economy s ad revenue problem and india s ai ambitions": 1,
      "why creators are ditching ad revenue for chocolate bars and fintech acquisitions": 1,
      "anthropic funded group backs candidate attacked by rival ai super pac": 1,
      "inscope nabs 14 5m to solve the pain of financial reporting": 1,
      "great news for xai grok is now pretty good at answering questions about baldur s gate": 1,
      "toy story 5 takes aim at creepy ai toys i m always listening": 1,
      "ai s promise to indie filmmakers faster cheaper lonelier": 1,
      "peak xv raises 1 3b doubles down on ai as global vc rivalry in india heats up": 1,
      "techcrunch disrupt 2026 super early bird rates end in 1 week": 1,
      "openai says 18 to 24 year olds account for nearly 50 of chatgpt usage in india": 1,
      "uae s g42 teams up with cerebras to deploy 8 exaflops of compute in india": 1,
      "general catalyst commits 5b to india over five years": 1,
      "google s new gemini pro model has record benchmark scores again": 1,
      "nvidia deepens early stage push into india s ai startup ecosystem": 1,
      "ggml and llama cpp join hf to ensure the long term progress of local ai": 1,
      "train ai models with unsloth and hugging face jobs for free": 1,
      "amazon sagemaker ai in 2025 a year in review part 1 flexible training plans and improvements to price performance for inference workloads": 1,
      "amazon sagemaker ai in 2025 a year in review part 2 improved observability and enhanced features for sagemaker ai model customization and hosting": 1,
      "integrate external tools with amazon quick agents using model context protocol mcp": 1
    },
    "total_papers_deduped": 258,
    "total_news_deduped": 34,
    "news_recent_filtered": 34
  }
}