{
  "date": "2026-02-19",
  "generatedAt": "2026-02-19T23:59:51.627325",
  "introduction": "今日AI领域迎来多重关键进展：OpenAI投入750万美元支持独立对齐研究，凸显AGI安全紧迫性；微软发布媒体真实性技术报告，直面AI伪造内容泛滥危机；Gemini 3.1 Pro发布，强化复杂任务处理能力。论文方面，《AI污染网络导致检索崩溃》揭示生成内容对信息生态的结构性威胁；《Agent Skill Framework》获GitHub Copilot等主流平台采纳，推动小模型在工业场景落地；医疗、自动驾驶、机器人控制等领域亦有多项高影响力成果，涵盖安全验证、实时推理与不确定性建模。",
  "introductionZh": "今日AI领域迎来多重关键进展：OpenAI投入750万美元支持独立对齐研究，凸显AGI安全紧迫性；微软发布媒体真实性技术报告，直面AI伪造内容泛滥危机；Gemini 3.1 Pro发布，强化复杂任务处理能力。论文方面，《AI污染网络导致检索崩溃》揭示生成内容对信息生态的结构性威胁；《Agent Skill Framework》获GitHub Copilot等主流平台采纳，推动小模型在工业场景落地；医疗、自动驾驶、机器人控制等领域亦有多项高影响力成果，涵盖安全验证、实时推理与不确定性建模。",
  "introductionEn": "Today’s AI landscape features pivotal developments: OpenAI commits $7.5M to independent alignment research, underscoring AGI safety urgency; Microsoft releases a comprehensive report on media authenticity amid rising AI-generated disinformation; and Google launches Gemini 3.1 Pro for complex reasoning tasks. Key papers reveal how AI-generated content risks collapsing web retrieval systems, while the Agent Skill Framework gains industry adoption for small-model deployment. Breakthroughs also emerge in medical imaging, autonomous driving, and robotic control—addressing safety verification, real-time video understanding, and uncertainty-aware planning.",
  "longformScript": "今天，AI领域正从多个方向加速演进：一边是巨头们在模型能力、安全机制和基础设施上持续加码，另一边，开源社区与学术界也在探索更实用、更可控的智能体路径。这些动作看似分散，实则共同指向一个核心问题——当AI越来越强大，我们如何确保它既好用，又可信？\n\n首先，安全与对齐问题正在从理论走向制度化投入。OpenAI宣布向“对齐项目”（The Alignment Project）注资750万美元，专门支持独立研究团队探索AI对齐技术。这不仅是资金支持，更是一种信号：随着通用人工智能（AGI）的轮廓逐渐清晰，行业头部玩家开始主动将部分研发权交予外部力量，以避免“自己监管自己”的盲区。与此同时，Anthropic也收紧了Claude的使用规则，明确禁止第三方应用通过用户订阅账户的OAuth凭据接入其模型，强制要求开发者改用API密钥。这一变化看似是技术细节调整，实则反映出大模型公司正试图在开放生态与安全边界之间划出更清晰的红线——未来，任何绕过官方接口的“捷径”都可能被切断。\n\n而在内容真实性这个日益紧迫的战场上，微软发布了《媒体真实性方法实践报告》，系统梳理了当前验证合成内容真伪的技术手段、局限与发展方向。报告坦承，尽管水印、元数据签名等技术已有进展，但在大规模、高保真伪造面前，现有方案仍显脆弱。更关键的是，微软强调“真实性”不能只靠技术解决，还需平台、政策与用户教育协同。这意味着，未来我们看到的视频或音频，或许会附带某种“可信度标签”，但这类标签是否被信任、是否被滥用，将成为新的社会博弈点。对普通人来说，辨别信息真伪的成本可能不会降低，反而需要更强的媒介素养。\n\n模型能力本身也在悄然升级。DeepMind推出的Gemini 3.1 Pro，并非简单堆叠参数，而是针对“复杂任务”重新设计推理架构——比如处理多步骤规划、跨模态整合或模糊指令。这类模型不再满足于给出一个答案，而是试图理解任务背后的意图链条。值得注意的是，Google在同期举办的AI Impact Summit 2026上，不仅发布了这款模型，还宣布了包括美印海底光缆新路由、3000万美元科学影响力挑战在内的全球合作计划。这透露出一个趋势：顶级AI能力正与基础设施、气候科技、政府服务等现实议题深度绑定，AI的价值不再仅由基准测试分数衡量，而要看它能否真正嵌入人类社会的关键系统。\n\n与此同时，轻量化、可落地的智能体框架正在开源社区快速生长。GitHub上两个热门项目值得关注：一个是obra/superpowers提出的“超能力”智能体技能框架，它试图为开发者提供一套模块化工具，让AI代理能像人类一样组合基础技能完成复杂目标；另一个是openclaw/openclaw，标榜以“龙虾方式”打造跨平台个人AI助手——虽命名略显戏谑，但其强调本地运行、隐私优先的设计思路，恰好回应了大众对云端AI过度依赖的隐忧。这些项目或许短期内无法撼动大模型地位，却代表了一种“去中心化智能”的可能性：未来的AI助手，未必来自硅谷巨头，也可能运行在你的笔记本或手机上，只为你服务。\n\n更令人振奋的是，AI正从虚拟世界走向物理交互。MIT与新加坡合作团队受人脑突触启发，开发出一种新型软体机器人控制系统。它结合“结构突触”（离线训练的基础动作库）与“可塑突触”（在线实时调整机制），让机械臂在执行器部分失效或负载突变时仍能稳定工作，轨迹误差降低超过40%。这项突破的意义在于，它首次在同一框架内实现了泛化性、适应性与鲁棒性的统一。想象一下，未来的康复外骨骼或手术机器人，无需每次任务都重新训练，就能像人类肌肉记忆一样灵活应变——这不再是科幻，而是正在实验室成型的现实。\n\n面对今天的这些进展，普通用户或许不必深究技术细节，但值得留意几个信号：一是AI服务的“认证门槛”正在提高，无论是访问模型还是验证内容，合规路径将越来越标准化；二是复杂任务处理能力正从企业级向个人场景渗透，未来你可能用Gemini 3.1 Pro级别的模型规划旅行、管理财务，而不仅限于聊天问答；三是开源与本地化AI的兴起，或许会带来一波“隐私友好型”工具的爆发，如果你对数据上传感到不安，不妨关注这类项目。\n\n今天的AI世界，既在攀登能力高峰，也在加固安全堤坝。模型变得更聪明，但使用规则也更严格；技术更开放，但边界也更清晰。这种张力恰恰说明，行业正在从狂飙突进转向成熟治理。对我们每个人而言，重要的不是追逐最新模型，而是理解这些变化如何重塑我们与技术的关系——毕竟，真正的智能，从来不只是算法的事。",
  "longformScriptZh": "今天，AI领域正从多个方向加速演进：一边是巨头们在模型能力、安全机制和基础设施上持续加码，另一边，开源社区与学术界也在探索更实用、更可控的智能体路径。这些动作看似分散，实则共同指向一个核心问题——当AI越来越强大，我们如何确保它既好用，又可信？\n\n首先，安全与对齐问题正在从理论走向制度化投入。OpenAI宣布向“对齐项目”（The Alignment Project）注资750万美元，专门支持独立研究团队探索AI对齐技术。这不仅是资金支持，更是一种信号：随着通用人工智能（AGI）的轮廓逐渐清晰，行业头部玩家开始主动将部分研发权交予外部力量，以避免“自己监管自己”的盲区。与此同时，Anthropic也收紧了Claude的使用规则，明确禁止第三方应用通过用户订阅账户的OAuth凭据接入其模型，强制要求开发者改用API密钥。这一变化看似是技术细节调整，实则反映出大模型公司正试图在开放生态与安全边界之间划出更清晰的红线——未来，任何绕过官方接口的“捷径”都可能被切断。\n\n而在内容真实性这个日益紧迫的战场上，微软发布了《媒体真实性方法实践报告》，系统梳理了当前验证合成内容真伪的技术手段、局限与发展方向。报告坦承，尽管水印、元数据签名等技术已有进展，但在大规模、高保真伪造面前，现有方案仍显脆弱。更关键的是，微软强调“真实性”不能只靠技术解决，还需平台、政策与用户教育协同。这意味着，未来我们看到的视频或音频，或许会附带某种“可信度标签”，但这类标签是否被信任、是否被滥用，将成为新的社会博弈点。对普通人来说，辨别信息真伪的成本可能不会降低，反而需要更强的媒介素养。\n\n模型能力本身也在悄然升级。DeepMind推出的Gemini 3.1 Pro，并非简单堆叠参数，而是针对“复杂任务”重新设计推理架构——比如处理多步骤规划、跨模态整合或模糊指令。这类模型不再满足于给出一个答案，而是试图理解任务背后的意图链条。值得注意的是，Google在同期举办的AI Impact Summit 2026上，不仅发布了这款模型，还宣布了包括美印海底光缆新路由、3000万美元科学影响力挑战在内的全球合作计划。这透露出一个趋势：顶级AI能力正与基础设施、气候科技、政府服务等现实议题深度绑定，AI的价值不再仅由基准测试分数衡量，而要看它能否真正嵌入人类社会的关键系统。\n\n与此同时，轻量化、可落地的智能体框架正在开源社区快速生长。GitHub上两个热门项目值得关注：一个是obra/superpowers提出的“超能力”智能体技能框架，它试图为开发者提供一套模块化工具，让AI代理能像人类一样组合基础技能完成复杂目标；另一个是openclaw/openclaw，标榜以“龙虾方式”打造跨平台个人AI助手——虽命名略显戏谑，但其强调本地运行、隐私优先的设计思路，恰好回应了大众对云端AI过度依赖的隐忧。这些项目或许短期内无法撼动大模型地位，却代表了一种“去中心化智能”的可能性：未来的AI助手，未必来自硅谷巨头，也可能运行在你的笔记本或手机上，只为你服务。\n\n更令人振奋的是，AI正从虚拟世界走向物理交互。MIT与新加坡合作团队受人脑突触启发，开发出一种新型软体机器人控制系统。它结合“结构突触”（离线训练的基础动作库）与“可塑突触”（在线实时调整机制），让机械臂在执行器部分失效或负载突变时仍能稳定工作，轨迹误差降低超过40%。这项突破的意义在于，它首次在同一框架内实现了泛化性、适应性与鲁棒性的统一。想象一下，未来的康复外骨骼或手术机器人，无需每次任务都重新训练，就能像人类肌肉记忆一样灵活应变——这不再是科幻，而是正在实验室成型的现实。\n\n面对今天的这些进展，普通用户或许不必深究技术细节，但值得留意几个信号：一是AI服务的“认证门槛”正在提高，无论是访问模型还是验证内容，合规路径将越来越标准化；二是复杂任务处理能力正从企业级向个人场景渗透，未来你可能用Gemini 3.1 Pro级别的模型规划旅行、管理财务，而不仅限于聊天问答；三是开源与本地化AI的兴起，或许会带来一波“隐私友好型”工具的爆发，如果你对数据上传感到不安，不妨关注这类项目。\n\n今天的AI世界，既在攀登能力高峰，也在加固安全堤坝。模型变得更聪明，但使用规则也更严格；技术更开放，但边界也更清晰。这种张力恰恰说明，行业正在从狂飙突进转向成熟治理。对我们每个人而言，重要的不是追逐最新模型，而是理解这些变化如何重塑我们与技术的关系——毕竟，真正的智能，从来不只是算法的事。",
  "longformScriptEn": "Today, the AI ecosystem is navigating a critical inflection point—not just in raw capability, but in how we govern, deploy, and trust these systems. As models grow more powerful and agents more autonomous, the industry is shifting from pure performance benchmarks to questions of alignment, authenticity, and real-world robustness. From OpenAI’s major investment in independent safety research to breakthroughs in soft robotics that mimic human adaptability, the focus is increasingly on building AI that’s not only smart but also reliable, verifiable, and responsibly integrated into society.\n\nOne of the most significant developments this week comes from OpenAI, which has committed $7.5 million to The Alignment Project—a new initiative funding independent researchers working on AI alignment. This move signals a growing recognition that safety can’t be left solely to internal corporate teams. By supporting external scrutiny, OpenAI aims to foster more transparent, diverse approaches to ensuring future systems act in accordance with human intent, especially as we edge closer to advanced general intelligence. Meanwhile, Anthropic has tightened its own governance by banning third-party apps from using consumer Claude subscription credentials for authentication. Developers must now use official API keys through platforms like AWS Bedrock or Google Vertex. While this may disrupt some integrations, it underscores a broader trend: foundational model providers are prioritizing security and compliance over open-ended access, reflecting heightened regulatory and operational caution.\n\nAt the same time, the rise of AI-generated content is forcing a reckoning with truth and provenance. Microsoft Research has released a comprehensive report titled “Media Authenticity Methods in Practice,” which examines current tools for detecting synthetic media and verifying content origins. The findings are sobering: while watermarking and metadata standards show promise, they remain vulnerable to manipulation or stripping during distribution. As deepfakes become indistinguishable from reality, the report argues that technical solutions alone won’t suffice—interoperable standards, platform accountability, and user education must work in concert. This isn’t just about preventing misinformation; it’s about preserving the integrity of digital evidence, journalism, and even legal testimony in an era where seeing is no longer believing.\n\nOn the capability front, Google’s DeepMind has unveiled Gemini 3.1 Pro, a model explicitly engineered for complex, multi-step reasoning tasks where simple answers fall short. Unlike earlier iterations optimized for speed or cost, 3.1 Pro targets scenarios like scientific hypothesis generation, legal contract analysis, or strategic planning—domains requiring sustained logical coherence and contextual awareness. Early benchmarks suggest it significantly outperforms predecessors in chain-of-thought accuracy and tool integration. But perhaps more telling is how this aligns with Google’s broader strategy: at the AI Impact Summit 2026, the company announced $30 million in grants for AI-driven scientific discovery, new fiber-optic infrastructure linking the U.S. and India, and a climate tech hub in Bangalore. These moves reveal a pivot from chasing model scale to embedding AI within global infrastructure and high-impact domains like sustainability and public sector innovation.\n\nBeyond software, hardware and embodied intelligence are also leaping forward. Researchers from the Singapore-MIT Alliance have developed a neural control system for soft robots that mimics how human synapses learn and adapt. Their approach uses “structural synapses” to encode foundational movements offline and “plastic synapses” to adjust in real time—without retraining—when faced with disturbances like payload shifts or partial actuator failure. In physical tests, the system cut tracking errors by over 40% and maintained shape accuracy above 92%, even under extreme stress. This isn’t just a robotics milestone; it’s a blueprint for resilient, adaptive machines that could safely assist in surgeries, elder care, or hazardous environments. Complementing this, open-source frameworks like obra/superpowers are gaining traction by offering developers a modular “agentic skills” methodology—essentially a playbook for building task-specific AI agents that combine reasoning, memory, and tool use without bloated architectures. Similarly, the GitHub project openclaw offers a cross-platform personal assistant built on what its creators call the “lobster way”—a philosophy emphasizing minimalism, user control, and local execution over cloud dependency.\n\nSo where do we go from here? Keep an eye on three emerging dynamics. First, the tension between openness and control: as companies lock down API access and fund external alignment research, the balance between innovation and oversight will define who gets to shape AI’s future. Second, the race to authenticate reality—expect coalitions around content provenance standards to accelerate, possibly backed by legislation. Third, the quiet revolution in embodied AI: soft robotics, real-time adaptation, and uncertainty-aware planning may soon bring AI out of chat windows and into the physical world in ways that demand new safety paradigms. For developers, the opportunity lies in building modular, verifiable agents; for policymakers, in ensuring these advances serve public good without entrenching new risks.\n\nIn sum, today’s AI story isn’t just about smarter models—it’s about smarter stewardship. Whether through billion-dollar safety grants, neural-inspired robots, or stricter authentication rules, the field is maturing beyond hype into hard questions of reliability, equity, and real-world impact. The systems we build next won’t just need to be intelligent—they’ll need to be trustworthy. And that, more than any benchmark score, may be the true measure of progress.",
  "audioUrl": "",
  "papers": [
    {
      "id": "arxiv_2602_16136v1",
      "title": "Retrieval Collapses When AI Pollutes the Web",
      "titleZh": "Retrieval Collapses When AI Pollutes the Web",
      "titleEn": "Retrieval Collapses When AI Pollutes the Web",
      "url": "https://arxiv.org/abs/2602.16136v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究揭示了AI生成内容泛滥正引发“检索崩溃”（Retrieval Collapse）：当网络中AI合成内容占比达67%时，搜索结果中80%以上会暴露于此类内容，导致信息源多样性丧失；尽管答案准确性看似稳定，但系统已悄然依赖低质量或对抗性合成证据。实验显示，传统BM25检索器会暴露约19%的有害内容，而基于LLM的排序器具备更强抑制能力，凸显需设计检索感知机制以阻断Web信息质量自我恶化的循环。",
      "summaryZh": "研究揭示了AI生成内容泛滥正引发“检索崩溃”（Retrieval Collapse）：当网络中AI合成内容占比达67%时，搜索结果中80%以上会暴露于此类内容，导致信息源多样性丧失；尽管答案准确性看似稳定，但系统已悄然依赖低质量或对抗性合成证据。实验显示，传统BM25检索器会暴露约19%的有害内容，而基于LLM的排序器具备更强抑制能力，凸显需设计检索感知机制以阻断Web信息质量自我恶化的循环。",
      "summaryEn": "The study identifies 'Retrieval Collapse'—a systemic failure where AI-generated content polluting the web erodes source diversity in search and RAG systems. When 67% of the content pool is AI-generated, over 80% of retrieved results are contaminated, creating a deceptively stable but homogenized evidence base. While answer accuracy appears preserved, reliance on synthetic sources grows silently. Experiments show BM25 exposes ~19% harmful content under adversarial conditions, whereas LLM-based rankers suppress it more effectively, underscoring the need for retrieval-aware safeguards against self-reinforcing quality degradation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "RAG"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：首次系统揭示AI污染对检索系统的结构性威胁，提出“检索坍塌”概念，可能引发全球信息基础设施的重新设计，属历史性警示。",
        "热度：12 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-18T02:01:02+00:00",
      "authors": [
        "Hongyeon Yu",
        "Dongchan Kim",
        "Young-Bum Kim"
      ]
    },
    {
      "id": "arxiv_2602_16653v1",
      "title": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments",
      "titleZh": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments",
      "titleEn": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments",
      "url": "https://arxiv.org/abs/2602.16653v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究系统评估了Agent Skill框架在小语言模型（SLMs）中的适用性，发现参数量约12B–30B的中等规模SLMs能显著受益于该框架，提升任务准确率并减少幻觉；而极小模型难以可靠选择技能。在真实保险理赔数据集上，80B参数的代码专用SLM借助Agent Skill达到闭源模型水平，同时提升GPU效率，为工业场景中因数据安全与成本限制无法依赖公有API的部署提供了可行路径。",
      "summaryZh": "研究系统评估了Agent Skill框架在小语言模型（SLMs）中的适用性，发现参数量约12B–30B的中等规模SLMs能显著受益于该框架，提升任务准确率并减少幻觉；而极小模型难以可靠选择技能。在真实保险理赔数据集上，80B参数的代码专用SLM借助Agent Skill达到闭源模型水平，同时提升GPU效率，为工业场景中因数据安全与成本限制无法依赖公有API的部署提供了可行路径。",
      "summaryEn": "This work systematically evaluates the Agent Skill framework on small language models (SLMs), showing that moderately sized SLMs (12B–30B parameters) substantially benefit from improved task accuracy and reduced hallucinations, while tiny models struggle with skill selection. On a real-world insurance claims dataset, an 80B-parameter code-specialized SLM achieves performance comparable to closed-source baselines with better GPU efficiency, offering a practical deployment path for industrial settings constrained by data security and API costs.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "Industry",
        "Open Source"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出并被主流平台广泛采纳的Agent Skill框架，显著提升小模型在工业场景中的可靠性与效率，是当前AI工程化落地的核心突破。",
        "热度：11 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T17:52:17+00:00",
      "authors": [
        "Yangjie Xu",
        "Lujun Li",
        "Lama Sleem"
      ]
    },
    {
      "id": "arxiv_2602_16512v1",
      "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs",
      "titleZh": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs",
      "titleEn": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs",
      "url": "https://arxiv.org/abs/2602.16512v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为克服现有思维链（CoT）、思维树（ToT）等推理方法静态、不可调优的缺陷，研究提出通用框架Framework of Thoughts（FoT），支持动态构建并优化基于链、树、图的推理结构，内置超参调优、提示优化、并行执行与智能缓存功能；实验证明FoT在实现ToT、GoT和ProbTree时显著加速推理、降低成本并提升任务得分，代码已开源以推动高效动态推理方案发展。",
      "summaryZh": "为克服现有思维链（CoT）、思维树（ToT）等推理方法静态、不可调优的缺陷，研究提出通用框架Framework of Thoughts（FoT），支持动态构建并优化基于链、树、图的推理结构，内置超参调优、提示优化、并行执行与智能缓存功能；实验证明FoT在实现ToT、GoT和ProbTree时显著加速推理、降低成本并提升任务得分，代码已开源以推动高效动态推理方案发展。",
      "summaryEn": "To address the static and suboptimal nature of existing reasoning schemes like Chain/Tree/Graph of Thoughts, the paper introduces Framework of Thoughts (FoT)—a general-purpose foundation for dynamic, optimized reasoning. FoT integrates hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching. Empirical results show FoT significantly speeds up execution, reduces cost, and improves task scores when implementing ToT, GoT, and ProbTree, with code released to foster future development of efficient dynamic reasoning systems.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Reasoning"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Framework of Thoughts整合链、树、图推理结构，实现动态优化推理，是大模型认知能力跃升的关键范式创新，影响深远。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T14:58:25+00:00",
      "authors": [
        "Felix Fricke",
        "Simon Malberg",
        "Georg Groh"
      ]
    },
    {
      "id": "arxiv_2602_16603v1",
      "title": "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving",
      "titleZh": "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving",
      "titleEn": "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving",
      "url": "https://arxiv.org/abs/2602.16603v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对大语言模型服务中预填充阶段的队头阻塞问题，研究提出FlowPrefill系统，通过解耦抢占粒度与调度频率，在保障高优先级请求响应的同时维持吞吐效率；其核心创新包括算子级抢占（利用算子边界实现细粒度中断而不损计算效率）和事件驱动调度（仅在请求到达或完成时触发调度），在真实生产负载下相比现有系统最高提升5.6倍有效吞吐量并满足异构SLO要求。",
      "summaryZh": "针对大语言模型服务中预填充阶段的队头阻塞问题，研究提出FlowPrefill系统，通过解耦抢占粒度与调度频率，在保障高优先级请求响应的同时维持吞吐效率；其核心创新包括算子级抢占（利用算子边界实现细粒度中断而不损计算效率）和事件驱动调度（仅在请求到达或完成时触发调度），在真实生产负载下相比现有系统最高提升5.6倍有效吞吐量并满足异构SLO要求。",
      "summaryEn": "To mitigate head-of-line blocking during the prefill phase of LLM serving, FlowPrefill decouples preemption granularity from scheduling frequency. It introduces Operator-Level Preemption—enabling fine-grained interruption at operator boundaries without efficiency loss—and Event-Driven Scheduling, which triggers decisions only on request arrival/completion. Evaluated on real-world traces, FlowPrefill achieves up to 5.6× higher goodput than state-of-the-art systems while meeting diverse SLOs.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "RAG",
        "Research",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：FlowPrefill创新解耦预填充调度粒度，有效缓解大模型服务中的头阻塞问题，直接提升生产级推理系统的性能与可用性。",
        "热度：12 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T16:57:45+00:00",
      "authors": [
        "Chia-chi Hsieh",
        "Zan Zong",
        "Xinyang Chen"
      ]
    },
    {
      "id": "arxiv_2602_16442v1",
      "title": "Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA",
      "titleZh": "Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA",
      "titleEn": "Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA",
      "url": "https://arxiv.org/abs/2602.16442v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究提出一种基于SoC FPGA的硬件加速事件图神经网络架构，用于处理神经形态音频事件流；在SHD数据集上以仅1/10至1/67的参数量达到92.7%准确率（距SOTA差2.4%），量化模型在相同平台超越FPGA尖峰神经网络19.3%；首次实现端到端事件音频关键词识别，词尾检测准确率达95%，延迟仅10.53微秒，功耗1.18W，为边缘设备提供高能效解决方案。",
      "summaryZh": "研究提出一种基于SoC FPGA的硬件加速事件图神经网络架构，用于处理神经形态音频事件流；在SHD数据集上以仅1/10至1/67的参数量达到92.7%准确率（距SOTA差2.4%），量化模型在相同平台超越FPGA尖峰神经网络19.3%；首次实现端到端事件音频关键词识别，词尾检测准确率达95%，延迟仅10.53微秒，功耗1.18W，为边缘设备提供高能效解决方案。",
      "summaryEn": "The paper presents a hardware-accelerated event-graph neural network on SoC FPGA for neuromorphic audio processing. Using sparse event data from an artificial cochlea, the system achieves 92.7% accuracy on SHD with 10–67× fewer parameters than SOTA. Its quantized model outperforms FPGA-based spiking networks by up to 19.3%. The work also reports the first end-to-end FPGA implementation for event-based keyword spotting, achieving 95% word-end detection accuracy, 10.53μs latency, and 1.18W power—setting a benchmark for energy-efficient edge KWS.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Audio",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：面向边缘计算与神经形态硬件的高效音频处理方案，结合FPGA加速与事件驱动架构，契合全球智能物联网与低功耗AI发展趋势，具产业落地前景。",
        "热度：9 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T13:26:22+00:00",
      "authors": [
        "Kamil Jeziorek",
        "Piotr Wzorek",
        "Krzysztof Blachut"
      ]
    },
    {
      "id": "arxiv_2602_16435v1",
      "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning",
      "titleZh": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning",
      "titleEn": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning",
      "url": "https://arxiv.org/abs/2602.16435v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为提升自动特征工程（AFE）在分布偏移下的鲁棒性，研究提出CAFE框架，将因果发现与多智能体强化学习结合：先学习特征与目标间的稀疏因果图以划分直接/间接影响组，再通过分层多智能体DQN选择因果组与变换操作；在15个基准测试中性能提升最高7%，在协变量偏移下性能下降减少约4倍，并生成更紧凑、解释性更稳定的特征集，证明软因果先验可显著增强AFE的稳健性与效率。",
      "summaryZh": "为提升自动特征工程（AFE）在分布偏移下的鲁棒性，研究提出CAFE框架，将因果发现与多智能体强化学习结合：先学习特征与目标间的稀疏因果图以划分直接/间接影响组，再通过分层多智能体DQN选择因果组与变换操作；在15个基准测试中性能提升最高7%，在协变量偏移下性能下降减少约4倍，并生成更紧凑、解释性更稳定的特征集，证明软因果先验可显著增强AFE的稳健性与效率。",
      "summaryEn": "CAFE reformulates automated feature engineering (AFE) as a causally-guided sequential decision process. It first learns a sparse causal DAG to group features by their influence on the target, then uses a cascading multi-agent DQN with hierarchical rewards to select transformations. Across 15 benchmarks, CAFE improves performance by up to 7%, reduces convergence time, and—under covariate shift—cuts performance drop by ~4× versus non-causal baselines, yielding more compact and interpretable features. This demonstrates that soft causal priors significantly enhance AFE robustness and efficiency.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：将因果引导与多智能体强化学习结合，突破传统特征工程依赖统计的局限，为高鲁棒性AI系统提供新范式，对金融、医疗等关键领域具变革潜力。",
        "热度：12 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T13:12:11+00:00",
      "authors": [
        "Arun Vignesh Malarkkan",
        "Wangyang Ying",
        "Yanjie Fu"
      ]
    },
    {
      "id": "arxiv_2602_15882v1",
      "title": "FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution",
      "titleZh": "FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution",
      "titleEn": "FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution",
      "url": "https://arxiv.org/abs/2602.15882v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决通用视觉语言模型在机器人部署中因长视频历史处理导致的高延迟问题，研究提出FUTURE-VLA架构，将长期控制与未来预测统一为单次序列生成任务，采用时序自适应压缩策略维持恒定推理延迟，同时通过潜在空间自回归同步输出可操作动力学与可视化未来预览；该系统支持人类通过交互式执行门控实时验证行为，在LIBERO、RoboTwin及真实Piper平台上分别达到99.2%、75.4%和78.0%成功率，时空窗口扩展16倍而延迟不变。",
      "summaryZh": "为解决通用视觉语言模型在机器人部署中因长视频历史处理导致的高延迟问题，研究提出FUTURE-VLA架构，将长期控制与未来预测统一为单次序列生成任务，采用时序自适应压缩策略维持恒定推理延迟，同时通过潜在空间自回归同步输出可操作动力学与可视化未来预览；该系统支持人类通过交互式执行门控实时验证行为，在LIBERO、RoboTwin及真实Piper平台上分别达到99.2%、75.4%和78.0%成功率，时空窗口扩展16倍而延迟不变。",
      "summaryEn": "FUTURE-VLA addresses the high latency of long-horizon video processing in robotic VLM deployment by unifying control and forecasting into a single sequence-generation task. It uses temporally adaptive compression to maintain constant inference latency while ingesting extended multi-view histories, and performs latent-space autoregression to jointly output actionable dynamics and visual look-aheads. This enables human-in-the-loop validation via interactive gating. The system achieves 99.2% (LIBERO), 75.4% (RoboTwin), and 78.0% (real-world Piper) success rates with a 16× larger spatiotemporal window at baseline-level latency.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Robotics"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：FUTURE-VLA提出实时执行下的统一轨迹预测框架，直接解决机器人长时序推理延迟难题，具备重大产业落地意义。",
        "热度：14 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-05T14:27:43+00:00",
      "authors": [
        "Jingjing Fan",
        "Yushan Liu",
        "Shoujie Li"
      ]
    },
    {
      "id": "arxiv_2602_16669v1",
      "title": "PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction",
      "titleZh": "PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction",
      "titleEn": "PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction",
      "url": "https://arxiv.org/abs/2602.16669v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对现有高清矢量地图构建方法因随机查询初始化和隐式时序建模导致的时间不一致性问题，研究提出PredMapNet框架，通过语义感知查询生成器初始化空间对齐的查询，并引入历史栅格地图记忆模块显式存储实例级历史轨迹；结合历史引导与短期未来预测模块，利用预测位置作为提示避免不合理推断，在nuScenes和Argoverse2数据集上超越当前最优方法，实现高效且时序一致的在线HD地图构建。",
      "summaryZh": "针对现有高清矢量地图构建方法因随机查询初始化和隐式时序建模导致的时间不一致性问题，研究提出PredMapNet框架，通过语义感知查询生成器初始化空间对齐的查询，并引入历史栅格地图记忆模块显式存储实例级历史轨迹；结合历史引导与短期未来预测模块，利用预测位置作为提示避免不合理推断，在nuScenes和Argoverse2数据集上超越当前最优方法，实现高效且时序一致的在线HD地图构建。",
      "summaryEn": "PredMapNet tackles temporal inconsistency in online HD vector map construction caused by random query initialization and implicit temporal modeling. It introduces a Semantic-Aware Query Generator for spatially aligned initialization, a History Rasterized Map Memory to store instance-level trajectories, and integrates both historical guidance and short-term future prediction—using forecasted locations as hints to avoid implausible outputs. Evaluated on nuScenes and Argoverse2, PredMapNet outperforms SOTA methods with strong efficiency and temporal consistency.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Reasoning"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：PredMapNet实现高精地图的时空一致性在线构建，突破自动驾驶环境建模核心瓶颈，具备全球产业变革潜力。",
        "热度：9 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T18:08:26+00:00",
      "authors": [
        "Bo Lang",
        "Nirav Savaliya",
        "Zhihao Zheng"
      ]
    },
    {
      "id": "arxiv_2602_15884v1",
      "title": "The SLAM Confidence Trap",
      "titleZh": "The SLAM Confidence Trap",
      "titleEn": "The SLAM Confidence Trap",
      "url": "https://arxiv.org/abs/2602.15884v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "论文指出SLAM（同步定位与建图）领域陷入“置信度陷阱”，即过度追求基准分数而忽视对不确定性进行原则性估计，导致系统虽几何精度高却概率不一致且脆弱；作者呼吁将实时、一致的不确定性计算作为核心成功指标，推动范式转变。",
      "summaryZh": "论文指出SLAM（同步定位与建图）领域陷入“置信度陷阱”，即过度追求基准分数而忽视对不确定性进行原则性估计，导致系统虽几何精度高却概率不一致且脆弱；作者呼吁将实时、一致的不确定性计算作为核心成功指标，推动范式转变。",
      "summaryEn": "The paper identifies a 'Confidence Trap' in the SLAM community, where prioritizing benchmark scores over principled uncertainty estimation yields geometrically accurate but probabilistically inconsistent and brittle systems; it advocates a paradigm shift making consistent, real-time uncertainty computation a primary success metric.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Benchmark"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：揭示SLAM领域的“置信度陷阱”，呼吁从精度导向转向概率一致性，具有行业范式变革意义，影响深远。",
        "热度：5 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-05T19:37:24+00:00",
      "authors": [
        "Sebastian Sansoni",
        "Santiago Ramón Tosetti Sanz"
      ]
    },
    {
      "id": "arxiv_2602_16187v1",
      "title": "SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks",
      "titleZh": "SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks",
      "titleEn": "SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks",
      "url": "https://arxiv.org/abs/2602.16187v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究提出SIT-LMPC算法，一种面向迭代任务的安全信息论学习型模型预测控制方法，通过自适应惩罚机制保障约束满足，并利用归一化流从历史轨迹中学习价值函数以实现更丰富的不确定性建模；该算法支持GPU高度并行化，在仿真与硬件实验中均能迭代提升性能并稳健遵守安全约束。",
      "summaryZh": "研究提出SIT-LMPC算法，一种面向迭代任务的安全信息论学习型模型预测控制方法，通过自适应惩罚机制保障约束满足，并利用归一化流从历史轨迹中学习价值函数以实现更丰富的不确定性建模；该算法支持GPU高度并行化，在仿真与硬件实验中均能迭代提升性能并稳健遵守安全约束。",
      "summaryEn": "The paper introduces SIT-LMPC, a safe information-theoretic learning model predictive control algorithm for iterative tasks that uses an adaptive penalty method to ensure safety and leverages normalizing flows to learn a value function from past trajectories for richer uncertainty modeling; designed for highly parallel GPU execution, it demonstrably improves performance iteratively while robustly satisfying constraints in both simulation and hardware experiments.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "3D",
        "Research",
        "Benchmark"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出安全信息论驱动的模型预测控制算法，兼顾安全性与性能，在机器人迭代任务中表现优异，有望成为下一代自主系统核心控制范式。",
        "热度：7 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T05:13:45+00:00",
      "authors": [
        "Zirui Zang",
        "Ahmad Amine",
        "Nick-Marios T. Kokolakis"
      ]
    },
    {
      "id": "arxiv_2602_16073v1",
      "title": "ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios",
      "titleZh": "ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios",
      "titleEn": "ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios",
      "url": "https://arxiv.org/abs/2602.16073v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究推出ScenicRules自动驾驶评测基准，首次结合多目标优先级规则与形式化环境建模，通过分层规则手册编码驾驶目标及其优先关系，并基于Scenic语言构建涵盖多样交通场景和近事故情境的数据集；实验证明其评估指标与人类驾驶判断高度一致，能有效暴露智能体在优先目标上的失败行为。",
      "summaryZh": "研究推出ScenicRules自动驾驶评测基准，首次结合多目标优先级规则与形式化环境建模，通过分层规则手册编码驾驶目标及其优先关系，并基于Scenic语言构建涵盖多样交通场景和近事故情境的数据集；实验证明其评估指标与人类驾驶判断高度一致，能有效暴露智能体在优先目标上的失败行为。",
      "summaryEn": "The work presents ScenicRules, an autonomous driving benchmark that uniquely integrates prioritized multi-objective specifications with formally modeled environments via a Hierarchical Rulebook framework and a compact set of Scenic-encoded scenarios spanning diverse contexts and near-accident situations; experiments show its metrics align well with human judgments and effectively reveal agent failures regarding objective priorities.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent",
        "Open Source",
        "Benchmark"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：构建多目标规范的自动驾驶基准ScenicRules，对安全、合规与效率的平衡提供系统化评估框架，推动行业标准演进。",
        "热度：9 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T22:57:43+00:00",
      "authors": [
        "Kevin Kai-Chun Chang",
        "Ekin Beyazit",
        "Alberto Sangiovanni-Vincentelli"
      ]
    },
    {
      "id": "arxiv_2602_16110v1",
      "title": "OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis",
      "titleZh": "OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis",
      "titleEn": "OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis",
      "url": "https://arxiv.org/abs/2602.16110v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对现有医学大视觉语言模型在CT图像理解中割裂处理切片与体数据的问题，研究提出OmniCT统一模型，通过空间一致性增强、器官级语义对齐和最大规模的MedEval-CT混合评测基准，同时兼顾微观细节敏感性与宏观空间推理能力，在多项临床任务上显著优于现有方法，为跨模态医学影像理解建立新范式。",
      "summaryZh": "针对现有医学大视觉语言模型在CT图像理解中割裂处理切片与体数据的问题，研究提出OmniCT统一模型，通过空间一致性增强、器官级语义对齐和最大规模的MedEval-CT混合评测基准，同时兼顾微观细节敏感性与宏观空间推理能力，在多项临床任务上显著优于现有方法，为跨模态医学影像理解建立新范式。",
      "summaryEn": "Addressing the fragmentation in existing medical LVLMs between slice-level and volumetric CT understanding, OmniCT introduces a unified architecture featuring Spatial Consistency Enhancement, Organ-level Semantic Enhancement, and the large-scale MedEval-CT hybrid benchmark; it achieves state-of-the-art performance across clinical tasks by jointly supporting fine-grained detail sensitivity and holistic spatial reasoning, establishing a new paradigm for cross-modal medical imaging.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "RAG"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：面向CT影像的统一多尺度LVLM OmniCT，推动医学影像智能化分析迈向全面整合，对医疗AI具有深远影响。",
        "热度：17 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T00:42:41+00:00",
      "authors": [
        "Tianwei Lin",
        "Zhongwei Qiu",
        "Wenqiao Zhang"
      ]
    },
    {
      "id": "arxiv_2602_15915v1",
      "title": "MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering",
      "titleZh": "MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering",
      "titleEn": "MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering",
      "url": "https://arxiv.org/abs/2602.15915v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决知识驱动视觉问答中检索知识噪声大、与视觉内容错位的问题，研究提出MaS-VQA框架，采用Mask-and-Select机制联合剪枝无关图像区域与弱相关知识片段，生成高信噪比的多模态知识，并以此引导模型在受限语义空间内激活内部知识，实现显式与隐式知识的互补协同，在多个基准上持续提升答案准确率。",
      "summaryZh": "为解决知识驱动视觉问答中检索知识噪声大、与视觉内容错位的问题，研究提出MaS-VQA框架，采用Mask-and-Select机制联合剪枝无关图像区域与弱相关知识片段，生成高信噪比的多模态知识，并以此引导模型在受限语义空间内激活内部知识，实现显式与隐式知识的互补协同，在多个基准上持续提升答案准确率。",
      "summaryEn": "To address noisy and misaligned retrieved knowledge in knowledge-based VQA, MaS-VQA proposes a Mask-and-Select framework that jointly prunes irrelevant image regions and weakly relevant knowledge fragments to produce high-signal multimodal knowledge, which then guides constrained activation of internal knowledge for complementary explicit-implicit co-modeling, consistently improving accuracy across multiple MLLM backbones on Encyclopedic-VQA and InfoSeek.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "RAG"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出掩码与选择框架提升知识增强视觉问答性能，有效缓解外部知识噪声问题，属当前多模态理解前沿进展。",
        "热度：9 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T04:45:05+00:00",
      "authors": [
        "Xianwei Mao",
        "Kai Ye",
        "Sheng Zhou"
      ]
    },
    {
      "id": "arxiv_2602_15836v1",
      "title": "EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices",
      "titleZh": "EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices",
      "titleEn": "EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices",
      "url": "https://arxiv.org/abs/2602.15836v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为在边缘设备高效部署大型动作模型（LAM）用于导航，研究提出EdgeNav-QE框架，结合QLoRA 4比特量化与动态早退机制，使模型对简单任务提前终止推理、复杂任务保留完整深度；在Habitat-Sim环境中，该方法相比全精度基线降低82.7%延迟和66.7%内存占用，同时保持81.8%导航成功率，并显著优于静态早退方法。",
      "summaryZh": "为在边缘设备高效部署大型动作模型（LAM）用于导航，研究提出EdgeNav-QE框架，结合QLoRA 4比特量化与动态早退机制，使模型对简单任务提前终止推理、复杂任务保留完整深度；在Habitat-Sim环境中，该方法相比全精度基线降低82.7%延迟和66.7%内存占用，同时保持81.8%导航成功率，并显著优于静态早退方法。",
      "summaryEn": "EdgeNav-QE enables efficient edge deployment of Large Action Models (LAMs) for navigation by integrating QLoRA 4-bit quantization with a dynamic early-exit mechanism that terminates inference early for simple tasks while retaining full depth for complex decisions; on Habitat-Sim with Matterport3D, it reduces latency by 82.7% and memory by 66.7% versus full-precision baselines while maintaining an 81.8% success rate, outperforming static early-exit methods by 17.9% in latency.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "3D",
        "Inference",
        "Reasoning",
        "Research"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出QLoRA量化与动态早退方案，显著降低大动作模型在边缘设备上的资源消耗，推动AI在智能导航落地。",
        "热度：12 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-01-12T09:20:53+00:00",
      "authors": [
        "Mengyun Liu",
        "Shanshan Huang",
        "Jianan Jiang"
      ]
    },
    {
      "id": "arxiv_2602_15873v1",
      "title": "Test-Time Adaptation for Tactile-Vision-Language Models",
      "titleZh": "Test-Time Adaptation for Tactile-Vision-Language Models",
      "titleEn": "Test-Time Adaptation for Tactile-Vision-Language Models",
      "url": "https://arxiv.org/abs/2602.15873v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对触觉-视觉-语言（TVL）模型在测试时遭遇异步跨模态分布偏移导致部分模态不可靠的问题，研究提出可靠性感知的测试时自适应框架，通过预测不确定性和扰动响应估计各模态可靠性，据此过滤样本、自适应融合特征并指导优化；在TAG-C等基准上，该方法在严重模态损坏下最高提升49.9%准确率。",
      "summaryZh": "针对触觉-视觉-语言（TVL）模型在测试时遭遇异步跨模态分布偏移导致部分模态不可靠的问题，研究提出可靠性感知的测试时自适应框架，通过预测不确定性和扰动响应估计各模态可靠性，据此过滤样本、自适应融合特征并指导优化；在TAG-C等基准上，该方法在严重模态损坏下最高提升49.9%准确率。",
      "summaryEn": "Addressing asynchronous cross-modal distribution shifts that render some modalities unreliable during test-time adaptation (TTA) for tactile-vision-language (TVL) models, the work proposes a reliability-aware TTA framework that estimates per-modality reliability via prediction uncertainty and perturbation responses to filter samples, adaptively fuse features, and regularize optimization; it achieves up to 49.9% accuracy gains under severe corruptions on TAG-C and other TVL benchmarks.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Robotics"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：针对触觉-视觉-语言模型的测试时自适应方法，解决多模态分布偏移问题，对机器人感知系统可靠性有关键提升。",
        "热度：13 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-01-31T02:26:01+00:00",
      "authors": [
        "Chuyang Ye",
        "Haoxian Jing",
        "Qinting Jiang"
      ]
    },
    {
      "id": "arxiv_2602_16412v1",
      "title": "ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding",
      "titleZh": "ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding",
      "titleEn": "ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding",
      "url": "https://arxiv.org/abs/2602.16412v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为克服多模态大语言模型处理长视频时计算冗余和序列长度二次复杂度的瓶颈，研究提出ReMoRa模型，通过保留稀疏关键帧并引入经去噪细化的运动表征替代连续RGB帧，实现线性可扩展的视频压缩表示；在LongVideoBench等多个长视频理解基准上，ReMoRa显著超越现有方法。",
      "summaryZh": "为克服多模态大语言模型处理长视频时计算冗余和序列长度二次复杂度的瓶颈，研究提出ReMoRa模型，通过保留稀疏关键帧并引入经去噪细化的运动表征替代连续RGB帧，实现线性可扩展的视频压缩表示；在LongVideoBench等多个长视频理解基准上，ReMoRa显著超越现有方法。",
      "summaryEn": "To overcome the computational intractability of processing full RGB streams in long-video understanding with MLLMs, ReMoRa operates directly on compressed representations: sparse keyframes preserve appearance while a denoised, fine-grained motion representation captures temporal dynamics as a compact optical flow proxy, enabling linear scalability with sequence length; it outperforms baselines on LongVideoBench, NExT-QA, and MLVU.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Multimodal",
        "Research",
        "Benchmark"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：面向长视频理解的多模态大模型新架构，解决关键瓶颈问题，具备推动视频AI应用落地的潜力。",
        "热度：15 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T12:37:35+00:00",
      "authors": [
        "Daichi Yashima",
        "Shuhei Kurita",
        "Yusuke Oda"
      ]
    },
    {
      "id": "arxiv_2602_15904v1",
      "title": "A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving",
      "titleZh": "A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving",
      "titleEn": "A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving",
      "url": "https://arxiv.org/abs/2602.15904v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while ...；关键点：A Comprehensive Survey on Deep Learning-Based LiDAR Super-Re；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while ...；关键点：A Comprehensive Survey on Deep Learning-Based LiDAR Super-Re；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while affordable low-resolution sens.... Key takeaway: A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonom. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Inference",
        "Research",
        "Benchmark"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：深度学习超分辨率LiDAR在自动驾驶中的综述，系统梳理关键技术路径，被产业界广泛引用。",
        "热度：13 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-15T22:34:28+00:00",
      "authors": [
        "June Moh Goo",
        "Zichao Zeng",
        "Jan Boehm"
      ]
    },
    {
      "id": "arxiv_2602_16149v1",
      "title": "Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing",
      "titleZh": "Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing",
      "titleEn": "Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing",
      "url": "https://arxiv.org/abs/2602.16149v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "主要内容：Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-...；关键点：Evaluating Demographic Misrepresentation in Image-to-Image P；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryZh": "主要内容：Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-...；关键点：Evaluating Demographic Misrepresentation in Image-to-Image P；为什么重要：这是近期 AI 领域值得关注的进展。",
      "summaryEn": "Main point: Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-guided image-to-image (I2I) ed.... Key takeaway: Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing. Why it matters: this is a notable AI development to track.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Inference"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：首次系统评估图像编辑中的种族偏差问题，引发AI伦理讨论，推动生成式AI公平性标准建设。",
        "热度：13 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T02:47:36+00:00",
      "authors": [
        "Huichan Seo",
        "Minki Hong",
        "Sieun Choi"
      ]
    }
  ],
  "news": [
    {
      "id": "rss_9860578875",
      "title": "Advancing independent research on AI alignment",
      "titleZh": "Advancing independent research on AI alignment",
      "titleEn": "Advancing independent research on AI alignment",
      "url": "https://openai.com/index/advancing-independent-research-ai-alignment",
      "type": "news",
      "source": "OpenAI Blog",
      "summary": "OpenAI commits $7.5M to The Alignment Project to fund independent AI alignment r，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "OpenAI commits $7.5M to The Alignment Project to fund independent AI alignment r，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "OpenAI commits $7.5M to The Alignment Project to fund independent AI alignment research, strengthening global efforts to. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "OpenAI commits $7.5M to The Alignment Project to fund independent AI alignment research, strengthening global efforts to address AGI safety and security risks.",
      "imageUrl": "https://tse1.mm.bing.net/th/id/OIP.b_GktcodOTp_nU5tBgkjXQHaHa?w=1200&h=630&c=7&r=0&o=5&cb=defcache2&pid=1.7&defcache=1",
      "tags": [
        "Industry",
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：OpenAI巨额投入独立对齐研究，体现全球顶级机构对AGI安全的战略布局，具有深远产业与政策影响。",
        "热度：0 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-19T10:00:00+00:00",
      "authors": []
    },
    {
      "id": "hn_47073947",
      "title": "Measuring AI agent autonomy in practice",
      "titleZh": "Measuring AI agent autonomy in practice",
      "titleEn": "Measuring AI agent autonomy in practice",
      "url": "https://www.anthropic.com/research/measuring-agent-autonomy",
      "type": "news",
      "source": "Hacker News",
      "summary": "Measuring AI agent autonomy in practice，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "Measuring AI agent autonomy in practice，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "Measuring AI agent autonomy in practice. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "Skip to main content Skip to footer Research Economic Futures Commitments Learn News Try Claude Societal Impacts Measuring AI agent autonomy in practice Feb 18, 2026 AI agents are here, and already they’re being deployed across contexts that vary widely in consequence, from email triage to cyber espionage . Understanding this spectrum is critical for deploying AI safely, yet we know surprisingly little about how people actually use agents in the real world. We analyzed millions of human-agent interactions across both Claude Code and our public API using our privacy-preserving tool , to ask: How much autonomy do people grant agents? How does that change as people gain experience? Which domains are agents operating in? And are the actions taken by agents risky? We found that: Claude Code is working autonomously for longer. Among the longest-running sessions, the length of time Claude Code works before stopping has nearly doubled in three months, from under 25 minutes to over 45 minutes. This increase is smooth across model releases, which suggests it isn’t purely a result of increased capabilities, and that existing models are capable of more autonomy than they exercise in practice. Experienced users in Claude Code auto-approve more frequently, but interrupt more often. As users gain experience with Claude Code, they tend to stop reviewing each action and instead let Claude run autonomously, intervening only when needed. Among new users, roughly 20% of sessions use full auto-approve, which increases to over 40% as users gain experience. Claude Code pauses for clarification more often than humans interrupt it. In addition to human-initiated stops, agent -initiated stops are also an important form of oversight in deployed systems. On the most complex tasks, Claude Code stops to ask for clarification more than twice as often as humans interrupt it. Agents are used in risky domains, but not yet at scale. Most agent actions on our public API are low-risk and reversible. Software engineering accounted for nearly 50% of agentic activity, but we saw emerging usage in healthcare, finance, and cybersecurity. Below, we present our methodology and findings in more detail, and end with recommendations for model developers, product developers, and policymakers. Our central conclusion is that effective oversight of agents will require new forms of post-deployment monitoring infrastructure and new human-AI interaction paradigms that help both the human and the AI manage autonomy and risk together. We view our research as a small but important first step towards empirically understanding how people deploy and use agents. We will continue to iterate on our methods and communicate our findings as agents are adopted more widely. Studying agents in the wild Agents are difficult to study empirically. First, there is no agreed-upon definition of what an agent is. Second, agents are evolving quickly. Last year, many of the most sophisticated agents—including Claude Code—involved a single conversational thread, but today there are multi-agent systems that operate autonomously for hours. Finally, model providers have limited visibility into the architecture of their customers’ agents. For example, we have no reliable way to associate independent requests to our API into “sessions” of agentic activity. (We discuss this challenge in more detail at the end of this post.) In light of these challenges, how can we study agents empirically? To start, for this study we adopted a definition of agents that is conceptually grounded and operationalizable: an agent is an AI system equipped with tools that allow it to take actions , like running code, calling external APIs, and sending messages to other agents. 1 Studying the tools that agents use tells us a great deal about what they are doing in the world. Next, we developed a collection of metrics that draw on data from both agentic uses of our public API and Claude Code , our own coding agent. These offer a tradeoff between breadth and depth: Our public API gives us broad visibility into agentic deployments across thousands of different customers. Rather than attempting to infer our customers’ agent architectures, we instead perform our analysis at the level of individual tool calls . 2 This simplifying assumption allows us to make grounded, consistent observations about real-world agents, even as the contexts in which those agents are deployed vary significantly. The limitation of this approach is that we must analyze actions in isolation, and cannot reconstruct how individual actions compose into longer sequences of behavior over time. Claude Code offers the opposite tradeoff. Because Claude Code is our own product, we can link requests across sessions and understand entire agent workflows from start to finish. This makes Claude Code especially useful for studying autonomy—for example, how long agents run without human intervention, what triggers interruptions, and how users maintain oversight over Claude as they develop experience. However, because Claude Code is only one product, it does not provide the same diversity of insight into agentic use as API traffic. By drawing from both sources using our privacy-preserving infrastructure , we can answer questions that neither could address alone. Claude Code is working autonomously for longer How long do agents actually run without human involvement? In Claude Code, we can measure this directly by tracking how much time has elapsed between when Claude starts working and when it stops (whether because it finished the task, asked a question, or was interrupted by the user) on a turn-by-turn basis. 3 Turn duration is an imperfect proxy for autonomy. 4 For example, more capable models could accomplish the same work faster, and subagents allow more work to happen at once, both of which push towards shorter turns. 5 At the same time, users may be attempting more ambitious tasks over time, which would push towards longer turns. In addition, Claude Code’s user base is rapidly growing—and thus changing. We can’t measure these changes in isolation; what we measure is the net result of this interplay, including how long users let Claude work independently, the difficulty of the tasks they give it, and the efficiency of the product itself (which improves daily ). Most Claude Code turns are short. The median turn lasts around 45 seconds, and this duration has fluctuated only slightly over the past few months (between 40 and 55 seconds). In fact, nearly every percentile below the 99th has remained relatively stable. 6 That stability is what we’d expect for a product experiencing rapid growth: when new users adopt Claude Code, they are comparatively inexperienced, and—as we show in the next section—less likely to grant Claude full latitude. The more revealing signal is in the tail. The longest turns tell us the most about the most ambitious uses of Claude Code, and point to where autonomy is heading. Between October 2025 and January 2026, the 99.9th percentile turn duration nearly doubled, from under 25 minutes to over 45 minutes (Figure 1). Figure 1. 99.9th percentile turn duration (how long Claude works on a per-turn basis) in interactive Claude Code sessions, 7-day rolling average. The 99.9th percentile has grown steadily from under 25 minutes in late September to over 45 minutes in early January. This analysis reflects all interactive Claude Code usage. Notably, this increase is smooth across model releases. If autonomy were purely a function of model capability, we would expect sharp jumps with each new launch. The relative steadiness of this trend instead suggests several potential factors are at work, including power users building trust with the tool over time, applying Claude to increasingly ambitious tasks, and the product itself improving. The extreme turn duration has declined somewhat since mid-January. We hypothesize a few reasons why. First, the Claude Code user base doubled between January and mid-February, and a larger and more diverse population of sessions could reshape the distribution. Second, as users returned from the holiday break, the projects they brought to Claude Code may have shifted from hobby projects to more tightly circumscribed work tasks. Most likely, it’s a combination of these factors and others we haven’t identified. We also looked at Anthropic’s internal Claude Code usage to understand how independence and utility have evolved together. From August to December, Claude Code’s success rate on internal users’ most challenging tasks doubled, at the same time that the average number of human interventions per session decreased from 5.4 to 3.3. 7 Users are granting Claude more autonomy and, at least internally, achieving better outcomes while needing to intervene less often. Both measurements point to a significant deployment overhang, where the autonomy models are capable of handling exceeds what they exercise in practice. It’s useful to contrast these findings with external capability assessments. One of the most widely cited capability assessments is METR’s “Measuring AI Ability to Complete Long Tasks,” which estimates that Claude Opus 4.5 can complete tasks with a 50% success rate that would take a human nearly 5 hours . The 99.9th percentile turn duration in Claude Code, in contrast, is ~42 minutes, and the median is much shorter. However, the two metrics are not directly comparable. The METR evaluation captures what a model is capable of in an idealized setting with no human interaction and no real-world consequences. Our measurements capture what happens in practice, where Claude pauses to ask for feedback and users interrupt. 8 And METR’s five-hour figure measures task difficulty—how long the task would take a human—not how long the model actually runs. Neither capability evaluations nor our measurements alone give a complete picture of agent autonomy, but together they suggest that the latitude granted to models in practice lags behind what they can handle. Experienced users in Claude Code auto-approve more frequently, but interrupt more often How do humans adapt how they work with agents over time? We found that people grant Claude Code more autonomy as they gain experience using it (Figure 2). Newer users (<50 sessions) employ full auto-approve roughly 20% of the time; by 750 sessions, this increases to over 40% of sessions. This shift is gradual, suggesting a steady accumulation of trust. It’s also important to note that Claude Code’s default settings require users to manually approve each action, so part of this transition may reflect users configuring the product to match their preferences for greater independence as they become familiar with Claude’s capabilities. Figure 2. Auto-approve rate by account tenure. Experienced users increasingly let Claude run without any manual approval. Data reflects all interactive Claude Code usage for users who signed up after September 19, 2025. Line and CI bounds are LOWESS-smoothed (0.15 bandwidth). The x-axis is a log scale. Approving actions is only one method of supervising Claude Code. Users can also interrupt Claude while it is working to provide feedback. We find that interrupt rates increase with experience. New users (those with around 10 sessions) interrupt Claude in 5% of turns, while more experienced users interrupt in around 9% of turns (Figure 3). Figure 3. Interrupt rates by account tenure on a turn-by-turn basis. Experienced users interrupt Claude more often, not less. Data reflects all interactive Claude Code usage for users who signed up after September 19, 2025. Shaded region shows 95% Wilson score confidence interval. Line and CI bounds are LOWESS-smoothed (0.15 bandwidth). The x-axis is a log scale. Both interruptions and auto-approvals increase with experience. This apparent contradiction reflects a shift in users’ oversight strategy. New users are more likely to approve each action before it’s taken, and therefore rar",
      "imageUrl": "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa86a9559ec987a33340c265265463843846ad8c7-3840x2160.png&w=3840&q=75",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：首次大规模实证研究AI代理自主性，揭示真实世界中代理行为模式，对安全部署和模型设计具有显著实践指导意义。",
        "热度：69 / 评论 32"
      ],
      "score": 9.95,
      "publishedAt": "2026-02-19T14:14:14+00:00",
      "authors": [
        "jbredeche"
      ]
    },
    {
      "id": "rss_1662003939",
      "title": "Media Authenticity Methods in Practice: Capabilities, Limitations, and Directions",
      "titleZh": "Media Authenticity Methods in Practice: Capabilities, Limitations, and Directions",
      "titleEn": "Media Authenticity Methods in Practice: Capabilities, Limitations, and Directions",
      "url": "https://www.microsoft.com/en-us/research/blog/media-authenticity-methods-in-practice-capabilities-limitations-and-directions/",
      "type": "news",
      "source": "Microsoft Research",
      "summary": "As synthetic media grows, verifying what’s real, and the origin of content, matt，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "As synthetic media grows, verifying what’s real, and the origin of content, matt，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "As synthetic media grows, verifying what’s real, and the origin of content, matters more than ever. Our latest report ex. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "Insights from Microsoft’s Media Integrity and Authentication: Status, Directions, and Futures report It has become increasingly difficult to distinguish fact from fiction when viewing online images and videos. Resilient, trustworthy technologies can help people determine whether the content they are viewing was captured by a camera or microphone—or generated or modified by AI tools.&nbsp; We refer to technologies aimed at helping viewers verify the source and history—that is, the provenance—of digital content as media integrity and authentication (MIA) methods. This technique, driven by the Coalition for Content Provenance and Authenticity (opens in new tab) (C2PA), a standards body dedicated to scaling these capabilities, as well as complementary methods such as watermarks and fingerprinting, have become critically important with the rapid advance of AI systems capable of creating, realistic imagery, video, and audio at scale. A convergence of forces Our team recognized an inflection point in the evolution of online content integrity, driven by the convergence of four forces: Growing saturation of synthetic media, driven by proliferation of high-fidelity content-generation tools and the explosion of AI generated or modified media online Forthcoming legislation both nationally and internationally seeking to define what “verifiable” provenance should mean in practice Mounting pressure on implementers to ensure authentication signals are clear and helpful, especially as signals increase when legislation goes into effect in 2026 Heightened awareness of&nbsp;potential&nbsp;adversarial attacks that attempt to exploit weaknesses in authenticity systems The usefulness and trustworthiness of provenance signals, whether certifying content as synthetic or as an authentic capture of real-world scenes, will depend not only on advances in technology, but also on how the broader digital ecosystem adopts, implements, and governs these tools. Aligning around implementation choices that promote consistency and clarity is essential to ensure transparency signals strengthen, rather than erode, public confidence. To address these challenges, we launched a comprehensive evaluation of the real-world limits, edge cases, and emerging “attack surfaces” for MIA methods. Today, we are publishing our findings in the Media Integrity & Authentication: Status, Directions & Futures report. The report distills lessons learned and outlines practical directions for strengthening media integrity in the years ahead. PODCAST SERIES The AI Revolution in Medicine, Revisited Join Microsoft’s Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine. Listen now Opens in a new tab Findings and directions forward Our research recognizes that different media integrity and authenticity methods serve differing purposes and offer distinct levels of protection. After defining each method in detail, we focused on secure provenance (C2PA), imperceptible watermarking, and soft hash fingerprinting across images, audio, and video. Grounded in our evaluation of these MIA methods across modalities, attack categories, and real-world workflows, several new findings emerged including two new concepts: High-Confidence Provenance Authentication: a&nbsp;critical capability for verifying, under defined conditions, whether claims about the origin of and modifications made to an asset can be&nbsp;validated&nbsp;with high certainty. Sociotechnical Provenance Attacks: attacks aimed at deception and capable of inverting signals, making authentic content appear synthetic, and synthetic content appear authentic. Drawing on our findings, we identified four promising directions for further strengthening media authentication, along with suggestions to support more effective implementation strategies and future decisions. We’ve summarized the findings and directions below, with additional detail available in the report. Promising directionsHigh-level findingsDelivering high-confidence provenance authentication&#8211; Implementation and display choices may affect the reliability of provenance indicators and how they are interpreted by the public. &#8211; Using a C2PA provenance manifest for media created and signed in a high security environment enables high-confidence validation. &#8211; High-confidence validation is also possible across a broader volume of images, audio, and video when an imperceptible watermark is linked to C2PA provenance manifest as an additional layer to recover the provenance information if removed. &#8211; Fingerprinting is not an enabler for high-confidence validation and can involve significant costs when expected at scale. However, it can support manual forensics.Mitigating confusion from sociotechnical provenance attacks&#8211; MIA methods are susceptible to sociotechnical attacks on provenance that may mislead the public, resulting in confusion and misplaced trust about an asset’s provenance if there is an overreliance on low-quality signals.&#8211; Layering and linking secure provenance and imperceptible watermarking methods to achieve high confidence validation also offers a promising option to both deter and mitigate the impact of attacks.&#8211; Unintended consequences may result from the use of methods lacking authentication, such as the use of perceptible watermarks in the absence of secure provenance. Perceptible watermarks may cause confusion in cases of forgery or discourage people from consulting high-confidence provenance information via a validation tool, if such perceptible disclosures are taken at face value. &#8211; UX design that enables users to explore manifest details—such as where edits occurred&nbsp;or region of interest—has the potential to&nbsp;reduce confusion and&nbsp;support forensics and fact checking efforts.&nbsp;&nbsp;Enabling more trusted provenance on edge devices&#8211; High-confidence results aren&#8217;t feasible when provenance is added by a conventional offline device (e.g., camera or recording device without connectivity).&#8211; Implementing a secure enclave within the hardware layer of offline devices is essential to make the provenance of captured images, audio, and video more trustworthy.Investing in ongoing research and policy development&#8211; All three methods offer organizations&nbsp;valuable tools for addressing operational challenges&nbsp;such as fraud prevention, risk management, and digital accountability.&nbsp;&#8211; UX and display&nbsp;are promising directions for research. Important directions include in-stream tools that display provenance information where people are&nbsp;and&nbsp;distinguish&nbsp;between&nbsp;high- and lower-confidence&nbsp;provenance signals.&#8211; Stakeholders&nbsp;should&nbsp;conduct ongoing analysis and red teaming&nbsp;to&nbsp;identify&nbsp;and mitigate weaknesses&nbsp;through&nbsp;technical approaches,&nbsp;policies, and&nbsp;laws.&nbsp;&nbsp;&nbsp; The journey continues This report marks the beginning of a new chapter in our media provenance journey (opens in new tab), building on years of foundational work, from developing the very first prototype in 2019 to co-founding the C2PA in 2021 and helping catalyze an ecosystem that has since grown to more than 6,000 members and affiliates (opens in new tab) supporting C2PA Content Credentials. This research represents the next evolution of that long‑standing commitment. We hope that by sharing our learnings will help others prepare for an important wave, especially as generative technologies accelerate and provenance signals multiply. This work is already underway across our products at Microsoft. Together, these directions highlight opportunities for the ecosystem to align, harden, and innovate, so authentication signals are not merely visible, but robust, meaningful, and resilient throughout the content lifecycle. Opens in a new tabThe post Media Authenticity Methods in Practice: Capabilities, Limitations, and Directions appeared first on Microsoft Research.",
      "imageUrl": "https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/MediaIntegrityReport-TWLIFB-1200x627-1.jpg",
      "tags": [
        "Vision",
        "Audio",
        "Industry",
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：微软发布权威媒体真实性报告，系统性分析合成内容治理框架，推动全球数字可信生态建设。",
        "热度：0 / 评论 0"
      ],
      "score": 9.5,
      "publishedAt": "2026-02-19T16:00:51+00:00",
      "authors": [
        "Eric Horvitz, Andrew Jenks, Jessica Young"
      ]
    },
    {
      "id": "rss_4814811816",
      "title": "Gemini 3.1 Pro: A smarter model for your most complex tasks",
      "titleZh": "Gemini 3.1 Pro: A smarter model for your most complex tasks",
      "titleEn": "Gemini 3.1 Pro: A smarter model for your most complex tasks",
      "url": "https://deepmind.google/blog/gemini-3-1-pro-a-smarter-model-for-your-most-complex-tasks/",
      "type": "news",
      "source": "DeepMind Blog",
      "summary": "3.1 Pro is designed for tasks where a simple answer isn’t enough.，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "3.1 Pro is designed for tasks where a simple answer isn’t enough.，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "3.1 Pro is designed for tasks where a simple answer isn’t enough.. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "Gemini 3.1 Pro: A smarter model for your most complex tasks",
      "imageUrl": "https://lh3.googleusercontent.com/bZ8aFD7yMP8ue-XfAwrEMPDLgVua4ThZvdZu9mFYcsQTk0QVfc_kd2ygbXCCmTOR6dTvw6FhCkzc55j7-rUW_cYHnsOzmPHrzzJqDLTCCrhnCrOQkg=w528-h297-n-nu-rw-lo",
      "tags": [
        "LLM"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：Gemini 3.1 Pro定位复杂任务优化，反映主流大模型向高阶推理演进，具备行业标杆意义。",
        "热度：0 / 评论 0"
      ],
      "score": 9.4,
      "publishedAt": "2026-02-19T16:06:14+00:00",
      "authors": []
    },
    {
      "id": "rss_1466549133",
      "title": "Survey Reveals AI Advances in Telecom: Networks and Automation in Driver’s Seat as Return on Investment Climbs",
      "titleZh": "Survey Reveals AI Advances in Telecom: Networks and Automation in Driver’s Seat as Return on Investment Climbs",
      "titleEn": "Survey Reveals AI Advances in Telecom: Networks and Automation in Driver’s Seat as Return on Investment Climbs",
      "url": "https://blogs.nvidia.com/blog/ai-in-telco-survey-2026/",
      "type": "news",
      "source": "NVIDIA Blog",
      "summary": "AI is accelerating the telecommunications industry’s transformation, becoming th，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "AI is accelerating the telecommunications industry’s transformation, becoming th，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "AI is accelerating the telecommunications industry’s transformation, becoming the backbone of autonomous networks and AI. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "AI is accelerating the telecommunications industry’s transformation, becoming the backbone of autonomous networks and AI-native wireless infrastructure. At the same time, the technology is unlocking new business and revenue opportunities, as telecom operators accelerate AI adoption across consumers, enterprises and nations. NVIDIA’s fourth annual “State of AI in Telecommunications” survey report unpacks these trends, underscoring strong AI adoption, impact and investment in the industry. Highlights from the report include: 90% said AI is helping increase annual revenue and drive down costs. 77% said they expect to see AI-native networks launch before the deployment of 6G. 65% of telecom operators said network automation is being driven by AI. 60% said their organization is using or assessing generative AI, up from 49% in 2024. 89% said open source models and software are important to their AI strategy. 89% of telcos plan to boost AI spending in 2026, up from 65% a year ago. “There is a seismic shift underway in the telecom industry driven by AI,” said Sebastian Barros, managing director of Circles, a Singapore-based telecommunications provider. “Communication service providers are converging on a new realization. Their role in society extends beyond moving bits across networks toward moving intelligence across local and regulated infrastructure. That transition defines the move from telco to ‘AICO’ — AI infrastructure companies operating at network proximity, not application vendors riding on top.” Here are some more key findings from the report. Tangible Revenue Impact and Return on Investment The telecommunications industry is seeing a definitive revenue impact from the use of AI. Overall, about nine out of 10 respondents said AI is helping to increase revenue and reduce costs. Telecommunications operators, which represent about a quarter of the 1,000 responses in the survey, are also seeing the benefit, with 90% saying AI has had a positive impact on revenue and costs. The top AI use cases cited for return on investment (ROI) were AI for autonomous networks (50%), followed by improved customer service (41%) and internal process optimization (33%). “Autonomous networks deliver immediate ROI by eliminating human effort from repetitive, reactive workflows,” said Barros. “The fastest impact areas are energy management, fault prediction, configuration drift correction and capacity planning.” This strong impact on revenue and ROI is leading telecommunications companies to increase their AI budgets in 2026. Overall, 89% of respondents said their AI budget will increase in the next 12 months, up from 65% in last year’s survey, with 35% saying their budgets would increase more than 10% from this year. Focus on AI-Native Networks and Autonomous Operations Network automation has overtaken customer experience as the leading use case for investment, deployment and ROI impact. This signals a bold step toward autonomous networks — AI-driven, self-managing systems that can self-configure, self-heal and self-optimize with minimal human intervention. Eighty-eight percent of organizations report being between levels 1-3 of autonomy, as defined by the TM Forum, and the use of generative AI and agentic AI is expected to accelerate the shift to level 5 autonomous networks. “Autonomous networks are delivering return on investment faster than any other AI use case because they directly reduce outages, energy consumption and manual intervention,” said Chetan Sharma, CEO of Chetan Sharma Consulting. “Agentic AI accelerates this by coordinating decisions across domains in real time.” A surge in edge computing investment is reshaping telecom network architectures, bringing AI inferencing closer to users through a distributed computing infrastructure. Telcos are stepping up investments in AI-native RAN and 6G — signaling a major industry intercept ahead of the traditional 6G deployment cycle, with 77% of respondents anticipating a much faster time to deployment of this new AI-native wireless network architecture. The top drivers of investment are using AI to enhance spectral efficiency, improving the performance of the radio access network supporting edge AI applications and accelerating the research and development of 6G. A Universal Boost in Productivity AI in telecommunications is advancing autonomous networks and business opportunities as well as improving internal operations. Nearly every respondent in the survey said AI is boosting employee productivity, with 26% citing major to significant improvements to their ability to complete more tasks with higher quality in less time. The productivity gains are coming from generative and agentic AI solutions deployed across operations, from the back office to networks. “Generative AI delivered fast productivity gains, but agentic AI is where telecoms begin to see structural ROI,” Sharma said. “Autonomous agents can act across networks, IT and customer journeys, turning insights into decisions without human delay.” Download the “State of AI in Telecommunications 2026 Trends” report for in-depth results and insights. Explore NVIDIA AI technologies for telecommunications.",
      "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2026/02/telco-corp-blog-2026-state-of-ai-report-1280x680-1.jpeg",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：NVIDIA调查揭示电信业AI深度渗透趋势，数据详实且指向6G前AI网络转型，具有重大产业变革信号。",
        "热度：0 / 评论 0"
      ],
      "score": 8.9,
      "publishedAt": "2026-02-19T14:00:45+00:00",
      "authors": [
        "Kanika Atri"
      ]
    },
    {
      "id": "hn_47074735",
      "title": "Gemini 3.1 Pro",
      "titleZh": "Gemini 3.1 Pro",
      "titleEn": "Gemini 3.1 Pro",
      "url": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/",
      "type": "news",
      "source": "Hacker News",
      "summary": "Gemini 3.1 Pro，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryZh": "Gemini 3.1 Pro，该事件带来新的技术/监管/产品变化，并将改变AI领域的将影响AI模型能力、成本或应用边界，同时意味着普通人可能在工具可用性、价格或隐私体验上感知变化。",
      "summaryEn": "Gemini 3.1 Pro. This matters because it may reshape AI capability, cost, or deployment choices, and can affect how end users use AI tools.",
      "fullText": "Gemini 3.1 Pro: Announcing our latest Gemini AI model Skip to main content The Keyword Gemini 3.1 Pro: A smarter model for your most complex tasks Share x.com Facebook LinkedIn Mail Copy link Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Subscribe Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) MENA (English) Nederlands (Nederland) New Zealand (English) Polska (Polski) Portugal (Português) Sverige (Svenska) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文) [\"What does AI mean for retail?\", \"How did Nano Banana get its name?\", \"How can AI help me plan travel?\"] Subscribe The Keyword Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Images RSS feed Subscribe Breadcrumb Innovation & AI Models & research Gemini Models Gemini 3.1 Pro: A smarter model for your most complex tasks Feb 19, 2026 · Share x.com Facebook LinkedIn Mail Copy link 3.1 Pro is designed for tasks where a simple answer isn’t enough. The Gemini Team Read AI-generated summary General summary Gemini 3.1 Pro is here to help you tackle complex tasks. The upgraded core intelligence is rolling out across consumer and developer products. You can access 3.1 Pro through the Gemini API, Vertex AI, the Gemini app, and NotebookLM. Summaries were generated by Google AI. Generative AI is experimental. Bullet points \"Gemini 3.1 Pro: A smarter model for your most complex tasks\" introduces Google's upgraded AI model. Gemini 3.1 Pro is rolling out to developers, enterprises, and consumers via various platforms. This new model shows improved reasoning, scoring significantly higher on complex problem-solving benchmarks. It's designed for tasks needing advanced reasoning, like synthesizing data or explaining complex topics. Google is releasing 3.1 Pro in preview to validate updates and advance agentic workflows further. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: General summary Bullet points Share x.com Facebook LinkedIn Mail Copy link Your browser does not support the audio element. Listen to article This content is generated by Google AI. Generative AI is experimental [[duration]] minutes Voice Speed Voice Speed 0.75X 1X 1.5X 2X Last week, we released a major update to Gemini 3 Deep Think to solve modern challenges across science, research and engineering. Today, we’re releasing the upgraded core intelligence that makes those breakthroughs possible: Gemini 3.1 Pro. We are shipping 3.1 Pro across our consumer and developer products to bring this progress in intelligence to your everyday applications. Starting today, 3.1 Pro is rolling out: For developers in preview via the Gemini API in Google AI Studio , Gemini CLI , our agentic development platform Google Antigravity and Android Studio For enterprises in Vertex AI and Gemini Enterprise For consumers via the Gemini app and NotebookLM Building on the Gemini 3 series, 3.1 Pro represents a step forward in core reasoning. 3.1 Pro is a smarter, more capable baseline for complex problem-solving. This is reflected in our progress on rigorous benchmarks. On ARC-AGI-2, a benchmark that evaluates a model’s ability to solve entirely new logic patterns, 3.1 Pro achieved a verified score of 77.1%. This is more than double the reasoning performance of 3 Pro. Intelligence applied 3.1 Pro is designed for tasks where a simple answer isn’t enough, taking advanced reasoning and making it useful for your hardest challenges. This improved intelligence can help in practical applications — whether you’re looking for a clear, visual explanation of a complex topic, a way to synthesize data into a single view, or bringing a creative project to life. Code-based animation: 3.1 Pro can generate website-ready, animated SVGs directly from a text prompt. Because these are built in pure code rather than pixels, they remain crisp at any scale and maintain incredibly small file sizes compared to traditional video. Complex system synthesis: 3.1 Pro utilizes advanced reasoning to bridge the gap between complex APIs and user-friendly design. In this example, the model built a live aerospace dashboard, successfully configuring a public telemetry stream to visualize the International Space Station’s orbit. Interactive design: 3.1 Pro codes a complex 3D starling murmuration. It doesn't just generate the visual code; it builds an immersive experience where users can manipulate the flock with hand-tracking and listen to a generative score that shifts based on the birds’ movement. For researchers and designers, this provides a powerful way to prototype sensory-rich interfaces. Creative coding: 3.1 Pro can translate literary themes into functional code. When prompted to build a modern personal portfolio for Emily Brontë’s \"Wuthering Heights,\" the model didn’t just summarize the text. It reasoned through the novel’s atmospheric tone to design a sleek, contemporary interface, creating a website that captures the essence of the protagonist. What’s next Since releasing Gemini 3 Pro in November, your feedback and the pace of progress have driven these rapid improvements. We are releasing 3.1 Pro in preview today to validate these updates and continue to make further advancements in areas such as ambitious agentic workflows before we make it generally available soon. Starting today, Gemini 3.1 Pro in the Gemini app is rolling out with higher limits for users with the Google AI Pro and Ultra plans. 3.1 Pro is also now available on NotebookLM exclusively for Pro and Ultra users. And developers and enterprises can access 3.1 Pro now in preview in the Gemini API via AI Studio, Antigravity, Vertex AI, Gemini Enterprise, Gemini CLI and Android Studio. We can’t wait to see what you build and discover with it. POSTED IN: Gemini models Related stories Gemini models Gemini 3 Deep Think: Advancing science, research and engineering By The Deep Think team Feb 12, 2026 Developer tools Introducing Agentic Vision in Gemini 3 Flash By Rohan Doshi Jan 27, 2026 Developer tools New developer tools for Google AI Pro and Ultra subscribers By Niv Govindaraju & Bala Muthukrishnan Jan 27, 2026 Search Just ask anything: a seamless new Search experience By Robby Stein Jan 27, 2026 AI In our latest podcast, hear how the “Smoke Jumpers” team brings Gemini to billions of people. Jan 27, 2026 Developer tools Increased file size limits and expanded inputs support in Gemini API By Lucia Loher Jan 12, 2026 . Jump to position 1 Jump to position 2 Jump to position 3 Jump to position 4 Jump to position 5 Jump to position 6 Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks Follow Us Privacy Terms About Google Google Products About the Keyword Help Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) MENA (English) Nederlands (Nederland) New Zealand (English) Polska (Polski) Portugal (Português) Sverige (Svenska) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文)",
      "imageUrl": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3.1_pro_meta_dark.width-1300.png",
      "tags": [
        "LLM"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Gemini 3.1 Pro 的发布代表 Google DeepMind 在大模型能力上的关键跃迁，具备全球产业影响力和战略意义，符合顶级实验室核心突破的标准。",
        "热度：424 / 评论 650"
      ],
      "score": 9.29,
      "publishedAt": "2026-02-19T15:19:57+00:00",
      "authors": [
        "MallocVoidstar"
      ]
    },
    {
      "id": "github_openclaw_openclaw",
      "title": "openclaw/openclaw",
      "titleZh": "openclaw/openclaw",
      "titleEn": "openclaw/openclaw",
      "url": "https://github.com/openclaw/openclaw",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "开源项目 openclaw/openclaw 宣称提供一个跨操作系统、跨平台的个人 AI 助手，以“龙虾方式”（The lobster way）为特色，强调其独特性和普适性。",
      "summaryZh": "开源项目 openclaw/openclaw 宣称提供一个跨操作系统、跨平台的个人 AI 助手，以“龙虾方式”（The lobster way）为特色，强调其独特性和普适性。",
      "summaryEn": "The open-source project openclaw/openclaw offers a personal AI assistant that works across any operating system and platform, featuring its distinctive 'lobster way' approach.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/859ba4965ae366406770cea0c211798014aadafae61562f4f35ed70259a82432/openclaw/openclaw",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：OpenClaw作为可执行的AI代理引发安全关注，体现自主AI Agent的潜力与风险，具备行业示范意义。",
        "热度：211790 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-19T23:41:18.831615+00:00",
      "authors": []
    },
    {
      "id": "rss_3617145009",
      "title": "Google 在 AI Impact Summit 2026 宣布多项全球合作与投资",
      "titleZh": "Google 在 AI Impact Summit 2026 宣布多项全球合作与投资",
      "titleEn": "Google Unveils Global Partnerships and Investments at AI Impact Summit 2026",
      "url": "https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection/",
      "type": "news",
      "source": "Google AI Blog",
      "summary": "**Google 在 2026 年 AI Impact Summit 上宣布多项全球合作与投资**，包括美印海底光缆新路由、在印度设立气候技术中心、启动两项 Google.org 影响力挑战（分别聚焦政府创新与科学，后者投入 3000 万美元），并发布《2026 负责任 AI 进展报告》；这些举措旨在推动 AI 技术普惠化，应对人类重大挑战，对开发者意味着更多基础设施支持，对公众则可能带来更安全、可及的 AI 应用和服务。",
      "summaryZh": "**Google 在 2026 年 AI Impact Summit 上宣布多项全球合作与投资**，包括美印海底光缆新路由、在印度设立气候技术中心、启动两项 Google.org 影响力挑战（分别聚焦政府创新与科学，后者投入 3000 万美元），并发布《2026 负责任 AI 进展报告》；这些举措旨在推动 AI 技术普惠化，应对人类重大挑战，对开发者意味着更多基础设施支持，对公众则可能带来更安全、可及的 AI 应用和服务。",
      "summaryEn": "At the AI Impact Summit 2026, Google announced new global partnerships and investments, including new America-India fiber-optic routes, a climate tech center in India, and two Google.org Impact Challenges—one for government innovation and a $30 million initiative for AI in science—alongside its 2026 Responsible AI Progress Report. These efforts aim to make AI benefits widely accessible, offering developers enhanced infrastructure and the public safer, more equitable AI applications.",
      "fullText": "AI Impact Summit 2026 Skip to main content The Keyword AI Impact Summit 2026 Share x.com Facebook LinkedIn Mail Copy link Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Subscribe Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) MENA (English) Nederlands (Nederland) New Zealand (English) Polska (Polski) Portugal (Português) Sverige (Svenska) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文) [\"What does AI mean for retail?\", \"How did Nano Banana get its name?\", \"How can AI help me plan travel?\"] Subscribe The Keyword Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Images RSS feed Subscribe Breadcrumb Innovation & AI Technology AI Collection Share x.com Facebook LinkedIn Mail Copy link AI Impact Summit 2026 8 articles articles 8 8 articles articles 8 Our last decade of breakthroughs in AI are helping us make progress against some of humanity’s biggest challenges. At the AI Impact Summit in India, we’re launching new global partnerships, research, investment and innovation, to ensure that these benefits are accessible for everyone. A message from our CEO “No technology has me dreaming bigger than AI” CEO Sundar Pichai’s remarks at the opening ceremony of the AI Impact Summit 2026 By Sundar Pichai - Feb 19, 2026 How we’re partnering to make AI work for everyone An overview of Google’s new global partnerships and funding announcements at the AI Impact Summit in India. Announcing America-India Connect fiber-optic routes New fiber-optic routes will increase digital connectivity between the U.S., India and locations across the Southern Hemisphere. Introducing our National Partnerships for AI & collaboration in India Google DeepMind announces new partnerships in India to advance science, empower students and support agriculture and renewable energy. Google.org Impact Challenge: AI for Government Innovation This is a global call for organizations building AI-powered solutions that transform public services and drive societal impact. Google.org Impact Challenge: AI for Science A $30 million AI for Science Impact Challenge to support researchers globally who are using AI to drive scientific breakthroughs. Our 2026 Responsible AI Progress Report Our latest Responsible AI Progress Report shares how we’re applying our AI Principles to the development of our products and research. Announcing our new climate tech collaboration in India In collaboration with the Office of the Principal Scientific Advisor we’ve launched the Google Center for Climate Technology. Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks Follow Us Privacy Terms About Google Google Products About the Keyword Help Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) MENA (English) Nederlands (Nederland) New Zealand (English) Polska (Polski) Portugal (Português) Sverige (Svenska) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文)",
      "imageUrl": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CollectionSS-1.max-1440x810.png",
      "tags": [
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：6/10，理由：AI Impact Summit为行业重要事件，但仅提及“合作与投资”概要，未披露实质性突破，信息价值有限。",
        "热度：0 / 评论 0"
      ],
      "score": 7.7,
      "publishedAt": "2026-02-19T04:30:00+00:00",
      "authors": []
    },
    {
      "id": "hn_47069299",
      "title": "Anthropic 禁止第三方使用 Claude 订阅账户凭据",
      "titleZh": "Anthropic 禁止第三方使用 Claude 订阅账户凭据",
      "titleEn": "Anthropic Bans Third-Party Use of Claude Subscription Credentials",
      "url": "https://code.claude.com/docs/en/legal-and-compliance",
      "type": "news",
      "source": "Hacker News",
      "summary": "**Anthropic 正式禁止第三方应用使用 Claude 订阅账户（Free/Pro/Max）的 OAuth 凭据进行身份验证**，明确要求开发者必须通过 API 密钥（经 Claude Console 或云平台如 AWS Bedrock、Google Vertex 获取）接入 Claude 能力；此举旨在强化合规与安全，防止滥用消费者账户凭证，影响范围涵盖所有基于 Agent SDK 或 Claude API 构建的第三方服务，开发者需立即调整认证方式以避免服务中断。",
      "summaryZh": "**Anthropic 正式禁止第三方应用使用 Claude 订阅账户（Free/Pro/Max）的 OAuth 凭据进行身份验证**，明确要求开发者必须通过 API 密钥（经 Claude Console 或云平台如 AWS Bedrock、Google Vertex 获取）接入 Claude 能力；此举旨在强化合规与安全，防止滥用消费者账户凭证，影响范围涵盖所有基于 Agent SDK 或 Claude API 构建的第三方服务，开发者需立即调整认证方式以避免服务中断。",
      "summaryEn": "Anthropic has officially banned third-party applications from using OAuth credentials from Claude consumer subscriptions (Free, Pro, Max) for authentication, requiring developers to instead use API keys obtained via Claude Console or supported cloud platforms like AWS Bedrock and Google Vertex. This policy enforces compliance and security, affecting all services built with the Agent SDK or Claude API, and mandates immediate authentication method updates to avoid disruption.",
      "fullText": "Legal and compliance - Claude Code Docs Skip to main content Claude Code Docs home page English Search... ⌘ K Ask AI Claude Developer Platform Claude Code on the Web Claude Code on the Web Search... Navigation Resources Legal and compliance Getting started Build with Claude Code Deployment Administration Configuration Reference Resources Resources Legal and compliance On this page Legal agreements License Commercial agreements Compliance Healthcare compliance (BAA) Usage policy Acceptable use Authentication and credential use Security and trust Trust and safety Security vulnerability reporting Resources Legal and compliance Copy page Legal agreements, compliance certifications, and security information for Claude Code. Copy page ​ Legal agreements ​ License Your use of Claude Code is subject to: Commercial Terms - for Team, Enterprise, and Claude API users Consumer Terms of Service - for Free, Pro, and Max users ​ Commercial agreements Whether you’re using the Claude API directly (1P) or accessing it through AWS Bedrock or Google Vertex (3P), your existing commercial agreement will apply to Claude Code usage, unless we’ve mutually agreed otherwise. ​ Compliance ​ Healthcare compliance (BAA) If a customer has a Business Associate Agreement (BAA) with us, and wants to use Claude Code, the BAA will automatically extend to cover Claude Code if the customer has executed a BAA and has Zero Data Retention (ZDR) activated. The BAA will be applicable to that customer’s API traffic flowing through Claude Code. ​ Usage policy ​ Acceptable use Claude Code usage is subject to the Anthropic Usage Policy . Advertised usage limits for Pro and Max plans assume ordinary, individual usage of Claude Code and the Agent SDK. ​ Authentication and credential use Claude Code authenticates with Anthropic’s servers using OAuth tokens or API keys. These authentication methods serve different purposes: OAuth authentication (used with Free, Pro, and Max plans) is intended exclusively for Claude Code and Claude.ai. Using OAuth tokens obtained through Claude Free, Pro, or Max accounts in any other product, tool, or service — including the Agent SDK — is not permitted and constitutes a violation of the Consumer Terms of Service . Developers building products or services that interact with Claude’s capabilities, including those using the Agent SDK , should use API key authentication through Claude Console or a supported cloud provider. Anthropic does not permit third-party developers to offer Claude.ai login or to route requests through Free, Pro, or Max plan credentials on behalf of their users. Anthropic reserves the right to take measures to enforce these restrictions and may do so without prior notice. For questions about permitted authentication methods for your use case, please contact sales . ​ Security and trust ​ Trust and safety You can find more information in the Anthropic Trust Center and Transparency Hub . ​ Security vulnerability reporting Anthropic manages our security program through HackerOne. Use this form to report vulnerabilities . © Anthropic PBC. All rights reserved. Use is subject to applicable Anthropic Terms of Service. Was this page helpful? Yes No Claude Code Docs home page x linkedin Company Anthropic Careers Economic Futures Research News Trust center Transparency Help and security Availability Status Support center Learn Courses MCP connectors Customer stories Engineering blog Events Powered by Claude Service partners Startups program Terms and policies Privacy policy Disclosure policy Usage policy Commercial terms Consumer terms Assistant Responses are generated using AI and may contain mistakes.",
      "imageUrl": "https://tse3.mm.bing.net/th/id/OIP.WbeHRHx0C1p3uAQk3r0t_wHaHa?w=1200&h=630&c=7&r=0&o=5&cb=defcache2&pid=1.7&defcache=1",
      "tags": [
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：Anthropic 明确限制订阅认证的第三方使用，反映大型 AI 公司在合规与生态控制方面的战略调整，对开发者生态有实质性影响。",
        "热度：602 / 评论 733"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-19T02:52:26+00:00",
      "authors": [
        "theahura"
      ]
    },
    {
      "id": "github_obra_superpowers",
      "title": "obra/superpowers",
      "titleZh": "obra/superpowers",
      "titleEn": "obra/superpowers",
      "url": "https://github.com/obra/superpowers",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "开源项目 obra/superpowers 提出了一套名为“超能力”（Superpowers）的智能体技能框架与软件开发方法论，旨在为构建具备实际效用的 AI 智能体提供可落地的技术路径。",
      "summaryZh": "开源项目 obra/superpowers 提出了一套名为“超能力”（Superpowers）的智能体技能框架与软件开发方法论，旨在为构建具备实际效用的 AI 智能体提供可落地的技术路径。",
      "summaryEn": "The open-source project obra/superpowers introduces an agentic skills framework and software development methodology called 'Superpowers,' designed to provide a practical approach for building effective AI agents.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/8d596fb5f99c99c579cb39213c51355fffa71dcd5bcdfd0bb12445541bcc204b/obra/superpowers",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：提出“代理技能框架”这一新型开发方法论，具备实用价值和开源社区传播潜力，可能推动AI辅助开发范式演进。",
        "热度：55342 / 评论 0"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-19T23:41:10.500469+00:00",
      "authors": []
    },
    {
      "id": "rss_5823674709",
      "title": "A neural blueprint for human-like intelligence in soft robots",
      "titleZh": "A neural blueprint for human-like intelligence in soft robots",
      "titleEn": "A neural blueprint for human-like intelligence in soft robots",
      "url": "https://news.mit.edu/2026/neural-blueprint-human-intelligence-in-soft-robots-0219",
      "type": "news",
      "source": "MIT CSAIL News",
      "summary": "新加坡-MIT 联盟（SMART）研究人员受人脑神经突触启发，开发出一种新型 AI 控制系统，使软体机械臂能通过离线训练掌握基础动作（结构突触），并在运行中实时在线调整行为（可塑突触），从而在无需重新训练的情况下适应任务变化、负载扰动甚至半数执行器失效等复杂环境；该系统在两种物理平台上验证，轨迹跟踪误差降低 44–55%，形状精度超 92%，首次在同一框架内实现跨任务泛化、即时适应与稳定性保障，为医疗康复、可穿戴设备和工业软体机器人走向实用铺平道路。",
      "summaryZh": "新加坡-MIT 联盟（SMART）研究人员受人脑神经突触启发，开发出一种新型 AI 控制系统，使软体机械臂能通过离线训练掌握基础动作（结构突触），并在运行中实时在线调整行为（可塑突触），从而在无需重新训练的情况下适应任务变化、负载扰动甚至半数执行器失效等复杂环境；该系统在两种物理平台上验证，轨迹跟踪误差降低 44–55%，形状精度超 92%，首次在同一框架内实现跨任务泛化、即时适应与稳定性保障，为医疗康复、可穿戴设备和工业软体机器人走向实用铺平道路。",
      "summaryEn": "Researchers from the Singapore-MIT Alliance for Research and Technology (SMART) have developed a novel AI control system inspired by human neuronal synapses, enabling soft robotic arms to learn foundational movements offline via 'structural synapses' and adapt in real time through 'plastic synapses' without retraining. Tested on two physical platforms, the system reduced tracking error by 44–55% under heavy disturbances and maintained over 92% shape accuracy despite payload changes, airflow, or up to 50% actuator failure. By unifying cross-task generalization, instant adaptation, and stability in one framework, this breakthrough paves the way for practical soft robots in healthcare, wearables, and industrial applications.",
      "fullText": "A new artificial intelligence control system enables soft robotic arms to learn a wide repertoire of motions and tasks once, then adjust to new scenarios on the fly, without needing retraining or sacrificing functionality.&nbsp;This breakthrough brings soft robotics closer to human-like adaptability for real-world applications, such as in assistive robotics, rehabilitation robots, and wearable or medical soft robots, by making them more intelligent, versatile, and safe.The work was led by the Mens, Manus and Machina (M3S) interdisciplinary research group —&nbsp;a play on the Latin MIT motto “mens et manus,” or “mind and hand,” with the addition of “machina” for “machine” — within the Singapore-MIT Alliance for Research and Technology. Co-leading the project are researchers from the National University of Singapore (NUS), alongside collaborators from MIT and Nanyang Technological University in Singapore (NTU Singapore).Unlike regular robots that move using rigid motors and joints, soft robots are made from flexible materials such as soft rubber and move using special actuators — components that act like artificial muscles to produce physical motion. While their flexibility makes them ideal for delicate or adaptive tasks, controlling soft robots has always been a challenge because their shape changes in unpredictable ways. Real-world environments are often complicated and full of unexpected disturbances, and even small changes in conditions — like a shift in weight, a gust of wind, or a minor hardware fault — can throw off their movements.&nbsp;Despite substantial progress in soft robotics, existing approaches often can only achieve one or two of the three capabilities needed for soft robots to operate intelligently in real-world environments: using what they’ve learned from one task to perform a different task, adapting quickly when the situation changes, and guaranteeing that the robot will stay stable and safe while adapting its movements. This lack of adaptability and reliability has been a major barrier to deploying soft robots in real-world applications until now.In an open-access study titled “A general soft robotic controller inspired by neuronal structural and plastic synapses that adapts to diverse arms, tasks, and perturbations,” published Jan. 6 in&nbsp;Science Advances, the researchers describe how they developed a new AI control system that allows soft robots to adapt across diverse tasks and disturbances. The study takes inspiration from the way the human brain learns and adapts, and was built on extensive research in learning-based robotic control, embodied intelligence, soft robotics, and meta-learning.The system uses two complementary sets of “synapses” — connections that adjust how the robot moves — working in tandem. The first set, known as “structural synapses”, is trained offline on a variety of foundational movements, such as bending or extending a soft arm smoothly. These form the robot’s built‑in skills and provide a strong, stable foundation. The second set, called “plastic synapses,” continually updates online as the robot operates, fine-tuning the arm’s behavior to respond to what is happening in the moment. A built-in stability measure acts like a safeguard, so even as the robot adjusts during online adaptation, its behavior remains smooth and controlled.“Soft robots hold immense potential to take on tasks that conventional machines simply cannot, but true adoption requires control systems that are both highly capable and reliably safe. By combining structural learning with real-time adaptiveness, we’ve created a system that can handle the complexity of soft materials in unpredictable environments,” says&nbsp;MIT Professor Daniela Rus, co-lead principal investigator at M3S, director of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), and co-corresponding author of the paper. “It’s a step closer to a future where versatile soft robots can operate safely and intelligently alongside people — in clinics, factories, or everyday lives.”“This new AI control system is one of the first general soft-robot controllers that can achieve all three key aspects needed for soft robots to be used in society and various industries. It can apply what it learned offline across different tasks, adapt instantly to new conditions, and remain stable throughout — all within one control framework,” says Associate Professor Zhiqiang Tang, first author and co-corresponding author of the paper who was a postdoc at M3S and at NUS when he carried out the research and is now an associate professor at Southeast University in China (SEU China).The system supports multiple task types, enabling soft robotic arms to execute trajectory tracking, object placement, and whole-body shape regulation within one unified approach. The method also generalizes across different soft-arm platforms, demonstrating cross-platform applicability.&nbsp;The system was tested and validated on two physical platforms — a cable-driven soft arm and a shape-memory-alloy–actuated soft arm — and delivered impressive results. It achieved a 44–55 percent reduction in tracking error under heavy disturbances; over 92 percent shape accuracy under payload changes, airflow disturbances, and actuator failures; and stable performance even when up to half of the actuators failed.&nbsp;“This work redefines what’s possible in soft robotics. We’ve shifted the paradigm from task-specific tuning and capabilities toward a truly generalizable framework with human-like intelligence. It is a breakthrough that opens the door to scalable, intelligent soft machines capable of operating in real-world environments,” says&nbsp;Professor Cecilia Laschi, co-corresponding author and principal investigator at M3S, Provost’s Chair Professor in the NUS Department of Mechanical Engineering at the College of Design and Engineering, and director of the NUS Advanced Robotics Centre.This breakthrough opens doors for more robust soft robotic systems to develop manufacturing, logistics, inspection, and medical robotics without the need for constant reprogramming — reducing downtime and costs. In health care, assistive and rehabilitation devices can automatically tailor their movements to a patient’s changing strength or posture, while wearable or medical soft robots can respond more sensitively to individual needs, improving safety and patient outcomes.The researchers plan to extend this technology to robotic systems or components that can operate at higher speeds and more complex environments, with potential applications in assistive robotics, medical devices, and industrial soft manipulators, as well as integration into real-world autonomous systems.The research conducted at SMART was supported by the National Research Foundation Singapore under its Campus for Research Excellence and Technological Enterprise program.",
      "imageUrl": "https://tse4.mm.bing.net/th/id/OIP.92l6k1b0_YQtkpyFZ2_0CgHaE8?w=1200&h=630&c=7&r=0&o=5&cb=defcache2&pid=1.7&defcache=1",
      "tags": [
        "Robotics",
        "Training",
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：软体机器人智能控制突破实现无需重训的即时适应，推动人机协作在医疗等场景落地，具应用前景。",
        "热度：0 / 评论 0"
      ],
      "score": 6.8,
      "publishedAt": "2026-02-19T17:55:00+00:00",
      "authors": [
        "Singapore-MIT Alliance for Research and Technology"
      ]
    }
  ],
  "stats": {
    "total_papers_ingested": 224,
    "total_news_ingested": 72,
    "l1_papers_passed": 102,
    "l1_news_passed": 58,
    "l2_papers_scored": 54,
    "l2_news_scored": 30,
    "l3_papers_selected": 18,
    "l3_news_selected": 11,
    "news_source_counts": {
      "Hacker News": 33,
      "TechCrunch AI": 13,
      "GitHub Trending": 6,
      "The Verge AI": 5,
      "AWS Machine Learning Blog": 3,
      "Google AI Blog": 2,
      "NVIDIA Blog": 2,
      "Hugging Face Blog": 2,
      "MIT CSAIL News": 2,
      "OpenAI Blog": 1,
      "DeepMind Blog": 1,
      "Microsoft Research": 1,
      "MIT Tech Review AI": 1
    },
    "rss_source_counts": {
      "TechCrunch AI": 13,
      "The Verge AI": 5,
      "AWS Machine Learning Blog": 3,
      "Google AI Blog": 2,
      "NVIDIA Blog": 2,
      "Hugging Face Blog": 2,
      "MIT CSAIL News": 2,
      "OpenAI Blog": 1,
      "DeepMind Blog": 1,
      "Microsoft Research": 1,
      "MIT Tech Review AI": 1
    },
    "news_title_source_counts": {
      "gemini 3 1 pro": 1,
      "we re no longer attracting top talent the brain drain killing american science": 1,
      "show hn ghostty based terminal with vertical tabs and notifications": 1,
      "dinosaur food 100m year old foods we still eat today 2022": 1,
      "single vaccine could protect against all coughs colds and flus": 1,
      "a psychedelic medicine performs well against depression": 1,
      "overall the colorectal cancer story is encouraging": 1,
      "ai is not a coworker it s an exoskeleton": 1,
      "measuring ai agent autonomy in practice": 1,
      "hud proposes rule that would force noncitizens from public housing": 1,
      "ai makes you boring": 1,
      "mark zuckerberg grilled on usage goals and underage users at california trial": 1,
      "old school visual effects the cloud tank 2010": 1,
      "anthropic officially bans using subscription auth for third party use": 1,
      "palantir partnership is at heart of anthropic pentagon rift": 1,
      "chatgpt ads are appearing on the first prompt not after conversations": 1,
      "meta ceo knew kids were being hurt and he covered it up": 1,
      "15 years of fp64 segmentation and why the blackwell ultra breaks the pattern": 1,
      "south korean ex president yoon suk yeol jailed for life for leading insurrection": 1,
      "sam altman openai and dario amodei anthropic refuse to hold hands": 1,
      "members only philly cop bar has been linked to two duis and a third crash": 1,
      "show hn a lisp where each function call runs a docker container": 1,
      "i traced 3 177 api calls to see what 4 ai coding tools put in the context window": 1,
      "how ai is affecting productivity and jobs in europe": 1,
      "the future belongs to those who can refute ai not just generate with ai": 1,
      "microsoft s new 10k year data storage medium glass": 1,
      "techno cynics are wounded techno optimists": 1,
      "productivity gains from ai coding assistants haven t budged past 10 survey": 1,
      "why are ai leaders fleeing": 1,
      "ai made coding more enjoyable": 1,
      "warren warns fed treasury against crypto bailout": 1,
      "chris lattner on what the claude c compiler reveals about the future of software": 1,
      "valve wins patent troll lawsuit against rothschild": 1,
      "obra superpowers": 1,
      "richardatct claude code telegram": 1,
      "open mercato open mercato": 1,
      "harvard edge cs249r book": 1,
      "hailtododongo pyrite64": 1,
      "openclaw openclaw": 1,
      "advancing independent research on ai alignment": 1,
      "no technology has me dreaming bigger than ai": 1,
      "ai impact summit 2026": 1,
      "gemini 3 1 pro a smarter model for your most complex tasks": 1,
      "media authenticity methods in practice capabilities limitations and directions": 1,
      "survey reveals ai advances in telecom networks and automation in driver s seat as return on investment climbs": 1,
      "all about the games play over 4 500 titles with geforce now": 1,
      "the pitt has a sharp take on ai": 1,
      "the ai security nightmare is here and it looks suspiciously like lobster": 1,
      "the speech police came for colbert": 1,
      "money no longer matters to ai s top talent": 1,
      "it 8217 s maga v broligarch in the battle over prediction markets": 1,
      "why these startup ceos don t think ai will replace human roles": 1,
      "youtube s latest experiment brings its conversational ai tool to tvs": 1,
      "reddit is testing a new ai search feature for shopping": 1,
      "openai reportedly finalizing 100b deal at more than 850b valuation": 1,
      "reload wants to give your ai agents a shared memory": 1,
      "openai reliance partner to add ai search to jiohotstar": 1,
      "co founders behind reface and prisma join hands to improve on device model inference with mirai": 1,
      "for open source programs ai coding tools are a mixed blessing": 1,
      "altman and amodei share a moment of awkwardness at india s big ai summit": 1,
      "freeform raises 67m series b to scale up laser ai manufacturing": 1,
      "reliance unveils 110b ai investment plan as india ramps up tech ambitions": 1,
      "openai taps tata for 100mw ai data center capacity in india eyes 1gw": 1,
      "openai deepens india push with pine labs fintech partnership": 1,
      "train ai models with unsloth and hugging face jobs for free": 1,
      "不足 壁 越 合成 日本 ai開発 加速": 1,
      "microsoft has a new plan to prove what s real and what s ai online": 1,
      "build ai workflows on amazon eks with union ai and flyte": 1,
      "amazon quick now supports key pair authentication to snowflake data source": 1,
      "build unified intelligence with amazon bedrock agentcore": 1,
      "mit faculty alumni named 2026 sloan research fellows": 1,
      "a neural blueprint for human like intelligence in soft robots": 1
    },
    "total_papers_deduped": 224,
    "total_news_deduped": 72,
    "news_recent_filtered": 72
  }
}