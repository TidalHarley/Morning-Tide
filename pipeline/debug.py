"""
AI Tides - è°ƒè¯•å·¥å…·
æä¾›æœ¬åœ°è°ƒè¯•å’Œæµ‹è¯•åŠŸèƒ½
"""
import logging
import json
import argparse
from datetime import datetime, timedelta, timezone
from typing import List

from pipeline.models import ContentItem, ContentType, SourceType
from pipeline.filters import HeuristicFilter, AIScorer, Refiner
from pipeline.output import OutputGenerator
from pipeline.config import config

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


def create_mock_data() -> tuple[List[ContentItem], List[ContentItem]]:
    """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•"""
    
    now = datetime.now(timezone.utc)
    
    # æ¨¡æ‹Ÿè®ºæ–‡
    mock_papers = [
        ContentItem(
            id="mock_paper_1",
            title="GPT-5: A Revolutionary Large Language Model",
            url="https://example.com/paper1",
            content_type=ContentType.PAPER,
            source_type=SourceType.ARXIV,
            source_name="arXiv",
            abstract="This paper introduces GPT-5, a state-of-the-art language model with breakthrough capabilities.",
            authors=["OpenAI Research"],
            published_at=now - timedelta(hours=12),
            score=150
        ),
        ContentItem(
            id="mock_paper_2",
            title="Novel Transformer Architecture for Vision Tasks",
            url="https://example.com/paper2",
            content_type=ContentType.PAPER,
            source_type=SourceType.HUGGINGFACE,
            source_name="HuggingFace",
            abstract="We propose a new transformer architecture that achieves SOTA results on vision benchmarks.",
            authors=["DeepMind"],
            published_at=now - timedelta(hours=6),
            score=80
        ),
        ContentItem(
            id="mock_paper_3",
            title="Introduction to Machine Learning Tutorial",
            url="https://example.com/paper3",
            content_type=ContentType.PAPER,
            source_type=SourceType.ARXIV,
            source_name="arXiv",
            abstract="A beginner-friendly tutorial on machine learning basics.",
            authors=["Unknown"],
            published_at=now - timedelta(hours=3),
            score=5
        ),
    ]
    
    # æ¨¡æ‹Ÿæ–°é—»
    mock_news = [
        ContentItem(
            id="mock_news_1",
            title="OpenAI Announces GPT-5 Release",
            url="https://openai.com/blog/gpt-5",
            content_type=ContentType.NEWS,
            source_type=SourceType.RSS,
            source_name="OpenAI Blog",
            abstract="OpenAI has released GPT-5, their most advanced language model yet.",
            authors=[],
            published_at=now - timedelta(hours=8),
            score=500,
            is_whitelist=True
        ),
        ContentItem(
            id="mock_news_2",
            title="Anthropic Releases Claude 4 with Enhanced Reasoning",
            url="https://anthropic.com/news/claude-4",
            content_type=ContentType.NEWS,
            source_type=SourceType.RSS,
            source_name="Anthropic",
            abstract="Claude 4 introduces new reasoning capabilities.",
            authors=[],
            published_at=now - timedelta(hours=4),
            score=300,
            is_whitelist=True
        ),
        ContentItem(
            id="mock_news_3",
            title="How to Use ChatGPT: A Beginner's Guide",
            url="https://example.com/tutorial",
            content_type=ContentType.NEWS,
            source_type=SourceType.HACKERNEWS,
            source_name="Hacker News",
            abstract="Learn how to use ChatGPT with this simple tutorial.",
            authors=[],
            published_at=now - timedelta(hours=2),
            score=15
        ),
    ]
    
    return mock_papers, mock_news


def test_l1_filter():
    """æµ‹è¯• L1 å¯å‘å¼è¿‡æ»¤"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª æµ‹è¯• L1 å¯å‘å¼è¿‡æ»¤")
    logger.info("=" * 60)
    
    papers, news = create_mock_data()
    
    filter_obj = HeuristicFilter()
    result = filter_obj.run(papers, news)
    
    logger.info(f"\nè®ºæ–‡ L2: {len(result['papers_l2'])}")
    logger.info(f"è®ºæ–‡ç™½åå•: {len(result['papers_whitelist'])}")
    logger.info(f"æ–°é—» L2: {len(result['news_l2'])}")
    logger.info(f"æ–°é—»ç™½åå•: {len(result['news_whitelist'])}")
    
    return result


def test_l2_scorer():
    """æµ‹è¯• L2 AI æ‰“åˆ†"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª æµ‹è¯• L2 AI æ‰“åˆ†")
    logger.info("=" * 60)
    
    papers, news = create_mock_data()
    
    # å…ˆè¿‡ L1
    filter_obj = HeuristicFilter()
    l1_result = filter_obj.run(papers, news)
    
    # å†æ‰“åˆ†
    scorer = AIScorer()
    l2_result = scorer.run(
        papers_l2=l1_result["papers_l2"],
        papers_whitelist=l1_result["papers_whitelist"],
        news_l2=l1_result["news_l2"],
        news_whitelist=l1_result["news_whitelist"]
    )
    
    logger.info(f"\nè®ºæ–‡ L3 å€™é€‰: {len(l2_result['papers_l3'])}")
    for paper in l2_result['papers_l3']:
        logger.info(f"  - {paper.title[:50]}... (åˆ†æ•°: {paper.l2_combined_score})")
    
    logger.info(f"\næ–°é—» L3 å€™é€‰: {len(l2_result['news_l3'])}")
    for news_item in l2_result['news_l3']:
        logger.info(f"  - {news_item.title[:50]}... (åˆ†æ•°: {news_item.l2_combined_score})")
    
    return l2_result


def test_full_pipeline(mock: bool = False):
    """æµ‹è¯•å®Œæ•´ Pipeline"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª æµ‹è¯•å®Œæ•´ Pipeline")
    logger.info("=" * 60)
    
    if mock:
        logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        papers, news = create_mock_data()
    else:
        logger.info("ä½¿ç”¨çœŸå®æ•°æ®")
        from pipeline.ingestion import fetch_all_papers, fetch_all_news
        papers = fetch_all_papers()
        news = fetch_all_news()
    
    # L1
    filter_obj = HeuristicFilter()
    l1_result = filter_obj.run(papers, news)
    
    # L2
    scorer = AIScorer()
    l2_result = scorer.run(
        papers_l2=l1_result["papers_l2"],
        papers_whitelist=l1_result["papers_whitelist"],
        news_l2=l1_result["news_l2"],
        news_whitelist=l1_result["news_whitelist"]
    )
    
    # L3
    refiner = Refiner()
    report = refiner.run(
        papers_l3=l2_result["papers_l3"],
        news_l3=l2_result["news_l3"]
    )
    
    # è¾“å‡º
    output_gen = OutputGenerator()
    output_paths = output_gen.save_report(report)
    
    logger.info("\nâœ… æµ‹è¯•å®Œæˆ!")
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_paths}")
    
    return report


def test_ingestion():
    """æµ‹è¯•æ•°æ®æ‘„å–"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª æµ‹è¯•æ•°æ®æ‘„å–")
    logger.info("=" * 60)
    
    from pipeline.ingestion import fetch_all_papers, fetch_all_news
    
    logger.info("è·å–è®ºæ–‡...")
    papers = fetch_all_papers()
    logger.info(f"âœ… è·å–åˆ° {len(papers)} ç¯‡è®ºæ–‡")
    
    logger.info("\nè·å–æ–°é—»...")
    news = fetch_all_news()
    logger.info(f"âœ… è·å–åˆ° {len(news)} æ¡æ–°é—»")
    
    # æ˜¾ç¤ºå‰å‡ æ¡
    if papers:
        logger.info("\nå‰3ç¯‡è®ºæ–‡:")
        for i, paper in enumerate(papers[:3], 1):
            logger.info(f"  {i}. {paper.title[:60]}...")
    
    if news:
        logger.info("\nå‰3æ¡æ–°é—»:")
        for i, news_item in enumerate(news[:3], 1):
            logger.info(f"  {i}. {news_item.title[:60]}...")
    
    return papers, news


def main():
    parser = argparse.ArgumentParser(description="AI Tides è°ƒè¯•å·¥å…·")
    parser.add_argument(
        "mode",
        choices=["l1", "l2", "full", "ingestion", "mock"],
        help="æµ‹è¯•æ¨¡å¼: l1=æµ‹è¯•L1è¿‡æ»¤, l2=æµ‹è¯•L2æ‰“åˆ†, full=å®Œæ•´pipeline, ingestion=æ•°æ®æ‘„å–, mock=ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="å¼€å¯è°ƒè¯•æ¨¡å¼ï¼ˆæ›´è¯¦ç»†çš„æ—¥å¿—ï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        if args.mode == "l1":
            test_l1_filter()
        elif args.mode == "l2":
            test_l2_scorer()
        elif args.mode == "full":
            test_full_pipeline(mock=False)
        elif args.mode == "mock":
            test_full_pipeline(mock=True)
        elif args.mode == "ingestion":
            test_ingestion()
        
        return 0
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())
