"""
AI Tides - è¾“å‡ºç”Ÿæˆæ¨¡å—
ç”Ÿæˆ Markdown æŠ¥å‘Šå’Œ JSON æ•°æ®
"""
import json
import os
import logging
import re
from datetime import datetime
from typing import Optional

from .models import DailyReport, ContentItem
from .audio.rewrite import rewrite_audio_text
from .audio.tts import generate_daily_audio
from .config import config

logger = logging.getLogger(__name__)


class OutputGenerator:
    """è¾“å‡ºç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: Optional[str] = None):
        self.output_dir = output_dir or config.output_dir
        os.makedirs(self.output_dir, exist_ok=True)
    
    def _format_tags(self, tags: list) -> str:
        """æ ¼å¼åŒ–æ ‡ç­¾"""
        if not tags:
            return ""
        return " ".join([f"`{tag}`" for tag in tags])

    def _normalize_title(self, title: str) -> str:
        text = (title or "").lower().strip()
        text = re.sub(r"[^a-z0-9\u4e00-\u9fff]+", " ", text)
        return re.sub(r"\s+", " ", text).strip()

    def _is_official_source(self, item: ContentItem) -> bool:
        if item.is_whitelist:
            return True
        if not item.url:
            return False
        try:
            from urllib.parse import urlparse

            domain = urlparse(item.url).netloc.lower()
        except Exception:
            domain = ""
        if not domain:
            return False
        for wl_domain in config.whitelist_domains:
            normalized = (wl_domain or "").strip().lower()
            if not normalized:
                continue
            if domain == normalized or domain.endswith(f".{normalized}"):
                return True
        return False

    def _build_signal_reasons(self, item: ContentItem, stats: dict) -> list:
        reasons = []
        # æ¥æºæƒå¨
        if self._is_official_source(item):
            reasons.append("æ¥æºæƒå¨ï¼šå®˜æ–¹/ç™½åå•")
        else:
            reasons.append(f"æ¥æºï¼š{item.source_name or 'Unknown'}")

        # è·¨æºé‡å¤
        title_key = self._normalize_title(item.title or "")
        cross_map = stats.get("news_title_source_counts", {}) if isinstance(stats, dict) else {}
        if title_key and title_key in cross_map:
            reasons.append(f"è·¨æºé‡å¤ï¼š{cross_map[title_key]} ä¸ªæ¥æº")
        else:
            reasons.append("è·¨æºé‡å¤ï¼š1 ä¸ªæ¥æº")

        # æ¨¡å‹è¯„åˆ†ä¾æ®
        if item.l2_reason:
            reasons.append(f"æ¨¡å‹è¯„åˆ†ï¼š{item.l2_score}/10ï¼Œç†ç”±ï¼š{item.l2_reason}")
        else:
            reasons.append(f"æ¨¡å‹è¯„åˆ†ï¼š{item.l2_score}/10")

        # å¼•ç”¨/çƒ­åº¦
        reasons.append(f"çƒ­åº¦ï¼š{item.score} / è¯„è®º {item.comments_count}")
        return reasons

    def _safe_image_url(self, url: str) -> str:
        value = (url or "").strip()
        if value.lower().startswith(("http://", "https://")):
            return value
        if value.startswith("/"):
            return value
        return ""
    
    def generate_markdown(self, report: DailyReport) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        
        intro_zh = report.introduction_zh or report.introduction
        longform_zh = report.longform_script_zh or report.longform_script

        md = f"""# ğŸŒŠ AI Tides Daily Report
## {report.date}

> *Signal over Noise - ç©¿è¶Šå–§åš£ï¼Œç›´æŠµæœ¬è´¨*

---

## ğŸ“ ä»Šæ—¥ç»¼è¿°

{intro_zh}

---

## ğŸ™ï¸ æ’­å®¢é•¿æ–‡ç¨¿

{longform_zh or "ï¼ˆæœªç”Ÿæˆï¼‰"}

---

## ğŸ“š ç²¾é€‰è®ºæ–‡ ({len(report.papers)} ç¯‡)

"""
        
        for i, paper in enumerate(report.papers, 1):
            tags = self._format_tags(paper.tags)
            summary = paper.summary_zh or ((paper.abstract[:150] + "...") if paper.abstract else (paper.title_zh or paper.title))
            authors = ", ".join(paper.authors[:3]) if paper.authors else "Unknown"
            display_title = paper.title_zh or paper.title
            
            md += f"""### {i}. {display_title}

{tags}

**æ¥æº:** {paper.source_name} | **ä½œè€…:** {authors}

{summary}

ğŸ”— [é˜…è¯»åŸæ–‡]({paper.url})

---

"""
        
        md += f"""
## ğŸ“° è¡Œä¸šæ–°é—» ({len(report.news)} æ¡)

"""
        
        for i, news in enumerate(report.news, 1):
            tags = self._format_tags(news.tags)
            summary = news.summary_zh or news.abstract or news.title
            display_title = news.title_zh or news.title
            
            md += f"""### {i}. {display_title}

{tags}

**æ¥æº:** {news.source_name}

{summary}

ğŸ”— [é˜…è¯»åŸæ–‡]({news.url})

---

"""
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats = report.stats
        md += f"""
## ğŸ“Š Pipeline ç»Ÿè®¡

| é˜¶æ®µ | è®ºæ–‡ | æ–°é—» |
|------|------|------|
| æ‘„å– | {stats.get('total_papers_ingested', 'N/A')} | {stats.get('total_news_ingested', 'N/A')} |
| L1 é€šè¿‡ | {stats.get('l1_papers_passed', 'N/A')} | {stats.get('l1_news_passed', 'N/A')} |
| L2 è¯„åˆ† | {stats.get('l2_papers_scored', 'N/A')} | {stats.get('l2_news_scored', 'N/A')} |
| L3 å…¥é€‰ | {stats.get('l3_papers_selected', 'N/A')} | {stats.get('l3_news_selected', 'N/A')} |

---

## ğŸ§­ RSS æ¥æºæ¡æ•°

"""
        rss_counts = stats.get("rss_source_counts", {})
        if isinstance(rss_counts, dict) and rss_counts:
            md += "| RSS æ¥æº | æ¡æ•° |\n|------|------|\n"
            for name, count in rss_counts.items():
                md += f"| {name} | {count} |\n"
        else:
            md += "æš‚æ—  RSS æ¥æºç»Ÿè®¡ã€‚\n"

        md += f"""

*Generated by AI Tides Pipeline at {report.generated_at.strftime('%Y-%m-%d %H:%M:%S')} UTC*
"""
        
        return md

    def generate_news_sources_markdown(self, report: DailyReport) -> str:
        stats = report.stats or {}
        counts = stats.get("news_source_counts", {})
        rss_counts = stats.get("rss_source_counts", {})
        lines = [
            "# æ–°é—»æ¥æºç»Ÿè®¡",
            f"æ—¥æœŸ: {report.date}",
            "",
            "| æ¥æº | æ•°é‡ |",
            "|------|------|",
        ]
        if isinstance(counts, dict) and counts:
            for name, count in counts.items():
                lines.append(f"| {name} | {count} |")
        else:
            lines.append("| æ—  | 0 |")
        lines.append("")

        lines.append("## RSS æ¥æºæ¡æ•°")
        lines.append("")
        lines.append("| RSS æ¥æº | æ•°é‡ |")
        lines.append("|---------|------|")
        if isinstance(rss_counts, dict) and rss_counts:
            for name, count in rss_counts.items():
                lines.append(f"| {name} | {count} |")
        else:
            lines.append("| æ—  | 0 |")
        lines.append("")
        return "\n".join(lines)
    
    def generate_json_for_frontend(self, report: DailyReport) -> dict:
        """ç”Ÿæˆå‰ç«¯æ‰€éœ€çš„ JSON æ•°æ®"""
        
        def item_to_dict(item: ContentItem) -> dict:
            title_zh = item.title_zh or item.title
            title_en = item.title_en or item.title
            summary_zh = item.summary_zh or (item.abstract[:200] if item.abstract else item.title)
            summary_en = item.summary_en or (item.abstract[:200] if item.abstract else item.title)
            return {
                "id": item.id,
                "title": title_zh,
                "titleZh": title_zh,
                "titleEn": title_en,
                "url": item.url,
                "type": item.content_type.value,
                "source": item.source_name,
                "summary": summary_zh,
                "summaryZh": summary_zh,
                "summaryEn": summary_en,
                "fullText": item.full_text or "",
                "imageUrl": self._safe_image_url(item.image_url),
                "tags": item.tags,
                "paperCategory": item.paper_category or "",
                "signalReasons": self._build_signal_reasons(item, report.stats),
                "score": item.l2_combined_score,
                "publishedAt": item.published_at.isoformat() if item.published_at else None,
                "authors": item.authors
            }
        
        return {
            "date": report.date,
            "generatedAt": report.generated_at.isoformat(),
            "introduction": report.introduction_zh or report.introduction,
            "introductionZh": report.introduction_zh or report.introduction,
            "introductionEn": report.introduction_en or report.introduction,
            "longformScript": report.longform_script_zh or report.longform_script or "",
            "longformScriptZh": report.longform_script_zh or report.longform_script or "",
            "longformScriptEn": report.longform_script_en or "",
            "audioUrl": report.audio_url or "",
            "papers": [item_to_dict(p) for p in report.papers],
            "news": [item_to_dict(n) for n in report.news],
            "stats": report.stats
        }
    
    def save_report(self, report: DailyReport) -> dict:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        
        date_str = report.date
        
        # ä¿å­˜ Markdown
        md_content = self.generate_markdown(report)
        md_path = os.path.join(self.output_dir, f"report_{date_str}.md")
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(md_content)
        logger.info(f"[Output] Markdown æŠ¥å‘Šå·²ä¿å­˜: {md_path}")

        # ä¿å­˜æ–°é—»æ¥æºç»Ÿè®¡
        sources_md = self.generate_news_sources_markdown(report)
        sources_path = os.path.join(self.output_dir, f"news_sources_{date_str}.md")
        with open(sources_path, "w", encoding="utf-8") as f:
            f.write(sources_md)
        logger.info(f"[Output] æ–°é—»æ¥æºç»Ÿè®¡å·²ä¿å­˜: {sources_path}")
        
        # ç”Ÿæˆæ’­å®¢éŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
        audio_text = report.longform_script_zh or report.longform_script or report.introduction_zh or report.introduction
        audio_text = rewrite_audio_text(audio_text)
        audio_url = generate_daily_audio(audio_text, report.date)
        if audio_url:
            report.audio_url = audio_url

        # ä¿å­˜ JSON (ç”¨äºå­˜æ¡£)
        json_data = self.generate_json_for_frontend(report)
        json_path = os.path.join(self.output_dir, f"report_{date_str}.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        logger.info(f"[Output] JSON æŠ¥å‘Šå·²ä¿å­˜: {json_path}")
        
        # ä¿å­˜åˆ°å‰ç«¯æ•°æ®ç›®å½•
        frontend_path = config.data_json_path
        frontend_dir = os.path.dirname(frontend_path)
        if os.path.exists(frontend_dir):
            with open(frontend_path, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            logger.info(f"[Output] å‰ç«¯æ•°æ®å·²æ›´æ–°: {frontend_path}")

        # ä¿å­˜åˆ° public reports ç›®å½•ï¼ˆç”¨äºå‰ç«¯æ—¥æœŸåˆ‡æ¢ï¼‰
        public_reports_dir = config.public_reports_dir
        if public_reports_dir:
            os.makedirs(public_reports_dir, exist_ok=True)
            public_report_path = os.path.join(public_reports_dir, f"report_{date_str}.json")
            with open(public_report_path, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            logger.info(f"[Output] Public æŠ¥å‘Šå·²ä¿å­˜: {public_report_path}")
        
        # ä¿å­˜å†å²è®°å½• (è¿½åŠ æ¨¡å¼)
        history_path = os.path.join(self.output_dir, "history.json")
        history = []
        if os.path.exists(history_path):
            try:
                with open(history_path, "r", encoding="utf-8") as f:
                    history = json.load(f)
            except:
                history = []
        
        # æ·»åŠ ä»Šæ—¥è®°å½•æ‘˜è¦
        history_entry = {
            "date": date_str,
            "papers_count": len(report.papers),
            "news_count": len(report.news),
            "top_paper": (report.papers[0].title_zh or report.papers[0].title) if report.papers else None,
            "top_news": (report.news[0].title_zh or report.news[0].title) if report.news else None
        }
        
        # é¿å…é‡å¤
        history = [h for h in history if h["date"] != date_str]
        history.insert(0, history_entry)
        history = history[:30]  # åªä¿ç•™æœ€è¿‘30å¤©
        
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)

        # åŒæ­¥ history åˆ° public ç›®å½•
        public_history_path = config.public_history_path
        if public_history_path:
            public_history_dir = os.path.dirname(public_history_path)
            if public_history_dir:
                os.makedirs(public_history_dir, exist_ok=True)
            with open(public_history_path, "w", encoding="utf-8") as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            logger.info(f"[Output] Public history å·²æ›´æ–°: {public_history_path}")
        
        output_paths = {
            "markdown_path": md_path,
            "json_path": json_path,
            "frontend_path": frontend_path if os.path.exists(frontend_dir) else None,
            "news_sources_path": sources_path,
        }

        # ç”Ÿæˆæ¯æ—¥ç®€æŠ¥é•¿å›¾ï¼ˆä¸­/è‹±åŒè¯­ PNGï¼‰
        if config.briefing_enabled:
            try:
                from .briefing import generate_briefing_images
                briefing_paths = generate_briefing_images(report)
                output_paths.update(briefing_paths)
            except Exception as e:
                logger.warning(f"[Briefing] ç®€æŠ¥å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼ˆä¸å½±å“å…¶ä»–è¾“å‡ºï¼‰: {e}")

        return output_paths
