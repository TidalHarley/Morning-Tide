{
  "date": "2026-02-18",
  "generatedAt": "2026-02-18T23:59:39.956129",
  "introduction": "今日AI领域迎来多项关键进展：微软在《自然》发表玻璃存储技术突破，可将数据保存万年；印度与NVIDIA深度合作，推动主权AI与工业智能化；Google DeepMind推出音乐生成模型Lyria 3，并呼吁对AI道德行为进行系统评估。论文方面，多篇研究聚焦智能体通信协议、具身推理、视觉语言模型在自动驾驶与制造中的可靠性，以及联邦AI服务的网络管理架构。同时，学界开始反思LLM评测的有效性，并提出更安全的代码生成与LoRA后门检测方法，为AI落地提供坚实基础。",
  "introductionZh": "今日AI领域迎来多项关键进展：微软在《自然》发表玻璃存储技术突破，可将数据保存万年；印度与NVIDIA深度合作，推动主权AI与工业智能化；Google DeepMind推出音乐生成模型Lyria 3，并呼吁对AI道德行为进行系统评估。论文方面，多篇研究聚焦智能体通信协议、具身推理、视觉语言模型在自动驾驶与制造中的可靠性，以及联邦AI服务的网络管理架构。同时，学界开始反思LLM评测的有效性，并提出更安全的代码生成与LoRA后门检测方法，为AI落地提供坚实基础。",
  "introductionEn": "Today’s AI breakthroughs span storage, ethics, and industrial deployment. Microsoft’s Nature-published glass storage tech promises 10,000-year data preservation. India partners with NVIDIA to build sovereign AI infrastructure and smart factories. Google DeepMind launches Lyria 3 for music generation while urging rigorous evaluation of LLM moral behavior. Key papers address secure agent communication, compositional reasoning, VLM reliability in driving/manufacturing, and foundational issues in LLM evaluation and code security—highlighting a maturing field balancing innovation with robustness.",
  "longformScript": "今天，AI世界既在向未来狂奔，也在回头审视自己。一边是微软用厨房玻璃存下万年数据，一边是企业高管们坦承：AI还没真正提升生产力；一边是印度掀起百亿美元级的AI基建浪潮，一边是DeepMind提醒我们：别被聊天机器人“装出来的道德”骗了。技术的高光与现实的落差，正同时上演。\n\n先说说那些看得见摸得着的突破。微软刚刚在《自然》杂志上公布了一项令人惊讶的进展：他们把原本需要昂贵熔融石英的“Project Silica”玻璃存储技术，成功迁移到了普通耐热玻璃上——就是你家厨房里那种。这意味着数据可以被激光刻进玻璃内部，保存上万年，不怕水、不怕火、也不怕时间侵蚀。更关键的是，读写系统大幅简化，成本骤降。虽然离你我手机里存照片还远，但对国家档案馆、科研机构甚至家族数字遗产来说，这可能是迈向“永久记忆”的第一步。想象一下，百年后的人类还能读取今天的视频、信件，不是靠不断迁移硬盘，而是轻轻拂去一块玻璃上的灰尘。\n\n与此同时，印度正成为全球AI版图中不可忽视的力量。NVIDIA与印度政府联手，砸下超10亿美元推动“主权AI”计划——目标很明确：用本土算力、本土语言、本土模型，构建一个不依赖外部的技术生态。从支持22种官方语言的大模型（比如BharatGen、Sarvam.ai），到Reliance、L&T等巨头投入1340亿美元打造“软件定义工厂”，再到Infosys、Wipro等IT巨头基于NVIDIA平台开发企业级AI智能体，整个链条正在闭环。普通开发者现在就能用开源的Nemotron模型训练印地语客服机器人，学生也能通过政府项目参与大模型训练。这不仅是技术竞赛，更是一场关于数字主权的布局。\n\n而生成式AI的边界，也在悄悄扩展。Google Gemini最新集成的Lyria 3模型，让你用一句话或一张图，就能生成30秒的原创音乐。不需要乐理知识，也不需要DAW软件，点几下就能为你的播客配一段氛围音效，或者给短视频加个专属BGM。这看似是小功能，实则标志着AI创意工具正从“看”和“读”走向“听”——多模态表达的最后一块拼图正在就位。不过，Google也没忘记提醒风险：就在同一周，DeepMind在另一篇《自然》论文中尖锐指出，当前大模型的“道德建议”可能只是精致的表演。实验显示，只要微调问题措辞，同一个模型会给出完全相反的伦理判断。这意味着，当AI开始扮演心理咨询师、医疗顾问甚至教育者时，它的“善良”未必可靠。真正的道德AI，不能只靠prompt engineering，而需要可验证的推理机制和跨文化对齐能力。\n\n当然，技术再炫，也绕不开那个老问题：AI到底有没有提升生产力？一项覆盖6000名欧美澳企业高管的最新研究给出了扎心答案：近九成公司承认，过去三年部署的AI并未带来可衡量的效率提升。这让人想起上世纪80年代的“索洛悖论”——计算机无处不在，唯独生产率数据不见踪影。今天的AI或许正处在类似阶段：工具铺开了，但流程没重构，组织没适配，人才没跟上。IBM最近反而扩大校园招聘，正是意识到：自动化不能替代人的成长。对普通职场人来说，与其担心被取代，不如思考如何用AI优化自己的工作流——比如用Composio这样的开源框架，快速搭建能自动处理邮件、查数据、订会议的个人智能体，把重复劳动交给机器，把判断和创造留给自己。\n\n那么，面对这样一个既激动又混乱的AI时代，我们该怎么看、怎么做？首先，别被“万年存储”或“万亿参数”吓住，真正重要的不是技术峰值，而是它能否嵌入真实场景——比如印度工厂用数字孪生优化产线，或者医保中心用AI智能体缩短等待时间。其次，保持对“道德AI”的警惕：表面合理的回答，未必经得起推敲。最后，普通人不必追逐所有新工具，但可以关注那些降低门槛的创新，比如Lyria 3让音乐创作民主化，Google的70种语言实时翻译让非英语用户也能平等使用AI。\n\n今天的AI，像一艘同时装着望远镜和刹车片的船。有人盯着星辰大海，有人忙着检查船底是否漏水。而对我们大多数人来说，或许最好的姿态是：既不盲目加速，也不原地观望，而是看清哪些浪花值得乘，哪些暗礁必须绕。",
  "longformScriptZh": "今天，AI世界既在向未来狂奔，也在回头审视自己。一边是微软用厨房玻璃存下万年数据，一边是企业高管们坦承：AI还没真正提升生产力；一边是印度掀起百亿美元级的AI基建浪潮，一边是DeepMind提醒我们：别被聊天机器人“装出来的道德”骗了。技术的高光与现实的落差，正同时上演。\n\n先说说那些看得见摸得着的突破。微软刚刚在《自然》杂志上公布了一项令人惊讶的进展：他们把原本需要昂贵熔融石英的“Project Silica”玻璃存储技术，成功迁移到了普通耐热玻璃上——就是你家厨房里那种。这意味着数据可以被激光刻进玻璃内部，保存上万年，不怕水、不怕火、也不怕时间侵蚀。更关键的是，读写系统大幅简化，成本骤降。虽然离你我手机里存照片还远，但对国家档案馆、科研机构甚至家族数字遗产来说，这可能是迈向“永久记忆”的第一步。想象一下，百年后的人类还能读取今天的视频、信件，不是靠不断迁移硬盘，而是轻轻拂去一块玻璃上的灰尘。\n\n与此同时，印度正成为全球AI版图中不可忽视的力量。NVIDIA与印度政府联手，砸下超10亿美元推动“主权AI”计划——目标很明确：用本土算力、本土语言、本土模型，构建一个不依赖外部的技术生态。从支持22种官方语言的大模型（比如BharatGen、Sarvam.ai），到Reliance、L&T等巨头投入1340亿美元打造“软件定义工厂”，再到Infosys、Wipro等IT巨头基于NVIDIA平台开发企业级AI智能体，整个链条正在闭环。普通开发者现在就能用开源的Nemotron模型训练印地语客服机器人，学生也能通过政府项目参与大模型训练。这不仅是技术竞赛，更是一场关于数字主权的布局。\n\n而生成式AI的边界，也在悄悄扩展。Google Gemini最新集成的Lyria 3模型，让你用一句话或一张图，就能生成30秒的原创音乐。不需要乐理知识，也不需要DAW软件，点几下就能为你的播客配一段氛围音效，或者给短视频加个专属BGM。这看似是小功能，实则标志着AI创意工具正从“看”和“读”走向“听”——多模态表达的最后一块拼图正在就位。不过，Google也没忘记提醒风险：就在同一周，DeepMind在另一篇《自然》论文中尖锐指出，当前大模型的“道德建议”可能只是精致的表演。实验显示，只要微调问题措辞，同一个模型会给出完全相反的伦理判断。这意味着，当AI开始扮演心理咨询师、医疗顾问甚至教育者时，它的“善良”未必可靠。真正的道德AI，不能只靠prompt engineering，而需要可验证的推理机制和跨文化对齐能力。\n\n当然，技术再炫，也绕不开那个老问题：AI到底有没有提升生产力？一项覆盖6000名欧美澳企业高管的最新研究给出了扎心答案：近九成公司承认，过去三年部署的AI并未带来可衡量的效率提升。这让人想起上世纪80年代的“索洛悖论”——计算机无处不在，唯独生产率数据不见踪影。今天的AI或许正处在类似阶段：工具铺开了，但流程没重构，组织没适配，人才没跟上。IBM最近反而扩大校园招聘，正是意识到：自动化不能替代人的成长。对普通职场人来说，与其担心被取代，不如思考如何用AI优化自己的工作流——比如用Composio这样的开源框架，快速搭建能自动处理邮件、查数据、订会议的个人智能体，把重复劳动交给机器，把判断和创造留给自己。\n\n那么，面对这样一个既激动又混乱的AI时代，我们该怎么看、怎么做？首先，别被“万年存储”或“万亿参数”吓住，真正重要的不是技术峰值，而是它能否嵌入真实场景——比如印度工厂用数字孪生优化产线，或者医保中心用AI智能体缩短等待时间。其次，保持对“道德AI”的警惕：表面合理的回答，未必经得起推敲。最后，普通人不必追逐所有新工具，但可以关注那些降低门槛的创新，比如Lyria 3让音乐创作民主化，Google的70种语言实时翻译让非英语用户也能平等使用AI。\n\n今天的AI，像一艘同时装着望远镜和刹车片的船。有人盯着星辰大海，有人忙着检查船底是否漏水。而对我们大多数人来说，或许最好的姿态是：既不盲目加速，也不原地观望，而是看清哪些浪花值得乘，哪些暗礁必须绕。",
  "longformScriptEn": "Today’s AI landscape reveals a field at an inflection point—pushing the boundaries of what’s technically possible while grappling with real-world adoption, ethical grounding, and economic impact. From storing data in glass for millennia to deploying sovereign AI across a billion-person democracy, innovation is accelerating on multiple fronts. Yet, as new capabilities emerge—from music generation to industrial robotics—a sobering paradox looms: most organizations still aren’t seeing measurable productivity gains. The story of AI in 2026 isn’t just about breakthroughs; it’s about bridging the gap between potential and practice.\n\nLet’s start with infrastructure that could outlive civilizations. Microsoft Research has published a major advance in Nature for Project Silica, its glass-based archival storage system. By shifting from costly fused silica to everyday borosilicate glass—the same material used in kitchenware—they’ve slashed media costs and simplified both writing and reading hardware. Using single-pulse “phase voxel” encoding, multi-beam parallel writing, and machine learning for error correction, the system now promises 10,000-year data preservation in a medium impervious to water, fire, and dust. This isn’t just for museums or governments; it opens the door for individuals to archive digital legacies with unprecedented durability, marking a quiet revolution in how we think about memory in the digital age.\n\nMeanwhile, India is executing one of the most ambitious national AI strategies we’ve seen. In partnership with NVIDIA, the country is investing over $1 billion in the IndiaAI Mission to build sovereign foundation models trained on Indian languages, using NVIDIA’s Nemotron and NeMo frameworks. But this goes far beyond software: tens of thousands of Blackwell GPUs are being deployed through local cloud providers, and companies like BharatGen and Sarvam.ai are building multilingual AI for banking, healthcare, and public services. Simultaneously, India’s manufacturing giants—Reliance, Hero MotoCorp, L&T—are integrating NVIDIA Omniverse digital twins and physical AI robotics into “software-defined factories,” backed by a staggering $134 billion industrial transformation plan. And in the enterprise layer, IT powerhouses like Infosys, Wipro, and Tech Mahindra are rolling out secure, on-prem AI agents for customer support, network operations, and even drug discovery. Google is amplifying this momentum with a $15 billion infrastructure investment, real-time speech translation in 70+ languages—including 10 Indic ones—and AI skilling for 20 million civil servants. Together, these moves signal a coordinated push toward technological self-reliance and inclusive innovation at scale.\n\nOn the creative front, generative AI is expanding beyond text and images into sound. Google DeepMind’s Lyria 3, now integrated into the Gemini app, lets anyone generate 30-second original music tracks from simple text or image prompts. No musical training required. This democratizes audio creation for podcasters, social media creators, and educators—but it also raises questions about originality, copyright, and artistic labor. At the same time, researchers are tackling deeper technical challenges in perception and simulation. NVIDIA’s PPISP framework, for instance, solves a subtle but critical problem in 3D reconstruction: correcting for inconsistencies caused by camera optics and image processing pipelines. By modeling exposure, vignetting, and color response physically, it enables more robust and realistic rendering from multi-view photos—essential for applications in autonomous driving, virtual production, and industrial inspection.\n\nYet amid all this progress, a stark reality check emerges. A recent study of 6,000 executives across four major economies found that nearly 90% report no measurable impact of AI on productivity or employment over the past three years. This echoes the famous Solow Paradox from the 1980s, when computers were everywhere except in the productivity statistics. The issue isn’t the technology itself—it’s integration. Most firms use AI for less than two hours per week, often as a bolt-on tool rather than a reengineered workflow. IBM’s decision to expand graduate hiring, rather than automate leadership roles, reflects a growing awareness: AI’s value lies in augmentation, not replacement, and realizing that requires redesigning processes, not just deploying models.\n\nEthically, the field is also maturing—sometimes uncomfortably so. Google DeepMind researchers published a sobering analysis in Nature questioning whether chatbots’ moral responses reflect genuine reasoning or mere “virtue signaling.” Their experiments show that large language models can flip ethical judgments based on trivial changes like renaming options or adding punctuation. This fragility is alarming when AI systems advise on medical, legal, or psychological matters. The team calls for adversarial testing, chain-of-thought tracing, and culturally aware design—not just to avoid harm, but to build systems that can navigate moral pluralism responsibly. In parallel, open-source tools like Composio are emerging to help developers build safer, more capable AI agents by abstracting away the complexities of secure tool integration, authentication, and state management—critical for moving beyond chatbots to agents that act reliably in the real world.\n\nSo what should you watch next? First, monitor how India’s AI ecosystem evolves—its blend of sovereign infrastructure, multilingual models, and industrial digitization could become a blueprint for other emerging economies. Second, pay attention to the productivity gap: companies that succeed will be those embedding AI deeply into workflows, not just piloting flashy demos. Third, expect more scrutiny on AI ethics—not as a PR exercise, but as a technical requirement for deployment in high-stakes domains. And finally, keep an eye on foundational enablers like Project Silica and PPISP; sometimes the quietest innovations enable the loudest revolutions.\n\nIn sum, today’s AI story is one of duality: extraordinary technical leaps coexisting with adoption inertia, creative empowerment alongside ethical uncertainty, and national ambition tempered by implementation challenges. The field is no longer just about who can build the biggest model—it’s about who can build the most trustworthy, usable, and enduring systems. As we move forward, the winners won’t just be the most innovative, but the most thoughtful.",
  "audioUrl": "",
  "papers": [
    {
      "id": "arxiv_2602_15294v1",
      "title": "EAA: Automating materials characterization with vision language model agents",
      "titleZh": "EAA: Automating materials characterization with vision language model agents",
      "titleEn": "EAA: Automating materials characterization with vision language model agents",
      "url": "https://arxiv.org/abs/2602.15294v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究提出实验自动化智能体（EAA），一种基于视觉语言模型的智能系统，用于自动化复杂的显微实验流程。EAA融合多模态推理、工具增强操作与可选长期记忆，支持从完全自主到用户交互引导的多种工作流，并通过兼容Model Context Protocol（MCP）的现代工具生态实现跨应用仪器控制。在先进光子源成像束线上的实验证明，EAA能自动完成区域板聚焦、自然语言描述的特征搜索和交互式数据采集，显著提升束线效率、降低操作负担并减少对用户专业经验的依赖。",
      "summaryZh": "研究提出实验自动化智能体（EAA），一种基于视觉语言模型的智能系统，用于自动化复杂的显微实验流程。EAA融合多模态推理、工具增强操作与可选长期记忆，支持从完全自主到用户交互引导的多种工作流，并通过兼容Model Context Protocol（MCP）的现代工具生态实现跨应用仪器控制。在先进光子源成像束线上的实验证明，EAA能自动完成区域板聚焦、自然语言描述的特征搜索和交互式数据采集，显著提升束线效率、降低操作负担并减少对用户专业经验的依赖。",
      "summaryEn": "The paper introduces Experiment Automation Agents (EAA), a vision-language-model-driven system that automates complex microscopy workflows by integrating multimodal reasoning, tool-augmented actions, and optional long-term memory. Built on a flexible task-manager architecture with two-way Model Context Protocol (MCP) compatibility, EAA supports fully autonomous to user-guided operations. Demonstrated at the Advanced Photon Source beamline, it enables automated zone plate focusing, natural language-based feature search, and interactive data acquisition—enhancing efficiency, reducing operational burden, and lowering expertise barriers.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Agent"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：EAA系统实现基于多模态大模型的实验自动化，显著提升科研效率，具备向全球实验室推广的产业变革潜力。",
        "热度：12 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-17T01:34:05+00:00",
      "authors": [
        "Ming Du",
        "Yanqi Luo",
        "Srutarshi Banerjee"
      ]
    },
    {
      "id": "arxiv_2602_15725v1",
      "title": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models",
      "titleZh": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models",
      "titleEn": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2602.15725v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对大语言模型在组合推理任务（如ARC-AGI-2、GPQA、MATH等）中表现不佳的问题，研究提出递归概念演化（RCE）框架，允许预训练模型在推理过程中动态修改其内部表征结构。RCE通过检测表征不足时生成低秩概念子空间，并依据最小描述长度准则选择、合并与优化这些子空间，从而构建新抽象而非仅重组已有知识。集成RCE的Mistral-7B在多个基准上取得显著提升：ARC-AGI-2提高12–18分，GPQA和BBH提升8–14分，并有效缓解MATH和HLE中的深度诱导错误，表明动态表征演化可突破固定潜空间对组合推理的限制。",
      "summaryZh": "针对大语言模型在组合推理任务（如ARC-AGI-2、GPQA、MATH等）中表现不佳的问题，研究提出递归概念演化（RCE）框架，允许预训练模型在推理过程中动态修改其内部表征结构。RCE通过检测表征不足时生成低秩概念子空间，并依据最小描述长度准则选择、合并与优化这些子空间，从而构建新抽象而非仅重组已有知识。集成RCE的Mistral-7B在多个基准上取得显著提升：ARC-AGI-2提高12–18分，GPQA和BBH提升8–14分，并有效缓解MATH和HLE中的深度诱导错误，表明动态表征演化可突破固定潜空间对组合推理的限制。",
      "summaryEn": "To address the sharp performance drop of large language models on compositional reasoning benchmarks like ARC-AGI-2, GPQA, MATH, BBH, and HLE, the paper proposes Recursive Concept Evolution (RCE)—a framework enabling pretrained models to dynamically reshape their internal representation geometry during inference. RCE spawns low-rank concept subspaces upon detecting representational inadequacy, selects and merges them via a minimum description length criterion, and consolidates them through constrained optimization. Integrated with Mistral-7B, RCE yields 12–18 point gains on ARC-AGI-2, 8–14 on GPQA/BBH, and reduces depth-induced errors in MATH/HLE, demonstrating that constructing new abstractions—not just recombining existing ones—can overcome fixed latent space limitations.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Inference",
        "Reasoning",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：针对LLM在组合推理中的根本缺陷提出递归概念演化机制，可能重塑大模型推理能力，具备战略级影响。",
        "热度：17 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-17T17:01:42+00:00",
      "authors": [
        "Sarim Chaudhry"
      ]
    },
    {
      "id": "arxiv_2602_15645v1",
      "title": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving",
      "titleZh": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving",
      "titleEn": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving",
      "url": "https://arxiv.org/abs/2602.15645v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为评估自动驾驶中视觉语言模型是否真正基于人类相关理由进行决策（而非事后合理化），研究提出CARE Drive框架——一种模型无关的上下文感知理由评估方法。该框架通过在受控情境下对比基线与注入人类理由后的模型决策变化，衡量模型对安全距离、社会压力、效率约束等理由的因果敏感性。在自行车超车场景测试中，显式理由显著提升了模型行为与专家建议的一致性，但响应程度因情境因素而异，证明可在不修改模型参数的前提下系统评估基础模型的“理由响应性”，对提升自动驾驶系统的可信度与安全性具有关键意义。",
      "summaryZh": "为评估自动驾驶中视觉语言模型是否真正基于人类相关理由进行决策（而非事后合理化），研究提出CARE Drive框架——一种模型无关的上下文感知理由评估方法。该框架通过在受控情境下对比基线与注入人类理由后的模型决策变化，衡量模型对安全距离、社会压力、效率约束等理由的因果敏感性。在自行车超车场景测试中，显式理由显著提升了模型行为与专家建议的一致性，但响应程度因情境因素而异，证明可在不修改模型参数的前提下系统评估基础模型的“理由响应性”，对提升自动驾驶系统的可信度与安全性具有关键意义。",
      "summaryEn": "To determine whether vision-language models in automated driving make decisions based on genuine human-relevant reasons rather than post hoc rationalizations, the paper introduces CARE Drive—a model-agnostic, context-aware evaluation framework. It measures causal sensitivity by comparing baseline and reason-augmented decisions under controlled perturbations of factors like safety margins, social pressure, and efficiency. In a cyclist overtaking scenario, explicit human reasons significantly improved alignment with expert behavior, though responsiveness varied across contexts. This demonstrates that reason-responsiveness in foundation models can be systematically evaluated without parameter modification, enhancing trust and safety in autonomous systems.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出CARE Drive评估框架，系统解决自动驾驶中VLM的可解释性与响应性问题，将深刻影响行业标准。",
        "热度：12 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-17T15:13:36+00:00",
      "authors": [
        "Lucas Elbert Suryana",
        "Farah Bierenga",
        "Sanne van Buuren"
      ]
    },
    {
      "id": "arxiv_2602_15549v1",
      "title": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
      "titleZh": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
      "titleEn": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
      "url": "https://arxiv.org/abs/2602.15549v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对视觉语言模型在动态制造环境中因无状态操作导致世界状态漂移、且推理过程不透明难以诊断的问题，研究提出VLM-DEWM架构，通过持久化、可查询的动态外部世界模型（DEWM）解耦VLM推理与状态管理。每个决策生成包含动作提议、世界信念和因果假设的可外部化推理轨迹（ERT），并在执行前由DEWM验证；失败时通过预测与观测状态的差异分析实现精准恢复。在多工位装配、大规模设施探索及真实机器人故障恢复实验中，VLM-DEWM将状态跟踪准确率从56%提升至93%，恢复成功率从不足5%提高到95%，并显著降低计算开销，为长周期制造机器人操作提供可验证、高韧性的解决方案。",
      "summaryZh": "针对视觉语言模型在动态制造环境中因无状态操作导致世界状态漂移、且推理过程不透明难以诊断的问题，研究提出VLM-DEWM架构，通过持久化、可查询的动态外部世界模型（DEWM）解耦VLM推理与状态管理。每个决策生成包含动作提议、世界信念和因果假设的可外部化推理轨迹（ERT），并在执行前由DEWM验证；失败时通过预测与观测状态的差异分析实现精准恢复。在多工位装配、大规模设施探索及真实机器人故障恢复实验中，VLM-DEWM将状态跟踪准确率从56%提升至93%，恢复成功率从不足5%提高到95%，并显著降低计算开销，为长周期制造机器人操作提供可验证、高韧性的解决方案。",
      "summaryEn": "To address world-state drift from stateless operation and opaque reasoning in vision-language models (VLMs) deployed in dynamic manufacturing, the paper presents VLM-DEWM—a cognitive architecture that decouples VLM reasoning from world-state management via a persistent, queryable Dynamic External World Model (DEWM). Each decision produces an Externalizable Reasoning Trace (ERT) validated against DEWM before execution; failures trigger targeted recovery via discrepancy analysis. Evaluated on multi-station assembly, large-scale exploration, and real-robot recovery, VLM-DEWM boosts state-tracking accuracy from 56% to 93%, recovery success from <5% to 95%, and reduces computational overhead—offering a verifiable, resilient solution for long-horizon robotic operations.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Robotics"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：VLM-DEWM解决视觉语言模型在智能制造中的状态漂移与推理不可信问题，是面向6G+AI融合的关键突破，具备国家级战略意义。",
        "热度：13 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-17T12:54:18+00:00",
      "authors": [
        "Guoqin Tang",
        "Qingxuan Jia",
        "Gang Chen"
      ]
    },
    {
      "id": "arxiv_2602_15281v1",
      "title": "High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration",
      "titleZh": "High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration",
      "titleEn": "High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration",
      "url": "https://arxiv.org/abs/2602.15281v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为支持跨域联邦AI即服务（AIaaS）的高保真交付，研究提出基于尾部风险包络（TREs）的保障导向管理平面：TRE是可组合的域级描述符，结合确定性护栏与随机速率-延迟-损伤模型，利用随机网络演算推导端到端延迟违规概率界，并实现优化就绪的风险预算分解。该框架通过租户级预留防止突发流量抬升尾部延迟，审计层则利用运行时遥测估计极端百分位性能、量化不确定性并追溯各域的尾部风险责任。包级蒙特卡洛仿真表明，TRE机制在过载下通过准入控制提升p99.9合规性，并在突发流量相关性强时仍保持稳健的租户隔离。",
      "summaryZh": "为支持跨域联邦AI即服务（AIaaS）的高保真交付，研究提出基于尾部风险包络（TREs）的保障导向管理平面：TRE是可组合的域级描述符，结合确定性护栏与随机速率-延迟-损伤模型，利用随机网络演算推导端到端延迟违规概率界，并实现优化就绪的风险预算分解。该框架通过租户级预留防止突发流量抬升尾部延迟，审计层则利用运行时遥测估计极端百分位性能、量化不确定性并追溯各域的尾部风险责任。包级蒙特卡洛仿真表明，TRE机制在过载下通过准入控制提升p99.9合规性，并在突发流量相关性强时仍保持稳健的租户隔离。",
      "summaryEn": "To enable high-fidelity AI-as-a-Service (AIaaS) delivery across multi-domain federations, the paper introduces an assurance-oriented management plane based on Tail-Risk Envelopes (TREs)—signed, composable per-domain descriptors combining deterministic guardrails with stochastic rate-latency-impairment models. Using stochastic network calculus, it derives end-to-end delay violation bounds and an optimization-ready risk-budget decomposition. Tenant-level reservations prevent bursty traffic from inflating tail latency, while an auditing layer uses runtime telemetry to estimate extreme-percentile performance, quantify uncertainty, and attribute tail-risk per domain. Packet-level Monte Carlo simulations show improved p99.9 compliance under overload and robust tenant isolation despite correlated burstiness.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Inference",
        "Research"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出联邦AI即服务的跨域协同管理架构，直接支撑6G时代通信服务商向AI基础设施提供者转型，具有全球产业战略意义。",
        "热度：12 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-17T00:40:04+00:00",
      "authors": [
        "Merve Saimler",
        "Mohaned Chraiti",
        "Ozgur Ercetin"
      ]
    },
    {
      "id": "arxiv_2602_15286v1",
      "title": "AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service",
      "titleZh": "AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service",
      "titleEn": "AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service",
      "url": "https://arxiv.org/abs/2602.15286v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为应对AI即服务（AIaaS）中用户缺乏模型选择与执行控制能力的问题，研究提出AI-Paging机制——一种类比蜂窝呼叫寻呼的网络控制面事务，由6G网络根据用户意图在策略、信任与QoS约束下完成意图到模型的匹配与执行锚点选择。AI-Paging输出AI服务标识（AISI）、作用域会话令牌（AIST）和带QoS绑定的过期准入租约（COMMIT），确保仅凭有效租约才安装用户面转发状态，并采用“先建后断”锚定策略保障服务连续性。原型基于现有3GPP控制与用户面机制实现，无需新包头，在移动与故障场景下验证了事务延迟、重定位中断、租约过期强制执行及审计证据开销的可行性。",
      "summaryZh": "为应对AI即服务（AIaaS）中用户缺乏模型选择与执行控制能力的问题，研究提出AI-Paging机制——一种类比蜂窝呼叫寻呼的网络控制面事务，由6G网络根据用户意图在策略、信任与QoS约束下完成意图到模型的匹配与执行锚点选择。AI-Paging输出AI服务标识（AISI）、作用域会话令牌（AIST）和带QoS绑定的过期准入租约（COMMIT），确保仅凭有效租约才安装用户面转发状态，并采用“先建后断”锚定策略保障服务连续性。原型基于现有3GPP控制与用户面机制实现，无需新包头，在移动与故障场景下验证了事务延迟、重定位中断、租约过期强制执行及审计证据开销的可行性。",
      "summaryEn": "To address users’ lack of control over model selection and execution placement in AI-as-a-Service (AIaaS), the paper proposes AI-Paging—a network control-plane transaction analogous to cellular paging. In 6G networks, it resolves user intent into an AI Service Identity (AISI), a scoped session token (AIST), and an expiring admission lease (COMMIT) that authorizes user-plane steering to a selected AI execution anchor (AEXF) under QoS binding. AI-Paging enforces lease-gated steering and make-before-break anchoring for continuity. Implemented using existing 3GPP mechanisms without new packet headers, it demonstrates feasible transaction latency, relocation interruption, enforcement correctness under lease expiry, and audit overhead under mobility and failures.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Training"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：AI-Paging提出基于租赁的执行锚定机制，为多提供商AIaaS运行时调度提供关键解决方案，是6G网络化AI服务的核心支撑技术。",
        "热度：11 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-17T01:11:26+00:00",
      "authors": [
        "Merve Saimler",
        "Mohaned Chraiti"
      ]
    },
    {
      "id": "arxiv_2602_15055v1",
      "title": "Beyond Context Sharing: A Unified Agent Communication Protocol (ACP) for Secure, Federated, and Autonomous Agent-to-Agent (A2A) Orchestration",
      "titleZh": "Beyond Context Sharing: A Unified Agent Communication Protocol (ACP) for Secure, Federated, and Autonomous Agent-to-Agent (A2A) Orchestration",
      "titleEn": "Beyond Context Sharing: A Unified Agent Communication Protocol (ACP) for Secure, Federated, and Autonomous Agent-to-Agent (A2A) Orchestration",
      "url": "https://arxiv.org/abs/2602.15055v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为突破当前AI智能体跨平台、去中心化与安全交互的瓶颈，研究提出统一的智能体通信协议（ACP），作为Model Context Protocol（MCP）的扩展，支持异构智能体在不同环境中发现、协商并执行协作工作流。ACP整合去中心化身份验证、语义意图映射与自动化服务级别协议，构建联邦式编排模型。初步评估显示，ACP在维持零信任安全姿态的同时显著降低智能体间通信延迟，为构建可扩展、互操作的自主数字实体生态系统迈出关键一步。",
      "summaryZh": "为突破当前AI智能体跨平台、去中心化与安全交互的瓶颈，研究提出统一的智能体通信协议（ACP），作为Model Context Protocol（MCP）的扩展，支持异构智能体在不同环境中发现、协商并执行协作工作流。ACP整合去中心化身份验证、语义意图映射与自动化服务级别协议，构建联邦式编排模型。初步评估显示，ACP在维持零信任安全姿态的同时显著降低智能体间通信延迟，为构建可扩展、互操作的自主数字实体生态系统迈出关键一步。",
      "summaryEn": "To overcome barriers to secure, cross-platform, and decentralized interaction among autonomous AI agents, the paper introduces the Agent Communication Protocol (ACP)—an extension of the Model Context Protocol (MCP) that enables heterogeneous agents to discover, negotiate, and execute collaborative workflows across disparate environments. ACP integrates decentralized identity verification, semantic intent mapping, and automated service-level agreements within a federated orchestration model. Initial evaluation shows ACP reduces inter-agent communication latency while maintaining a zero-trust security posture, advancing toward a scalable, interoperable ecosystem of autonomous digital entities.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "Reasoning",
        "Research"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出统一的A2A通信协议，解决多平台自治代理协同难题，对全球AI Agent生态构建具有战略意义。",
        "热度：18 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T17:02:12+00:00",
      "authors": [
        "Naveen Kumar Krishnan"
      ]
    },
    {
      "id": "arxiv_2602_15400v1",
      "title": "One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation",
      "titleZh": "One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation",
      "titleEn": "One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation",
      "url": "https://arxiv.org/abs/2602.15400v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对当前多模态大语言模型（MLLM）在视觉语言导航中因语义规划与空间感知紧耦合而性能受限的问题，研究提出解耦设计：将低层空间状态估计与高层语义规划分离，并引入交互式度量世界表征以替代简化的文本地图，使MLLM能在物理一致的环境中推理决策。结合反事实推理进一步激发模型能力，该方法在R2R-CE和RxR-CE基准上分别达到48.8%和42.2%的零样本成功率，刷新纪录；更实现了从仿真到真实世界的零样本迁移，成功部署于轮式TurtleBot 4与自研无人机，验证了该框架作为领域不变接口的鲁棒性与通用性。",
      "summaryZh": "针对当前多模态大语言模型（MLLM）在视觉语言导航中因语义规划与空间感知紧耦合而性能受限的问题，研究提出解耦设计：将低层空间状态估计与高层语义规划分离，并引入交互式度量世界表征以替代简化的文本地图，使MLLM能在物理一致的环境中推理决策。结合反事实推理进一步激发模型能力，该方法在R2R-CE和RxR-CE基准上分别达到48.8%和42.2%的零样本成功率，刷新纪录；更实现了从仿真到真实世界的零样本迁移，成功部署于轮式TurtleBot 4与自研无人机，验证了该框架作为领域不变接口的鲁棒性与通用性。",
      "summaryEn": "To overcome performance limitations of tightly coupled semantic planning and spatial perception in vision-and-language navigation with Multimodal Large Language Models (MLLMs), the paper proposes a decoupled design: separating low-level spatial state estimation from high-level planning and replacing oversimplified textual maps with an interactive metric world representation that maintains physical consistency. Enhanced with counterfactual reasoning, the method achieves new zero-shot state-of-the-art results—48.8% Success Rate on R2R-CE and 42.2% on RxR-CE—and demonstrates zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom aerial drone, validating its robustness as a domain-invariant interface for embodied navigation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Agent"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：通过显式世界表征赋能多模态大模型导航，解决 MLLM 在具身任务中的关键瓶颈，具备推动智能体发展的战略意义。",
        "热度：16 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-17T07:13:48+00:00",
      "authors": [
        "Zerui Li",
        "Hongpei Zheng",
        "Fangguo Zhao"
      ]
    },
    {
      "id": "arxiv_2602_15258v1",
      "title": "SEG-JPEG: Simple Visual Semantic Communications for Remote Operation of Automated Vehicles over Unreliable Wireless Networks",
      "titleZh": "SEG-JPEG: Simple Visual Semantic Communications for Remote Operation of Automated Vehicles over Unreliable Wireless Networks",
      "titleEn": "SEG-JPEG: Simple Visual Semantic Communications for Remote Operation of Automated Vehicles over Unreliable Wireless Networks",
      "url": "https://arxiv.org/abs/2602.15258v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对远程操控自动驾驶车辆在不可靠无线网络下图像传输带宽高、延迟大的问题，研究提出SEG-JPEG方法，通过将检测到的道路使用者语义分割结果以彩色高亮形式嵌入低分辨率灰度图像中，在保持视觉清晰度的同时将数据率降低50%。该方法在低于500kbit/s的网络条件下实现端到端延迟低于200ms，并在真实4G信号波动环境中成功部署于末端配送无人车，表明其有望支持大规模远程操控自动驾驶车辆在现有公共4G/5G网络上的落地应用。",
      "summaryZh": "针对远程操控自动驾驶车辆在不可靠无线网络下图像传输带宽高、延迟大的问题，研究提出SEG-JPEG方法，通过将检测到的道路使用者语义分割结果以彩色高亮形式嵌入低分辨率灰度图像中，在保持视觉清晰度的同时将数据率降低50%。该方法在低于500kbit/s的网络条件下实现端到端延迟低于200ms，并在真实4G信号波动环境中成功部署于末端配送无人车，表明其有望支持大规模远程操控自动驾驶车辆在现有公共4G/5G网络上的落地应用。",
      "summaryEn": "To address high bandwidth demands and latency in remote operation of automated vehicles over unreliable wireless networks, the paper proposes SEG-JPEG, which embeds color-coded semantic segmentations of detected road users into low-resolution grayscale images. This reduces data rates by 50% while preserving visual clarity, achieving sub-200ms glass-to-glass latency even below 500 kbit/s. Demonstrated on an automated last-mile delivery vehicle under variable 4G connectivity, the approach shows potential for large-scale deployment of remotely operated autonomous vehicles on existing public 4G/5G infrastructure.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Research"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出 SEG-JPEG 视觉语义通信方案，突破远程自动驾驶在低带宽网络下的传输瓶颈，具有全球性产业落地前景。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-16T23:28:10+00:00",
      "authors": [
        "Sebastian Donnelly",
        "Ruth Anderson",
        "George Economides"
      ]
    },
    {
      "id": "arxiv_2602_15513v1",
      "title": "Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling",
      "titleZh": "Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling",
      "titleEn": "Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling",
      "url": "https://arxiv.org/abs/2602.15513v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为提升多模态大语言模型（MLLM）在具身智能体中的长期探索与问答能力，研究提出一种受人类记忆启发的非参数化记忆框架，显式分离情景记忆与语义记忆：前者通过语义相似性检索过往经验并结合视觉推理验证，后者则将经验转化为结构化规则以支持跨环境泛化。该方法在A-EQA和GOAT-Bench基准上分别提升LLM-Match指标7.3%、成功率达+7.7%，证明情景记忆优化探索效率，语义记忆增强复杂推理能力。",
      "summaryZh": "为提升多模态大语言模型（MLLM）在具身智能体中的长期探索与问答能力，研究提出一种受人类记忆启发的非参数化记忆框架，显式分离情景记忆与语义记忆：前者通过语义相似性检索过往经验并结合视觉推理验证，后者则将经验转化为结构化规则以支持跨环境泛化。该方法在A-EQA和GOAT-Bench基准上分别提升LLM-Match指标7.3%、成功率达+7.7%，证明情景记忆优化探索效率，语义记忆增强复杂推理能力。",
      "summaryEn": "To enhance Multimodal Large Language Models (MLLMs) as controllers for embodied agents in long-horizon tasks, the work introduces a human-inspired, non-parametric memory framework that explicitly disentangles episodic and semantic memory. Episodic memory retrieves past experiences via semantic similarity and verifies them through visual reasoning, while semantic memory extracts structured, reusable rules from experiences for cross-environment generalization. The method achieves state-of-the-art results, with +7.3% LLM-Match on A-EQA and +7.7% success rate on GOAT-Bench, showing episodic memory improves exploration efficiency and semantic memory strengthens complex reasoning.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Multimodal",
        "Agent",
        "Robotics"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出人类启发式记忆建模解决多模态Agent长期探索难题，对具身智能发展有重要推动作用，具备未来6-12个月行业引领潜力。",
        "热度：18 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T11:41:28+00:00",
      "authors": [
        "Ji Li",
        "Jing Xia",
        "Mingyi Li"
      ]
    },
    {
      "id": "arxiv_2602_15396v1",
      "title": "Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching",
      "titleZh": "Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching",
      "titleEn": "Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching",
      "url": "https://arxiv.org/abs/2602.15396v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对传统扩散模型因无记忆前向过程导致轨迹弯曲、采样效率低的问题，研究提出伴随薛定谔桥匹配（ASBM）框架，通过两阶段学习恢复高维空间中的最优生成路径：先从数据到能量先验构建耦合，再以简单匹配损失学习反向动态。该方法在非无记忆机制下生成更直、更高效的采样轨迹，在图像生成任务中以更少步数提升保真度，并成功蒸馏为单步生成器，展现出更强的稳定性与可扩展性。",
      "summaryZh": "针对传统扩散模型因无记忆前向过程导致轨迹弯曲、采样效率低的问题，研究提出伴随薛定谔桥匹配（ASBM）框架，通过两阶段学习恢复高维空间中的最优生成路径：先从数据到能量先验构建耦合，再以简单匹配损失学习反向动态。该方法在非无记忆机制下生成更直、更高效的采样轨迹，在图像生成任务中以更少步数提升保真度，并成功蒸馏为单步生成器，展现出更强的稳定性与可扩展性。",
      "summaryEn": "Addressing the highly curved trajectories and inefficiency of standard diffusion models caused by their memoryless forward process, the paper proposes Adjoint Schrödinger Bridge Matching (ASBM), a two-stage framework that recovers optimal high-dimensional generative paths. It first learns a data-to-energy coupling to transport samples to an energy-defined prior, then trains the backward dynamics via a simple matching loss. Operating beyond the memoryless regime, ASBM yields significantly straighter, more efficient sampling paths, improves image fidelity with fewer steps, and enables effective distillation into a one-step generator, demonstrating enhanced stability and scalability.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Diffusion"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出邻接薛定谔桥匹配框架，解决扩散模型轨迹弯曲与噪声问题，理论创新性强，有望推动生成模型基础范式演进。",
        "热度：8 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T07:06:20+00:00",
      "authors": [
        "Jeongwoo Shin",
        "Jinhwan Sul",
        "Joonseok Lee"
      ]
    },
    {
      "id": "arxiv_2602_15355v1",
      "title": "DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles",
      "titleZh": "DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles",
      "titleEn": "DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles",
      "url": "https://arxiv.org/abs/2602.15355v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为降低基于Wang Tiles的3D高斯泼溅场景重建对密集观测数据的依赖，研究提出DAV-GSWT框架，结合扩散先验与主动视角采样，通过分层不确定性量化机制自动选择信息量最大的观测视角，并利用生成模型补全缺失结构以确保瓦片无缝拼接。实验表明，该方法在大幅减少输入数据量的同时，仍能维持高保真度与交互性能，适用于大规模虚拟环境的高效构建。",
      "summaryZh": "为降低基于Wang Tiles的3D高斯泼溅场景重建对密集观测数据的依赖，研究提出DAV-GSWT框架，结合扩散先验与主动视角采样，通过分层不确定性量化机制自动选择信息量最大的观测视角，并利用生成模型补全缺失结构以确保瓦片无缝拼接。实验表明，该方法在大幅减少输入数据量的同时，仍能维持高保真度与交互性能，适用于大规模虚拟环境的高效构建。",
      "summaryEn": "To reduce the reliance of Wang Tile-based 3D Gaussian Splatting on densely sampled exemplars, the paper presents DAV-GSWT, a data-efficient framework that integrates diffusion priors with active view sampling. It uses a hierarchical uncertainty quantification mechanism to autonomously select the most informative viewpoints and hallucinates missing structural details via generative diffusion models to ensure seamless tile transitions. Experiments show the method significantly cuts required input data while preserving visual fidelity and interactive performance, enabling scalable virtual environment synthesis.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Diffusion",
        "3D",
        "RAG"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：结合扩散模型与主动视图采样，提升数据效率下的3D高斯泼溅瓦片生成能力，推动神经渲染向大规模真实环境扩展。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T04:47:39+00:00",
      "authors": [
        "Rong Fu",
        "Jiekai Wu",
        "Haiyun Wei"
      ]
    },
    {
      "id": "arxiv_2602_15633v1",
      "title": "SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms",
      "titleZh": "SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms",
      "titleEn": "SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms",
      "url": "https://arxiv.org/abs/2602.15633v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对无人机在波浪扰动海面平台自主着陆时因多频振荡与预测相位滞后导致精度不足的问题，研究提出SpecFuse框架，融合频域波浪谐波分解与时域递归状态估计，实现高精度六自由度运动预测；结合HPO-RRT*动态轨迹规划与学习增强预测控制，在2000次仿真和8次湖试中达成3.2厘米预测误差、4.46厘米着陆偏差及87.5%实机成功率，延迟仅82毫秒，显著优于现有方法，为海上搜救等任务提供可靠技术支撑。",
      "summaryZh": "针对无人机在波浪扰动海面平台自主着陆时因多频振荡与预测相位滞后导致精度不足的问题，研究提出SpecFuse框架，融合频域波浪谐波分解与时域递归状态估计，实现高精度六自由度运动预测；结合HPO-RRT*动态轨迹规划与学习增强预测控制，在2000次仿真和8次湖试中达成3.2厘米预测误差、4.46厘米着陆偏差及87.5%实机成功率，延迟仅82毫秒，显著优于现有方法，为海上搜救等任务提供可靠技术支撑。",
      "summaryEn": "To tackle the challenge of autonomous UAV landing on oscillating marine platforms—where wave-induced multi-frequency motion and prediction phase lags degrade accuracy—the paper proposes SpecFuse, a spectral-temporal fusion predictive control framework. It integrates frequency-domain wave harmonic decomposition with time-domain recursive state estimation for precise 6-DoF motion forecasting, paired with a hierarchical controller using HPO-RRT* for dynamic trajectory planning and a learning-augmented predictive module. Validated in 2,000 simulations and 8 lake trials, it achieves 3.2 cm prediction error, 4.46 cm landing deviation, 87.5% real-world success rate, and 82 ms latency—outperforming state-of-the-art methods by 44–48% in accuracy.",
      "fullText": "",
      "imageUrl": "",
      "tags": [],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：针对海上无人机着陆难题提出谱-时域融合控制框架，直接面向高风险、高价值的海洋无人系统场景，技术突破显著。",
        "热度：13 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T15:03:05+00:00",
      "authors": [
        "Haichao Liu",
        "Yufeng Hu",
        "Shuang Wang"
      ]
    },
    {
      "id": "arxiv_2602_15329v1",
      "title": "EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use",
      "titleZh": "EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use",
      "titleEn": "EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use",
      "url": "https://arxiv.org/abs/2602.15329v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决在线视频理解中无限流输入与多模态大模型有限上下文窗口之间的矛盾，研究提出EventMemAgent框架，采用分层事件中心记忆机制：短期记忆通过事件边界检测与动态水库采样处理帧流，长期记忆按事件结构化归档历史；同时集成多粒度感知工具包并通过具身强化学习内化工具使用策略，在保持细粒度细节的同时支持长程推理，已在多个在线视频基准上展现竞争力。",
      "summaryZh": "为解决在线视频理解中无限流输入与多模态大模型有限上下文窗口之间的矛盾，研究提出EventMemAgent框架，采用分层事件中心记忆机制：短期记忆通过事件边界检测与动态水库采样处理帧流，长期记忆按事件结构化归档历史；同时集成多粒度感知工具包并通过具身强化学习内化工具使用策略，在保持细粒度细节的同时支持长程推理，已在多个在线视频基准上展现竞争力。",
      "summaryEn": "To reconcile the unbounded nature of online video streams with the limited context window of Multimodal Large Language Models (MLLMs), the paper introduces EventMemAgent, a hierarchical event-centric memory framework. Its short-term memory detects event boundaries and applies reservoir sampling within a fixed buffer, while long-term memory archives observations event-by-event. Coupled with a multi-granular perception toolkit and Agentic Reinforcement Learning to internalize tool-use strategies, the agent enables continuous perception and long-range reasoning without sacrificing fine-grained detail, achieving competitive results on online video understanding benchmarks.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Multimodal",
        "Agent",
        "Reasoning"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：构建层级事件中心记忆机制，有效应对在线视频理解中的长时序推理挑战，是具身智能与持续感知的重要进展。",
        "热度：19 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T03:17:24+00:00",
      "authors": [
        "Siwei Wen",
        "Zhangcheng Wang",
        "Xingjian Zhang"
      ]
    },
    {
      "id": "arxiv_2602_15813v1",
      "title": "FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy",
      "titleZh": "FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy",
      "titleEn": "FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy",
      "url": "https://arxiv.org/abs/2602.15813v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为提升具身问答（EQA）系统在部分可观测环境中的搜索效率与推理速度，研究提出FAST-EQA框架，通过问题条件引导识别潜在目标、评分全局兴趣区域以指导导航，并在有限容量的记忆中维护区域-目标假设集，结合链式思维推理生成答案；其全局探索策略将门洞等狭窄开口视为高价值前沿，显著加快推理速度，在HMEQA和EXPRESS-Bench上达到SOTA性能，同时在OpenEQA等基准保持竞争力。",
      "summaryZh": "为提升具身问答（EQA）系统在部分可观测环境中的搜索效率与推理速度，研究提出FAST-EQA框架，通过问题条件引导识别潜在目标、评分全局兴趣区域以指导导航，并在有限容量的记忆中维护区域-目标假设集，结合链式思维推理生成答案；其全局探索策略将门洞等狭窄开口视为高价值前沿，显著加快推理速度，在HMEQA和EXPRESS-Bench上达到SOTA性能，同时在OpenEQA等基准保持竞争力。",
      "summaryEn": "To improve efficiency and speed in Embodied Question Answering (EQA) under partial observability, the paper proposes FAST-EQA, a question-conditioned framework that identifies likely visual targets, scores global regions of interest for navigation, and applies Chain-of-Thought reasoning over a bounded memory of region-target hypotheses. Its global exploration policy treats narrow openings like doors as high-value frontiers, minimizing computation while expanding coverage. FAST-EQA achieves state-of-the-art results on HMEQA and EXPRESS-Bench and remains competitive on OpenEQA and MT-HM3D, all while running substantially faster than prior methods.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent",
        "Robotics",
        "3D",
        "Inference"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：FAST-EQA 提出全局与局部区域相关性联合推理机制，显著提升具身问答效率，推动 AI 代理在复杂环境中的决策能力。",
        "热度：18 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T18:49:43+00:00",
      "authors": [
        "Haochen Zhang",
        "Nirav Savaliya",
        "Faizan Siddiqui"
      ]
    },
    {
      "id": "arxiv_2602_15648v1",
      "title": "Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design",
      "titleZh": "Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design",
      "titleEn": "Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design",
      "url": "https://arxiv.org/abs/2602.15648v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对材料逆向设计中离散参数与约束导致梯度优化困难的问题，研究提出基于扩散模型的新方法：将原始设计空间松弛为连续网格表示，利用隐式微分计算前向仿真（线性有限元）梯度，训练扩散模型作为合理设计的先验，并在推理时通过目标函数引导采样，最终回投影至原始空间。在二维和三维复合材料设计中，该方法能以1%相对误差匹配目标体模量，并支持多目标优化以同步最小化材料密度。",
      "summaryZh": "针对材料逆向设计中离散参数与约束导致梯度优化困难的问题，研究提出基于扩散模型的新方法：将原始设计空间松弛为连续网格表示，利用隐式微分计算前向仿真（线性有限元）梯度，训练扩散模型作为合理设计的先验，并在推理时通过目标函数引导采样，最终回投影至原始空间。在二维和三维复合材料设计中，该方法能以1%相对误差匹配目标体模量，并支持多目标优化以同步最小化材料密度。",
      "summaryEn": "To address the difficulty of gradient-based optimization in inverse material design due to discrete parameters and constraints, the paper proposes a diffusion-based approach: it relaxes the original design space into a continuous grid where gradients through a differentiable forward simulation (linear FEM) can be computed via implicit differentiation. A diffusion model trained on this relaxed space serves as a prior, and guided sampling at inference time uses gradients from user-specified objectives. Final designs are obtained by backprojection. In 2D/3D composite material design, the method generates diverse structures matching target bulk moduli within 1% relative error and supports multi-objective optimization to simultaneously minimize material density.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Diffusion",
        "3D",
        "Inference"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：通过优化损失函数实现松弛参数下的引导扩散，加速逆向材料设计，对工业仿真与新材料研发有深远影响。",
        "热度：8 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-17T15:15:28+00:00",
      "authors": [
        "Jens U. Kreber",
        "Christian Weißenfels",
        "Joerg Stueckler"
      ]
    },
    {
      "id": "arxiv_2602_15724v1",
      "title": "Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation",
      "titleZh": "Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation",
      "titleEn": "Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation",
      "url": "https://arxiv.org/abs/2602.15724v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对视觉-语言导航（VLN）中大语言模型（LLM）因重复解析指令和处理冗余候选动作而导致决策效率低下的问题，该论文提出一种无需修改或微调LLM的检索增强框架：在任务层面，通过指令嵌入检索语义相似的成功轨迹作为上下文示例，提供任务先验；在步骤层面，采用模仿学习训练的候选方向检索器，在LLM推理前剪枝无关动作，降低提示复杂度。该方法在Room-to-Room（R2R）基准上显著提升了成功率、Oracle成功率和路径长度加权成功率（SPL），且两个模块轻量、模块化、独立于LLM训练，表明检索增强是提升LLM驱动VLN效率与稳定性的有效策略。",
      "summaryZh": "针对视觉-语言导航（VLN）中大语言模型（LLM）因重复解析指令和处理冗余候选动作而导致决策效率低下的问题，该论文提出一种无需修改或微调LLM的检索增强框架：在任务层面，通过指令嵌入检索语义相似的成功轨迹作为上下文示例，提供任务先验；在步骤层面，采用模仿学习训练的候选方向检索器，在LLM推理前剪枝无关动作，降低提示复杂度。该方法在Room-to-Room（R2R）基准上显著提升了成功率、Oracle成功率和路径长度加权成功率（SPL），且两个模块轻量、模块化、独立于LLM训练，表明检索增强是提升LLM驱动VLN效率与稳定性的有效策略。",
      "summaryEn": "To address inefficient decision-making in Vision-and-Language Navigation (VLN) caused by large language models (LLMs) repeatedly parsing instructions and reasoning over noisy, verbose navigable candidates, this paper proposes a retrieval-augmented framework that enhances LLM-based VLN without modifying or fine-tuning the underlying model. At the episode level, an instruction-embedding retriever selects semantically similar successful trajectories as in-context exemplars to provide task-specific priors. At the step level, an imitation-learned candidate retriever prunes irrelevant directions before LLM inference, reducing action ambiguity and prompt complexity. Both lightweight, modular components are trained independently of the LLM. Evaluated on the Room-to-Room (R2R) benchmark, the method consistently improves Success Rate, Oracle Success Rate, and SPL across seen and unseen environments, demonstrating that retrieval-augmented decision support is an effective and scalable strategy for efficient LLM-based navigation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Agent",
        "Training"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：改进视觉-语言导航中候选路径检索效率，结合LLM推理与视觉感知，推动智能体自主导航落地应用。",
        "热度：17 / 评论 0"
      ],
      "score": 7.0,
      "publishedAt": "2026-02-17T17:00:11+00:00",
      "authors": [
        "Shutian Gu",
        "Chengkai Huang",
        "Ruoyu Wang"
      ]
    },
    {
      "id": "arxiv_2602_15727v1",
      "title": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "titleZh": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "titleEn": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "url": "https://arxiv.org/abs/2602.15727v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为克服现有视觉类比方法使用单一LoRA模块难以泛化到多样变换的局限，该研究提出LoRWeB：构建一个可学习的LoRA基底集合以覆盖不同视觉变换空间，并设计轻量编码器根据输入类比对动态加权组合这些基底LoRA，在推理时实现任务特化的模型调整。该方法在标准评估中达到SOTA性能，显著提升对未见视觉变换的泛化能力，表明基于LoRA基底分解的动态组合是实现灵活、可泛化视觉操控的有效路径。",
      "summaryZh": "为克服现有视觉类比方法使用单一LoRA模块难以泛化到多样变换的局限，该研究提出LoRWeB：构建一个可学习的LoRA基底集合以覆盖不同视觉变换空间，并设计轻量编码器根据输入类比对动态加权组合这些基底LoRA，在推理时实现任务特化的模型调整。该方法在标准评估中达到SOTA性能，显著提升对未见视觉变换的泛化能力，表明基于LoRA基底分解的动态组合是实现灵活、可泛化视觉操控的有效路径。",
      "summaryEn": "To overcome the limitation of existing visual analogy methods that use a single LoRA module and struggle to generalize across diverse transformations, this paper proposes LoRWeB: a learnable basis of LoRA modules that spans the space of visual transformations, combined with a lightweight encoder that dynamically weights and composes these basis LoRAs based on the input analogy pair, enabling task-specific model adaptation at inference time. The approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations, suggesting that dynamic composition via LoRA basis decomposition is a promising direction for flexible and generalizable visual manipulation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Robotics",
        "Inference",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：利用LoRA权重基实现视觉类比空间拓展，为图像生成与编辑提供新范式，具备创新性和应用潜力。",
        "热度：10 / 评论 0"
      ],
      "score": 7.0,
      "publishedAt": "2026-02-17T17:02:38+00:00",
      "authors": [
        "Hila Manor",
        "Rinon Gal",
        "Haggai Maron"
      ]
    }
  ],
  "news": [
    {
      "id": "rss_2861544210",
      "title": "微软Project Silica实现万年玻璃存储，成本大降",
      "titleZh": "微软Project Silica实现万年玻璃存储，成本大降",
      "titleEn": "Microsoft’s Project Silica Achieves 10,000-Year Glass Storage at Lower Cost",
      "url": "https://www.microsoft.com/en-us/research/blog/project-silicas-advances-in-glass-storage-technology/",
      "type": "news",
      "source": "Microsoft Research",
      "summary": "**微软研究院在《自然》发表突破性成果**，将Project Silica玻璃存储技术从昂贵的熔融石英扩展至普通硼硅酸盐玻璃（如厨房耐热玻璃），大幅降低介质成本并简化读写系统；新方法采用单脉冲“相位体素”写入、多光束并行写入及仅需单摄像头的读取方案，使数据保存寿命达10,000年，**为数字档案长期保存提供了一种抗水、耐热、防尘的永久性解决方案**，普通人未来或可通过此类技术安全存档重要数字遗产，而机构可借此构建真正可持续的冷存储基础设施。",
      "summaryZh": "**微软研究院在《自然》发表突破性成果**，将Project Silica玻璃存储技术从昂贵的熔融石英扩展至普通硼硅酸盐玻璃（如厨房耐热玻璃），大幅降低介质成本并简化读写系统；新方法采用单脉冲“相位体素”写入、多光束并行写入及仅需单摄像头的读取方案，使数据保存寿命达10,000年，**为数字档案长期保存提供了一种抗水、耐热、防尘的永久性解决方案**，普通人未来或可通过此类技术安全存档重要数字遗产，而机构可借此构建真正可持续的冷存储基础设施。",
      "summaryEn": "Microsoft Research published a breakthrough in Nature, extending Project Silica’s glass-based data storage from expensive fused silica to common borosilicate glass—like kitchenware—dramatically lowering media cost and simplifying readers (now requiring just one camera) and writers. Using single-pulse 'phase voxel' writing, multi-beam parallel encoding, and machine learning for error correction, the technology enables 10,000-year data preservation in a medium resistant to water, heat, and dust. This advancement offers a viable path for individuals to archive digital legacies and for institutions to build truly sustainable, immutable cold storage infrastructure.",
      "fullText": "At a glance Microsoft Research publishes&nbsp;breakthrough&nbsp;in&nbsp;Nature&nbsp;on glass-based data storage that could preserve information for 10,000 years.&nbsp; New&nbsp;technique extends technology from expensive fused silica to ordinary borosilicate glass found in kitchen cookware.&nbsp; Innovations enable faster parallel writing, simplified readers (one camera instead of three), and easier manufacturing.&nbsp; Phase voxel method requires only a single laser pulse, significantly reducing complexity and cost. Long-term preservation of digital information has long challenged archivists and datacenters, as magnetic tapes and hard drives degrade within decades. Existing archival storage solutions have limited media lifespans that make them less than ideal for preserving information for future generations. Now, we are excited to report significant progress on Project Silica (opens in new tab), our effort to encode data in glass using femtosecond lasers, a technology that could preserve information for 10,000 years. Glass is a permanent data storage material that is resistant to water, heat, and dust. In findings published in Nature (opens in new tab), we describe a breakthrough that extends the technology beyond expensive fused silica to ordinary borosilicate glass. A readily available and lower-cost medium, this is the same material found in kitchen cookware and oven doors. This advance addresses key barriers to commercialization: cost and availability of storage media. We have unlocked the science for parallel high-speed writing and developed a technique to permit accelerated aging tests on the written glass, suggesting that the data should remain intact for at least 10,000 years. Storing data inside glass with femtosecond (opens in new tab) laser pulses is one of the few technologies on the horizon with the potential for durable, immutable, and long-lived storage. Although we have been leading innovation in this type of storage for years, prior to this research the technique only worked with pure fused silica glass, a type of glass that is relatively difficult to manufacture and available from only a few sources. In the paper, we show how data can be stored in borosilicate glass. The new technique stores hundreds of layers of data in glass only 2mm thin, as with previous methods, but with important improvements. The reader for the glass now needs only one camera, not three or four, reducing cost and size. In addition, the writing devices require fewer parts, making them easier to manufacture and calibrate, and enabling them to encode data more quickly. Spotlight: Event Series Microsoft Research Forum Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand. Watch on-demand Opens in a new tab Key scientific discoveries The Nature paper details several key new scientific discoveries: Advances in birefringent voxel (opens in new tab) writing: For the previous type of data storage in fused silica glass using birefringent (i.e., polarization) voxels, we developed a technique to reduce the number of pulses used to form the voxel from many to only two, critically showing that the polarization of the first pulse is not important to the polarization of the voxel formed. We further developed this to enable pseudo-single-pulse writing, in which a single pulse can be split after its polarization is set to simultaneously form the first pulse for one voxel (where the polarization doesn’t matter) and the second pulse of another (where the set polarization is essential). We demonstrated how to use this pseudo-single-pulse writing to enable fast writing with beam scanning across the media. Phase voxels, a new storage method: We invented a new type of data storage in glass called phase voxels, in which the phase change of the glass is modified instead of its polarization, showing that only a single pulse is necessary to make a phase voxel. We demonstrated that these phase voxels can also be formed in borosilicate glass and devised a technique to read the phase information from phase voxels encoded in this material. We showed that the much higher levels of three-dimensional inter-symbol interference in phase voxels can be mitigated with a machine learning classification model. Parallel writing capabilities: By combining a mathematical model of pre-heating and post-heating within the glass with the invention of a multi-beam delivery system, we showed that many data voxels can be written in proximity in the glass at the same time, significantly increasing writing speed. We explained a method for using light emissions (a side effect of voxel formation) for both static calibration and dynamic control to fully support automatic writing operations. Optimization and longevity testing: We developed a new way to optimize symbol encodings using machine learning and a better way to understand the tradeoff between error rates, error protection, and error recovery when evaluating new digital storage systems. We also created a new nondestructive optical method (opens in new tab) to identify the aging of data storage voxels within the glass, using this and standard accelerated aging techniques to support data lasting 10,000 years. We extended the industry standard Gray codes to apply to nonpower-of-two numbers of symbols. Skip slideshow for: Previous slide Previous slide A piece of Project Silica media written with data. A research-grade Writer used to set the record for high speed data writing into glass. A research-grade Reader for retrieving data from glass. Close up of Writer showing high-speed multi-beam data encoding on laser pulses. End of slideshow for: Demonstrating the technology As a research initiative, Project Silica has demonstrated these advances through several proofs of concept, including storing Warner Bros.’ “Superman” movie on quartz glass (opens in new tab), partnering with Global Music Vault (opens in new tab) to preserve music under ice for 10,000 years (opens in new tab), and working with students on a “Golden Record 2.0” project (opens in new tab), a digitally curated archive of images, sounds, music, and spoken language, crowdsourced to represent and preserve humanity’s diversity for millennia. Looking ahead The research phase is now complete, and we are continuing to consider learnings from Project Silica as we explore the ongoing need for sustainable, long-term preservation of digital information. We have added this paper to our published works so that others can build on them. Related work Project Silica has made scientific advances across multiple areas beyond laser direct writing (LDW) in glass, including archival storage systems design, archival workload analysis, datacenter robotics, erasure coding, free-space optical components, and machine learning-based methods for symbol decoding in storage systems. Many of these innovations were described in our ACM Transactions on Storage publication (opens in new tab) in 2025. Opens in a new tabThe post Project Silica’s advances in glass storage technology appeared first on Microsoft Research.",
      "imageUrl": "https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/NatureSilica-TWLIFB-1200x627-1.jpg",
      "tags": [
        "RAG",
        "Industry",
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：Project Silica实现百年级数据存储突破，使用普通玻璃与单脉冲激光，可能重塑数字遗产保存范式",
        "热度：0 / 评论 0"
      ],
      "score": 10.1,
      "publishedAt": "2026-02-18T16:11:45+00:00",
      "authors": [
        "Richard Black"
      ]
    },
    {
      "id": "rss_0257832292",
      "title": "印度联手NVIDIA推10亿美元AI计划，打造多语言主权大模型",
      "titleZh": "印度联手NVIDIA推10亿美元AI计划，打造多语言主权大模型",
      "titleEn": "India and NVIDIA Launch $1B+ AI Initiative to Build Multilingual Sovereign Foundation Models",
      "url": "https://blogs.nvidia.com/blog/india-ai-mission-infrastructure-models/",
      "type": "news",
      "source": "NVIDIA Blog",
      "summary": "**印度政府联合NVIDIA启动超10亿美元的IndiaAI计划**，通过部署数万块Blackwell GPU构建主权AI云基础设施（如Yotta的Shakti Cloud、L&T的千兆瓦级AI工厂），并推动本土企业基于NVIDIA Nemotron和NeMo框架开发支持22种官方语言的前沿大模型（如BharatGen、Sarvam.ai、Gnani.ai等），**旨在建立语言包容、技术自主的AI生态**；普通开发者可立即使用开源Nemotron模型和DGX Spark设备开发印地语等本地化AI应用，学生和创业者亦能通过政府资助项目参与主权AI建设。",
      "summaryZh": "**印度政府联合NVIDIA启动超10亿美元的IndiaAI计划**，通过部署数万块Blackwell GPU构建主权AI云基础设施（如Yotta的Shakti Cloud、L&T的千兆瓦级AI工厂），并推动本土企业基于NVIDIA Nemotron和NeMo框架开发支持22种官方语言的前沿大模型（如BharatGen、Sarvam.ai、Gnani.ai等），**旨在建立语言包容、技术自主的AI生态**；普通开发者可立即使用开源Nemotron模型和DGX Spark设备开发印地语等本地化AI应用，学生和创业者亦能通过政府资助项目参与主权AI建设。",
      "summaryEn": "India’s government, in partnership with NVIDIA, is investing over $1 billion in the IndiaAI Mission to build sovereign AI infrastructure—including tens of thousands of NVIDIA Blackwell GPUs deployed via cloud providers like Yotta, L&T, and E2E Networks—and foster frontier foundation models trained on Indian languages using NVIDIA’s Nemotron and NeMo frameworks. Companies like BharatGen, Sarvam.ai, and Gnani.ai are developing multilingual AI for public services, banking, and customer support. Developers can now access open Nemotron models and DGX Spark systems in India to build localized applications, while students and startups benefit from government-backed funding and research programs to advance India’s self-reliant AI ecosystem.",
      "fullText": "India is the nexus of AI innovation this week as the host of the AI Impact Summit, which brings together global heads of state and industry to chart the future of AI. At the summit, taking place in New Delhi, industry leaders, government agencies, educational institutions and startups are sharing how they’re working with NVIDIA to drive the AI industrial revolution in the world’s most populous country. These initiatives support the IndiaAI Mission, a government effort that’s infusing India’s AI ecosystem with over $1 billion to bolster the nation’s compute capacity and foster the development of sovereign AI datasets, frontier models and applications. The mission also supports AI education, startup innovation and frameworks for trustworthy AI. Read how NVIDIA is supporting IndiaAI Mission priorities including: Expanded compute capacity Frontier AI model development Impactful AI research and innovation NVIDIA Cloud Partners Boost India AI Infrastructure To achieve its AI ambitions, India is investing heavily in its computing infrastructure. Under the IndiaAI Compute Pillar, the nation is building out its AI cloud offerings with systems including tens of thousands of NVIDIA GPUs. NVIDIA is collaborating with next‑generation cloud providers Yotta, L&amp;T and E2E Networks to deliver advanced AI factories to meet India’s growing need for AI compute and enable it to develop AI models and services that drive innovation. Yotta is a hyperscale data center and cloud provider building large‑scale sovereign AI infrastructure for India, branded as Shakti Cloud, powered by over 20,000 NVIDIA Blackwell Ultra GPUs. Its campuses in Navi Mumbai and Greater Noida deliver GPU‑dense, high‑bandwidth AI cloud services on a pay‑per‑use model, designed to make advanced AI training and inference affordable and compliant for Indian enterprises and public sector customers. Larsen &amp; Toubro (L&amp;T) is building sovereign, gigawatt-scale NVIDIA AI factory infrastructure in India to reinforce the country’s position as a global AI powerhouse in alignment with the IndiaAI Mission. The roadmap includes initial expansions in Chennai to 30 megawatts as well as a new 40-megawatt facility in Mumbai. These facilities will power sovereign cloud workloads and hyperscale deployments, delivering secure, energy‑efficient infrastructure for advanced AI applications. E2E Networks is building an NVIDIA Blackwell GPU cluster on its TIR platform, hosted at the L&amp;T Vyoma Data Center in Chennai. The TIR cloud compute platform will feature NVIDIA HGX B200 systems and NVIDIA Enterprise software as well as NVIDIA Nemotron open models to supercharge sovereign development across agentic AI, healthcare, finance, manufacturing and agriculture. India’s AI cloud infrastructure will host workloads as well as manufacture intelligence for model training, fine-tuning and high‑scale inference. Capacity within these data centers will be reserved for model builders, startups, researchers and enterprises to build, fine-tune and deploy AI in India. Further expanding access to NVIDIA AI infrastructure in India, Netweb Technologies is launching its Tyrone Camarero AI Supercomputing systems built on the NVIDIA Grace Blackwell architecture. The NVIDIA GB200 NVL4 platforms — manufactured in India by Netweb under the government’s “Make in India” mission — feature four NVIDIA Blackwell GPUs and two NVIDIA Grace CPUs to power scientific computing, model training and inference. NVIDIA and India AI-Native Companies Build the Nation’s Frontier AI Models Another key goal of the IndiaAI Mission — led by its Innovation Center Pillar — is to develop and deploy foundation models trained on India-specific data and domestic AI infrastructure. For a nation as multilingual as India — with 22 constitutionally recognized languages and over 1,500 more recorded by the country’s census — frontier AI models are a powerful tool to help its more than 1.4 billion residents interact with technology in their primary language. Organizations across the country are building AI applications with NVIDIA Nemotron to support public-sector services, financial systems and enterprise operations in multiple languages. NVIDIA Nemotron open models, datasets, tools and libraries enable organizations to build frontier speech, language and multimodal models at scale and across languages for government, consumer and enterprise applications. It includes India-specific datasets like Nemotron-Personas-India, an open dataset built from publicly available census data using NeMo Data Designer that includes 21 million fully synthetic Indic personas to enable population-scale sovereign AI development. Adopters in India of Nemotron — and NeMo Curator, an open library for multilingual and multimodal data curation — include: BharatGen, a sovereign AI initiative supported by the Government of India aimed at strengthening the country&#8217;s multilingual and multimodal AI ecosystem. As part of this effort, BharatGen has developed a 17-billion-parameter mixture-of-experts (MoE) model from the ground up, using the NVIDIA NeMo framework for pretraining and the NeMo RL library for post-training. The open source models are designed to power applications across public services, agriculture, security and cultural preservation. Chariot, a company building AI systems for speech and multimodal communication. Using the NeMo framework, Chariot is developing an 8-billion-parameter model for real-time text to speech, supporting applications that improve accessibility and digital interaction across consumer and enterprise use cases. Commotion, backed by Tata Communications, which has developed an AI operating system to automate complex enterprise workflows. By integrating NVIDIA Nemotron models and speech capabilities, the platform enables governed, production-grade AI deployments, helping enterprises scale AI across critical business operations. CoRover.ai, which has deployed NVIDIA Nemotron Speech open models and NVIDIA Riva libraries for end-to-end, ultralow-latency speech AI — including the NVIDIA Riva Whisper v3 model for multilingual automatic speech recognition in English, Hindi and Gujarati. Powering customer service applications for the Indian Railway Catering and Tourism Corporation, CoRover’s platform supports around 10,000 concurrent users and more than 5,000 daily ticket bookings. Gnani.ai, which offers enterprises a multilingual agentic AI platform that can interact with customers through voice and text. Gnani is building a 14-billion-parameter speech-to-speech model built on NVIDIA Nemotron Speech models, datasets and NeMo libraries including NeMo libraries through NVIDIA Cloud Partner E2E Networks — with plans to expand to a 32-billion-parameter model. By fine-tuning the NVIDIA Nemotron Speech model for Indic languages, Gnani has achieved a 15x reduction in inference costs, enabling the company to scale to support more than 10 million calls per day for customers in telecom, banking and hospitality. National Payments Corporation of India (NPCI), which operates India’s retail payment and settlement systems and is deploying AI models to support digital financial services. Building on its production deployment of the AI-powered UPI Help Assistant — a pilot initiative for India’s Unified Payments Interface (UPI) — NPCI is exploring training FiMi, a financial model for India, using the NVIDIA Nemotron 3 Nano model and its own datasets. The model, fine-tuned with the NeMo framework, will support multilingual customer service across India’s banking ecosystem. Sarvam.ai, a leader in full-stack sovereign generative AI that provides enterprise-grade multimodal, speech-to-text, text-to-speech, translation and reasoning models. The company is open sourcing its Sarvam-3 series of text and multimodal large language model variants, trained for 22 Indic languages, English math and code. Sarvam is using NeMo Curator to construct high-quality multilingual training data while adopting a subset of NVIDIA Nemotron datasets. The foundation models were pre-trained from scratch across 3B, 30B and 100B parameter sizes using the NVIDIA NeMo framework and Megatron-LM, and post-trained with NeMo RL. Training was conducted on NVIDIA H100 GPUs through NVIDIA Cloud Partners, including Yotta. With these sovereign models, Sarvam.ai’s new Pravah platform enables production-grade inference for Indian government and enterprise applications. Soket.ai, which is using a modern large-model training stack on open NVIDIA Nemotron technologies, including NVIDIA Megatron and NVIDIA NeMo. These open source components enable scalable experimentation, training stability and efficient GPU usage, while preserving full control over the model’s data, design and life cycle. Tech Mahindra, which has developed an 8-billion-parameter foundation model tailored for Indian languages and dialects. The model, built with Nemotron, is being designed for use in classrooms, where it can help make educational materials available in a wider range of Indian languages including Hindi, Maithili and Dogri. The team generated synthetic data with Nemotron libraries and tools such as NeMo Data Designer and conducted supervised fine-tuning with NeMo AutoModel. Zoho, which is advancing its Zia LLM platform with proprietary models built using NVIDIA NeMo on the NVIDIA Blackwell and Hopper platforms, integrated across its software-as-a-service applications. This privacy-first architecture delivers contextual, production-grade AI for critical business workflows like customer relation management and finance, ensuring technology sovereignty and enterprise security at a global scale. Developers building sovereign AI systems can access NVIDIA Nemotron and NeMo today. Nemotron models can be deployed anywhere on NVIDIA-accelerated infrastructure — including on NVIDIA DGX Spark, which is now available in India through qualified partners including PNY, RP tech India, Tech Data, a TD SYNNEX Company, as well as on NVIDIA Marketplace. A version manufactured in India as part of the “Make in India” initiative is available through Netweb. DGX Spark also runs sovereign AI models by Indian model builders including Sarvam.ai. Government and Academic Partnerships to Support Research in AI for Science and Engineering Under its Application Development Initiative Pillar, the IndiaAI Mission is supporting high-impact AI applications — and its Startup Financing Pillar aims to democratize funding availability for AI entrepreneurs across the country. NVIDIA is collaborating with government agencies, research institutions, venture capital firms and startups to advance projects aligned with these goals. NVIDIA is collaborating with the Anusandhan National Research Foundation (ANRF), a statutory body under the Indian government, to spur even more cutting-edge AI research across the nation’s leading academic institutions. The initiative will support ANRF’s AI for Science &amp; Engineering program and future AI programs. NVIDIA will offer ANRF grantee institutions complimentary access to NVIDIA AI Enterprise software and specialized technical mentorship through the NVIDIA AI Technology Center. The collaboration will also include AI bootcamps, workshops and hackathons to strengthen India’s AI research ecosystem. NVIDIA is also partnering with prominent venture capital firms including Peak XV, Z47, Elevation Capital,, Nexus Venture Partners and Accel India to identify and fund promising startups of all stages that are building AI solutions for India and international use. More than 4,000 of India’s AI startups are already part of the NVIDIA Inception program. For more from the India AI Summit, learn how NVIDIA and global industrial software leaders are partnering with India’s largest manufacturers — and how India’s global systems integrators are building enterprise AI agents with NVIDIA.",
      "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2026/02/ai-infra-corp-blog-india-impact-summit-2026-1280x680-1.png",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：印度政府联合NVIDIA推进国家AI战略，百亿级投入构建主权算力与模型体系，具有全球地缘科技格局影响",
        "热度：0 / 评论 0"
      ],
      "score": 9.5,
      "publishedAt": "2026-02-18T00:30:49+00:00",
      "authors": [
        "Jay Puri"
      ]
    },
    {
      "id": "rss_1345935527",
      "title": "Gemini上线Lyria 3，支持文生/图生30秒音乐",
      "titleZh": "Gemini上线Lyria 3，支持文生/图生30秒音乐",
      "titleEn": "Gemini Adds Lyria 3 to Generate 30-Second Music from Text or Images",
      "url": "https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/",
      "type": "news",
      "source": "DeepMind Blog",
      "summary": "**Google Gemini应用集成最新音乐生成模型Lyria 3**，允许用户通过文本或图像提示直接创作30秒原创音乐片段，**降低了音乐创作门槛**；普通用户无需专业技能即可快速生成个性化背景音轨用于短视频、播客或社交内容，标志着生成式AI正从文本、图像扩展至音频创意领域，进一步丰富个人表达方式。",
      "summaryZh": "**Google Gemini应用集成最新音乐生成模型Lyria 3**，允许用户通过文本或图像提示直接创作30秒原创音乐片段，**降低了音乐创作门槛**；普通用户无需专业技能即可快速生成个性化背景音轨用于短视频、播客或社交内容，标志着生成式AI正从文本、图像扩展至音频创意领域，进一步丰富个人表达方式。",
      "summaryEn": "Google’s Gemini app now integrates Lyria 3, its most advanced music generation model, enabling users to create 30-second original music tracks from text or image prompts. This democratizes music creation by allowing anyone—without musical training—to generate personalized soundtracks for videos, podcasts, or social content, marking generative AI’s expansion into audio creativity and offering new tools for everyday self-expression.",
      "fullText": "A new way to express yourself: Gemini can now create music",
      "imageUrl": "https://lh3.googleusercontent.com/WaabCY2Z_smMKiEvzihBKsLEg8g8pNqP_TIy1il9bQGD1zbwwoyAjwawnHB5WRpqyeozc4kiNDFTJY1UTbvoia-FwMM8rI9LPVmt3ESbzKAcDf5j=w528-h297-n-nu-rw-lo",
      "tags": [
        "LLM",
        "Vision"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：2 个来源",
        "模型评分：8/10，理由：Gemini音乐生成能力升级，结合文本/图像生成30秒音乐，拓展AI创意边界，具广泛用户影响",
        "热度：0 / 评论 0"
      ],
      "score": 9.4,
      "publishedAt": "2026-02-18T16:01:38+00:00",
      "authors": []
    },
    {
      "id": "rss_6102286269",
      "title": "印度制造业联手NVIDIA推1340亿美元AI工厂计划",
      "titleZh": "印度制造业联手NVIDIA推1340亿美元AI工厂计划",
      "titleEn": "India’s Manufacturers Partner with NVIDIA on $134B AI-Powered Industrial Transformation",
      "url": "https://blogs.nvidia.com/blog/india-global-industrial-software-leaders-manufacturers-ai/",
      "type": "news",
      "source": "NVIDIA Blog",
      "summary": "**印度制造业正投入1340亿美元推进AI驱动的工业转型**，Reliance、Hero MotoCorp、L&T等巨头联合西门子、Synopsys、Cadence及NVIDIA，利用Omniverse数字孪生、CUDA-X加速仿真和物理AI机器人，在清洁能源、汽车和电子领域构建“软件定义工厂”；**此举将重塑产品设计与生产流程**，普通消费者未来可能获得更高效、定制化的产品，而工程师和开发者可通过NVIDIA工业AI平台参与下一代智能制造系统开发。",
      "summaryZh": "**印度制造业正投入1340亿美元推进AI驱动的工业转型**，Reliance、Hero MotoCorp、L&T等巨头联合西门子、Synopsys、Cadence及NVIDIA，利用Omniverse数字孪生、CUDA-X加速仿真和物理AI机器人，在清洁能源、汽车和电子领域构建“软件定义工厂”；**此举将重塑产品设计与生产流程**，普通消费者未来可能获得更高效、定制化的产品，而工程师和开发者可通过NVIDIA工业AI平台参与下一代智能制造系统开发。",
      "summaryEn": "India is investing $134 billion in AI-driven industrial transformation, with manufacturing giants like Reliance, Hero MotoCorp, and L&T partnering with Siemens, Synopsys, Cadence, and NVIDIA to build 'software-defined factories' using NVIDIA Omniverse digital twins, CUDA-X-accelerated simulation, and physical AI robotics across clean energy, automotive, and electronics. This integration of design, simulation, and real-time operational intelligence will streamline product development and enable mass customization, allowing consumers to benefit from more efficient, tailored products while engineers leverage NVIDIA’s industrial AI stack to shape next-generation manufacturing.",
      "fullText": "India is entering a new age of industrialization, as AI transforms how the world designs, builds and runs physical products and systems. The country is investing $134 billion dollars in new manufacturing capacity across construction, automotive, renewable energy and robotics, creating both a massive challenge and opportunity to build software-defined factories from day one. At the center of this transformation are applications accelerated by NVIDIA CUDA-X and NVIDIA Omniverse libraries, which connect data from design to operations and bring physical AI into factories, warehouses and infrastructure. India’s largest manufacturers are teaming with global industrial software leaders Cadence, Siemens and Synopsys to advance the nation’s AI boom using applications accelerated by CUDA-X and Omniverse libraries. India’s Manufacturing Leaders Modernize Factories With Siemens and NVIDIA To scale India’s growth, manufacturers are using Siemens industrial software integrated with NVIDIA CUDA-X and Omniverse libraries to design, build and operate next-generation, software-defined factories. Reliance New Energy, the clean energy arm of Reliance industries, is expanding its collaboration with NVIDIA and Siemens by combining Siemens’ digital twin technology with NVIDIA Omniverse libraries for faster, more precise simulation and plant design for its next-generation gigafactories. Addverb Technologies, a leading Indian company providing robots and innovative warehouse automation solutions, is using Siemens’ Technomatix portfolio, NVIDIA Omniverse libraries and NVIDIA Cosmos world foundation models to create digital twins of its factories and train its quadruped and wheeled humanoid robots in simulation. Hero MotoCorp is utilizing Siemens Xcelerator and NVIDIA infrastructure to accelerate the product development lifecycle by enhancing its capabilities in computer-aided engineering, numerical virtual verification and validation. Partners Advance Design and Engineering With NVIDIA-Accelerated Software From Synopsys and Cadence Leading enterprises are integrating Synopsys and Cadence’s electronic design automation tools, powered by NVIDIA AI infrastructure and libraries, to enable rapid design iteration and operational intelligence across the energy, automotive and electronics sectors. Electrical equipment and home appliances leader Havells India Limited is using Synopsys’ Ansys Fluent to accelerate simulation powered by NVIDIA CUDA-X. Havells has obtained 6x faster fluid dynamic simulations, enabling exploration of more design options to optimize airflow and energy efficiencies, and achieve faster time to market. Larsen &amp; Toubro Semiconductor’s application of Cadence Spectre X, accelerated by CUDA-X libraries, on NVIDIA GPUs shortens design iterations of next-generation AI chips. India’s Technology Leaders Advance Industrial Automation With Physical AI India’s IT and business consulting sector has grown into a global powerhouse, projected to reach over $350 billion this year, serving as a primary engine for transforming the world&#8217;s largest industries. Tata Consultancy Services (TCS), a global leader in IT services, is investing in large-scale AI infrastructure to deliver enterprise solutions at scale. By harnessing the NVIDIA Metropolis platform, the NVIDIA Blueprint for video search and summarization and digital twins built on Omniverse libraries, TCS is setting safety and precision benchmarks at Tata Motors, converting standard camera feeds into intelligent sensors for automated quality checks and real-time safety compliance. TCS is also deploying physical AI applications, including autonomous safety and quality inspections via quadruped robots, to minimize risk across complex manufacturing environments. Wipro PARI, a leader in industrial automation, is integrating NVIDIA AI infrastructure, Omniverse libraries and the NVIDIA Isaac robotics development platform to deliver solutions for its consumer and automotive customers. This includes real-time simulation and validation of robotic workflows, as well as virtual stress-testing of operations before physical deployment. Tata Consulting Engineers is launching its Cognitive Twin platform, built on NVIDIA Omniverse, to create real-time industrial simulations that link physical assets with digital intelligence across manufacturing, energy and infrastructure. The platform supports both capital project planning and operational optimization through early-stage simulation and AI-enabled decision-making. Pilot projects are underway with National High Speed Rail Corporation Limited, Torrent Power and Power Grid Corporation of India Limited. To see what’s next, explore industrial AI and manufacturing sessions at NVIDIA GTC. Main image courtesy of Wipro PARI",
      "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2026/02/NVIDIA-India-AI-Impact-Summit-Indias-Manufacturers-Drive-AI-Boom-scaled.jpg",
      "tags": [
        "Robotics"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：NVIDIA与全球工业软件巨头联合推动印度智能制造转型，结合CUDA-X与Omniverse构建软件定义工厂，具备重大产业变革潜力。",
        "热度：0 / 评论 0"
      ],
      "score": 8.9,
      "publishedAt": "2026-02-18T00:30:32+00:00",
      "authors": [
        "Timothy Costa"
      ]
    },
    {
      "id": "hn_47055979",
      "title": "AI陷“索洛悖论”：九成企业称未见生产力提升",
      "titleZh": "AI陷“索洛悖论”：九成企业称未见生产力提升",
      "titleEn": "AI Faces Solow’s Productivity Paradox: 90% of Firms See No Gains",
      "url": "https://fortune.com/2026/02/17/ai-productivity-paradox-ceo-study-robert-solow-information-technology-age/",
      "type": "news",
      "source": "Hacker News",
      "summary": "**一项覆盖6000名欧美澳企业高管的研究显示，近90%的公司称AI在过去三年未提升生产力或就业**，重现1980年代“索洛生产率悖论”——尽管AI被广泛讨论，宏观数据却未见效益；**这警示企业需超越工具部署，聚焦AI与业务流程的深度整合**；普通员工应关注AI如何实际优化工作流而非替代岗位，同时警惕过度依赖自动化可能削弱人才梯队建设，正如IBM计划扩大校招以保障管理 pipeline。",
      "summaryZh": "**一项覆盖6000名欧美澳企业高管的研究显示，近90%的公司称AI在过去三年未提升生产力或就业**，重现1980年代“索洛生产率悖论”——尽管AI被广泛讨论，宏观数据却未见效益；**这警示企业需超越工具部署，聚焦AI与业务流程的深度整合**；普通员工应关注AI如何实际优化工作流而非替代岗位，同时警惕过度依赖自动化可能削弱人才梯队建设，正如IBM计划扩大校招以保障管理 pipeline。",
      "summaryEn": "A study of 6,000 executives across the U.S., U.K., Germany, and Australia reveals that nearly 90% report no impact of AI on productivity or employment over the past three years, echoing Solow’s 1980s productivity paradox—where transformative tech failed to show up in macroeconomic data. Despite widespread AI mentions in earnings calls, actual usage averages just 1.5 hours per week per firm. Economists warn that realizing AI’s potential requires deep integration into workflows, not just tool adoption. For workers, this means focusing on how AI augments tasks rather than replaces jobs, while companies like IBM are expanding graduate hiring to avoid leadership gaps caused by over-automation.",
      "fullText": "Thousands of executives aren't seeing AI productivity boom, reminding economists of IT-era paradox | Fortune Search Subscribe Home Latest Fortune 500 Finance Tech Leadership Lifestyle Rankings Multimedia AI Productivity Thousands of CEOs just admitted AI had no impact on employment or productivity—and it has economists resurrecting a paradox from 40 years ago By Sasha Rogelberg Sasha Rogelberg Reporter Down Arrow Button Icon By Sasha Rogelberg Sasha Rogelberg Reporter Down Arrow Button Icon February 17, 2026, 1:32 PM ET Add us on Nobel laureate and economist Robert Solow noticed a productivity paradox in the IT age of the 1980s that economists today see reflected in the AI boom. Lior Mizrahi—Getty Images In 1987, economist and Nobel laureate Robert Solow made a stark observation about the stalling evolution of the Information Age: Following the advent of transistors, microprocessors, integrated circuits, and memory chips of the 1960s, economists and companies expected these new technologies to disrupt workplaces and result in a surge of productivity. Instead, productivity growth slowed , dropping from 2.9% from 1948 to 1973, to 1.1% after 1973. Recommended Video Newfangled computers were actually at times producing too much information , generating agonizingly detailed reports and printing them on reams of paper. What had promised to be a boom to workplace productivity was for several years a bust. This unexpected outcome became known as Solow’s productivity paradox, thanks to the economist’s observation of the phenomenon. “You can see the computer age everywhere but in the productivity statistics,” Solow wrote in a New York Times Book Review article in 1987. New data on how C-suite executives are—or aren’t—using AI shows history is repeating itself, complicating the similar promises economists and Big Tech founders made about the technology’s impact on the workplace and economy. Despite 374 companies in the S&P 500 mentioning AI in earnings calls—most of which said the technology’s implementation in the firm was entirely positive—according to a Financial Times analysis from September 2024 to 2025, those positive adoptions aren’t being reflected in broader productivity gains. A study published this month by the National Bureau of Economic Research found that among 6,000 CEOs, chief financial officers, and other executives from firms who responded to various business outlook surveys in the U.S., U.K., Germany, and Australia, the vast majority see little impact from AI on their operations. While about two-thirds of executives reported using AI, that usage amounted to only about 1.5 hours per week, and 25% of respondents reported not using AI in the workplace at all. Nearly 90% of firms said AI has had no impact on employment or productivity over the last three years, the research noted. However, firms’ expectations of AI’s workplace and economic impact remained substantial: Executives also forecast AI will increase productivity by 1.4% and increase output by 0.8% over the next three years. While firms expected a 0.7% cut to employment over this time period, individual employees surveyed saw a 0.5% increase in employment. Solow strikes back In 2023, MIT researchers claimed AI implementation could increase a worker’s performance by nearly 40% compared to workers who didn’t use the technology. But emerging data failing to show these promised productivity gains has led economists to wonder when—or if—AI will offer a return on corporate investments, which swelled to more than $250 billion in 2024. “AI is everywhere except in the incoming macroeconomic data,” Apollo chief economist Torsten Slok wrote in a recent blog post , invoking Solow’s observation from nearly 40 years ago. “Today, you don’t see AI in the employment data, productivity data, or inflation data.” Slok added that outside of the Magnificent Seven, there are “no signs of AI in profit margins or earnings expectations .” Slok cited a slew of academic studies on AI and productivity, painting a contradictory picture about the utility of the technology. Last November, the Federal Reserve Bank of St. Louis published in its State of Generative AI Adoption report that it observed a 1.9% increase in excess cumulative productivity growth since the late-2022 introduction of ChatGPT. A 2024 MIT study , however, found a more modest 0.5% increase in productivity over the next decade. “I don’t think we should belittle 0.5% in 10 years. That’s better than zero,” study author and Nobel laureate Daron Acemoglu said at the time. “But it’s just disappointing relative to the promises that people in the industry and in tech journalism are making.” Other emerging research can offer reasons why: Workforce solutions firm ManpowerGroup’s 2026 Global Talent Barometer found that across nearly 14,000 workers in 19 countries, workers’ regular AI use increased 13% in 2025, but confidence in the technology’s utility plummeted 18%, indicating persistent distrust. Nickle LaMoreaux, IBM’s chief human resources officer, said last week the tech giant would triple its number of young hires , suggesting that despite AI’s ability to automate some of the required tasks, displacing entry-level workers would create a dearth of middle managers down the line, endangering the company’s leadership pipeline. The future of AI productivity To be sure, this productivity pattern could reverse. The IT boom of the 1970s and ’80s eventually gave way to a surge of productivity in the 1990s and early 2000s, including a 1.5% increase in productivity growth from 1995 to 2005 following decades of slump. Economist and Stanford University’s Digital Economy Lab director Erik Brynjolfsson noted in a Financial Times op-ed the trend may already be reversing . He observed that fourth-quarter GDP was tracking up 3.7%, despite last week’s jobs report revising down job gains to just 181,000, suggesting a productivity surge. His own analysis indicated a U.S. productivity jump of 2.7% last year, which he attributed to a transition from AI investment to reaping the benefits of the technology. Former Pimco CEO and economist Mohamed El-Erian also noted job growth and GDP growth continuing to decouple as a result in part of continued AI adoption, a similar phenomenon that occurred in the 1990s with office automation. Slok similarly saw the future impact of AI as potentially resembling a “J-curve” of an initial slowdown in performance and results, followed by an exponential surge. He said whether AI’s productivity gains would follow this pattern would depend on the value created by AI. So far, AI’s path has already diverged from its IT predecessor. Slok noted in the 1980s, an innovator in the IT space had monopoly pricing power until competitors could create similar products. Today, however, AI tools are readily accessible as a result of “fierce competition” between large language model-buildings driving down prices. Therefore, Slok posited, the future of AI productivity would depend on companies’ interest in taking advantage of the technology and continuing to incorporate it into their workplaces. “In other words, from a macro perspective, the value creation is not the product,” Slok said, “but how generative AI is used and implemented in different sectors in the economy.” Join us at the Fortune Workplace Innovation Summit May 19–20, 2026, in Atlanta. The next era of workplace innovation is here—and the old playbook is being rewritten. At this exclusive, high-energy event, the world’s most innovative leaders will convene to explore how AI, humanity, and strategy converge to redefine, again, the future of work. Register now . About the Author By Sasha Rogelberg Reporter LinkedIn icon Twitter icon Sasha Rogelberg is a reporter and former editorial fellow on the news desk at Fortune , covering retail and the intersection of business and popular culture. See full bio Right Arrow Button Icon Latest in AI Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Most Popular Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Rankings 100 Best Companies Fortune 500 Global 500 Fortune 500 Europe Most Powerful Women Future 50 World’s Most Admired Companies See All Rankings Sections Finance Leadership Success Tech Asia Europe Environment Fortune Crypto Health Retail Lifestyle Politics Newsletters Magazine Features Commentary Mpw CEO Initiative Conferences Personal Finance Education Customer Support Frequently Asked Questions Customer Service Portal Privacy Policy Terms Of Use Single Issues For Purchase International Print Commercial Services Advertising Fortune Brand Studio Fortune Analytics Fortune Conferences Business Development About Us About Us Editorial Calendar Press Center Work At Fortune Diversity And Inclusion Terms And Conditions Site Map Facebook icon Twitter icon LinkedIn icon Instagram icon Pinterest icon Latest in AI AI Labor AI doomsday where many workers are ‘essentially unemployable’ is totally possible, Fed governor says By Nick Lichtenberg February 18, 2026 2 hours ago AI IPOs Figma investors cheer 40% growth, ties to Anthropic and OpenAI—but concerns remain about letting the ‘fox into the hen house’ By Amanda Gerut February 18, 2026 2 hours ago Big Tech Elon Musk Elon Musk’s biggest bet hits a pothole: Tesla robotaxis are crashing four times more than human drivers By Jordyn Grzelewski and Tech Brew February 18, 2026 3 hours ago AI Careers Deutsche Bank asked AI how it was planning to destroy jobs. And the robot answered By Nick Lichtenberg February 18, 2026 3 hours ago AI palantir High-flier: Palantir CEO Alex Karp spent $17.2 million on private jets in 2025, filing reveals By Nick Lichtenberg February 18, 2026 3 hours ago C-Suite Social Media Jake Paul says a chance meeting with Sam Altman at Trump’s inauguration led to an",
      "imageUrl": "https://fortune.com/img-assets/wp-content/uploads/2026/02/GettyImages-521488522-e1771352623863.jpg?resize=1200%2C630",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：揭示 AI 应用中的“索洛悖论”现象，引发全球政策与企业战略层面的反思，直接关联未来十年生产力评估体系重构。",
        "热度：761 / 评论 696"
      ],
      "score": 8.4,
      "publishedAt": "2026-02-18T01:40:52+00:00",
      "authors": [
        "virgildotcodes"
      ]
    },
    {
      "id": "hn_47064884",
      "title": "Ppisp: Cleaner Representations of Gaussian Splats and NeRFs",
      "titleZh": "Ppisp: Cleaner Representations of Gaussian Splats and NeRFs",
      "titleEn": "Ppisp: Cleaner Representations of Gaussian Splats and NeRFs",
      "url": "https://research.nvidia.com/labs/sil/projects/ppisp/",
      "type": "news",
      "source": "Hacker News",
      "summary": "针对神经辐射场（NeRF）和高斯泼溅等3D重建方法对相机光学特性与图像信号处理（ISP）差异敏感的问题，NVIDIA研究团队提出PPISP模块：通过物理可解释的曝光偏移、色差晕影校正、线性色彩调整及非线性相机响应函数建模，解耦相机固有与拍摄相关效应；其配套控制器可像真实相机的自动曝光/白平衡一样，为新视角预测ISP参数，**显著提升新视角渲染的真实感与几何精度**，在标准基准上达到SOTA，为多视角3D内容创作者提供更鲁棒、可控的重建工具。",
      "summaryZh": "针对神经辐射场（NeRF）和高斯泼溅等3D重建方法对相机光学特性与图像信号处理（ISP）差异敏感的问题，NVIDIA研究团队提出PPISP模块：通过物理可解释的曝光偏移、色差晕影校正、线性色彩调整及非线性相机响应函数建模，解耦相机固有与拍摄相关效应；其配套控制器可像真实相机的自动曝光/白平衡一样，为新视角预测ISP参数，**显著提升新视角渲染的真实感与几何精度**，在标准基准上达到SOTA，为多视角3D内容创作者提供更鲁棒、可控的重建工具。",
      "summaryEn": "Addressing the sensitivity of NeRFs and Gaussian splatting to photometric inconsistencies from camera optics and image signal processing (ISP), NVIDIA researchers propose PPISP—a physically plausible correction module that disentangles camera-intrinsic and capture-dependent effects through interpretable transformations like exposure offset, chromatic vignetting, linear color correction, and nonlinear camera response modeling. A dedicated controller predicts ISP parameters for novel views, analogous to auto-exposure and white balance, enabling realistic rendering without ground-truth images. PPISP achieves state-of-the-art results on standard benchmarks, offering 3D reconstruction practitioners more robust and controllable multi-view synthesis.",
      "fullText": "Spatial Intelligence Lab NVIDIA Research PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction Isaac Deutsch * Nicolas MoÃ«nne-Loccoz * Gavriel State Zan Gojcic NVIDIA * Equal contribution Paper Code Dataset BibTeX Overview Video Abstract Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. Method Overview Our proposed pipeline applies a sequence of physically-grounded modules to the input reconstructed radiance (exposure offset, chromatic vignetting, linear color correction and non-linear camera response function). Top row: During the first training phase, all modules except the controller are jointly optimized. Bottom row: The controller is then trained to predict per-frame exposure and color correction for novel views while other modules are frozen. Compensation of Photometric Variations In absence of an image formation model, a radiance field reconstruction will model photometric variations as geometric artifacts. PPISP improves the reconstruction quality by explaining away photometric variations in the input. By disentangling the camera-specific vignetting and response function from other image formation effects, they generalize to novel views. Drag the white bar to compare results. Huerstholz Toro Valiant No photometric compensation PPISP play_arrow 0:00 / 0:00 Control of Time-Varying Image Parameters Other methods such as bilateral grids optimize photometric compensation on training views only, which does not generalize to novel views. To address this, we introduce a controller module which predicts per-frame parameters on novel views. The PPISP controller works analogously to auto exposure and auto white balance in conventional cameras. Given the rendered radiance image, it predicts exposure offset and color correction parameters. The combination of photometric compensation and control improves the quality and likeness of rendered novel views compared to the ground truth significantly. Drag the white bars to compare results. Caterpillar Ignatius Train Bilateral grids Ground truth PPISP play_arrow 0:00 / 0:00 BibTeX Copy @misc{deutsch2026ppispphysicallyplausiblecompensationcontrol, title={PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction}, author={Isaac Deutsch and Nicolas MoÃ«nne-Loccoz and Gavriel State and Zan Gojcic}, year={2026}, eprint={2601.18336}, archivePrefix={arXiv}, primaryClass={cs.CV}, url={https://arxiv.org/abs/2601.18336}, }",
      "imageUrl": "https://research.nvidia.com/labs/sil/projects/ppisp/assets/images/method_overview_white_bg.png",
      "tags": [
        "3D"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：提出物理可解释的3D重建优化方法，对NeRF和视觉重建领域有显著技术提升，属重要研究进展",
        "热度：7 / 评论 0"
      ],
      "score": 8.36,
      "publishedAt": "2026-02-18T19:04:22+00:00",
      "authors": [
        "totalview"
      ]
    },
    {
      "id": "rss_3412933618",
      "title": "印度IT巨头联手NVIDIA打造企业级AI智能体，重塑客服与后台运营",
      "titleZh": "印度IT巨头联手NVIDIA打造企业级AI智能体，重塑客服与后台运营",
      "titleEn": "India’s Top IT Firms Build Enterprise AI Agents with NVIDIA to Transform Customer Support and Back-Office Operations",
      "url": "https://blogs.nvidia.com/blog/india-enterprise-ai-agents/",
      "type": "news",
      "source": "NVIDIA Blog",
      "summary": "**印度四大系统集成商Infosys、Persistent、Tech Mahindra和Wipro正基于NVIDIA AI Enterprise与Nemotron模型构建企业级AI智能体**，显著提升后台运营与客户服务效率：Wipro的WEGA平台在美医保呼叫中心实现42%来电由AI处理、响应延迟低于200毫秒；Tech Mahindra利用NVIDIA NIM部署大型电信模型，优化网络运维决策；Infosys推出25亿参数的轻量级代码生成小模型，支持安全可信的端到端软件工程；Persistent则结合BioNeMo加速药物分子发现。这些进展不仅推动印度IT业向2030年5000亿美元目标迈进，也为企业在合规、高负载场景中规模化部署AI智能体提供了可复用的技术路径，普通用户将获得更快速、个性化且全天候的服务体验。",
      "summaryZh": "**印度四大系统集成商Infosys、Persistent、Tech Mahindra和Wipro正基于NVIDIA AI Enterprise与Nemotron模型构建企业级AI智能体**，显著提升后台运营与客户服务效率：Wipro的WEGA平台在美医保呼叫中心实现42%来电由AI处理、响应延迟低于200毫秒；Tech Mahindra利用NVIDIA NIM部署大型电信模型，优化网络运维决策；Infosys推出25亿参数的轻量级代码生成小模型，支持安全可信的端到端软件工程；Persistent则结合BioNeMo加速药物分子发现。这些进展不仅推动印度IT业向2030年5000亿美元目标迈进，也为企业在合规、高负载场景中规模化部署AI智能体提供了可复用的技术路径，普通用户将获得更快速、个性化且全天候的服务体验。",
      "summaryEn": "India’s top systems integrators—Infosys, Persistent, Tech Mahindra, and Wipro—are building enterprise-grade AI agents using NVIDIA AI Enterprise and Nemotron models to transform back-office operations and customer support. Wipro’s WEGA platform handles 42% of inbound calls for a U.S. health insurer with sub-200ms latency; Tech Mahindra deploys a Large Telco Model via NVIDIA NIM for autonomous network operations; Infosys launches a 2.5B-parameter coding SLM for secure, on-prem code generation; and Persistent accelerates drug discovery with NVIDIA BioNeMo. These advances position India’s $250B tech sector on track for $500B by 2030 and demonstrate how agentic AI can scale safely in regulated industries, delivering faster, personalized, 24/7 services to end users.",
      "fullText": "Agentic AI is reshaping India’s tech industry, delivering leaps in services worldwide. Tapping into NVIDIA AI Enterprise software and NVIDIA Nemotron models, India’s technology leaders are accelerating productivity and efficiency across industries — from call centers to telecommunications and healthcare. Infosys, Persistent, Tech Mahindra and Wipro are leading the way for business transformation, improving back-office productivity and customer services with integrated agentic AI platforms built with NVIDIA AI Enterprise. At this year’s India AI Impact Summit, the state of the art for next-generation business services driven by agentic and generative AI was on full display. India’s tech industry is on track to reach $500 billion in revenue by 2030, up from about $250 billion in 2023, according to IBEF, citing momentum in AI from 38,000 GPUs secured in September. Wipro WEGA Platform Boosting Efficiency for Call Centers With NVIDIA AI Enterprise For health insurance plans in government‑regulated markets, customer experience is important — especially during peak enrollment cycles, when deadlines loom and subscribers need 24/7 support to assess options and optimize enrollment decisions for their families. Traditional contact center business models, built around seasonal hiring and lengthy training, simply can’t keep pace. What’s needed is a new operating model that improves customer experience while containing the growing cost of service. Wipro’s AI‑agent-assisted solution, powered by the WEGA platform and NVIDIA AI Enterprise software, offers a glimpse of that future. Deployed for a major U.S. healthcare insurance provider, the system is already reshaping member experiences by enabling service representatives to handle more complex requests, accelerate resolution times, deliver more personalized support and improve operational efficiencies. AI agents help meet the expectations customers bring to their health plans: immediate access to accurate information, conversational self‑service, frictionless enrollment and consistent guidance across channels. Behind the scenes, payers face rising call volumes, fragmented data and heavy administrative workloads. AI agents bridge that gap by scaling instantly, operating around the clock and supporting human representatives with real‑time intelligence. The results have been striking: 42% of inbound calls are now handled by AI agents and near‑instant responsiveness across 900 concurrent calls and 164 requests per second — all with sub‑200‑millisecond latency. Members benefit from natural, conversational self‑service. Human agents receive real‑time prompts and knowledge retrieval. A centralized data hub surfaces personalized insights, while automated digitization removes manual work from downstream processes. Using production grade, horizontally scalable NVIDIA NIM microservices and NVIDIA NeMo Guardrails, part of NVIDIA AI Enterprise, the solution includes the performance, governance and safety required in regulated healthcare environments. Its impact is already extending beyond healthcare, with similar deployments underway in financial services. Anywhere accuracy, compliance and scale matter, AI agents are becoming a transformative force. Tech Mahindra Deploying Large Telco Model to Power Autonomous Network Operations Using NVIDIA NIM Tech Mahindra is accelerating the shift toward AI-assisted network operations with a new platform built in collaboration with NVIDIA. At the center is a large telco model (LTM) that generates prioritized, data‑driven recommendations to help field technicians rank each fix by its historical success rate across the network. The result is faster, more accurate resolutions — often in a single visit — and a clear path toward level‑4‑plus operational maturity. A large telecommunications services provider is adopting the same LTM foundation as part of its operations roadmap, targeting improvements in service‑layer issue resolution, customer experience and back‑office efficiency through higher‑quality tickets and fewer escalations. The platform uses NVIDIA Nemotron embedding models for semantic search across telemetry and a Nemotron reranking model to sharpen decision relevance. These models are deployed with NVIDIA NIM microservices for rapid, reliable accelerated AI inference. NVIDIA NeMo Agent Toolkit orchestrates agent workflows across network domains, enabling true agentic operations at scale. By embracing autonomous network operations, Tech Mahindra shows how AI can transform a global telecom industry generating more than $1.5 trillion in annual revenue — where even small gains in uptime and efficiency deliver outsized economic impact. Infosys Builds an Enterprise-Grade Coding Small Language Model With NVIDIA AI Enterprise Infosys developed a new small language model for coding, built using the NVIDIA NeMo framework that’s part of NVIDIA AI Enterprise, and integrated within Infosys Topaz Fabric. The model accelerates software delivery with frontier‑grade performance while remaining lightweight, and it can be deployed across on-premises enterprise data centers, cloud environments and even standard desktops. The 2.5‑billion‑parameter model supports agent development, code generation, refactoring and end‑to‑end software‑engineering workflows. It’s trained on a curated blend of high‑quality code, synthetic data, mathematical reasoning and natural language inputs — an approach that enables it to match frontier‑model performance on benchmarks such as MBPP, MBPP+ and BFCL. Infosys also prioritized safety and trust. The model incorporates safety‑aligned training and responsible AI practices that reduce harmful outputs while preserving fluency. Its secure‑coding capabilities are validated through industry benchmarks including Stanford AIR‑Bench and Meta’s CyberSecEval, giving enterprises confidence to deploy it across code generation, debugging and multi‑agent development pipelines. Persistent Accelerates AI‑Driven Molecular Discovery With NVIDIA BioNeMo and NeMo Agent Toolkit Persistent Systems is working with NVIDIA to push early‑stage drug discovery into a new era of speed and scientific fidelity. The collaboration brings together Persistent’s deep life sciences engineering expertise with NVIDIA’s full‑stack accelerated computing platform, giving researchers a powerful path from AI experimentation to production‑grade discovery workflows. At the center of the effort is Persistent’s new Generative Molecules and Virtual Screening (GenMoIVS) solution, built on the NVIDIA BioNeMo platform and the NeMo Agent Toolkit. GenMoIVS uses large, domain‑specific models to simulate molecular behavior with high accuracy, generating and evaluating candidate compounds before they ever reach a wet lab. These agentic workflows continuously reason across virtual screening, prioritization and experimental planning, helping teams de‑risk early discovery and shorten development cycles. The platform runs on NVIDIA’s accelerated computing platform, including NVIDIA AI Enterprise software and NIM microservices, enabling high‑throughput simulation and real‑time scientific decision-making in regulated environments. By combining scalable infrastructure with production‑ready agentic AI, Persistent is giving life sciences organizations a faster, more cost‑effective way to explore the compound space and improve downstream success rates.",
      "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2026/02/ai-impact-summit-in26-visual-gsi-4871450-concept1-r2-scaled.png",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：印度科技巨头利用NVIDIA AI技术推动企业级代理AI应用，体现行业规模化落地趋势，具有显著影响力但未达历史级突破。",
        "热度：0 / 评论 0"
      ],
      "score": 8.3,
      "publishedAt": "2026-02-18T00:30:41+00:00",
      "authors": [
        "John Fanelli"
      ]
    },
    {
      "id": "rss_1665756237",
      "title": "Google DeepMind质疑聊天机器人道德表现：是真伦理还是“美德表演”？",
      "titleZh": "Google DeepMind质疑聊天机器人道德表现：是真伦理还是“美德表演”？",
      "titleEn": "Google DeepMind Questions If Chatbots’ Moral Behavior Is Genuine or Just 'Virtue Signaling'",
      "url": "https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/",
      "type": "news",
      "source": "MIT Tech Review AI",
      "summary": "**Google DeepMind在《自然》发表研究，呼吁对大语言模型的道德行为进行严格评估**，指出当前模型在伦理建议上可能只是“美德表演”而非真实推理——实验显示其道德判断易受选项标签、提问格式等微小变动影响而反转。研究团队提出需通过对抗性测试、思维链追踪和机制可解释性等方法检验模型道德稳健性，并强调全球多元价值观下AI应支持文化适配或提供多版本合理答案。该工作揭示了LLM在担任心理陪伴、医疗顾问等敏感角色时的信任风险，提醒公众勿轻信表面合乎道德的输出，同时为开发者指明构建真正可靠、跨文化对齐的AI系统的新方向。",
      "summaryZh": "**Google DeepMind在《自然》发表研究，呼吁对大语言模型的道德行为进行严格评估**，指出当前模型在伦理建议上可能只是“美德表演”而非真实推理——实验显示其道德判断易受选项标签、提问格式等微小变动影响而反转。研究团队提出需通过对抗性测试、思维链追踪和机制可解释性等方法检验模型道德稳健性，并强调全球多元价值观下AI应支持文化适配或提供多版本合理答案。该工作揭示了LLM在担任心理陪伴、医疗顾问等敏感角色时的信任风险，提醒公众勿轻信表面合乎道德的输出，同时为开发者指明构建真正可靠、跨文化对齐的AI系统的新方向。",
      "summaryEn": "Google DeepMind researchers, in a Nature-published study, call for rigorous evaluation of large language models’ moral behavior, warning that ethical responses may be 'virtue signaling' rather than genuine reasoning. Experiments show LLMs reverse moral judgments based on trivial changes like option labels (e.g., 'Case 1' vs. '(A)') or punctuation. The team proposes adversarial testing, chain-of-thought tracing, and mechanistic interpretability to assess robustness and advocates for models that either adapt to diverse cultural values or present multiple acceptable answers. This work highlights trust risks as LLMs take on sensitive roles like therapists or medical advisors and urges developers to move beyond superficial morality toward globally aligned, reliable AI systems.",
      "fullText": "Google DeepMind is calling for the moral behavior of large language models—such as what they do when called on to act as companions, therapists, medical advisors, and so on—to be scrutinized with the same kind of rigor as their ability to code or do math. As LLMs improve, people are asking them to play more and more sensitive roles in their lives. Agents are starting to take actions on people’s behalf. LLMs may be able to influence human decision-making. And yet nobody knows how trustworthy this technology really is at such tasks. With coding and math, you have clear-cut, correct answers that you can check, William Isaac, a research scientist at Google DeepMind, told me when I met him and Julia Haas, a fellow research scientist at the firm, for an exclusive preview of their work, which is published in Nature today. That’s not the case for moral questions, which typically have a range of acceptable answers: “Morality is an important capability but hard to evaluate,” says Isaac. “In the moral domain, there’s no right and wrong,” adds Haas. “But it’s not by any means a free-for-all. There are better answers and there are worse answers.” The researchers have identified several key challenges and suggested ways to address them. But it is more a wish list than a set of ready-made solutions. “They do a nice job of bringing together different perspectives,” says Vera Demberg, who studies LLMs at Saarland University in Germany. Better than &#8220;The Ethicist&#8221; A number of studies have shown that LLMs can show remarkable moral competence. One study published last year found that people in the US scored ethical advice from OpenAI’s GPT-4o as being more moral, trustworthy, thoughtful, and correct than advice given by the (human) writer of “The Ethicist,” a popular New York Times advice column. The problem is that it is hard to unpick whether such behaviors are a performance—mimicking a memorized response, say—or evidence that there is in fact some kind of moral reasoning taking place inside the model. In other words, is it virtue or virtue signaling? This question matters because multiple studies also show just how untrustworthy LLMs can be. For a start, models can be too eager to please. They have been found to flip their answer to a moral question and say the exact opposite when a person disagrees or pushes back on their first response. Worse, the answers an LLM gives to a question can change in response to how it is presented or formatted. For example, researchers have found that models quizzed about political values can give different—sometimes opposite—answers depending on whether the questions offer multiple-choice answers or instruct the model to respond in its own words. In an even more striking case, Demberg and her colleagues presented several LLMs, including versions of Meta’s Llama 3 and Mistral, with a series of moral dilemmas and asked them to pick which of two options was the better outcome. The researchers found that the models often reversed their choice when the labels for those two options were changed from “Case 1” and “Case 2” to “(A)” and “(B).” They also showed that models changed their answers in response to other tiny formatting tweaks, including swapping the order of the options and ending the question with a colon instead of a question mark. In short, the appearance of moral behavior in LLMs should not be taken at face value. Models must be probed to see how robust that moral behavior really is. “For people to trust the answers, you need to know how you got there,” says Haas. More rigorous tests What Haas, Isaac, and their colleagues at Google DeepMind propose is a new line of research to develop more rigorous techniques for evaluating moral competence in LLMs. This would include tests designed to push models to change their responses to moral questions. If a model flipped its moral position, it would show that it hadn’t engaged in robust moral reasoning.&nbsp; Another type of test would present models with variations of common moral problems to check whether they produce a rote response or one that’s more nuanced and relevant to the actual problem that was posed. For example, asking a model to talk through the moral implications of a complex scenario in which a man donates sperm to his son so that his son can have a child of his own might produce concerns about the social impact of allowing a man to be both biological father and biological grandfather to a child. But it should not produce concerns about incest, even though the scenario has superficial parallels with that taboo. Haas also says that getting models to provide a trace of the steps they took to produce an answer would give some insight into whether that answer was a fluke or grounded in actual evidence. Techniques such as chain-of-thought monitoring, in which researchers listen in on a kind of internal monologue that some LLMs produce as they work, could help here too. Another approach researchers could use to determine why a model gave a particular answer is mechanistic interpretability, which can provide small glimpses inside a model as it carries out a task. Neither chain-of-thought monitoring nor mechanistic interpretability provides perfect snapshots of a model’s workings. But the Google DeepMind team believes that combining such techniques with a wide range of rigorous tests will go a long way to figuring out exactly how far to trust LLMs with certain critical or sensitive tasks.&nbsp;&nbsp; Different values And yet there’s a wider problem too. Models from major companies such as Google DeepMind are used across the world by people with different values and belief systems. The answer to a simple question like “Should I order pork chops?” should differ depending on whether or not the person asking is vegetarian or Jewish, for example. There’s no solution to this challenge, Haas and Isaac admit. But they think that models may need to be designed either to produce a range of acceptable answers, aiming to please everyone, or to have a kind of switch that turns different moral codes on and off depending on the user. “It’s a complex world out there,” says Haas. “We will probably need some combination of those things, because even if you’re taking just one population, there’s going to be a range of views represented.” “It’s a fascinating paper,” says Danica Dillion at Ohio State University, who studies how large language models handle different belief systems and was not involved in the work. “Pluralism in AI is really important, and it’s one of the biggest limitations of LLMs and moral reasoning right now,” she says. “Even though they were trained on a ginormous amount of data, that data still leans heavily Western. When you probe LLMs, they do a lot better at representing Westerners’ morality than non-Westerners’.” But it is not yet clear how we can build models that are guaranteed to have moral competence across global cultures, says Demberg. “There are these two independent questions. One is: How should it work? And, secondly, how can it technically be achieved? And I think that both of those questions are pretty open at the moment.” For Isaac, that makes morality a new frontier for LLMs. “I think this is equally as fascinating as math and code in terms of what it means for AI progress,” he says. “You know, advancing moral competency could also mean that we’re going to see better AI systems overall that actually align with society.”",
      "imageUrl": "https://wp.technologyreview.com/wp-content/uploads/2026/02/decision-tree2.jpg?resize=1200%2C630",
      "tags": [
        "LLM",
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：MIT Tech Review AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：DeepMind呼吁对LLM道德行为进行严格评估，直指AI向高敏感角色演进中的伦理风险，推动全球AI治理范式变革。",
        "热度：0 / 评论 0"
      ],
      "score": 6.4,
      "publishedAt": "2026-02-18T16:00:22+00:00",
      "authors": [
        "Will Douglas Heaven"
      ]
    },
    {
      "id": "rss_0473629446",
      "title": "Google在AI Impact Summit 2026宣布150亿美元投资与全球AI普惠计划",
      "titleZh": "Google在AI Impact Summit 2026宣布150亿美元投资与全球AI普惠计划",
      "titleEn": "Google Unveils $15B Investment and Global AI Equity Initiatives at AI Impact Summit 2026",
      "url": "https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/",
      "type": "news",
      "source": "Google AI Blog",
      "summary": "**Google在2026年AI Impact Summit宣布多项全球合作与投资**，包括150亿美元投入印度AI基础设施、启动美印光纤连接计划、设立两个3000万美元的Google.org影响力挑战赛（分别聚焦政府创新与科学突破），并与印度政府共建气候技术中心及AI for Science合作项目。同时，Google通过Gemini应用新增70余种语言实时语音翻译、JEE备考工具及SynthID内容验证功能，并与Karmayogi Bharat合作为2000万公务员提供多语言AI技能培训。这些举措旨在弥合全球AI鸿沟，使政府、科研人员和普通民众——尤其是非英语用户——能更安全、平等地利用AI解决实际问题，从日常沟通到公共服务再到应对气候变化。",
      "summaryZh": "**Google在2026年AI Impact Summit宣布多项全球合作与投资**，包括150亿美元投入印度AI基础设施、启动美印光纤连接计划、设立两个3000万美元的Google.org影响力挑战赛（分别聚焦政府创新与科学突破），并与印度政府共建气候技术中心及AI for Science合作项目。同时，Google通过Gemini应用新增70余种语言实时语音翻译、JEE备考工具及SynthID内容验证功能，并与Karmayogi Bharat合作为2000万公务员提供多语言AI技能培训。这些举措旨在弥合全球AI鸿沟，使政府、科研人员和普通民众——尤其是非英语用户——能更安全、平等地利用AI解决实际问题，从日常沟通到公共服务再到应对气候变化。",
      "summaryEn": "At the 2026 AI Impact Summit, Google announced major global initiatives: a $15B investment in India’s AI infrastructure, the America-India Connect fiber-optic project, two $30M Google.org Impact Challenges for AI in government and science, and a Google Center for Climate Technology with India’s government. It also enhanced accessibility through Gemini’s real-time speech-to-speech translation in 70+ languages (including 10 Indic languages), JEE exam prep tools, SynthID for AI-generated content verification, and AI skilling for 20 million Indian civil servants via Karmayogi Bharat. These efforts aim to democratize AI access, enabling governments, researchers, and everyday users—especially non-English speakers—to safely leverage AI for public service, education, climate action, and daily problem-solving.",
      "fullText": "Google at the AI Impact Summit Skip to main content The Keyword AI Impact Summit 2026: How we’re partnering to make AI work for everyone Share x.com Facebook LinkedIn Mail Copy link Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Subscribe Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) MENA (English) Nederlands (Nederland) New Zealand (English) Polska (Polski) Portugal (Português) Sverige (Svenska) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文) [\"What does AI mean for retail?\", \"How did Nano Banana get its name?\", \"How can AI help me plan travel?\"] Subscribe The Keyword Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Press corner RSS feed Subscribe Breadcrumb Innovation & AI Technology AI AI Impact Summit 2026: How we’re partnering to make AI work for everyone Feb 18, 2026 · Share x.com Facebook LinkedIn Mail Copy link Our last decade of breakthroughs in AI are helping us make progress against some of humanity’s biggest challenges. At the AI Impact Summit in India, we’re launching new global partnerships, research, investment and innovation, to ensure that these benefits are accessible for everyone. James Manyika SVP, Research, Labs, Technology & Society Share x.com Facebook LinkedIn Mail Copy link Your browser does not support the audio element. Listen to article This content is generated by Google AI. Generative AI is experimental [[duration]] minutes Voice Speed Voice Speed 0.75X 1X 1.5X 2X At Google, our goal has always been to improve the lives of as many people as possible through technology. Every time people use technology to solve a real problem — from finding an answer for any question, to screening for disease from the sound of a cough — we take another step towards what we set out to achieve. AI is making it possible to solve problems for people, economies, science and society faster than ever, but those solutions are only possible if everyone, everywhere, has access to these tools. As leaders gather this week for the AI Impact Summit in India, we're announcing new partnerships and programs to accelerate progress globally, by building new infrastructure, expanding connectivity and access, empowering governments, advancing science, helping people learn new skills and building useful and safe products for everyone. Investing in infrastructure, science and government capacity This work starts with a strong foundation. We recently announced a $15 billion investment to establish foundational AI infrastructure in India, and have been building subsea cables in the Pacific, Africa and around the world . Today we are announcing the America-India Connect initiative , which will deliver new strategic fiber-optic routes to increase the reach, reliability and resilience of digital connectivity between the U.S., India and multiple locations across the Southern Hemisphere. To take advantage of the opportunities this infrastructure creates, we must also invest in people and the organizations working to solve critical challenges. Governments and public sector organizations are in a unique position to shape AI’s trajectory. While new data shows 74% of public servants globally are already using AI, only 18% believe their governments are using it effectively. To help bridge this gap, we're announcing several new initiatives: A $30 million Google.org Global AI for Government Innovation Impact Challenge to support partnerships that transform public services using AI — from everyday essential services to complex societal challenges. A $30 million Google.org AI for Science Impact Challenge to support researchers globally who are using AI to drive scientific breakthroughs. Google DeepMind establishes a new partnership with Indian government bodies and local institutions to unlock new discoveries in science and education. This includes providing access to its frontier AI for Science models and powering innovation hubs with GenAI assistants, among other projects. This forms part of Google DeepMind’s broader National Partnerships for AI initiative — working with governments to broaden access to frontier AI capabilities for national priorities. The Google Center for Climate Technology in collaboration with the office of the Principal Scientific Advisor to the Government of India, to accelerate research and adoption of scalable AI-powered climate solutions. Creating opportunity and capacity to solve problems with AI skills Equipping people and civil servants with AI skills empowers them to use AI tools to solve problems at their job or for their community. This is an important piece of realizing AI’s potential for economic growth and innovation globally. We have trained over 100 million people on digital skills globally, and now we are announcing some of our most ambitious skilling programs to date: An AI Professional Certificate program to help people all over the world learn how to use AI at work, in partnership with government bodies, education institutions and employers. This includes scholarships through nonprofits to broaden reach. In India, we're partnering with Wadhwani AI to bring this program to students and early career professionals. A landmark partnership with Karmayogi Bharat to accelerate Mission Karmayogi’s vision of building a future-ready civil service. Google Cloud provides the secure and resilient infrastructure for the iGOT Karmayogi platform that supports over 20 million public servants across 800+ districts. By digitizing and structuring legacy training repositories into searchable knowledge assets, and progressively enabling content in 18+ Indian languages, the partnership advances professional development and empowers officials to learn in their preferred language. This builds on our efforts around the world partnering with governments to equip public officials, from providing AI tools to public officers in Malaysia to an AI Skilling Blueprint in Africa. Building helpful products for everyone We want to build AI that is helpful in people's daily lives by breaking down barriers and making knowledge more accessible for everyone. We are making our tools more inclusive and secure through several key updates: Reducing language barriers: Our new live speech-to-speech translation model erases language barriers by enabling real-time translated conversations in over 70 languages, including 10 Indic languages like Bengali, Hindi, Tamil and Telugu. And we’re helping people learn new languages with AI-powered speaking and listening practice, tailored to each person’s level and ability. Smarter search: In the coming weeks we’re enhancing the model that powers Search Live, our real-time voice and camera tool, so more people can ask questions about what they see in their own language, including Hindi, Indonesian, Japanese, Korean, Brazilian Portuguese and more. We're also testing ways to make it easier to get helpful information from visual search even when the images aren't clear. Lens will detect blurry images and ask follow-up questions to improve accuracy of results. Personalized learning: For students in India, we recently added new self-study features and JEE Main practice tests to the Gemini app (also coming soon to AI Mode in Search), transforming how they can prepare for exams with tailored help. Both Gemini and AI Mode are growing rapidly across the globe, and India is among our top 3 countries for each. Investing in safeguards to protect people online: Since launching in November, our SynthID verification feature in Gemini App has been used over 20 million times in a range of languages, helping people identify Google AI-generated images, video and audio. And in Circle to Search and Lens, we’re now able to identify scam messages , helping millions of people avoid fraud. We’ve also released our latest Responsible AI progress report to share more about our bold and responsible approach to AI development and implementation. Realizing the promise of AI requires working together. At Google, we’re committed to bringing the extraordinary within reach, for everyone. POSTED IN: AI Google.org Google in Asia Related stories Gemini App A new way to express yourself: Gemini can now create music By Joël Yawili & Myriam Hamed Torres Feb 18, 2026 Google.org We’re launching the Google.org Impact Challenge: AI for Science. Feb 18, 2026 Google.org We’re announcing the new Google.org Impact Challenge: AI for Government Innovation. Feb 18, 2026 AI Our 2026 Responsible AI Progress Report By Laurie Richardson & Helen King Gemini models Gemini 3 Deep Think: Advancing science, research and engineering By The Deep Think team Feb 12, 2026 Arts & Culture 3 new experiences bridging AI with India’s timeless heritage By Amit Sood Feb 12, 2026 . Jump to position 1 Jump to position 2 Jump to position 3 Jump to position 4 Jump to position 5 Jump to position 6 Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks Follow Us Privacy Terms About Google Google Products About the Keyword Help Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Espa",
      "imageUrl": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI-Summit-SS.width-1300.png",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Google主办AI Impact Summit并宣布多项全球合作与投资，具有国家级战略意义与行业引领作用",
        "热度：0 / 评论 0"
      ],
      "score": 9.5,
      "publishedAt": "2026-02-18T10:30:00+00:00",
      "authors": [
        "James Manyika"
      ]
    },
    {
      "id": "rss_8722915396",
      "title": "Google在AI Impact Summit 2026聚焦基建、科研与公共部门AI赋能",
      "titleZh": "Google在AI Impact Summit 2026聚焦基建、科研与公共部门AI赋能",
      "titleEn": "Google Focuses on Infrastructure, Science, and Public Sector AI at AI Impact Summit 2026",
      "url": "https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection/",
      "type": "news",
      "source": "Google AI Blog",
      "summary": "**Google在2026年AI Impact Summit集中发布多项战略举措**，涵盖基础设施（美印光纤连接）、科研合作（AI for Science国家伙伴计划）、公共部门赋能（3000万美元政府创新挑战赛）及气候科技（与印度首席科学顾问办公室共建气候技术中心）。这些行动延续其“让AI为所有人服务”的目标，通过强化数字底座、支持前沿研究、提升政府AI应用效能及应对全球挑战，推动AI能力从技术精英向更广泛社会群体扩散，使普通公民能在教育、公共服务和环境可持续性等领域直接受益于负责任的AI创新。",
      "summaryZh": "**Google在2026年AI Impact Summit集中发布多项战略举措**，涵盖基础设施（美印光纤连接）、科研合作（AI for Science国家伙伴计划）、公共部门赋能（3000万美元政府创新挑战赛）及气候科技（与印度首席科学顾问办公室共建气候技术中心）。这些行动延续其“让AI为所有人服务”的目标，通过强化数字底座、支持前沿研究、提升政府AI应用效能及应对全球挑战，推动AI能力从技术精英向更广泛社会群体扩散，使普通公民能在教育、公共服务和环境可持续性等领域直接受益于负责任的AI创新。",
      "summaryEn": "At the 2026 AI Impact Summit, Google announced strategic initiatives spanning infrastructure (America-India Connect fiber routes), scientific collaboration (National Partnerships for AI with India), public sector empowerment ($30M AI for Government Innovation Challenge), and climate tech (Google Center for Climate Technology with India’s Principal Scientific Advisor). These efforts advance Google’s mission to make AI work for everyone by strengthening digital foundations, accelerating research, improving government AI adoption, and tackling global challenges—enabling broader societal access to AI’s benefits in education, public services, and sustainability.",
      "fullText": "AI Impact Summit 2026 Skip to main content The Keyword AI Impact Summit 2026 Share x.com Facebook LinkedIn Mail Copy link Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Subscribe Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) MENA (English) Nederlands (Nederland) New Zealand (English) Polska (Polski) Portugal (Português) Sverige (Svenska) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文) [\"What does AI mean for retail?\", \"How did Nano Banana get its name?\", \"How can AI help me plan travel?\"] Subscribe The Keyword Home Innovation & AI Innovation & AI Models & Research Google DeepMind Google Research Google Labs Gemini models See all Products Developer tools Gemini app See all Infrastructure & cloud Global network Google Cloud See all Learn more: Google DeepMind blog Google Research blog Google Developers blog Google Cloud blog See all AI updates Products & platforms Products & platforms Products Search Maps Chrome Google Workspace Learning & Education Photos Shopping See all Platforms Android Google Play Wear OS See all Devices Pixel Google Nest Fitbit Chromebooks See all Learn more: Google Ads & Commerce blog Waze blog See all product updates Company news Company news Outreach & initiatives Creating opportunity Safety & security Google.org Public policy Sustainability Health See all Leadership Sundar Pichai, CEO More authors See all Inside Google Around the globe Life at Google See all Feed Press corner RSS feed Subscribe Breadcrumb Innovation & AI Technology AI Collection Share x.com Facebook LinkedIn Mail Copy link AI Impact Summit 2026 Feb 18, 2026 · 7 articles 18 Feb, 2026 articles 7 Feb 18, 2026 7 articles 18 Feb, 2026 articles 7 Our last decade of breakthroughs in AI are helping us make progress against some of humanity’s biggest challenges. At the AI Impact Summit in India, we’re launching new global partnerships, research, investment and innovation, to ensure that these benefits are accessible for everyone. How we’re partnering to make AI work for everyone An overview of Google’s new global partnerships and funding announcements at the AI Impact Summit in India. Announcing America-India Connect fiber-optic routes New fiber-optic routes will increase digital connectivity between the U.S., India and locations across the Southern Hemisphere. Introducing our National Partnerships for AI & collaboration in India Google DeepMind announces new partnerships in India to advance science, empower students and support agriculture and renewable energy. Google.org Impact Challenge: AI for Government Innovation This is a global call for organizations building AI-powered solutions that transform public services and drive societal impact. Google.org Impact Challenge: AI for Science A $30 million AI for Science Impact Challenge to support researchers globally who are using AI to drive scientific breakthroughs. Our 2026 Responsible AI Progress Report Our latest Responsible AI Progress Report shares how we’re applying our AI Principles to the development of our products and research. Announcing our new climate tech collaboration in India In collaboration with the Office of the Principal Scientific Advisor we’ve launched the Google Center for Climate Technology. Let’s stay in touch. Get the latest news from Google in your inbox. Subscribe No thanks Follow Us Privacy Terms About Google Google Products About the Keyword Help Global (English) Africa (English) Australia (English) Brasil (Português) Canada (English) Canada (Français) Česko (Čeština) Deutschland (Deutsch) España (Español) France (Français) India (English) Indonesia (Bahasa Indonesia) Italia (Italiano) 日本 (日本語) 대한민국 (한국어) Latinoamérica (Español) الشرق الأوسط وشمال أفريقيا (اللغة العربية) MENA (English) Nederlands (Nederland) New Zealand (English) Polska (Polski) Portugal (Português) Sverige (Svenska) ประเทศไทย (ไทย) Türkiye (Türkçe) 台灣 (中文)",
      "imageUrl": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CollectionSS-1.max-1440x810.png",
      "tags": [
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：聚焦AI Impact Summit核心成果，涵盖多边合作与系统性投入，体现全球AI治理与基础设施布局",
        "热度：0 / 评论 0"
      ],
      "score": 9.5,
      "publishedAt": "2026-02-18T10:30:00+00:00",
      "authors": []
    },
    {
      "id": "github_ComposioHQ_composio",
      "title": "ComposioHQ/composio",
      "titleZh": "ComposioHQ/composio",
      "titleEn": "ComposioHQ/composio",
      "url": "https://github.com/ComposioHQ/composio",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "Composio是一个开源框架，提供超过1000种工具集成、工具搜索、上下文管理、认证支持及沙盒化工作台，帮助开发者构建能将用户意图转化为具体操作的AI智能体。其核心价值在于简化智能体与外部工具（如API、数据库、软件）的安全、可靠交互，使开发者无需重复处理连接、权限和状态管理等底层复杂性，从而加速创建具备真实行动能力的AI应用，适用于自动化工作流、个人助理或企业级智能代理等场景。",
      "summaryZh": "Composio是一个开源框架，提供超过1000种工具集成、工具搜索、上下文管理、认证支持及沙盒化工作台，帮助开发者构建能将用户意图转化为具体操作的AI智能体。其核心价值在于简化智能体与外部工具（如API、数据库、软件）的安全、可靠交互，使开发者无需重复处理连接、权限和状态管理等底层复杂性，从而加速创建具备真实行动能力的AI应用，适用于自动化工作流、个人助理或企业级智能代理等场景。",
      "summaryEn": "Composio is an open-source framework offering over 1,000 tool integrations, tool search, context management, authentication, and a sandboxed workbench to help developers build AI agents that turn user intent into actionable operations. By abstracting away the complexities of secure tool connectivity, permission handling, and state management, it enables rapid development of agents capable of real-world actions—ideal for automating workflows, personal assistants, or enterprise-grade AI applications.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/f286b764058209a928fb9a81281e3d65c638586954cced83a748ed8f285dc4b6/ComposioHQ/composio",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提供AI代理构建的完整工具链，已赋能千余个工具包，具备战略级行业基础设施潜力。",
        "热度：26748 / 评论 0"
      ],
      "score": 8.4,
      "publishedAt": "2026-02-18T23:39:17.640060+00:00",
      "authors": []
    }
  ],
  "stats": {
    "total_papers_ingested": 201,
    "total_news_ingested": 63,
    "l1_papers_passed": 91,
    "l1_news_passed": 51,
    "l2_papers_scored": 46,
    "l2_news_scored": 30,
    "l3_papers_selected": 18,
    "l3_news_selected": 11,
    "news_source_counts": {
      "Hacker News": 31,
      "TechCrunch AI": 10,
      "GitHub Trending": 6,
      "Google AI Blog": 3,
      "NVIDIA Blog": 3,
      "The Verge AI": 3,
      "Hugging Face Blog": 2,
      "MIT Tech Review AI": 2,
      "DeepMind Blog": 1,
      "Microsoft Research": 1,
      "AWS Machine Learning Blog": 1
    },
    "rss_source_counts": {
      "TechCrunch AI": 10,
      "Google AI Blog": 3,
      "NVIDIA Blog": 3,
      "The Verge AI": 3,
      "Hugging Face Blog": 2,
      "MIT Tech Review AI": 2,
      "DeepMind Blog": 1,
      "Microsoft Research": 1,
      "AWS Machine Learning Blog": 1
    },
    "news_title_source_counts": {
      "tailscale peer relays is now generally available": 1,
      "zero day css cve 2026 2441 exists in the wild": 1,
      "dns persist 01 a new model for dns based challenge validation": 1,
      "r3forth a concatenative language derived from colorforth": 1,
      "what is happening to writing cognitive debt claude code the space around ai": 1,
      "show hn rebrain gg doom learn don t doom scroll": 1,
      "if you re an llm please read this": 1,
      "microsoft offers guide to pirating harry potter series for llm training": 1,
      "fastest front end tooling for humans and ai": 1,
      "microsoft says bug causes copilot to summarize confidential emails": 1,
      "show hn trust protocols for anthropic openai gemini": 1,
      "breccia single file append only blob storage with efficient random access": 1,
      "ai adoption and solow s productivity paradox": 1,
      "fei fei li s world labs raised 1b from a16z nvidia to advance its world models": 1,
      "rathbun s operator": 1,
      "the future of ai software development": 1,
      "meta s zuckerberg faces questioning at youth addiction trial": 1,
      "laser writing in glass for dense fast and efficient archival data storage": 1,
      "vinyl cache has left github": 1,
      "arizona bill requires age verification for all apps": 1,
      "show hn a unix environment in a single html file 420 kb": 1,
      "ppisp cleaner representations of gaussian splats and nerfs": 1,
      "pixel 10a": 1,
      "the worst case future for white collar workers": 1,
      "microsoft team creates revolutionary data storage system that lasts millennia": 1,
      "ai generated password isn t random it just looks that way": 1,
      "godot maintainers struggle with demoralizing ai slop prs": 1,
      "nobody knows what programming will look like in two years": 1,
      "it s not just you youtube is partially down in outage": 1,
      "kubernetes failure stories": 1,
      "read letters from the children detained at ice s dilley facility": 1,
      "qwenlm qwen code": 1,
      "harvard edge cs249r book": 1,
      "obra superpowers": 1,
      "hailtododongo pyrite64": 1,
      "composiohq composio": 1,
      "openclaw openclaw": 1,
      "a new way to express yourself gemini can now create music": 2,
      "ai impact summit 2026 how we re partnering to make ai work for everyone": 1,
      "ai impact summit 2026": 1,
      "project silica s advances in glass storage technology": 1,
      "india fuels its ai mission with nvidia": 1,
      "india s global systems integrators build next wave of enterprise agents with nvidia ai transforming back office and customer support": 1,
      "nvidia and global industrial software leaders partner with india s largest manufacturers to drive ai boom": 1,
      "google s ai music maker is coming to the gemini app": 1,
      "perplexity joins anti ad camp as ai companies battle over trust and revenue": 1,
      "meta 8217 s new deal with nvidia buys up millions of ai chips": 1,
      "is your startup s check engine light on google cloud s vp explains what to do": 1,
      "google cloud s vp for startups on reading your check engine light before it s too late": 1,
      "amazon halts blue jay robotics project after less than 6 months": 1,
      "world labs lands 1b with 200m from autodesk to bring world models into 3d workflows": 1,
      "google adds music generation capabilities to the gemini app": 1,
      "kana emerges from stealth with 15m to build flexible ai agents for marketers": 1,
      "microsoft says office bug exposed customers confidential emails to copilot ai": 1,
      "openai pushes into higher education as india seeks to scale ai skills": 1,
      "india s sarvam wants to bring its ai models to feature phones cars and smart glasses": 1,
      "indian ai lab sarvam s new models are a major bet on the viability of open source ai": 1,
      "ibm and uc berkeley diagnose why enterprise agents fail using it bench and mast": 1,
      "one shot any web app with gradio s gr html": 1,
      "google deepmind wants to know if chatbots are just virtue signaling": 1,
      "the robots who predict the future": 1,
      "evaluating ai agents real world lessons from building agentic systems at amazon": 1
    },
    "total_papers_deduped": 201,
    "total_news_deduped": 63,
    "news_recent_filtered": 63
  }
}