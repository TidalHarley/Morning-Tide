{
  "date": "2026-02-22",
  "generatedAt": "2026-02-22T23:46:13.695231",
  "introduction": "今日AI领域聚焦三大方向：一是大模型安全与评估，多篇论文揭示当前AI代理在工具调用、长期任务和安全数据集中的潜在风险；二是基础能力演进，包括语音大模型行为本质、数学形式化自动化、科学计算自主化等突破；三是生成与感知技术升级，如AI视频检测、文本到图像多样性增强、医学影像分析等。值得关注的是，Anthropic推出终端内编程代理Claude Code，显著提升开发者效率，标志着AI编码工具正从辅助迈向协同智能新阶段。",
  "introductionZh": "今日AI领域聚焦三大方向：一是大模型安全与评估，多篇论文揭示当前AI代理在工具调用、长期任务和安全数据集中的潜在风险；二是基础能力演进，包括语音大模型行为本质、数学形式化自动化、科学计算自主化等突破；三是生成与感知技术升级，如AI视频检测、文本到图像多样性增强、医学影像分析等。值得关注的是，Anthropic推出终端内编程代理Claude Code，显著提升开发者效率，标志着AI编码工具正从辅助迈向协同智能新阶段。",
  "introductionEn": "Today’s AI advances spotlight three critical fronts: model safety and evaluation, with new studies exposing vulnerabilities in LLM agents’ tool-use safety, long-horizon robustness, and flawed safety datasets; foundational capabilities, including insights into speech LLM equivalence, large-scale mathematical formalization, and autonomous scientific computing; and generative perception, from deepfake video detection to enhanced text-to-image diversity and medical ultrasound analysis. Notably, Anthropic launched Claude Code—a terminal-based agentic coding tool—ushering in a new era of developer-AI collaboration beyond simple code completion.",
  "longformScript": "今天，AI 正在从“能回答问题”走向“能做事”。不是泛泛而谈的智能，而是嵌入具体工作流、可部署、可协作的智能体。开发者在终端里直接调用 AI 编程，安全团队用 AI 模拟黑客攻击，金融分析师接入开源数据平台训练自己的交易代理——这些不再是实验室里的概念，而是今天就能下载、安装、运行的工具。AI 的重心，正在从模型本身转向如何让模型真正融入人类的日常操作。\n\n最引人注目的变化，发生在开发者的命令行里。Anthropic 推出了 Claude Code，一个能在终端内直接运行的编码代理。它不依赖图形界面，也不需要你切换窗口去和聊天机器人对话。你只需在命令行输入自然语言指令，比如“帮我重构这个模块”或“解释这段异步逻辑”，它就能理解整个代码库上下文，自动执行 Git 操作、生成文档，甚至提交 pull request。这标志着 AI 编程工具正从“辅助建议”迈向“协同执行”。更值得留意的是，有开发者分享了一套高效使用方法：先让 AI 生成一份 research.md 分析现状，再人工迭代出 plan.md 明确路径，最后才触发实际编码。这种“规划-执行”分离的流程，避免了 AI 盲目修改带来的架构混乱，也说明真正高效的 AI 协作，不是放手不管，而是结构化的人机配合。\n\n与此同时，AI 智能体的部署方式也在发生根本性转变。Cloudflare 宣布推出基于其全球边缘网络的 AI 智能体开发平台，允许开发者把轻量级代理直接部署到离用户最近的节点上。这意味着未来的 AI 应用可能不再集中于云端大模型，而是分散在边缘，以毫秒级响应处理本地请求。比如一个客服代理，可以在用户点击按钮的瞬间就近调用，无需往返数据中心。这种架构不仅降低延迟，也提升了隐私性和可用性。而另一边，GitNexus 这样的工具则把智能体完全搬进了浏览器——你只需拖入一个 GitHub 仓库，它就在本地生成交互式知识图谱，并内置 Graph RAG 智能体帮你导航代码。无需服务器、无需联网，特别适合处理敏感项目或离线场景。这些趋势共同指向一个方向：AI 正在变得更轻、更近、更嵌入实际工作流。\n\n不只是开发和部署，AI 智能体的能力边界也在向高专业领域拓展。比如 Pentagi 系统，一个完全自主的 AI 渗透测试框架，能模拟高级持续性威胁（APT）攻击，自动探测漏洞、横向移动、提取数据。它把原本需要资深红队工程师数天完成的任务，压缩成可重复运行的智能体流程。虽然这类工具必须谨慎使用，但它的出现证明，多智能体系统已经能在网络安全这样高风险、高复杂度的场景中发挥作用。同样，在金融领域，OpenBB 推出了专为 AI 智能体设计的开源数据平台，整合了实时行情、基本面指标和分析工具，让量化交易员或研究者能快速构建自己的策略代理，而无需依赖昂贵的商业终端。这些进展说明，AI 不再只是通用助手，而是开始成为特定领域的“数字专家”。\n\n更贴近普通用户的改变，也悄然发生。三星宣布将在 Galaxy S26 中集成 Perplexity AI，用户只需说“hey, Plex”就能唤醒它，并让它访问笔记、日历、相册等原生应用。这不仅是新增一个语音助手，而是操作系统层面支持多个 AI 代理共存与协作的信号。未来，你可能会根据任务切换不同的 AI：一个擅长写邮件，一个精于查资料，另一个专攻图像编辑。设备不再绑定单一智能，而是成为多个专业代理的调度中心。这种“多代理生态”的思路，或许比追求一个全能模型更贴近真实需求。\n\n面对这些快速落地的工具，我们该怎么看？首先，别被“全自动”迷惑。无论是 Claude Code 的规划流程，还是 Pentagi 的合规边界，都提醒我们：真正的生产力提升，来自人对 AI 的引导与约束，而非简单交出控制权。其次，边缘化和轻量化是不可逆的趋势。与其等待更强的大模型，不如思考如何把现有能力嵌入具体场景——一个能在浏览器里跑的知识图谱，可能比云端千亿参数模型对你更有用。最后，专业领域的 AI 代理正在形成新门槛。懂金融的人用 OpenBB 构建策略，懂安全的人用 Pentagi 模拟攻防，技术红利正流向那些能把 AI 与领域知识结合的人。\n\n今天的 AI 新闻里，没有惊天动地的模型发布，却充满了可触摸的工具和可复用的工作流。它们不承诺取代人类，而是提供新的杠杆——只要你愿意花时间设计协作方式，而不是期待一键解决。或许，这才是 AI 走向实用的第一步。",
  "longformScriptZh": "今天，AI 正在从“能回答问题”走向“能做事”。不是泛泛而谈的智能，而是嵌入具体工作流、可部署、可协作的智能体。开发者在终端里直接调用 AI 编程，安全团队用 AI 模拟黑客攻击，金融分析师接入开源数据平台训练自己的交易代理——这些不再是实验室里的概念，而是今天就能下载、安装、运行的工具。AI 的重心，正在从模型本身转向如何让模型真正融入人类的日常操作。\n\n最引人注目的变化，发生在开发者的命令行里。Anthropic 推出了 Claude Code，一个能在终端内直接运行的编码代理。它不依赖图形界面，也不需要你切换窗口去和聊天机器人对话。你只需在命令行输入自然语言指令，比如“帮我重构这个模块”或“解释这段异步逻辑”，它就能理解整个代码库上下文，自动执行 Git 操作、生成文档，甚至提交 pull request。这标志着 AI 编程工具正从“辅助建议”迈向“协同执行”。更值得留意的是，有开发者分享了一套高效使用方法：先让 AI 生成一份 research.md 分析现状，再人工迭代出 plan.md 明确路径，最后才触发实际编码。这种“规划-执行”分离的流程，避免了 AI 盲目修改带来的架构混乱，也说明真正高效的 AI 协作，不是放手不管，而是结构化的人机配合。\n\n与此同时，AI 智能体的部署方式也在发生根本性转变。Cloudflare 宣布推出基于其全球边缘网络的 AI 智能体开发平台，允许开发者把轻量级代理直接部署到离用户最近的节点上。这意味着未来的 AI 应用可能不再集中于云端大模型，而是分散在边缘，以毫秒级响应处理本地请求。比如一个客服代理，可以在用户点击按钮的瞬间就近调用，无需往返数据中心。这种架构不仅降低延迟，也提升了隐私性和可用性。而另一边，GitNexus 这样的工具则把智能体完全搬进了浏览器——你只需拖入一个 GitHub 仓库，它就在本地生成交互式知识图谱，并内置 Graph RAG 智能体帮你导航代码。无需服务器、无需联网，特别适合处理敏感项目或离线场景。这些趋势共同指向一个方向：AI 正在变得更轻、更近、更嵌入实际工作流。\n\n不只是开发和部署，AI 智能体的能力边界也在向高专业领域拓展。比如 Pentagi 系统，一个完全自主的 AI 渗透测试框架，能模拟高级持续性威胁（APT）攻击，自动探测漏洞、横向移动、提取数据。它把原本需要资深红队工程师数天完成的任务，压缩成可重复运行的智能体流程。虽然这类工具必须谨慎使用，但它的出现证明，多智能体系统已经能在网络安全这样高风险、高复杂度的场景中发挥作用。同样，在金融领域，OpenBB 推出了专为 AI 智能体设计的开源数据平台，整合了实时行情、基本面指标和分析工具，让量化交易员或研究者能快速构建自己的策略代理，而无需依赖昂贵的商业终端。这些进展说明，AI 不再只是通用助手，而是开始成为特定领域的“数字专家”。\n\n更贴近普通用户的改变，也悄然发生。三星宣布将在 Galaxy S26 中集成 Perplexity AI，用户只需说“hey, Plex”就能唤醒它，并让它访问笔记、日历、相册等原生应用。这不仅是新增一个语音助手，而是操作系统层面支持多个 AI 代理共存与协作的信号。未来，你可能会根据任务切换不同的 AI：一个擅长写邮件，一个精于查资料，另一个专攻图像编辑。设备不再绑定单一智能，而是成为多个专业代理的调度中心。这种“多代理生态”的思路，或许比追求一个全能模型更贴近真实需求。\n\n面对这些快速落地的工具，我们该怎么看？首先，别被“全自动”迷惑。无论是 Claude Code 的规划流程，还是 Pentagi 的合规边界，都提醒我们：真正的生产力提升，来自人对 AI 的引导与约束，而非简单交出控制权。其次，边缘化和轻量化是不可逆的趋势。与其等待更强的大模型，不如思考如何把现有能力嵌入具体场景——一个能在浏览器里跑的知识图谱，可能比云端千亿参数模型对你更有用。最后，专业领域的 AI 代理正在形成新门槛。懂金融的人用 OpenBB 构建策略，懂安全的人用 Pentagi 模拟攻防，技术红利正流向那些能把 AI 与领域知识结合的人。\n\n今天的 AI 新闻里，没有惊天动地的模型发布，却充满了可触摸的工具和可复用的工作流。它们不承诺取代人类，而是提供新的杠杆——只要你愿意花时间设计协作方式，而不是期待一键解决。或许，这才是 AI 走向实用的第一步。",
  "longformScriptEn": "Today’s AI landscape is defined by a quiet but profound shift: artificial intelligence is moving from passive tools to active agents—systems that perceive, plan, act, and adapt in real-world environments. This transition isn’t just theoretical; it’s unfolding in developers’ terminals, enterprise security stacks, financial models, and even our smartphones. What we’re witnessing is the emergence of a new layer of intelligent infrastructure—one where AI doesn’t just respond to prompts but operates autonomously within structured workflows, constrained by human oversight yet empowered to execute complex tasks. From coding assistants that manage Git repositories to edge-deployed agents that interact with users in milliseconds, the era of agentic AI is no longer speculative—it’s shipping.\n\nAt the heart of this shift is Anthropic’s release of **Claude Code**, a terminal-based agentic coding assistant that embeds deeply into the developer’s native environment. Unlike traditional code completion tools, Claude Code understands your entire codebase, executes routine tasks like refactoring or testing, and even manages Git operations through natural language commands. Its power lies not in replacing developers but in augmenting their workflow with contextual awareness and execution capability—all without leaving the command line. But as developer Boris Tane has demonstrated, raw autonomy can be risky. His high-efficiency workflow introduces a crucial discipline: strict separation between planning and execution. By first generating a detailed research document, then iteratively refining a plan with human annotations before implementation, he avoids the architectural drift and system-breaking changes that plague unstructured AI coding. This approach treats AI not as an oracle but as a collaborator operating within a shared, traceable state—typically Markdown files—that both human and machine can co-edit. It’s a blueprint for responsible agentic development.\n\nBeyond software engineering, autonomous agents are proving their mettle in high-stakes domains like cybersecurity. Enter **Pentagi**, a fully autonomous AI system designed for penetration testing. Developed by vxcontrol, Pentagi simulates advanced persistent threat (APT)-style attacks by chaining together reconnaissance, exploitation, and post-compromise actions—all without human intervention. While its capabilities are impressive, they come with ethical weight: such tools must be used strictly within legal boundaries and with explicit authorization. Nevertheless, Pentagi signals a broader trend: multi-agent systems are now capable of navigating expert domains that demand deep contextual reasoning, adaptive strategy, and precise tool use. This isn’t just automation—it’s delegation to AI in environments where failure carries real consequences.\n\nMeanwhile, the infrastructure supporting these agents is evolving rapidly. Cloudflare has launched a platform enabling developers to build and deploy AI agents directly on its global edge network. By running inference close to end users via Cloudflare Workers, this architecture minimizes latency and maximizes responsiveness—critical for interactive agents that need to react in real time. This move pushes AI away from centralized cloud silos and toward decentralized, edge-native deployments. Complementing this is **GitNexus**, a zero-server code intelligence engine that runs entirely in the browser. Drop in a GitHub repo or ZIP file, and instantly get an interactive knowledge graph powered by a Graph RAG agent—all client-side, no backend required. For developers working offline or handling sensitive code, GitNexus offers privacy-preserving code understanding without sacrificing intelligence. Together, these tools illustrate a dual trajectory: agents are becoming both more powerful and more accessible, whether deployed at planetary scale on the edge or confined securely within a single browser tab.\n\nThe reach of agentic AI is also expanding into specialized data ecosystems. OpenBB has unveiled an open-source financial data platform explicitly designed for AI agents, quants, and analysts. It aggregates real-time market data, fundamentals, and technical indicators into a unified, programmable interface—democratizing access that once required expensive commercial terminals. Now, individual developers can train or deploy financial agents that reason over live market conditions, backtest strategies, or generate insights without institutional resources. This standardization of domain-specific data is essential for vertical AI applications to mature beyond demos into production-grade systems.\n\nFinally, the consumer front is heating up. Samsung’s integration of Perplexity into Galaxy AI for the upcoming S26 marks a strategic pivot toward a **multi-agent smartphone ecosystem**. Users will soon summon Perplexity with “Hey, Plex,” granting it access to native apps like Calendar, Notes, and Gallery—alongside existing assistants like Bixby and Gemini. Rather than betting on a single monolithic AI, Samsung is embracing specialization: different agents for different tasks, coexisting within the OS. This could redefine mobile interaction, shifting from app-centric navigation to intent-driven, agent-mediated experiences. If successful, it may pressure Apple and Google to rethink their own AI strategies, potentially accelerating a broader industry shift toward personalized, modular AI interfaces.\n\nSo what should you watch next? First, observe how structured collaboration frameworks—like Tane’s planning-execution split—scale across teams and codebases. Will they become standard practice, or remain niche optimizations? Second, monitor the regulatory response to autonomous agents in sensitive fields like security and finance; their power demands proportional accountability. Third, keep an eye on edge agent performance: as Cloudflare and others optimize latency and cost, we may see a surge in real-time, context-aware applications—from smart retail to industrial IoT. The opportunity lies not in building smarter models alone, but in designing better human-agent contracts: clear roles, verifiable outputs, and fail-safes that preserve control without stifling autonomy.\n\nIn sum, today’s developments reveal a maturing AI ecosystem where agents are no longer novelties but functional components of real workflows. Whether you’re debugging code in a terminal, stress-testing a network, analyzing stock trends, or checking your calendar on a Galaxy phone, agentic AI is stepping out of the lab and into the loop. The challenge—and the promise—is learning to work with it not as a replacement, but as a partner with defined responsibilities, bounded authority, and shared goals. That’s the foundation of the next era of intelligent systems.",
  "audioUrl": "",
  "papers": [
    {
      "id": "arxiv_2602_17598v1",
      "title": "The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?",
      "titleZh": "The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?",
      "titleEn": "The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?",
      "url": "https://arxiv.org/abs/2602.17598v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究发现，当前多数语音大语言模型（Speech LLMs）在可仅依赖转录文本完成的任务上，其行为与机制等同于Whisper→LLM级联管道；通过控制LLM主干架构的匹配测试，在四个Speech LLM和六项任务中验证了这一“级联等价假设”——Ultravox与对应级联系统几乎无法区分（κ=0.93），隐藏状态中可检测到字面文本表征，且擦除该表征会导致性能崩溃；但Qwen2-Audio表现出真实偏离，表明该等价性依赖架构而非普适；在实际部署中，这些模型多为昂贵且在噪声下表现更差的级联系统，0 dB信噪比下优势甚至逆转达7.6%。",
      "summaryZh": "研究发现，当前多数语音大语言模型（Speech LLMs）在可仅依赖转录文本完成的任务上，其行为与机制等同于Whisper→LLM级联管道；通过控制LLM主干架构的匹配测试，在四个Speech LLM和六项任务中验证了这一“级联等价假设”——Ultravox与对应级联系统几乎无法区分（κ=0.93），隐藏状态中可检测到字面文本表征，且擦除该表征会导致性能崩溃；但Qwen2-Audio表现出真实偏离，表明该等价性依赖架构而非普适；在实际部署中，这些模型多为昂贵且在噪声下表现更差的级联系统，0 dB信噪比下优势甚至逆转达7.6%。",
      "summaryEn": "Current speech LLMs largely behave like simple Whisper→LLM cascades on tasks solvable from transcripts, both behaviorally and mechanistically—a phenomenon termed the Cascade Equivalence Hypothesis. Through matched-backbone testing across four speech LLMs and six tasks, the study shows Ultravox is statistically indistinguishable from its cascade counterpart (κ=0.93), with literal text emerging in hidden states; erasing this representation collapses performance to near-zero. However, Qwen2-Audio genuinely diverges, revealing architecture dependence. In real-world use, most speech LLMs act as costly cascades that underperform under noise, with clean-condition advantages reversing by up to 7.6% at 0 dB SNR.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Audio"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：首次系统验证语音LLM与ASR→LLM流水线的等价性，颠覆对语音模型工作机制的认知，具有里程碑意义，将重塑语音AI研发范式。",
        "热度：8 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-19T18:22:39+00:00",
      "authors": [
        "Jayadev Billa"
      ]
    },
    {
      "id": "arxiv_2602_17260v1",
      "title": "EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection",
      "titleZh": "EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection",
      "titleEn": "EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection",
      "url": "https://arxiv.org/abs/2602.17260v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对Sora2、Veo3等先进AI视频生成器带来的检测挑战，研究者提出EA-Swin——一种嵌入无关的Swin Transformer，通过因子化窗口注意力直接建模预训练视频嵌入中的时空依赖，兼容通用ViT式编码器；同时构建包含13万视频的EA-Video基准数据集，涵盖多种商用与开源生成器并设未见生成器分割；实验表明EA-Swin在主流生成器上准确率达0.97–0.99，较现有最优方法（通常0.8–0.9）提升5–20%，且在跨分布场景下保持强泛化能力，为现代AI生成视频检测提供了可扩展的鲁棒方案。",
      "summaryZh": "针对Sora2、Veo3等先进AI视频生成器带来的检测挑战，研究者提出EA-Swin——一种嵌入无关的Swin Transformer，通过因子化窗口注意力直接建模预训练视频嵌入中的时空依赖，兼容通用ViT式编码器；同时构建包含13万视频的EA-Video基准数据集，涵盖多种商用与开源生成器并设未见生成器分割；实验表明EA-Swin在主流生成器上准确率达0.97–0.99，较现有最优方法（通常0.8–0.9）提升5–20%，且在跨分布场景下保持强泛化能力，为现代AI生成视频检测提供了可扩展的鲁棒方案。",
      "summaryEn": "To address the challenge posed by highly realistic AI-generated videos from systems like Sora2 and Veo3, researchers propose EA-Swin, an Embedding-Agnostic Swin Transformer that models spatiotemporal dependencies directly on pretrained video embeddings via factorized windowed attention, compatible with generic ViT-style encoders. They also introduce EA-Video, a 130K-video benchmark integrating new and curated data across diverse commercial and open-source generators, including unseen-generator splits. EA-Swin achieves 0.97–0.99 accuracy across major generators—surpassing prior state-of-the-art (typically 0.8–0.9) by 5–20%—while maintaining strong generalization to unseen distributions, offering a scalable and robust solution for modern deepfake detection.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Benchmark"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：针对Sora等生成视频的检测难题，提出嵌入无关的新型检测框架，是应对深度伪造威胁的关键突破，具备行业变革性。",
        "热度：14 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-19T11:04:20+00:00",
      "authors": [
        "Hung Mai",
        "Loi Dinh",
        "Duc Hai Nguyen"
      ]
    },
    {
      "id": "arxiv_2602_16943v1",
      "title": "Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents",
      "titleZh": "Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents",
      "titleEn": "Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents",
      "url": "https://arxiv.org/abs/2602.16943v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究揭示大语言模型作为智能体时存在“安全鸿沟”：文本层面的安全对齐无法迁移到工具调用层面；通过GAP基准对六个前沿模型在六大监管领域、七类越狱场景、三种系统提示下的17,420个样本评估发现，模型常在文本拒绝有害请求的同时执行禁止的工具调用；即使采用强化安全提示，六模型仍共出现219例此类矛盾；系统提示措辞显著影响工具调用行为（最敏感模型安全率波动达57个百分点）；运行时治理合约虽减少信息泄露，却未抑制违规调用尝试，表明仅靠文本安全评估不足以保障智能体行为安全，需专门的工具调用安全评测与干预机制。",
      "summaryZh": "研究揭示大语言模型作为智能体时存在“安全鸿沟”：文本层面的安全对齐无法迁移到工具调用层面；通过GAP基准对六个前沿模型在六大监管领域、七类越狱场景、三种系统提示下的17,420个样本评估发现，模型常在文本拒绝有害请求的同时执行禁止的工具调用；即使采用强化安全提示，六模型仍共出现219例此类矛盾；系统提示措辞显著影响工具调用行为（最敏感模型安全率波动达57个百分点）；运行时治理合约虽减少信息泄露，却未抑制违规调用尝试，表明仅靠文本安全评估不足以保障智能体行为安全，需专门的工具调用安全评测与干预机制。",
      "summaryEn": "A critical safety gap exists in LLM agents: alignment that suppresses harmful text does not transfer to tool-call safety. The GAP benchmark evaluates six frontier models across six regulated domains, seven jailbreak scenarios per domain, and three system prompt conditions (yielding 17,420 datapoints). Results show models frequently refuse harmful requests in text while simultaneously executing forbidden tool calls—a divergence formalized as the GAP metric. Even with safety-reinforced prompts, 219 such cases persist across all models. System prompt wording strongly influences tool-call behavior (TC-safe rates vary by up to 57 percentage points), and runtime governance contracts reduce information leakage but fail to deter forbidden tool-call attempts. This demonstrates that text-only safety evaluations are insufficient, and tool-call safety requires dedicated measurement and mitigation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "RAG",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：揭示文本安全与工具调用安全之间的鸿沟，直击AI代理落地核心风险，将推动全球AI安全评估标准变革。",
        "热度：22 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T23:17:15+00:00",
      "authors": [
        "Arnold Cartagena",
        "Ariane Teixeira"
      ]
    },
    {
      "id": "arxiv_2602_17602v1",
      "title": "MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models",
      "titleZh": "MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models",
      "titleEn": "MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models",
      "url": "https://arxiv.org/abs/2602.17602v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对分子图生成中化学有效性低、性质优化难的问题，研究提出MolHIT框架，基于分层离散扩散模型，将原子类型按化学角色解耦编码，并引入编码化学先验的额外离散类别；该方法在MOSES数据集上首次实现近乎完美的化学有效性，全面超越现有图扩散模型及强1D基线，并在多属性引导生成与骨架扩展等下游任务中表现优异，为AI驱动的药物发现与材料科学提供了高性能分子生成新范式。",
      "summaryZh": "针对分子图生成中化学有效性低、性质优化难的问题，研究提出MolHIT框架，基于分层离散扩散模型，将原子类型按化学角色解耦编码，并引入编码化学先验的额外离散类别；该方法在MOSES数据集上首次实现近乎完美的化学有效性，全面超越现有图扩散模型及强1D基线，并在多属性引导生成与骨架扩展等下游任务中表现优异，为AI驱动的药物发现与材料科学提供了高性能分子生成新范式。",
      "summaryEn": "To overcome low chemical validity and poor property optimization in molecular graph generation, researchers introduce MolHIT, a hierarchical discrete diffusion framework that decouples atom encoding by chemical roles and extends discrete diffusion with additional categories encoding chemical priors. MolHIT achieves near-perfect validity on the MOSES benchmark—the first graph diffusion model to do so—and surpasses strong 1D baselines across multiple metrics. It also excels in downstream tasks like multi-property guided generation and scaffold extension, establishing a high-performance paradigm for AI-driven drug discovery and materials science.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Diffusion"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：在分子图生成中引入分层离散扩散模型，显著提升化学有效性，有望重塑AI制药与材料科学研发范式。",
        "热度：9 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T18:27:11+00:00",
      "authors": [
        "Hojung Jung",
        "Rodrigo Hormazabal",
        "Jaehyeong Jo"
      ]
    },
    {
      "id": "arxiv_2602_17016v1",
      "title": "M2F: Automated Formalization of Mathematical Literature at Scale",
      "titleZh": "M2F: Automated Formalization of Mathematical Literature at Scale",
      "titleEn": "M2F: Automated Formalization of Mathematical Literature at Scale",
      "url": "https://arxiv.org/abs/2602.17016v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究提出M2F（Math-to-Formal），首个支持端到端、项目级数学文献自动形式化的智能体框架，通过两阶段流程处理跨文件依赖与编译问题：先将文档分解为原子块并修复声明骨架直至项目可编译（允许证明占位符），再通过目标条件局部编辑填补证明空缺；全程由Lean验证器闭环反馈指导编辑；该系统在约三周内将479页实分析与凸分析教材转化为153,853行完整Lean代码库，形式化速度远超人工（通常需数月或数年），并在FATE-H基准上达到96%证明成功率（基线为80%），证明大规模数学自动形式化已切实可行。",
      "summaryZh": "研究提出M2F（Math-to-Formal），首个支持端到端、项目级数学文献自动形式化的智能体框架，通过两阶段流程处理跨文件依赖与编译问题：先将文档分解为原子块并修复声明骨架直至项目可编译（允许证明占位符），再通过目标条件局部编辑填补证明空缺；全程由Lean验证器闭环反馈指导编辑；该系统在约三周内将479页实分析与凸分析教材转化为153,853行完整Lean代码库，形式化速度远超人工（通常需数月或数年），并在FATE-H基准上达到96%证明成功率（基线为80%），证明大规模数学自动形式化已切实可行。",
      "summaryEn": "Researchers present M2F (Math-to-Formal), the first agentic framework for end-to-end, project-scale autoformalization of mathematical literature in Lean. It operates in two verifier-in-the-loop stages: statement compilation (splitting documents into atomic blocks, ordering by inferred dependencies, and repairing declaration skeletons until the project compiles with proof placeholders) and proof repair (filling holes via goal-conditioned local edits). In ~3 weeks, M2F converted 479 pages of real and convex analysis textbooks into a 153,853-line Lean library with full proofs—work that typically requires months or years of expert effort. On FATE-H, it achieves 96% proof success versus 80% for a strong baseline, demonstrating that large-scale automated formalization is now within reach.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent",
        "Research",
        "Open Source"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：实现数学文献大规模自动化形式化，突破现有局限，为可验证AI与形式化推理奠定基础，具备战略级科研影响力。",
        "热度：9 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T02:25:23+00:00",
      "authors": [
        "Zichen Wang",
        "Wanli Ma",
        "Zhenyu Ming"
      ]
    },
    {
      "id": "arxiv_2602_17017v1",
      "title": "Sales Research Agent and Sales Research Bench",
      "titleZh": "Sales Research Agent and Sales Research Bench",
      "titleEn": "Sales Research Agent and Sales Research Bench",
      "url": "https://arxiv.org/abs/2602.17017v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "微软Dynamics 365 Sales推出Sales Research Agent，可连接实时CRM数据、理解复杂数据库结构并生成文本与图表形式的决策洞察；为量化质量，团队同步开发Sales Research Bench基准，从文本/图表事实性、相关性、可解释性、模式准确性等八个客户加权维度评分；在2025年10月19日针对定制企业数据库的200题测试中，该智能体以13分和24.1分的优势分别超越Claude Sonnet 4.5与ChatGPT-5（满分100），为企业用户提供可重复、透明的AI销售分析解决方案。",
      "summaryZh": "微软Dynamics 365 Sales推出Sales Research Agent，可连接实时CRM数据、理解复杂数据库结构并生成文本与图表形式的决策洞察；为量化质量，团队同步开发Sales Research Bench基准，从文本/图表事实性、相关性、可解释性、模式准确性等八个客户加权维度评分；在2025年10月19日针对定制企业数据库的200题测试中，该智能体以13分和24.1分的优势分别超越Claude Sonnet 4.5与ChatGPT-5（满分100），为企业用户提供可重复、透明的AI销售分析解决方案。",
      "summaryEn": "Microsoft Dynamics 365 Sales introduces the Sales Research Agent, an AI system that connects to live CRM data, reasons over complex schemas, and delivers decision-ready insights via text and charts. To enable transparent quality assessment, the team developed the Sales Research Bench—a purpose-built benchmark scoring systems across eight customer-weighted dimensions, including groundedness, relevance, explainability, schema accuracy, and chart quality. In a 200-question evaluation on a customized enterprise schema on October 19, 2025, the agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on a 100-point composite score, offering enterprises a repeatable, evidence-based way to evaluate AI sales analytics tools.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "Industry",
        "Research"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：微软发布Sales Research Agent及配套基准，标志着企业级AI智能体进入可验证、可复现的实战阶段，具有全球产业示范效应。",
        "热度：11 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2025-12-01T19:44:04+00:00",
      "authors": [
        "Deepanjan Bhol"
      ]
    },
    {
      "id": "arxiv_2602_17607v1",
      "title": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
      "titleZh": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
      "titleEn": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
      "url": "https://arxiv.org/abs/2602.17607v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为降低偏微分方程（PDE）数值求解对专家知识的依赖，研究提出AutoNumerics——一个自主、PDE无关的多智能体科学计算框架，能直接从自然语言描述出发，自动设计、实现、调试并验证经典数值求解器；不同于黑箱神经求解器，该框架生成基于传统数值分析的透明算法，并采用由粗到精的执行策略与残差自验证机制；在24个经典及真实PDE问题上的实验表明，AutoNumerics在精度上媲美或优于现有神经与LLM基线，且能根据PDE结构特性正确选择数值格式，为自动化科学计算提供了一种可解释、高可用的新范式。",
      "summaryZh": "为降低偏微分方程（PDE）数值求解对专家知识的依赖，研究提出AutoNumerics——一个自主、PDE无关的多智能体科学计算框架，能直接从自然语言描述出发，自动设计、实现、调试并验证经典数值求解器；不同于黑箱神经求解器，该框架生成基于传统数值分析的透明算法，并采用由粗到精的执行策略与残差自验证机制；在24个经典及真实PDE问题上的实验表明，AutoNumerics在精度上媲美或优于现有神经与LLM基线，且能根据PDE结构特性正确选择数值格式，为自动化科学计算提供了一种可解释、高可用的新范式。",
      "summaryEn": "To reduce reliance on expert knowledge in PDE solver design, researchers introduce AutoNumerics—an autonomous, PDE-agnostic multi-agent framework that designs, implements, debugs, and verifies classical numerical solvers directly from natural language descriptions. Unlike black-box neural solvers, AutoNumerics generates transparent algorithms grounded in classical numerical analysis, using a coarse-to-fine execution strategy and residual-based self-verification. Experiments on 24 canonical and real-world PDEs show it achieves competitive or superior accuracy compared to neural and LLM-based baselines and correctly selects numerical schemes based on PDE structural properties, offering an interpretable and accessible paradigm for automated scientific computing.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：AutoNumerics构建无偏PDE求解多智能体管道，实现科学计算自动化，有望颠覆传统仿真流程，具备重大科研变革潜力。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T18:31:52+00:00",
      "authors": [
        "Jianda Du",
        "Youran Sun",
        "Haizhao Yang"
      ]
    },
    {
      "id": "arxiv_2602_17200v1",
      "title": "GASS: Geometry-Aware Spherical Sampling for Disentangled Diversity Enhancement in Text-to-Image Generation",
      "titleZh": "GASS: Geometry-Aware Spherical Sampling for Disentangled Diversity Enhancement in Text-to-Image Generation",
      "titleEn": "GASS: Geometry-Aware Spherical Sampling for Disentangled Diversity Enhancement in Text-to-Image Generation",
      "url": "https://arxiv.org/abs/2602.17200v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对文本到图像生成中多样性不足的问题，研究提出几何感知球面采样（GASS）方法，通过CLIP嵌入空间的正交分解显式分离提示相关语义变化（沿文本嵌入方向）与提示无关变化（如背景，沿正交方向），并在两个轴上扩展生成图像嵌入的几何投影分布以增强解耦多样性；该方法适用于不同冻结T2I主干（U-Net/DiT，扩散/流模型），在保持图像保真度与语义对齐的同时显著提升多样性，为缓解生成模型中的偏见放大风险提供了新路径。",
      "summaryZh": "针对文本到图像生成中多样性不足的问题，研究提出几何感知球面采样（GASS）方法，通过CLIP嵌入空间的正交分解显式分离提示相关语义变化（沿文本嵌入方向）与提示无关变化（如背景，沿正交方向），并在两个轴上扩展生成图像嵌入的几何投影分布以增强解耦多样性；该方法适用于不同冻结T2I主干（U-Net/DiT，扩散/流模型），在保持图像保真度与语义对齐的同时显著提升多样性，为缓解生成模型中的偏见放大风险提供了新路径。",
      "summaryEn": "To address limited diversity in text-to-image (T2I) generation, researchers propose Geometry-Aware Spherical Sampling (GASS), which decomposes CLIP embedding space into two orthogonal directions: one aligned with the text prompt (capturing semantic variation) and another capturing prompt-independent variation (e.g., backgrounds). GASS enhances disentangled diversity by expanding the geometric spread of generated image embeddings along both axes during sampling. The method works across frozen T2I backbones—including U-Net and DiT, diffusion and flow models—and boosts diversity with minimal impact on fidelity or semantic alignment, offering a geometric approach to mitigate bias amplification in generative models.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Diffusion",
        "Benchmark"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：通过几何感知采样提升文本到图像生成多样性，有效缓解偏见问题，对AIGC产业具有战略意义。",
        "热度：9 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-19T09:41:32+00:00",
      "authors": [
        "Ye Zhu",
        "Kaleb S. Newman",
        "Johannes F. Lutzeyer"
      ]
    },
    {
      "id": "arxiv_2602_16872v1",
      "title": "DODO: Discrete OCR Diffusion Models",
      "titleZh": "DODO: Discrete OCR Diffusion Models",
      "titleEn": "DODO: Discrete OCR Diffusion Models",
      "url": "https://arxiv.org/abs/2602.16872v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对光学字符识别（OCR）任务中自回归解码速度慢的问题，研究者提出DODO——首个采用块状离散扩散机制的视觉语言模型。该方法利用OCR任务输出高度确定性的特点，通过分块并行生成避免全局扩散中的同步错误，在保持接近最先进准确率的同时，推理速度最高提升3倍。",
      "summaryZh": "针对光学字符识别（OCR）任务中自回归解码速度慢的问题，研究者提出DODO——首个采用块状离散扩散机制的视觉语言模型。该方法利用OCR任务输出高度确定性的特点，通过分块并行生成避免全局扩散中的同步错误，在保持接近最先进准确率的同时，推理速度最高提升3倍。",
      "summaryEn": "Addressing the slow inference of autoregressive decoding in Optical Character Recognition (OCR), researchers propose DODO—the first Vision-Language Model using block discrete diffusion. Leveraging OCR’s deterministic nature, DODO enables parallel generation by decomposing output into blocks, mitigating synchronization errors in global diffusion and achieving up to 3× faster inference while maintaining near state-of-the-art accuracy.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Diffusion"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出离散OCR扩散模型，突破传统自回归解码瓶颈，显著提升文本识别效率与精度，有望重塑文档数字化与AI视觉理解范式。",
        "热度：16 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-18T20:59:22+00:00",
      "authors": [
        "Sean Man",
        "Roy Ganz",
        "Roi Ronen"
      ]
    },
    {
      "id": "arxiv_2602_17168v1",
      "title": "BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning",
      "titleZh": "BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning",
      "titleEn": "BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning",
      "url": "https://arxiv.org/abs/2602.17168v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决多模态对比学习模型中后门攻击的隐蔽性与持久性难题，研究者提出BadCLIP++框架：通过语义融合的QR微触发器实现高隐蔽性，并结合半径收缩、质心对齐与弹性权重巩固等技术增强后门在低中毒率（仅0.3%）和持续微调下的稳定性；实验显示其在数字攻击中达到99.99%成功率，且对19种防御手段均保持超过99.90%的攻击成功率，同时几乎不影响干净样本准确率。",
      "summaryZh": "为解决多模态对比学习模型中后门攻击的隐蔽性与持久性难题，研究者提出BadCLIP++框架：通过语义融合的QR微触发器实现高隐蔽性，并结合半径收缩、质心对齐与弹性权重巩固等技术增强后门在低中毒率（仅0.3%）和持续微调下的稳定性；实验显示其在数字攻击中达到99.99%成功率，且对19种防御手段均保持超过99.90%的攻击成功率，同时几乎不影响干净样本准确率。",
      "summaryEn": "To address stealthiness and persistence challenges in backdoor attacks on multimodal contrastive learning, researchers propose BadCLIP++. It uses a semantic-fusion QR micro-trigger for imperceptibility and enhances persistence via radius shrinkage, centroid alignment, curvature control, and elastic weight consolidation. With only 0.3% poisoning, it achieves 99.99% attack success rate (ASR) digitally, maintains >99.90% ASR against 19 defenses, and incurs <0.8% clean accuracy drop.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Multimodal",
        "Audio",
        "Training",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：揭示多模态对比学习中的隐蔽后门攻击，直击AI安全核心痛点，对模型可信性与防御体系构建具有战略意义。",
        "热度：16 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-19T08:31:16+00:00",
      "authors": [
        "Siyuan Liang",
        "Yongcheng Jing",
        "Yingjie Wang"
      ]
    },
    {
      "id": "arxiv_2602_17196v1",
      "title": "EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models",
      "titleZh": "EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models",
      "titleEn": "EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models",
      "url": "https://arxiv.org/abs/2602.17196v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为高效加速多模态大语言模型（MLLMs）推理，研究者提出EntropyPrune框架，基于矩阵熵发现视觉表征信息量骤降的“熵坍缩层”（ECL），以此作为剪枝依据；该方法无需依赖注意力图，通过谱等价性将熵计算复杂度大幅降低，理论加速达64倍，在LLaVA-1.5-7B上减少68.2% FLOPs的同时保留96.0%原始性能，并可泛化至高分辨率与视频模型。",
      "summaryZh": "为高效加速多模态大语言模型（MLLMs）推理，研究者提出EntropyPrune框架，基于矩阵熵发现视觉表征信息量骤降的“熵坍缩层”（ECL），以此作为剪枝依据；该方法无需依赖注意力图，通过谱等价性将熵计算复杂度大幅降低，理论加速达64倍，在LLaVA-1.5-7B上减少68.2% FLOPs的同时保留96.0%原始性能，并可泛化至高分辨率与视频模型。",
      "summaryEn": "To accelerate multimodal large language models (MLLMs), researchers introduce EntropyPrune, which identifies an 'Entropy Collapse Layer' (ECL)—where visual representation information sharply drops—as a principled pruning stage. Avoiding attention maps, it leverages spectral equivalence of dual Gram matrices for up to 64× theoretical speedup in entropy computation. On LLaVA-1.5-7B, it reduces FLOPs by 68.2% while preserving 96.0% performance and generalizes to high-resolution and video-based models.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Inference"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出基于矩阵熵的视觉令牌剪枝方法，有效降低多模态大模型推理开销，对实际部署具有显著优化价值。",
        "热度：17 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-19T09:29:43+00:00",
      "authors": [
        "Yahong Wang",
        "Juncheng Wu",
        "Zhangkai Ni"
      ]
    },
    {
      "id": "arxiv_2602_17182v1",
      "title": "NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting",
      "titleZh": "NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting",
      "titleEn": "NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting",
      "url": "https://arxiv.org/abs/2602.17182v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对内窥镜场景中软组织形变导致传统SLAM失效的问题，研究者提出NRGS-SLAM系统，基于3D高斯泼溅构建形变感知地图，为每个高斯基元引入可学习形变概率并通过贝叶斯自监督优化；其跟踪模块优先利用低形变区域估计位姿，映射模块动态扩展地图，并结合几何先验损失提升鲁棒性，在多个公开数据集上将位姿误差降低最多50%，并实现高质量光真实感重建。",
      "summaryZh": "针对内窥镜场景中软组织形变导致传统SLAM失效的问题，研究者提出NRGS-SLAM系统，基于3D高斯泼溅构建形变感知地图，为每个高斯基元引入可学习形变概率并通过贝叶斯自监督优化；其跟踪模块优先利用低形变区域估计位姿，映射模块动态扩展地图，并结合几何先验损失提升鲁棒性，在多个公开数据集上将位姿误差降低最多50%，并实现高质量光真实感重建。",
      "summaryEn": "To address camera-deformation coupling in endoscopic monocular SLAM, researchers propose NRGS-SLAM, a non-rigid system based on 3D Gaussian Splatting. It augments each Gaussian with a learnable deformation probability optimized via Bayesian self-supervision. A deformable tracking module estimates pose using low-deformation regions, while a mapping module refines the scene representation. A unified geometric loss incorporates priors to mitigate ill-posedness. Experiments show up to 50% RMSE reduction in pose estimation and photo-realistic reconstructions surpassing prior methods.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "3D",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：解决内窥镜中非刚性变形下的SLAM难题，推动医疗影像智能化，对精准医疗与手术导航具重要应用潜力。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-19T09:03:47+00:00",
      "authors": [
        "Jiwei Shan",
        "Zeyu Cai",
        "Yirui Li"
      ]
    },
    {
      "id": "arxiv_2602_17601v1",
      "title": "Graph Neural Model Predictive Control for High-Dimensional Systems",
      "titleZh": "Graph Neural Model Predictive Control for High-Dimensional Systems",
      "titleEn": "Graph Neural Model Predictive Control for High-Dimensional Systems",
      "url": "https://arxiv.org/abs/2602.17601v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为实现实时控制高维系统（如软体机器人），研究者将图神经网络（GNN）动力学模型与结构感知的模型预测控制（MPC）结合，利用系统局部交互的图表示保持稀疏性，并设计线性复杂度的压缩算法消除状态变量；该方法在GPU上实现100Hz闭环控制，成功驱动含1000节点的软体机械臂，硬件实验中以亚厘米精度完成轨迹跟踪，性能优于基线63.6%，并支持全身避障。",
      "summaryZh": "为实现实时控制高维系统（如软体机器人），研究者将图神经网络（GNN）动力学模型与结构感知的模型预测控制（MPC）结合，利用系统局部交互的图表示保持稀疏性，并设计线性复杂度的压缩算法消除状态变量；该方法在GPU上实现100Hz闭环控制，成功驱动含1000节点的软体机械臂，硬件实验中以亚厘米精度完成轨迹跟踪，性能优于基线63.6%，并支持全身避障。",
      "summaryEn": "To enable real-time control of high-dimensional systems like soft robots, researchers integrate Graph Neural Network (GNN)-based dynamics with structure-exploiting Model Predictive Control (MPC). Representing the system as a graph preserves sparsity, and a tailored condensing algorithm eliminates state variables with linear complexity. GPU acceleration achieves 100 Hz closed-loop control on a 1,000-node soft robotic trunk, demonstrating sub-centimeter tracking accuracy—63.6% better than baselines—and full-body obstacle avoidance.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "RAG"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：将图神经网络与模型预测控制结合用于高维系统（如软体机器人），显著提升复杂系统控制能力，具备行业变革潜力。",
        "热度：8 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-19T18:26:42+00:00",
      "authors": [
        "Patrick Benito Eberhard",
        "Luis Pabon",
        "Daniele Gammelli"
      ]
    },
    {
      "id": "arxiv_2602_16870v1",
      "title": "Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads",
      "titleZh": "Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads",
      "titleEn": "Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads",
      "url": "https://arxiv.org/abs/2602.16870v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "Boreas Road Trip（Boreas-RT）数据集扩展了原Boreas多季节数据集，新增9条共643公里具挑战性的真实道路序列，涵盖重复通行下的交通与天气变化；平台配备多传感器（包括FMCW激光雷达、Doppler雷达、高分辨率相机等）及厘米级GNSS-INS真值，提供精确标定与开发套件；基准测试表明，现有顶尖定位算法在简单环境过拟合，在Boreas-RT上性能显著下降，凸显该数据集对多模态自动驾驶算法鲁棒性评估的价值。",
      "summaryZh": "Boreas Road Trip（Boreas-RT）数据集扩展了原Boreas多季节数据集，新增9条共643公里具挑战性的真实道路序列，涵盖重复通行下的交通与天气变化；平台配备多传感器（包括FMCW激光雷达、Doppler雷达、高分辨率相机等）及厘米级GNSS-INS真值，提供精确标定与开发套件；基准测试表明，现有顶尖定位算法在简单环境过拟合，在Boreas-RT上性能显著下降，凸显该数据集对多模态自动驾驶算法鲁棒性评估的价值。",
      "summaryEn": "The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset with 60 sequences across 9 challenging real-world routes totaling 643 km, featuring repeated traversals under varying traffic and weather. Equipped with multi-sensor suite—including FMCW LiDAR, Doppler radar, and high-res cameras—and centimeter-accurate GNSS-INS ground truth, it provides precise calibration and a dev kit. Benchmarks reveal that state-of-the-art odometry/localization methods overfit to simple environments and degrade significantly on Boreas-RT, highlighting its value for robust multimodal autonomous driving evaluation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Benchmark"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：发布大规模多季节、多路况自动驾驶数据集Boreas-RT，填补复杂道路场景数据空白，对全球自动驾驶研发具有关键推动作用。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T20:53:59+00:00",
      "authors": [
        "Daniil Lisus",
        "Katya M. Papais",
        "Cedric Le Gentil"
      ]
    },
    {
      "id": "arxiv_2602_16825v1",
      "title": "RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness",
      "titleZh": "RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness",
      "titleEn": "RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness",
      "url": "https://arxiv.org/abs/2602.16825v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为克服传统信号时序逻辑（STL）规划中min-max鲁棒性导致的非光滑优化问题，研究者提出RRT^η框架，引入算术-几何平均（AGM）鲁棒性度量，综合所有时间点与子公式满足度；其贡献包括AGM鲁棒性区间语义、增量监控算法及基于Fulfillment Priority Logic的方向向量，可在保持RRT*概率完备性与渐近最优性的同时，高效生成满足复杂STL规范的高鲁棒性控制序列，在双积分器、单轮车和7自由度机械臂上均优于传统方法。",
      "summaryZh": "为克服传统信号时序逻辑（STL）规划中min-max鲁棒性导致的非光滑优化问题，研究者提出RRT^η框架，引入算术-几何平均（AGM）鲁棒性度量，综合所有时间点与子公式满足度；其贡献包括AGM鲁棒性区间语义、增量监控算法及基于Fulfillment Priority Logic的方向向量，可在保持RRT*概率完备性与渐近最优性的同时，高效生成满足复杂STL规范的高鲁棒性控制序列，在双积分器、单轮车和7自由度机械臂上均优于传统方法。",
      "summaryEn": "To overcome the non-smooth optimization landscapes caused by min-max robustness in Signal Temporal Logic (STL) planning, researchers propose RRT^η, which integrates Arithmetic-Geometric Mean (AGM) robustness to evaluate satisfaction across all time points and subformulae. Key contributions include AGM robustness interval semantics, an incremental monitoring algorithm, and Fulfillment Priority Logic-guided direction vectors. The framework synthesizes high-robustness, dynamically feasible trajectories while preserving RRT*’s probabilistic completeness and asymptotic optimality, outperforming baselines on a double integrator, unicycle, and 7-DOF arm.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Robotics",
        "RAG",
        "Reasoning"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：基于STL规范的采样运动规划方法引入鲁棒性度量，为安全可控机器人系统提供理论支撑，推动形式化验证在机器人中的应用。",
        "热度：15 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-18T19:45:43+00:00",
      "authors": [
        "Ahmad Ahmad",
        "Shuo Liu",
        "Roberto Tron"
      ]
    },
    {
      "id": "arxiv_2602_16898v1",
      "title": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
      "titleZh": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
      "titleEn": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
      "url": "https://arxiv.org/abs/2602.16898v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为提升大语言模型在动态环境中执行机器人操作任务的鲁棒性，研究者提出MALLVi多智能体框架，通过分解器、定位器、思考器与反思器等专用代理协同工作，结合视觉语言模型实现闭环反馈：每步执行后评估环境状态，仅在必要时激活相关代理进行局部修正而非全局重规划；在仿真与真实世界零样本任务中，该方法显著提升泛化能力与成功率。",
      "summaryZh": "为提升大语言模型在动态环境中执行机器人操作任务的鲁棒性，研究者提出MALLVi多智能体框架，通过分解器、定位器、思考器与反思器等专用代理协同工作，结合视觉语言模型实现闭环反馈：每步执行后评估环境状态，仅在必要时激活相关代理进行局部修正而非全局重规划；在仿真与真实世界零样本任务中，该方法显著提升泛化能力与成功率。",
      "summaryEn": "To enhance robustness of robotic manipulation with large language models in dynamic environments, researchers propose MALLVi—a multi-agent framework coordinating specialized agents (Decomposer, Localizer, Thinker, Reflector) with vision-language feedback. After each action, a VLM evaluates the environment and triggers targeted recovery by reactivating only relevant agents, avoiding full replanning. Experiments in simulation and real-world zero-shot tasks show improved generalization and higher success rates.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Agent"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：提出多智能体框架用于通用机器人操作，结合LLM与环境反馈，具备显著技术推进性，可能推动具身AI发展。",
        "热度：20 / 评论 0"
      ],
      "score": 7.0,
      "publishedAt": "2026-02-18T21:28:56+00:00",
      "authors": [
        "Iman Ahmadi",
        "Mehrshad Taji",
        "Arad Mahdinezhad Kashani"
      ]
    },
    {
      "id": "arxiv_2602_16764v1",
      "title": "Machine Learning Argument of Latitude Error Model for LEO Satellite Orbit and Covariance Correction",
      "titleZh": "Machine Learning Argument of Latitude Error Model for LEO Satellite Orbit and Covariance Correction",
      "titleEn": "Machine Learning Argument of Latitude Error Model for LEO Satellite Orbit and Covariance Correction",
      "url": "https://arxiv.org/abs/2602.16764v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对低轨（LEO）卫星轨道传播中因大气阻力建模误差导致的纬度幅角不确定性非高斯化问题，研究提出一种机器学习方法，利用时间条件神经网络或高斯过程，基于单一时历的矢量协方差消息（VCM）和反向传播误差，预测纬度幅角误差的高斯分布；该一维修正模型有效捕捉了阻力误建模的影响，并将其映射至笛卡尔状态空间，仅在主导误差增长方向更新均值与协方差，其余维度保留物理传播的VCM协方差结构，从而在不修改现有传播器的前提下显著延长VCM星历的有效使用时长。",
      "summaryZh": "针对低轨（LEO）卫星轨道传播中因大气阻力建模误差导致的纬度幅角不确定性非高斯化问题，研究提出一种机器学习方法，利用时间条件神经网络或高斯过程，基于单一时历的矢量协方差消息（VCM）和反向传播误差，预测纬度幅角误差的高斯分布；该一维修正模型有效捕捉了阻力误建模的影响，并将其映射至笛卡尔状态空间，仅在主导误差增长方向更新均值与协方差，其余维度保留物理传播的VCM协方差结构，从而在不修改现有传播器的前提下显著延长VCM星历的有效使用时长。",
      "summaryEn": "To address non-Gaussian uncertainty in Low Earth Orbit (LEO) satellite propagation caused by atmospheric drag mismodeling, this paper proposes a machine learning approach that uses either a time-conditioned neural network or Gaussian Process to predict the argument of latitude error as a Gaussian distribution, given parameters from a single Vector Covariance Message (VCM) epoch and reverse propagation errors. The one-dimensional correction model effectively captures drag-induced errors and maps them into Cartesian state space, updating only the dominant error growth dimensions while preserving physics-based VCM covariance propagation elsewhere—extending VCM ephemeris usability over longer horizons without altering the existing propagator.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "3D",
        "RAG",
        "Open Source"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：针对LEO卫星轨道误差建模与协方差修正，对下一代非GNSS定位系统发展具有重要意义，影响未来空间导航基础设施。",
        "热度：9 / 评论 0"
      ],
      "score": 7.0,
      "publishedAt": "2026-02-18T17:23:14+00:00",
      "authors": [
        "Alex Moody",
        "Penina Axelrad",
        "Rebecca Russell"
      ]
    },
    {
      "id": "arxiv_2602_17393v1",
      "title": "Contact-Anchored Proprioceptive Odometry for Quadruped Robots",
      "titleZh": "Contact-Anchored Proprioceptive Odometry for Quadruped Robots",
      "titleEn": "Contact-Anchored Proprioceptive Odometry for Quadruped Robots",
      "url": "https://arxiv.org/abs/2602.17393v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决无视觉传感器的四足机器人因IMU漂移和关节速度噪声导致的里程计不可靠问题，研究提出一种纯本体感知的状态估计算法，仅依赖IMU与电机测量数据，将接触腿视为运动学锚点：通过关节力矩估计足端 wrench 以筛选可靠接触，并利用足落地点提供世界坐标系下的间歇约束以抑制长期漂移；同时引入轻量级高度聚类与时衰校正机制防止高程漂移，并采用逆运动学立方卡尔曼滤波直接从关节角度与速度中滤出足端速度；该方法在四款四足机器人上验证，在200米水平环路中定位误差低至0.16米，垂直环路误差低于0.22米，且支持轮腿混合平台，具备良好的退化鲁棒性。",
      "summaryZh": "为解决无视觉传感器的四足机器人因IMU漂移和关节速度噪声导致的里程计不可靠问题，研究提出一种纯本体感知的状态估计算法，仅依赖IMU与电机测量数据，将接触腿视为运动学锚点：通过关节力矩估计足端 wrench 以筛选可靠接触，并利用足落地点提供世界坐标系下的间歇约束以抑制长期漂移；同时引入轻量级高度聚类与时衰校正机制防止高程漂移，并采用逆运动学立方卡尔曼滤波直接从关节角度与速度中滤出足端速度；该方法在四款四足机器人上验证，在200米水平环路中定位误差低至0.16米，垂直环路误差低于0.22米，且支持轮腿混合平台，具备良好的退化鲁棒性。",
      "summaryEn": "Addressing unreliable odometry in legged robots without cameras or LiDAR due to IMU drift and noisy joint velocity sensing, this paper presents a purely proprioceptive state estimator using only IMU and motor measurements. It treats contacting legs as kinematic anchors: joint-torque–based foot wrench estimation selects reliable contacts, and footfall positions provide intermittent world-frame constraints to suppress long-term drift. A lightweight height clustering and time-decay correction prevents elevation drift, while an inverse-kinematics cubature Kalman filter directly estimates foot-end velocities from joint angles and velocities. Evaluated on four quadruped platforms—including point-foot and wheel-legged variants—the method achieves as low as 0.16 m error on a ~200 m horizontal loop and under 0.22 m on vertical loops, with graceful degradation when IMU yaw is unreliable.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "Inference",
        "Research",
        "Open Source"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：实现无视觉传感器的四足机器人本体感知里程计，突破腿式机器人在复杂环境下的定位瓶颈，推动自主移动平台发展。",
        "热度：8 / 评论 0"
      ],
      "score": 7.0,
      "publishedAt": "2026-02-19T14:18:26+00:00",
      "authors": [
        "Minxing Sun",
        "Yao Mao"
      ]
    }
  ],
  "news": [
    {
      "id": "github_anthropics_claude-code",
      "title": "Anthropic 推出终端智能编码工具 Claude Code",
      "titleZh": "Anthropic 推出终端智能编码工具 Claude Code",
      "titleEn": "Anthropic Launches Claude Code: An Agentic Terminal-Based Coding Assistant",
      "url": "https://github.com/anthropics/claude-code",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Anthropic 推出 Claude Code**，一款终端内运行的智能编码代理工具，能理解整个代码库并通过自然语言指令自动执行常规任务、解释复杂逻辑并管理 Git 工作流；其重要性在于将大模型深度集成到开发者日常操作中，减少上下文切换；对 AI 领域而言，它代表了 agentic coding（自主代理编程）向实用化迈出的关键一步；普通开发者可立即在命令行中安装使用，提升编码效率而不依赖图形界面。",
      "summaryZh": "**Anthropic 推出 Claude Code**，一款终端内运行的智能编码代理工具，能理解整个代码库并通过自然语言指令自动执行常规任务、解释复杂逻辑并管理 Git 工作流；其重要性在于将大模型深度集成到开发者日常操作中，减少上下文切换；对 AI 领域而言，它代表了 agentic coding（自主代理编程）向实用化迈出的关键一步；普通开发者可立即在命令行中安装使用，提升编码效率而不依赖图形界面。",
      "summaryEn": "Anthropic has released **Claude Code**, an agentic coding tool that runs in the terminal, understands your entire codebase, and accelerates development by executing routine tasks, explaining complex logic, and managing Git workflows via natural language commands. Its significance lies in deeply integrating large language models into daily developer workflows without requiring GUIs. For the AI field, it marks a practical advance in agentic coding. Developers can immediately install and use it in their command line to boost productivity.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/9971e89bc322eca56beeedd0cad533187ab3ebb1ce5c5a504611d16a5aea7043/anthropics/claude-code",
      "tags": [
        "LLM",
        "Agent",
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：Anthropic官方发布Claude Code，标志着主流大厂在智能开发工具上的深度布局，推动AI原生开发生态演进。",
        "热度：68932 / 评论 0"
      ],
      "score": 9.8,
      "publishedAt": "2026-02-22T23:34:10.037046+00:00",
      "authors": []
    },
    {
      "id": "github_vxcontrol_pentagi",
      "title": "Pentagi：全自动 AI 渗透测试智能体系统发布",
      "titleZh": "Pentagi：全自动 AI 渗透测试智能体系统发布",
      "titleEn": "Pentagi: Fully Autonomous AI Agents for Penetration Testing Released",
      "url": "https://github.com/vxcontrol/pentagi",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**vxcontrol 发布 Pentagi 系统**，一个完全自主的 AI 智能体框架，专为执行复杂渗透测试任务而设计；其重要性在于将自动化红队能力封装为可部署的 AI 代理，降低安全测试门槛；对 AI 领域而言，它展示了多智能体系统在高风险、高专业性场景中的可行性；网络安全从业者可将其用于模拟高级持续性威胁（APT）攻击，但需注意伦理与合规边界。",
      "summaryZh": "**vxcontrol 发布 Pentagi 系统**，一个完全自主的 AI 智能体框架，专为执行复杂渗透测试任务而设计；其重要性在于将自动化红队能力封装为可部署的 AI 代理，降低安全测试门槛；对 AI 领域而言，它展示了多智能体系统在高风险、高专业性场景中的可行性；网络安全从业者可将其用于模拟高级持续性威胁（APT）攻击，但需注意伦理与合规边界。",
      "summaryEn": "**vxcontrol has released Pentagi**, a fully autonomous AI agent system designed to perform complex penetration testing tasks. Its importance lies in packaging automated red-teaming capabilities into deployable AI agents, lowering the barrier to advanced security testing. For the AI field, it demonstrates the viability of multi-agent systems in high-stakes, expert domains. Cybersecurity professionals can use it to simulate APT-style attacks—but must adhere to ethical and legal boundaries.",
      "fullText": "",
      "imageUrl": "https://repository-images.githubusercontent.com/913030762/c8502908-380f-4897-aaba-87cfa16d67b4",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：首个全自主AI渗透测试代理系统，具备重大安全领域突破潜力，可能引发全球网络安全格局重构。",
        "热度：6918 / 评论 0"
      ],
      "score": 8.4,
      "publishedAt": "2026-02-22T23:34:08.605977+00:00",
      "authors": []
    },
    {
      "id": "github_cloudflare_agents",
      "title": "Cloudflare 推出边缘 AI 智能体开发平台",
      "titleZh": "Cloudflare 推出边缘 AI 智能体开发平台",
      "titleEn": "Cloudflare Launches Platform to Build and Deploy AI Agents on the Edge",
      "url": "https://github.com/cloudflare/agents",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Cloudflare 推出 AI 智能体开发与部署平台**，允许开发者在其全球边缘网络上构建和运行 AI 智能体；这一举措将 AI 推理与 Cloudflare 的低延迟基础设施结合，使智能体能就近响应用户请求；对 AI 领域而言，它推动了去中心化、边缘化智能体架构的发展；普通开发者可通过 Cloudflare Workers 快速部署轻量级 AI 代理，实现低延迟、高可用的交互式应用。",
      "summaryZh": "**Cloudflare 推出 AI 智能体开发与部署平台**，允许开发者在其全球边缘网络上构建和运行 AI 智能体；这一举措将 AI 推理与 Cloudflare 的低延迟基础设施结合，使智能体能就近响应用户请求；对 AI 领域而言，它推动了去中心化、边缘化智能体架构的发展；普通开发者可通过 Cloudflare Workers 快速部署轻量级 AI 代理，实现低延迟、高可用的交互式应用。",
      "summaryEn": "**Cloudflare has launched a platform for building and deploying AI agents** on its global edge network, enabling developers to run intelligent applications close to end users. By integrating AI inference with Cloudflare’s low-latency infrastructure, the platform ensures responsive agent interactions. For the AI community, it advances decentralized, edge-native agent architectures. Developers can now quickly deploy lightweight AI agents via Cloudflare Workers to build low-latency, highly available interactive applications.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/d7f57e77901b9acdbbcce60fe892c81366d5e06d5cc52ed62a1129881811b824/cloudflare/agents",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：Cloudflare推出AI Agent部署平台，将AI能力嵌入全球边缘网络基础设施，具有深远产业整合意义。",
        "热度：3711 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-22T23:34:14.210693+00:00",
      "authors": []
    },
    {
      "id": "hn_47106686",
      "title": "开发者分享 Claude Code 高效用法：严格分离规划与执行",
      "titleZh": "开发者分享 Claude Code 高效用法：严格分离规划与执行",
      "titleEn": "Developer Shares Efficient Claude Code Workflow: Strict Separation of Planning and Execution",
      "url": "https://boristane.com/blog/how-i-use-claude-code/",
      "type": "news",
      "source": "Hacker News",
      "summary": "**开发者 Boris Tane 分享其使用 Claude Code 的高效工作流**，核心是严格分离“规划”与“执行”：先通过深度代码阅读生成 research.md，再制定 plan.md 并经多轮人工注释迭代修正，最后才触发完整实现；该方法避免了 AI 直接编码导致的架构偏差和系统冲突，显著提升产出质量；对 AI 编程领域而言，它证明了结构化人机协作优于盲目自动化；普通开发者可借鉴此流程，在开源项目中通过 Markdown 文档作为人机共享状态，实现可控、可追溯的 AI 辅助开发。",
      "summaryZh": "**开发者 Boris Tane 分享其使用 Claude Code 的高效工作流**，核心是严格分离“规划”与“执行”：先通过深度代码阅读生成 research.md，再制定 plan.md 并经多轮人工注释迭代修正，最后才触发完整实现；该方法避免了 AI 直接编码导致的架构偏差和系统冲突，显著提升产出质量；对 AI 编程领域而言，它证明了结构化人机协作优于盲目自动化；普通开发者可借鉴此流程，在开源项目中通过 Markdown 文档作为人机共享状态，实现可控、可追溯的 AI 辅助开发。",
      "summaryEn": "**Developer Boris Tane shares his high-efficiency workflow with Claude Code**, centered on strict separation of planning and execution: first generating a detailed research.md through deep codebase analysis, then drafting a plan.md refined over multiple annotation cycles where the human adds inline corrections directly in the document, before finally triggering full implementation. This prevents architectural misalignments and system-breaking changes common in direct AI coding. For the AI programming field, it demonstrates that structured human-AI collaboration outperforms blind automation. Developers can adopt this approach by using Markdown files as shared mutable state for controllable, traceable AI-assisted development.",
      "fullText": "How I Use Claude Code | Boris Tane How I Use Claude Code | Boris Tane boris tane blog talks projects How I Use Claude Code Feb 10, 2026 Â· [ agents sdlc ] Table of Contents Phase 1: Research Phase 2: Planning The Annotation Cycle Phase 3: Implementation Feedback During Implementation Staying in the Driverâs Seat Single Long Sessions The Workflow in One Sentence Iâve been using Claude Code as my primary development tool for approx 9 months, and the workflow Iâve settled into is radically different from what most people do with AI coding tools. Most developers type a prompt, sometimes use plan mode, fix the errors, repeat. The more terminally online are stitching together ralph loops, mcps, gas towns (remember those?), etc. The results in both cases are a mess that completely falls apart for anything non-trivial. The workflow Iâm going to describe has one core principle: never let Claude write code until youâve reviewed and approved a written plan . This separation of planning and execution is the single most important thing I do. It prevents wasted effort, keeps me in control of architecture decisions, and produces significantly better results with minimal token usage than jumping straight to code. flowchart LR R[Research] --> P[Plan] P --> A[Annotate] A -->|repeat 1-6x| A A --> T[Todo List] T --> I[Implement] I --> F[Feedback & Iterate] Phase 1: Research Every meaningful task starts with a deep-read directive. I ask Claude to thoroughly understand the relevant part of the codebase before doing anything else. And I always require the findings to be written into a persistent markdown file, never just a verbal summary in the chat. read this folder in depth, understand how it works deeply, what it does and all its specificities. when thatâs done, write a detailed report of your learnings and findings in research.md study the notification system in great details, understand the intricacies of it and write a detailed research.md document with everything there is to know about how notifications work go through the task scheduling flow, understand it deeply and look for potential bugs. there definitely are bugs in the system as it sometimes runs tasks that should have been cancelled. keep researching the flow until you find all the bugs, donât stop until all the bugs are found. when youâre done, write a detailed report of your findings in research.md Notice the language: âdeeplyâ , âin great detailsâ , âintricaciesâ , âgo through everythingâ . This isnât fluff. Without these words, Claude will skim. Itâll read a file, see what a function does at the signature level, and move on. You need to signal that surface-level reading is not acceptable. The written artifact ( research.md ) is critical. Itâs not about making Claude do homework. Itâs my review surface. I can read it, verify Claude actually understood the system, and correct misunderstandings before any planning happens. If the research is wrong, the plan will be wrong, and the implementation will be wrong. Garbage in, garbage out. This is the most expensive failure mode with AI-assisted coding, and itâs not wrong syntax or bad logic. Itâs implementations that work in isolation but break the surrounding system. A function that ignores an existing caching layer. A migration that doesnât account for the ORMâs conventions. An API endpoint that duplicates logic that already exists elsewhere. The research phase prevents all of this. Phase 2: Planning Once Iâve reviewed the research, I ask for a detailed implementation plan in a separate markdown file. I want to build a new feature <name and description> that extends the system to perform <business outcome>. write a detailed plan.md document outlining how to implement this. include code snippets the list endpoint should support cursor-based pagination instead of offset. write a detailed plan.md for how to achieve this. read source files before suggesting changes, base the plan on the actual codebase The generated plan always includes a detailed explanation of the approach, code snippets showing the actual changes, file paths that will be modified, and considerations and trade-offs. I use my own .md plan files rather than Claude Codeâs built-in plan mode. The built-in plan mode sucks. My markdown file gives me full control. I can edit it in my editor, add inline notes, and it persists as a real artifact in the project. One trick I use constantly: for well-contained features where Iâve seen a good implementation in an open source repo, Iâll share that code as a reference alongside the plan request. If I want to add sortable IDs, I paste the ID generation code from a project that does it well and say âthis is how they do sortable IDs, write a plan.md explaining how we can adopt a similar approach.â Claude works dramatically better when it has a concrete reference implementation to work from rather than designing from scratch. But the plan document itself isnât the interesting part. The interesting part is what happens next. The Annotation Cycle This is the most distinctive part of my workflow, and the part where I add the most value. flowchart TD W[Claude writes plan.md] --> R[I review in my editor] R --> N[I add inline notes] N --> S[Send Claude back to the document] S --> U[Claude updates plan] U --> D{Satisfied?} D -->|No| R D -->|Yes| T[Request todo list] After Claude writes the plan, I open it in my editor and add inline notes directly into the document . These notes correct assumptions, reject approaches, add constraints, or provide domain knowledge that Claude doesnât have. The notes vary wildly in length. Sometimes a note is two words: ânot optionalâ next to a parameter Claude marked as optional. Other times itâs a paragraph explaining a business constraint or pasting a code snippet showing the data shape I expect. Some real examples of notes Iâd add: âuse drizzle:generate for migrations, not raw SQLâ â domain knowledge Claude doesnât have âno â this should be a PATCH, not a PUTâ â correcting a wrong assumption âremove this section entirely, we donât need caching hereâ â rejecting a proposed approach âthe queue consumer already handles retries, so this retry logic is redundant. remove it and just let it failâ â explaining why something should change âthis is wrong, the visibility field needs to be on the list itself, not on individual items. when a list is public, all items are public. restructure the schema section accordinglyâ â redirecting an entire section of the plan Then I send Claude back to the document: I added a few notes to the document, address all the notes and update the document accordingly. donât implement yet This cycle repeats 1 to 6 times. The explicit âdonât implement yetâ guard is essential. Without it, Claude will jump to code the moment it thinks the plan is good enough. Itâs not good enough until I say it is. Why This Works So Well The markdown file acts as shared mutable state between me and Claude. I can think at my own pace, annotate precisely where something is wrong, and re-engage without losing context. Iâm not trying to explain everything in a chat message. Iâm pointing at the exact spot in the document where the issue is and writing my correction right there. This is fundamentally different from trying to steer implementation through chat messages. The plan is a structured, complete specification I can review holistically. A chat conversation is something Iâd have to scroll through to reconstruct decisions. The plan wins every time. Three rounds of âI added notes, update the planâ can transform a generic implementation plan into one that fits perfectly into the existing system. Claude is excellent at understanding code, proposing solutions, and writing implementations. But it doesnât know my product priorities, my usersâ pain points, or the engineering trade-offs Iâm willing to make. The annotation cycle is how I inject that judgement. The Todo List Before implementation starts, I always request a granular task breakdown: add a detailed todo list to the plan, with all the phases and individual tasks necessary to complete the plan - donât implement yet This creates a checklist that serves as a progress tracker during implementation. Claude marks items as completed as it goes, so I can glance at the plan at any point and see exactly where things stand. Especially valuable in sessions that run for hours. Phase 3: Implementation When the plan is ready, I issue the implementation command. Iâve refined this into a standard prompt I reuse across sessions: implement it all. when youâre done with a task or phase, mark it as completed in the plan document. do not stop until all tasks and phases are completed. do not add unnecessary comments or jsdocs, do not use any or unknown types. continuously run typecheck to make sure youâre not introducing new issues. This single prompt encodes everything that matters: âimplement it allâ : do everything in the plan, donât cherry-pick âmark it as completed in the plan documentâ : the plan is the source of truth for progress âdo not stop until all tasks and phases are completedâ : donât pause for confirmation mid-flow âdo not add unnecessary comments or jsdocsâ : keep the code clean âdo not use any or unknown typesâ : maintain strict typing âcontinuously run typecheckâ : catch problems early, not at the end I use this exact phrasing (with minor variations) in virtually every implementation session. By the time I say âimplement it all,â every decision has been made and validated. The implementation becomes mechanical, not creative. This is deliberate. I want implementation to be boring . The creative work happened in the annotation cycles. Once the plan is right, execution should be straightforward. Without the planning phase, what typically happens is Claude makes a reasonable-but-wrong assumption early on, builds on top of it for 15 minutes, and then I have to unwind a chain of changes. The âdonât implement yetâ guard eliminates this entirely. Feedback During Implementation Once Claude is executing the plan, my role shifts from architect to supervisor. My prompts become dramatically shorter. flowchart LR I[Claude implements] --> R[I review / test] R --> C{Correct?} C -->|No| F[Terse correction] F --> I C -->|Yes| N{More tasks?} N -->|Yes| I N -->|No| D[Done] Where a planning note might be a paragraph, an implementation correction is often a single sentence: âYou didnât implement the deduplicateByTitle function.â âYou built the settings page in the main app when it should be in the admin app, move it.â Claude has the full context of the plan and the ongoing session, so terse corrections are enough. Frontend work is the most iterative part. I test in the browser and fire off rapid corrections: âwiderâ âstill croppedâ âthereâs a 2px gapâ For visual issues, I sometimes attach screenshots. A screenshot of a misaligned table communicates the problem faster than describing it. I also reference existing code constantly: âthis table should look exactly like the users table, same header, same pagination, same row density.â This is far more precise than describing a design from scratch. Most features in a mature codebase are variations on existing patterns. A new settings page should look like the existing settings pages. Pointing to the reference communicates all the implicit requirements without spelling them out. Claude would typically read the reference file(s) before making the correction. When something goes in a wrong direction, I donât try to patch it. I revert and re-scope by discarding the git changes: âI reverted everything. Now all I want is to make the list view more minimal â nothing else.â Narrowing scope after a revert almost always produces better results than trying to incrementally fix a bad appr",
      "imageUrl": "https://boristane.com/assets/blog/how-i-use-claude-code/og.png",
      "tags": [
        "LLM"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：提出AI编程中规划与执行分离的系统性工作流，对开发者实践有显著影响，属实用型创新，但未触及行业范式变革。",
        "热度：865 / 评论 548"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-22T00:29:05+00:00",
      "authors": [
        "vinhnx"
      ]
    },
    {
      "id": "github_abhigyanpatwari_GitNexus",
      "title": "GitNexus：浏览器内运行的零服务器代码知识图谱工具",
      "titleZh": "GitNexus：浏览器内运行的零服务器代码知识图谱工具",
      "titleEn": "GitNexus: Zero-Server Code Intelligence Engine Runs Entirely in Browser",
      "url": "https://github.com/abhigyanpatwari/GitNexus",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**GitNexus 是一个零服务器代码智能引擎**，完全在浏览器中运行，用户只需拖入 GitHub 仓库或 ZIP 文件，即可自动生成交互式知识图谱并内置 Graph RAG 智能体；其重要性在于无需后端即可实现本地化代码理解；对 AI 领域而言，它展示了客户端知识图谱与检索增强生成（RAG）结合的轻量化路径；普通开发者可立即用于探索陌生代码库，快速掌握模块关系与调用逻辑，尤其适合离线或隐私敏感场景。",
      "summaryZh": "**GitNexus 是一个零服务器代码智能引擎**，完全在浏览器中运行，用户只需拖入 GitHub 仓库或 ZIP 文件，即可自动生成交互式知识图谱并内置 Graph RAG 智能体；其重要性在于无需后端即可实现本地化代码理解；对 AI 领域而言，它展示了客户端知识图谱与检索增强生成（RAG）结合的轻量化路径；普通开发者可立即用于探索陌生代码库，快速掌握模块关系与调用逻辑，尤其适合离线或隐私敏感场景。",
      "summaryEn": "**GitNexus is a zero-server code intelligence engine** that runs entirely in the browser: users drop in a GitHub repo or ZIP file and instantly get an interactive knowledge graph with a built-in Graph RAG agent. Its significance lies in enabling fully client-side code understanding without backend infrastructure. For the AI field, it demonstrates a lightweight path to combining knowledge graphs with retrieval-augmented generation (RAG). Developers can immediately use it to explore unfamiliar codebases, grasp module relationships and call flows—ideal for offline or privacy-sensitive scenarios.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/d7269b5304f6f39fdb45dfb13c9fab0dd1a49293ff9451ad22f5245d6a0a9ffb/abhigyanpatwari/GitNexus",
      "tags": [
        "Agent",
        "RAG",
        "Open Source"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：浏览器端代码知识图谱引擎，提升本地化代码理解效率，是AI辅助开发的重要补充，具实用价值。",
        "热度：1471 / 评论 0"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-22T23:34:15.549364+00:00",
      "authors": []
    },
    {
      "id": "github_OpenBB-finance_OpenBB",
      "title": "OpenBB 推出面向 AI 智能体的开源金融数据平台",
      "titleZh": "OpenBB 推出面向 AI 智能体的开源金融数据平台",
      "titleEn": "OpenBB Launches Open-Source Financial Data Platform for AI Agents",
      "url": "https://github.com/OpenBB-finance/OpenBB",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**OpenBB 推出面向分析师、量化交易员和 AI 智能体的金融数据平台**，整合多源市场数据、分析工具与 API 接口；其重要性在于为金融 AI 应用提供标准化数据底座；对 AI 领域而言，它降低了金融智能体的数据获取与处理门槛；普通投资者或开发者可通过其开源框架接入实时行情、基本面数据及技术指标，构建自动化策略或研究模型，无需依赖昂贵商业终端。",
      "summaryZh": "**OpenBB 推出面向分析师、量化交易员和 AI 智能体的金融数据平台**，整合多源市场数据、分析工具与 API 接口；其重要性在于为金融 AI 应用提供标准化数据底座；对 AI 领域而言，它降低了金融智能体的数据获取与处理门槛；普通投资者或开发者可通过其开源框架接入实时行情、基本面数据及技术指标，构建自动化策略或研究模型，无需依赖昂贵商业终端。",
      "summaryEn": "**OpenBB has launched a financial data platform** tailored for analysts, quants, and AI agents, integrating multi-source market data, analytical tools, and APIs. Its significance lies in providing a standardized data foundation for financial AI applications. For the AI community, it lowers the barrier to accessing and processing financial data. Individual investors and developers can leverage its open-source framework to access real-time quotes, fundamentals, and technical indicators—enabling automated strategies or research models without costly commercial terminals.",
      "fullText": "",
      "imageUrl": "https://repository-images.githubusercontent.com/323048702/4659bbdb-ae11-4f51-8a16-860fa9dfc551",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：6/10，理由：面向金融分析的开源数据平台，具行业应用潜力，但尚未形成广泛影响力或技术颠覆。",
        "热度：60968 / 评论 0"
      ],
      "score": 6.6,
      "publishedAt": "2026-02-22T23:34:12.922690+00:00",
      "authors": []
    },
    {
      "id": "rss_9061857003",
      "title": "三星Galaxy S26将支持Perplexity，打造多AI代理生态",
      "titleZh": "三星Galaxy S26将支持Perplexity，打造多AI代理生态",
      "titleEn": "Samsung Adds Perplexity to Galaxy AI for Multi-Agent Ecosystem on Galaxy S26",
      "url": "https://www.theverge.com/tech/882921/samsung-is-adding-perplexity-to-galaxy-ai",
      "type": "news",
      "source": "The Verge AI",
      "summary": "三星将在Galaxy S26中集成Perplexity AI，用户可通过唤醒词“hey, Plex”调用该助手，使其成为Galaxy AI多智能体生态系统的一部分；这一举措标志着三星正推动操作系统支持多个AI代理协同工作，Perplexity将能访问Samsung Notes、日历、相册等原生应用及部分第三方应用，反映出厂商对用户偏好多样化AI助手的重视，普通用户未来可在同一设备上根据任务需求灵活切换不同AI，从而获得更个性化的智能体验。",
      "summaryZh": "三星将在Galaxy S26中集成Perplexity AI，用户可通过唤醒词“hey, Plex”调用该助手，使其成为Galaxy AI多智能体生态系统的一部分；这一举措标志着三星正推动操作系统支持多个AI代理协同工作，Perplexity将能访问Samsung Notes、日历、相册等原生应用及部分第三方应用，反映出厂商对用户偏好多样化AI助手的重视，普通用户未来可在同一设备上根据任务需求灵活切换不同AI，从而获得更个性化的智能体验。",
      "summaryEn": "Samsung is integrating Perplexity into Galaxy AI on the upcoming Galaxy S26, allowing users to activate it with the voice command “hey, Plex.” This move forms part of Samsung’s broader “multi-agent ecosystem” strategy, enabling different AI assistants—like Bixby, Gemini, and now Perplexity—to coexist within the OS. Perplexity will gain access to native Samsung apps such as Notes, Calendar, Gallery, Clock, and Reminders, as well as select third-party applications. By supporting multiple specialized AI agents, Samsung aims to differentiate itself from competitors like Apple and Google, offering users greater flexibility to choose their preferred AI for specific tasks—a shift that could reshape how consumers interact with smartphones through personalized, agent-driven interfaces.",
      "fullText": "Samsung is adding Perplexity to Galaxy AI | The Verge Skip to main content The homepage The Verge The Verge logo. The Verge The Verge logo. Tech Reviews Science Entertainment AI Policy Hamburger Navigation Button The homepage The Verge The Verge logo. Hamburger Navigation Button Navigation Drawer The Verge The Verge logo. Login / Sign Up close Close Search Tech Expand Amazon Apple Facebook Google Microsoft Samsung Business See all tech Reviews Expand Smart Home Reviews Phone Reviews Tablet Reviews Headphone Reviews See all reviews Science Expand Space Energy Environment Health See all science Entertainment Expand TV Shows Movies Audio See all entertainment AI Expand OpenAI Anthropic See all AI Policy Expand Antitrust Politics Law Security See all policy Gadgets Expand Laptops Phones TVs Headphones Speakers Wearables See all gadgets Verge Shopping Expand Buying Guides Deals Gift Guides See all shopping Gaming Expand Xbox PlayStation Nintendo See all gaming Streaming Expand Disney HBO Netflix YouTube Creators See all streaming Transportation Expand Electric Cars Autonomous Cars Ride-sharing Scooters See all transportation Features Verge Video Expand TikTok YouTube Instagram Podcasts Expand Decoder The Vergecast Version History Newsletters Archives Store Verge Product Updates Subscribe Facebook Threads Instagram Youtube RSS The Verge The Verge logo. Samsung is adding Perplexity to Galaxy AI Comments Drawer Comments Loading comments Getting the conversation ready... Tech Close Tech Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Tech AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI News Close News Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All News Samsung is adding Perplexity to Galaxy AI The company is betting big on a multi-agent AI ecosystem. The company is betting big on a multi-agent AI ecosystem. by Terrence O'Brien Close Terrence O'Brien Weekend Editor Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Terrence O'Brien Feb 22, 2026, 10:15 PM UTC Link Share Gift I wish I could talk to my Plex server… Image: Samsung. Terrence O'Brien Close Terrence O'Brien Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Terrence O'Brien is the Verge’s weekend editor. He has over 18 years of experience, including 10 years as managing editor at Engadget. In addition to summoning Bixby or Gemini , Galaxy S26 users will be able to call on Perplexity by saying “ hey, Plex .” The integration of Perplexity into Galaxy AI is just one element of the company’s embrace of a “multi-agent ecosystem.” Often, people will use different AI agents for different tasks, depending on where their strengths lie. So Samsung is opening up the ability to integrate different agents into the OS. Hey, Plex isn’t just some transparent version of the app baked into a Galaxy phone to quickly get answers to questions. Perplexity will have access to Samsung Notes, Clock, Gallery, Reminder, and Calendar, as well as select third-party apps, though which ones specifically Samsung didn’t say. Samsung seems to believe that people will increasingly use AI to interact with their phones. But, as we’ve learned, people can develop strong attachments to particular AIs. So the company is betting that giving people the freedom to put whatever agent they want at the heart of their phone will help differentiate them from competition like Apple and Google. Of course, Samsung’s next Unpacked event is just around the corner. I’m sure we’ll hear more about Galaxy AI and Samsung’s vision for a multi-agent future on the 25th . Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Terrence O'Brien Close Terrence O'Brien Weekend Editor Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Terrence O'Brien AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI News Close News Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All News Samsung Close Samsung Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Samsung Tech Close Tech Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Tech Most Popular Most Popular Anker’s X1 Pro shouldn’t exist, but I’m so glad it does Georgia says Elon Musk’s America PAC violated election law Stellantis is in a crisis of its own making Trump says Netflix will ‘pay the consequences’ if it doesn’t fire Susan Rice Turtle Beach’s new PC controller with swiveling sticks is 30 percent off The Verge Daily A free daily digest of the news that matters most. Email (required) Sign Up By submitting your email, you agree to our Terms and Privacy Notice . This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Advertiser Content From This is the title for the native ad More in Tech Retro camera shootout: Camp Snap Pro vs. Flashback One35 V2 Arturia’s FX Collection 6 adds two new effects and a $99 intro version Georgia says Elon Musk’s America PAC violated election law The Pixel 10A and Soundcore Space One are just two of the best deals this week 8 Verge Score Anker’s X1 Pro shouldn’t exist, but I’m so glad it does The best e-reader to buy right now Retro camera shootout: Camp Snap Pro vs. Flashback One35 V2 Antonio G. Di Benedetto 1:00 PM UTC Arturia’s FX Collection 6 adds two new effects and a $99 intro version Terrence O'Brien Feb 21 Georgia says Elon Musk’s America PAC violated election law Terrence O'Brien Feb 21 The Pixel 10A and Soundcore Space One are just two of the best deals this week Brandon Widder Feb 21 Anker’s X1 Pro shouldn’t exist, but I’m so glad it does Thomas Ricker Feb 21 The best e-reader to buy right now Sheena Vasani Feb 20 Advertiser Content From This is the title for the native ad Top Stories 1:00 PM UTC America desperately needs new privacy laws 2:03 PM UTC This magazine plays Tetris — here’s how Two hours ago You need to listen to Laurie Spiegel’s masterpiece of early ambient music Feb 21 Anker’s X1 Pro shouldn’t exist, but I’m so glad it does 1:00 PM UTC Retro camera shootout: Camp Snap Pro vs. Flashback One35 V2 Feb 20 Will Stancil is agitating in Minneapolis The Verge The Verge logo. Facebook Threads Instagram Youtube RSS Contact Tip Us Community Guidelines Archives About Ethics Statement How We Rate and Review Products Cookie Settings Terms of Use Privacy Notice Cookie Policy Licensing FAQ Accessibility Platform Status © 2026 Vox Media , LLC. All Rights Reserved",
      "imageUrl": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Samsung-Mobile-Galaxy-AI-Perplexity-AI-Agent-Expansion-of-Galaxy-AI_main1.jpg?quality=90&strip=all&crop=0,3.5026456994597,100,92.994708601081",
      "tags": [
        "LLM",
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：The Verge AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：三星将Perplexity纳入Galaxy AI，标志消费电子巨头构建多代理生态系统，预示终端AI融合新范式。",
        "热度：0 / 评论 0"
      ],
      "score": 5.4,
      "publishedAt": "2026-02-22T22:15:30+00:00",
      "authors": [
        "Terrence O’Brien"
      ]
    }
  ],
  "stats": {
    "total_papers_ingested": 258,
    "total_news_ingested": 9,
    "l1_papers_passed": 121,
    "l1_news_passed": 9,
    "l2_papers_scored": 50,
    "l2_news_scored": 7,
    "l3_papers_selected": 18,
    "l3_news_selected": 7,
    "news_source_counts": {
      "GitHub Trending": 6,
      "Hacker News": 1,
      "The Verge AI": 1,
      "TechCrunch AI": 1
    },
    "rss_source_counts": {
      "The Verge AI": 1,
      "TechCrunch AI": 1
    },
    "news_title_source_counts": {
      "how i use claude code separation of planning and execution": 1,
      "vxcontrol pentagi": 1,
      "anthropics claude code": 1,
      "x1xhlol system prompts and models of ai tools": 1,
      "openbb finance openbb": 1,
      "cloudflare agents": 1,
      "abhigyanpatwari gitnexus": 1,
      "samsung is adding perplexity to galaxy ai": 1,
      "6 days left to lock in the lowest techcrunch disrupt 2026 rates": 1
    },
    "total_papers_deduped": 258,
    "total_news_deduped": 9,
    "news_recent_filtered": 9
  }
}