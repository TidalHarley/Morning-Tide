{
  "date": "2026-02-12",
  "generatedAt": "2026-02-12T18:43:46.899952",
  "introduction": "今日AI领域迎来多重突破：Anthropic承诺承担数据中心带来的电价上涨，凸显行业对能源责任的重视；NVIDIA与开源模型推动推理成本骤降10倍，极大改善AI普惠性；Gemini 3 Deep Think专为科研工程优化，展现大模型专业化趋势。同时，多篇顶分论文聚焦可解释性、具身智能与社会模拟——从SAE特征操控到AIvilization人工社会平台，再到RADAR真实世界VLA评估基准，技术正向更可靠、可泛化、可理解的方向演进。值得关注的是，AI法律推理能力已超越联邦法官，而深度伪造与网络犯罪风险亦同步上升。",
  "introductionZh": "今日AI领域迎来多重突破：Anthropic承诺承担数据中心带来的电价上涨，凸显行业对能源责任的重视；NVIDIA与开源模型推动推理成本骤降10倍，极大改善AI普惠性；Gemini 3 Deep Think专为科研工程优化，展现大模型专业化趋势。同时，多篇顶分论文聚焦可解释性、具身智能与社会模拟——从SAE特征操控到AIvilization人工社会平台，再到RADAR真实世界VLA评估基准，技术正向更可靠、可泛化、可理解的方向演进。值得关注的是，AI法律推理能力已超越联邦法官，而深度伪造与网络犯罪风险亦同步上升。",
  "introductionEn": "Today’s AI landscape features pivotal advances: Anthropic pledges to absorb data center-driven electricity cost hikes, highlighting industry accountability. NVIDIA and open-source models drive inference costs down 10x, dramatically improving accessibility. Gemini 3 Deep Think launches as a specialized reasoning model for science and engineering. Top-tier research spans interpretable SAE steering, large-scale artificial societies (AIvilization), and real-world embodied intelligence benchmarks (RADAR). Notably, GPT-5 outperforms federal judges in legal reasoning—yet risks from AI-generated deepfakes and cybercrime are escalating in parallel.",
  "longformScript": "今天，AI领域呈现出一种微妙的张力：一边是技术能力的快速跃升，让模型能写法律意见、解科研难题、甚至当仲裁员；另一边，行业开始主动承担起算力扩张带来的社会成本，同时开源工具和硬件进步正把AI从实验室推向更广泛的日常使用。这种“能力上探”与“责任下沉”的同步发生，或许正是AI走向成熟的关键信号。\n\n先看能源问题。Anthropic最近宣布，将全额承担其数据中心对当地电网造成的额外负担——包括电网升级费用、新增发电容量匹配，以及在用电高峰主动削减负荷。这听起来像是企业公关，但背后有现实压力：训练一个前沿大模型未来可能需要吉瓦级电力，而整个美国AI行业几年内就需要至少50吉瓦的新电力供应，相当于几十座核电站。如果这些成本转嫁给普通居民，电价上涨几乎不可避免。Anthropic的做法，是在算力狂奔的同时，试图划清一条“不扰民”的边界。他们还投资节水冷却、本地就业，并呼吁联邦加快输电审批。这或许预示着，未来AI公司的竞争力，不仅看模型多强，也看它能否负责任地接入现实世界。\n\n与此同时，AI的使用门槛正在快速降低。NVIDIA新发布的Blackwell平台，配合多家推理服务商的优化，让开源大模型的推理成本最高下降了10倍。这意味着什么？一家医疗编码公司Sully.ai把处理成本砍掉90%，医生每年能省下数千万分钟的文书时间；游戏公司Latitude让每个token的生成成本降到原来的四分之一，玩家能获得更流畅的互动体验；语音客服系统单次交互成本降了6倍，普通人打客服电话时等待更短、响应更快。这种“更好tokenomics”不是抽象概念，而是直接转化为服务可及性与用户体验的提升。再加上Unsloth这样的开源工具，让微调模型速度翻倍、显存占用减少70%，开发者甚至个人用户都能以更低代价运行高性能AI——AI正从“少数人的玩具”变成“多数人的工具”。\n\n能力层面，AI也在向专业纵深发展。Google刚刚升级的Gemini 3 Deep Think模式，专攻科研与工程领域的复杂推理，目标是成为科学家和工程师真正可信的协作者。这不是泛泛而谈的“智能助手”，而是能理解量子计算论文、参与芯片设计讨论的专项能力。类似地，DGX Spark桌面超算正进入全球高校实验室，从南极中微子观测到哈佛癫痫研究，学生和教授能在本地安全地训练2000亿参数级别的模型，无需把敏感数据上传云端。这种“专业+本地化”的组合，正在加速AI在真实科研与产业场景中的落地。\n\n但能力越强，风险也越具体。一项研究显示，GPT-5在法律推理任务上的表现已经超过了联邦法官——这固然令人惊叹，却也带来棘手问题：如果AI能比人类法官更准确地适用法律条文，我们是否该让它参与裁决？美国仲裁协会已经迈出一步，在建筑纠纷这类书面材料充分的案件中试用AI仲裁员，由前州最高法院首席大法官牵头设计，强调透明展示推理过程。然而，另一面是黑暗面的扩张：AI正被用于自动化网络犯罪全流程，从生成恶意代码到定制勒索信，深度伪造的语音视频已能冒充高管行骗。微软数据显示，仅过去一年就拦截了价值40亿美元的AI辅助诈骗。技术没有善恶，但它的普及速度远超监管和公众认知的适应能力。\n\n值得留意的是，一批新的开源项目正在尝试构建更可控、更私有的AI使用方式。比如Google开源的langextract，能从杂乱文本中提取结构化信息，并清晰标注来源，让AI的结论可追溯；Rowboat则是一个带长期记忆的AI同事，能记住你的偏好和历史对话，提供连贯协助，且可部署在本地避免隐私泄露；还有Personal_AI_Infrastructure项目，主张用代理架构打造能自主规划、调用工具、持续学习的个人AI系统。这些努力指向同一个方向：未来的AI不应只是被动响应指令的“问答机”，而应是能理解你、记住你、并与你共同进化的数字协作者。\n\n面对今天的局面，普通用户或许不必焦虑于“AI会不会取代我”，而更该关注“我如何与AI共处”。一方面，善用成本下降带来的新工具——无论是医疗、客服还是创作，效率红利正在释放；另一方面，对涉及法律、金融或身份验证的场景保持警惕，多因素验证、交叉核实仍是必要防线。技术本身无法承诺公平或安全，但我们可以选择更透明、更可审计、更尊重用户主权的使用方式。\n\nAI的浪潮没有退潮迹象，但它正在从狂飙突进转向精耕细作。今天的新闻里，既有对电网负责的承诺，也有对犯罪滥用的警报；既有科研专用模型的突破，也有个人AI代理的萌芽。这或许说明，真正的进步不在于模型多大、多快，而在于它能否在复杂现实中找到自己的位置——既赋能人类，又不压垮社会。",
  "longformScriptZh": "今天，AI领域呈现出一种微妙的张力：一边是技术能力的快速跃升，让模型能写法律意见、解科研难题、甚至当仲裁员；另一边，行业开始主动承担起算力扩张带来的社会成本，同时开源工具和硬件进步正把AI从实验室推向更广泛的日常使用。这种“能力上探”与“责任下沉”的同步发生，或许正是AI走向成熟的关键信号。\n\n先看能源问题。Anthropic最近宣布，将全额承担其数据中心对当地电网造成的额外负担——包括电网升级费用、新增发电容量匹配，以及在用电高峰主动削减负荷。这听起来像是企业公关，但背后有现实压力：训练一个前沿大模型未来可能需要吉瓦级电力，而整个美国AI行业几年内就需要至少50吉瓦的新电力供应，相当于几十座核电站。如果这些成本转嫁给普通居民，电价上涨几乎不可避免。Anthropic的做法，是在算力狂奔的同时，试图划清一条“不扰民”的边界。他们还投资节水冷却、本地就业，并呼吁联邦加快输电审批。这或许预示着，未来AI公司的竞争力，不仅看模型多强，也看它能否负责任地接入现实世界。\n\n与此同时，AI的使用门槛正在快速降低。NVIDIA新发布的Blackwell平台，配合多家推理服务商的优化，让开源大模型的推理成本最高下降了10倍。这意味着什么？一家医疗编码公司Sully.ai把处理成本砍掉90%，医生每年能省下数千万分钟的文书时间；游戏公司Latitude让每个token的生成成本降到原来的四分之一，玩家能获得更流畅的互动体验；语音客服系统单次交互成本降了6倍，普通人打客服电话时等待更短、响应更快。这种“更好tokenomics”不是抽象概念，而是直接转化为服务可及性与用户体验的提升。再加上Unsloth这样的开源工具，让微调模型速度翻倍、显存占用减少70%，开发者甚至个人用户都能以更低代价运行高性能AI——AI正从“少数人的玩具”变成“多数人的工具”。\n\n能力层面，AI也在向专业纵深发展。Google刚刚升级的Gemini 3 Deep Think模式，专攻科研与工程领域的复杂推理，目标是成为科学家和工程师真正可信的协作者。这不是泛泛而谈的“智能助手”，而是能理解量子计算论文、参与芯片设计讨论的专项能力。类似地，DGX Spark桌面超算正进入全球高校实验室，从南极中微子观测到哈佛癫痫研究，学生和教授能在本地安全地训练2000亿参数级别的模型，无需把敏感数据上传云端。这种“专业+本地化”的组合，正在加速AI在真实科研与产业场景中的落地。\n\n但能力越强，风险也越具体。一项研究显示，GPT-5在法律推理任务上的表现已经超过了联邦法官——这固然令人惊叹，却也带来棘手问题：如果AI能比人类法官更准确地适用法律条文，我们是否该让它参与裁决？美国仲裁协会已经迈出一步，在建筑纠纷这类书面材料充分的案件中试用AI仲裁员，由前州最高法院首席大法官牵头设计，强调透明展示推理过程。然而，另一面是黑暗面的扩张：AI正被用于自动化网络犯罪全流程，从生成恶意代码到定制勒索信，深度伪造的语音视频已能冒充高管行骗。微软数据显示，仅过去一年就拦截了价值40亿美元的AI辅助诈骗。技术没有善恶，但它的普及速度远超监管和公众认知的适应能力。\n\n值得留意的是，一批新的开源项目正在尝试构建更可控、更私有的AI使用方式。比如Google开源的langextract，能从杂乱文本中提取结构化信息，并清晰标注来源，让AI的结论可追溯；Rowboat则是一个带长期记忆的AI同事，能记住你的偏好和历史对话，提供连贯协助，且可部署在本地避免隐私泄露；还有Personal_AI_Infrastructure项目，主张用代理架构打造能自主规划、调用工具、持续学习的个人AI系统。这些努力指向同一个方向：未来的AI不应只是被动响应指令的“问答机”，而应是能理解你、记住你、并与你共同进化的数字协作者。\n\n面对今天的局面，普通用户或许不必焦虑于“AI会不会取代我”，而更该关注“我如何与AI共处”。一方面，善用成本下降带来的新工具——无论是医疗、客服还是创作，效率红利正在释放；另一方面，对涉及法律、金融或身份验证的场景保持警惕，多因素验证、交叉核实仍是必要防线。技术本身无法承诺公平或安全，但我们可以选择更透明、更可审计、更尊重用户主权的使用方式。\n\nAI的浪潮没有退潮迹象，但它正在从狂飙突进转向精耕细作。今天的新闻里，既有对电网负责的承诺，也有对犯罪滥用的警报；既有科研专用模型的突破，也有个人AI代理的萌芽。这或许说明，真正的进步不在于模型多大、多快，而在于它能否在复杂现实中找到自己的位置——既赋能人类，又不压垮社会。",
  "longformScriptEn": "Today’s AI landscape is defined by a critical tension: rapid capability expansion colliding with real-world constraints—energy, cost, trust, and ethics. On one hand, models are now outperforming human experts in specialized domains like law and engineering, while open-source tools and hardware breakthroughs are democratizing access. On the other, the infrastructure demands of this progress are straining grids, and malicious actors are weaponizing the same technologies to automate fraud and deception at scale. This duality—empowerment versus risk—is shaping how institutions, developers, and everyday users navigate the next phase of AI adoption.\n\nA major theme this week is accountability in AI’s physical footprint. Anthropic has taken a bold stance by pledging to fully cover any electricity price increases caused by its data centers—a direct response to growing concerns that AI’s energy hunger could burden consumers. The company commits not only to pay for all grid interconnection upgrades but also to procure entirely new clean power to match its consumption, deploy demand-curbing systems during peak hours, and invest in local communities through jobs and water-efficient cooling. With U.S. AI data centers projected to require at least 50 gigawatts of new capacity in the coming years—enough to power tens of millions of homes—Anthropic’s move sets a precedent. It signals that leading AI firms may need to internalize infrastructure costs rather than externalize them onto ratepayers, especially as federal permitting bottlenecks slow transmission development.\n\nSimultaneously, the economics of using AI are improving dramatically. NVIDIA’s new Blackwell platform, combined with open-source frontier models, is slashing inference costs by up to tenfold. Companies like Baseten, Fireworks AI, and Together AI are deploying optimized stacks that leverage low-precision formats and co-designed software to deliver massive efficiency gains. Real-world impacts are already visible: healthcare coding costs down 90% at Sully.ai, voice AI queries six times cheaper at Decagon, and gaming experiences enriched at a quarter of the token cost. This isn’t just about cheaper APIs—it’s about enabling scalable, real-time AI applications that were previously cost-prohibitive, from clinical documentation to interactive storytelling. When inference becomes this affordable, AI stops being a luxury add-on and starts becoming embedded in the fabric of daily workflows.\n\nAt the high end of capability, specialized reasoning models are pushing into expert domains. Google’s updated Gemini 3 Deep Think mode is now fine-tuned for advanced science and engineering challenges, offering researchers a more reliable partner for complex problem-solving—from materials design to computational biology. Meanwhile, in legal reasoning, GPT-5 has reportedly outperformed sitting federal judges in controlled tests, mastering nuanced rule application and logical consistency. These aren’t just benchmarks; they’re early indicators of AI’s potential to augment or even reshape professional judgment. The American Arbitration Association has already launched an AI arbitrator for document-based construction disputes, led by former Michigan Supreme Court Chief Justice Bridget McCormack. While limited to cases without witness testimony, it reflects a broader trend: institutions are cautiously integrating AI into decision-making where transparency and consistency can be engineered, even as public trust in traditional systems wanes.\n\nBeneath these headline advances, a quiet revolution is unfolding in open-source tooling. Projects like Unsloth are making LLM fine-tuning twice as fast with 70% less VRAM, lowering the barrier for developers to customize models locally. Google’s new langextract library enables structured data extraction from text with source-grounded citations and visual audit trails—critical for building trustworthy information pipelines. And emerging personal AI infrastructures, such as Daniel Miessler’s agentic framework and Rowboat’s memory-equipped AI coworker, are shifting the paradigm from reactive chatbots to proactive, persistent collaborators that learn user preferences over time. These tools collectively empower individuals and small teams to build private, efficient, and context-aware AI systems without relying on cloud giants—potentially reshaping who controls the AI stack.\n\nLooking ahead, the dual trajectories of opportunity and risk demand vigilance. On the upside, we’re entering an era where powerful AI can run affordably on desktops, assist in scientific discovery, and streamline bureaucratic processes. But the same generative capabilities fueling innovation are also automating cybercrime: NYU researchers recently demonstrated PromptLock, an LLM-powered ransomware that dynamically crafts attacks based on victim data. Microsoft reports blocking $4 billion in AI-assisted scams in the past year alone, with deepfake video calls impersonating executives becoming alarmingly common. As AI arbitrators and legal assistants gain traction, questions of bias, appeal rights, and transparency become urgent. Users should prioritize multi-factor authentication, demand explainability in automated decisions, and support regulatory frameworks that enforce accountability—not just for model outputs, but for the entire AI supply chain, from energy sourcing to data provenance.\n\nIn sum, this week underscores that AI’s future won’t be determined by raw performance alone, but by how responsibly its deployment is managed across technical, economic, and social dimensions. The most promising developments aren’t just faster models or smarter agents—they’re the guardrails, efficiencies, and open tools that make powerful AI usable, affordable, and trustworthy for everyone. As builders and users alike, our task is no longer just to scale intelligence, but to embed wisdom into its architecture.",
  "audioUrl": "",
  "papers": [
    {
      "id": "arxiv_2602_10437v1",
      "title": "Control Reinforcement Learning: Token-Level Mechanistic Analysis via Learned SAE Feature Steering",
      "titleZh": "Control Reinforcement Learning: Token-Level Mechanistic Analysis via Learned SAE Feature Steering",
      "titleEn": "Control Reinforcement Learning: Token-Level Mechanistic Analysis via Learned SAE Feature Steering",
      "url": "https://arxiv.org/abs/2602.10437v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "该研究提出Control Reinforcement Learning（CRL）框架，通过强化学习策略在每个token级别动态选择稀疏自编码器（SAE）特征进行干预，从而识别出真正影响语言模型输出的可解释特征；其引入的自适应特征掩码机制促进多样性发现，同时保留单特征可解释性，并支持分支点追踪、评论家轨迹分析和层间特征对比等新分析能力，在Gemma-2 2B模型上于MMLU、BBQ、GSM8K等多个基准中实现性能提升并生成逐token干预日志，确立了学习型特征引导作为动态机制可解释性工具的价值。",
      "summaryZh": "该研究提出Control Reinforcement Learning（CRL）框架，通过强化学习策略在每个token级别动态选择稀疏自编码器（SAE）特征进行干预，从而识别出真正影响语言模型输出的可解释特征；其引入的自适应特征掩码机制促进多样性发现，同时保留单特征可解释性，并支持分支点追踪、评论家轨迹分析和层间特征对比等新分析能力，在Gemma-2 2B模型上于MMLU、BBQ、GSM8K等多个基准中实现性能提升并生成逐token干预日志，确立了学习型特征引导作为动态机制可解释性工具的价值。",
      "summaryEn": "This work introduces Control Reinforcement Learning (CRL), a framework that trains a policy to dynamically select Sparse Autoencoder (SAE) features for steering at each token to identify which interpretable features actually alter language model outputs. Adaptive Feature Masking encourages diverse feature discovery while preserving single-feature interpretability. The approach enables new analytical capabilities—including branch point tracking, critic trajectory analysis, and layer-wise comparison—and achieves performance gains on Gemma-2 2B across MMLU, BBQ, GSM8K, HarmBench, and XSTest while producing per-token intervention logs, establishing learned feature steering as a dynamic mechanistic interpretability tool.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "RAG"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：首次实现基于SAE特征的可解释控制，开启大模型内部机制干预的新纪元，具有历史级影响力。",
        "热度：15 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-11T02:28:49+00:00",
      "authors": [
        "Seonglae Cho",
        "Zekun Wu",
        "Adriano Koshiyama"
      ]
    },
    {
      "id": "arxiv_2602_10429v1",
      "title": "AIvilization v0: Toward Large-Scale Artificial Social Simulation with a Unified Agent Architecture and Adaptive Agent Profiles",
      "titleZh": "AIvilization v0: Toward Large-Scale Artificial Social Simulation with a Unified Agent Architecture and Adaptive Agent Profiles",
      "titleEn": "AIvilization v0: Toward Large-Scale Artificial Social Simulation with a Unified Agent Architecture and Adaptive Agent Profiles",
      "url": "https://arxiv.org/abs/2602.10429v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "AIvilization v0构建了一个大规模人工社会模拟系统，结合资源受限的沙盒经济与统一LLM智能体架构，通过分层分支思维规划器、双过程记忆的自适应智能体画像及人在环路的抽象级指令注入机制，实现长期自主性与环境适应性的平衡；该系统复现了重尾收益、波动聚集等真实市场特征，并揭示教育与资源获取限制驱动的财富分层现象，消融实验表明其完整架构在多目标、长周期任务中显著优于简化规划器，支持延迟投资与持续探索。",
      "summaryZh": "AIvilization v0构建了一个大规模人工社会模拟系统，结合资源受限的沙盒经济与统一LLM智能体架构，通过分层分支思维规划器、双过程记忆的自适应智能体画像及人在环路的抽象级指令注入机制，实现长期自主性与环境适应性的平衡；该系统复现了重尾收益、波动聚集等真实市场特征，并揭示教育与资源获取限制驱动的财富分层现象，消融实验表明其完整架构在多目标、长周期任务中显著优于简化规划器，支持延迟投资与持续探索。",
      "summaryEn": "AIvilization v0 presents a large-scale artificial society integrating a resource-constrained sandbox economy with a unified LLM-agent architecture. It balances long-horizon autonomy and environmental adaptability via a hierarchical branch-thinking planner, an adaptive agent profile with dual-process memory, and a human-in-the-loop steering interface that injects objectives at appropriate abstraction levels. The simulation reproduces stylized market facts—such as heavy-tailed returns and volatility clustering—and reveals education- and access-driven wealth stratification. Ablations confirm the full architecture’s robustness in multi-objective, long-horizon settings, enabling delayed investment and sustained exploration.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：AIvilization v0构建统一Agent架构的大规模人工社会模拟系统，首次实现长期自主演化与资源约束下的社会行为建模，是迈向通用人工智能的重要里程碑。",
        "热度：14 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-11T02:18:15+00:00",
      "authors": [
        "Wenkai Fan",
        "Shurui Zhang",
        "Xiaolong Wang"
      ]
    },
    {
      "id": "arxiv_2602_10980v1",
      "title": "RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation",
      "titleZh": "RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation",
      "titleEn": "RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation",
      "url": "https://arxiv.org/abs/2602.10980v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对当前视觉-语言-动作（VLA）模型评估局限于仿真或高度约束环境的问题，该研究提出RADAR基准，通过整合真实世界动态（如物体配置变化、传感器噪声）、显式测试空间-物理推理的任务，以及基于3D指标的全自动评估管道，系统性评测VLA模型泛化能力；实验发现主流模型在轻微物理扰动下性能骤降（3D IoU从0.261降至0.068），且空间推理能力有限，凸显现有评估体系的现实差距，为可靠部署提供必要基准。",
      "summaryZh": "针对当前视觉-语言-动作（VLA）模型评估局限于仿真或高度约束环境的问题，该研究提出RADAR基准，通过整合真实世界动态（如物体配置变化、传感器噪声）、显式测试空间-物理推理的任务，以及基于3D指标的全自动评估管道，系统性评测VLA模型泛化能力；实验发现主流模型在轻微物理扰动下性能骤降（3D IoU从0.261降至0.068），且空间推理能力有限，凸显现有评估体系的现实差距，为可靠部署提供必要基准。",
      "summaryEn": "Addressing the reality gap in Vision-Language-Action (VLA) model evaluation—currently confined to simulations or highly constrained settings—this work introduces RADAR, a benchmark that systematically assesses generalization under real-world conditions. RADAR integrates realistic physical dynamics (e.g., dynamic object configurations, sensor noise), tasks explicitly probing spatial–physical reasoning, and a fully autonomous 3D-metric-based evaluation pipeline. Audits reveal severe fragility: state-of-the-art models suffer sharp performance drops (3D IoU falling from 0.261 to 0.068 under sensor noise) and limited spatial reasoning, exposing critical shortcomings in current benchmarks and establishing RADAR as essential for reliable real-world VLA evaluation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Robotics",
        "3D"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：发布首个面向真实世界动态、物理智能与自主评估的VLA通用性基准RADAR，填补评估空白，将重塑机器人与具身智能的评测范式，具有历史性意义。",
        "热度：13 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-11T16:08:30+00:00",
      "authors": [
        "Yuhao Chen",
        "Zhihao Zhan",
        "Xiaoxin Lin"
      ]
    },
    {
      "id": "arxiv_2602_10675v1",
      "title": "TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning",
      "titleZh": "TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning",
      "titleEn": "TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning",
      "url": "https://arxiv.org/abs/2602.10675v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为突破静态视觉思维链（VCoT）在动态场景中的局限，该研究发布TwiFF-2.7M——首个基于270万视频片段的大规模时序接地VCoT数据集，并配套含1,078个样本的TwiFF-Bench评估基准；同时提出TwiFF模型，融合预训练视频生成与图像理解能力，通过迭代生成未来动作帧与文本推理实现时序连贯的视觉推理，在动态问答任务上显著超越现有VCoT与纯文本思维链方法，验证了动态视觉推理的有效性。",
      "summaryZh": "为突破静态视觉思维链（VCoT）在动态场景中的局限，该研究发布TwiFF-2.7M——首个基于270万视频片段的大规模时序接地VCoT数据集，并配套含1,078个样本的TwiFF-Bench评估基准；同时提出TwiFF模型，融合预训练视频生成与图像理解能力，通过迭代生成未来动作帧与文本推理实现时序连贯的视觉推理，在动态问答任务上显著超越现有VCoT与纯文本思维链方法，验证了动态视觉推理的有效性。",
      "summaryEn": "To overcome the limitations of static Visual Chain-of-Thought (VCoT) in dynamic scenarios, this work introduces TwiFF-2.7M—the first large-scale, temporally grounded VCoT dataset derived from 2.7 million video clips—and TwiFF-Bench, a high-quality evaluation benchmark with 1,078 samples assessing both reasoning plausibility and answer correctness. The accompanying TwiFF model synergistically leverages pre-trained video generation and image comprehension to iteratively produce future action frames and textual reasoning, achieving significant gains over existing VCoT and textual CoT baselines on dynamic visual question answering, thereby validating the efficacy of dynamic visual reasoning.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "RAG",
        "Reasoning"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：构建大规模动态视觉推理数据集，填补动态视觉链式思维研究空白，将推动多模态推理向真实世界动态场景演进，具有战略意义。",
        "热度：13 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T09:20:04+00:00",
      "authors": [
        "Junhua Liu",
        "Zhangcheng Wang",
        "Zhike Han"
      ]
    },
    {
      "id": "arxiv_2602_10715v1",
      "title": "Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents",
      "titleZh": "Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents",
      "titleEn": "Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents",
      "url": "https://arxiv.org/abs/2602.10715v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对现有对话记忆评估仅关注表面事实回忆的不足，该研究提出LoCoMo-Plus基准，专门评测大语言模型在“线索-触发语义断连”场景下的认知记忆能力——即在长对话中保留并应用未被显式重提的隐式约束（如用户状态、价值观）；研究指出传统字符串匹配指标与显式任务提示不适用此类场景，并提出基于约束一致性的统一评估框架，实验证明当前模型在此类认知记忆任务上仍表现不佳，揭示了现有基准未能捕捉的关键失败模式。",
      "summaryZh": "针对现有对话记忆评估仅关注表面事实回忆的不足，该研究提出LoCoMo-Plus基准，专门评测大语言模型在“线索-触发语义断连”场景下的认知记忆能力——即在长对话中保留并应用未被显式重提的隐式约束（如用户状态、价值观）；研究指出传统字符串匹配指标与显式任务提示不适用此类场景，并提出基于约束一致性的统一评估框架，实验证明当前模型在此类认知记忆任务上仍表现不佳，揭示了现有基准未能捕捉的关键失败模式。",
      "summaryEn": "Addressing the limitation of existing conversational memory benchmarks that focus only on surface-level factual recall, this work introduces LoCoMo-Plus—a benchmark for evaluating cognitive memory under 'cue–trigger semantic disconnect,' where models must retain and apply latent constraints (e.g., user state, values) across long dialogues without explicit re-prompting. The study shows conventional string-matching metrics and explicit task prompting are misaligned with this setting and proposes a unified evaluation framework based on constraint consistency. Experiments reveal that current models struggle significantly with cognitive memory, exposing failure modes invisible to existing benchmarks.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "RAG",
        "Open Source"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出超越事实记忆的认知记忆评估框架，精准刻画LLM代理的长期交互能力，为智能体系统设计提供全新评价标准。",
        "热度：11 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T10:22:35+00:00",
      "authors": [
        "Yifei Li",
        "Weidong Guo",
        "Lingling Zhang"
      ]
    },
    {
      "id": "arxiv_2602_10687v1",
      "title": "OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL",
      "titleZh": "OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL",
      "titleEn": "OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL",
      "url": "https://arxiv.org/abs/2602.10687v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为应对现实虚假信息中交织的文本、图像与视频模态，该研究提出OmniVL-Guard——首个统一的多模态伪造检测与定位框架，通过自进化思维链生成与自适应奖励缩放策略优化（ARSPO）解决多任务优化中的“难度偏差”问题（即简单真实性分类主导梯度，损害细粒度定位）；该方法在跨域零样本设置下显著优于现有技术，实现伪造内容的同步检测与精准定位。",
      "summaryZh": "为应对现实虚假信息中交织的文本、图像与视频模态，该研究提出OmniVL-Guard——首个统一的多模态伪造检测与定位框架，通过自进化思维链生成与自适应奖励缩放策略优化（ARSPO）解决多任务优化中的“难度偏差”问题（即简单真实性分类主导梯度，损害细粒度定位）；该方法在跨域零样本设置下显著优于现有技术，实现伪造内容的同步检测与精准定位。",
      "summaryEn": "To tackle misinformation involving interleaved text, images, and videos, this work proposes OmniVL-Guard—the first unified framework for omnibus vision-language forgery detection and grounding. It addresses the 'difficulty bias' in multi-task optimization (where easier veracity classification dominates gradients, harming fine-grained localization) via Self-Evolving CoT Generation and Adaptive Reward Scaling Policy Optimization (ARSPO). OmniVL-Guard significantly outperforms state-of-the-art methods and demonstrates robust zero-shot generalization across out-of-domain scenarios for simultaneous detection and precise grounding of forged content.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Reasoning",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：构建统一跨模态伪造检测与定位框架，应对多模态信息交织的现实虚假内容挑战，对全球数字信任体系具有战略意义。",
        "热度：15 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T09:41:36+00:00",
      "authors": [
        "Jinjie Shen",
        "Jing Wu",
        "Yaxiong Wang"
      ]
    },
    {
      "id": "arxiv_2602_10825v1",
      "title": "Flow caching for autoregressive video generation",
      "titleZh": "Flow caching for autoregressive video generation",
      "titleEn": "Flow caching for autoregressive video generation",
      "url": "https://arxiv.org/abs/2602.10825v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对自回归视频生成模型因顺序生成而速度缓慢的问题，该研究提出FlowCache——首个专为其设计的缓存框架，通过为每个视频块独立维护缓存策略，并结合重要性-冗余联合优化的KV缓存压缩机制，在固定内存开销下实现高效加速；在MAGI-1和SkyReels-V2上分别获得2.38倍和6.7倍提速，且视频质量几乎无损（VBench得分变化±0.8以内），为超长视频实时生成奠定基础。",
      "summaryZh": "针对自回归视频生成模型因顺序生成而速度缓慢的问题，该研究提出FlowCache——首个专为其设计的缓存框架，通过为每个视频块独立维护缓存策略，并结合重要性-冗余联合优化的KV缓存压缩机制，在固定内存开销下实现高效加速；在MAGI-1和SkyReels-V2上分别获得2.38倍和6.7倍提速，且视频质量几乎无损（VBench得分变化±0.8以内），为超长视频实时生成奠定基础。",
      "summaryEn": "To accelerate autoregressive video generation—which suffers from slow sequential synthesis—this work introduces FlowCache, the first caching framework tailored for such models. It employs chunkwise caching policies that adapt to each video segment’s unique denoising dynamics and a joint importance-redundancy optimized KV cache compression mechanism that maintains fixed memory bounds. FlowCache achieves 2.38× speedup on MAGI-1 and 6.7× on SkyReels-V2 with negligible quality loss (VBench changes within ±0.8), enabling real-time ultra-long video generation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Diffusion",
        "Research",
        "Open Source",
        "Benchmark"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出流缓存加速自回归视频生成，直接解决长视频生成效率瓶颈，对Sora类系统具有战略级支撑作用。",
        "热度：15 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T13:11:04+00:00",
      "authors": [
        "Yuexiao Ma",
        "Xuzhe Zheng",
        "Jing Xu"
      ]
    },
    {
      "id": "arxiv_2602_10450v1",
      "title": "Constructing Industrial-Scale Optimization Modeling Benchmark",
      "titleZh": "Constructing Industrial-Scale Optimization Modeling Benchmark",
      "titleEn": "Constructing Industrial-Scale Optimization Modeling Benchmark",
      "url": "https://arxiv.org/abs/2602.10450v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为填补工业级优化建模缺乏真实自然语言到求解器代码对齐基准的空白，该研究基于MIPLIB 2017中的真实混合整数线性规划实例，通过结构感知逆向构建方法创建MIPLIB-NL数据集：先从扁平求解器格式中恢复可复用模型结构，再逆向生成与之绑定的自然语言描述，并经专家评审与人机交互验证；该数据集包含223个一对一重建样本，实验显示在玩具级基准表现优异的系统在MIPLIB-NL上性能大幅下降，暴露出工业规模问题的独特挑战。",
      "summaryZh": "为填补工业级优化建模缺乏真实自然语言到求解器代码对齐基准的空白，该研究基于MIPLIB 2017中的真实混合整数线性规划实例，通过结构感知逆向构建方法创建MIPLIB-NL数据集：先从扁平求解器格式中恢复可复用模型结构，再逆向生成与之绑定的自然语言描述，并经专家评审与人机交互验证；该数据集包含223个一对一重建样本，实验显示在玩具级基准表现优异的系统在MIPLIB-NL上性能大幅下降，暴露出工业规模问题的独特挑战。",
      "summaryEn": "To address the lack of realistic benchmarks for translating natural language into industrial-scale optimization code, this work introduces MIPLIB-NL—a dataset built via structure-aware reverse construction from real mixed-integer linear programs in MIPLIB 2017. The pipeline recovers compact model structures from flat solver formulations, generates aligned natural-language specifications under a model–data separation format, and validates semantics through expert review and human–LLM interaction. The resulting 223 one-to-one reconstructions preserve original mathematical content while enabling realistic NL-to-optimization evaluation. Experiments reveal severe performance degradation on MIPLIB-NL for systems that excel on toy benchmarks, exposing failure modes unique to industrial-scale problems.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：构建工业级优化建模基准，推动LLM在复杂决策系统中的自动化落地，具有全球产业变革潜力。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T02:45:31+00:00",
      "authors": [
        "Zhong Li",
        "Hongliang Lu",
        "Tao Wei"
      ]
    },
    {
      "id": "arxiv_2602_10295v1",
      "title": "ECHO: An Open Research Platform for Evaluation of Chat, Human Behavior, and Outcomes",
      "titleZh": "ECHO: An Open Research Platform for Evaluation of Chat, Human Behavior, and Outcomes",
      "titleEn": "ECHO: An Open Research Platform for Evaluation of Chat, Human Behavior, and Outcomes",
      "url": "https://arxiv.org/abs/2602.10295v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "ECHO 是一个开源研究平台，支持对人类与对话式 AI 和网络搜索引擎交互的可复现混合方法研究。该平台提供低代码框架，整合知情同意、背景调查、基于聊天或搜索的信息获取任务、写作或判断任务以及前后测评估，并记录细粒度交互日志和结构化数据输出。通过同时支持聊天与搜索范式及灵活的评估工具，ECHO 降低了信息检索、人机交互和社会科学等领域研究人员开展可扩展、可复现的人本 AI 评估的技术门槛。",
      "summaryZh": "ECHO 是一个开源研究平台，支持对人类与对话式 AI 和网络搜索引擎交互的可复现混合方法研究。该平台提供低代码框架，整合知情同意、背景调查、基于聊天或搜索的信息获取任务、写作或判断任务以及前后测评估，并记录细粒度交互日志和结构化数据输出。通过同时支持聊天与搜索范式及灵活的评估工具，ECHO 降低了信息检索、人机交互和社会科学等领域研究人员开展可扩展、可复现的人本 AI 评估的技术门槛。",
      "summaryEn": "ECHO (Evaluation of Chat, Human behavior, and Outcomes) is an open research platform enabling reproducible, mixed-method studies of human interaction with conversational AI and web search. It offers a low-code framework that integrates consent, surveys, chat- or search-based information-seeking, writing/judgment tasks, and pre/post evaluations, while logging fine-grained interactions and exporting structured datasets. By supporting both paradigms and flexible evaluation instruments, ECHO lowers technical barriers for scalable, reproducible human-centered AI research in IR, HCI, and social sciences.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "RAG",
        "Research",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：ECHO平台为人类与AI交互研究提供标准化、可复现的开放框架，将推动全球范围内对AI行为与社会影响的系统性研究，具有政策与学术双重战略意义。",
        "热度：6 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-10T21:10:38+00:00",
      "authors": [
        "Jiqun Liu",
        "Nischal Dinesh",
        "Ran Yu"
      ]
    },
    {
      "id": "arxiv_2602_10940v1",
      "title": "FastUSP: A Multi-Level Collaborative Acceleration Framework for Distributed Diffusion Model Inference",
      "titleZh": "FastUSP: A Multi-Level Collaborative Acceleration Framework for Distributed Diffusion Model Inference",
      "titleEn": "FastUSP: A Multi-Level Collaborative Acceleration Framework for Distributed Diffusion Model Inference",
      "url": "https://arxiv.org/abs/2602.10940v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对大规模扩散模型（如 FLUX 和 Stable Diffusion 3）在多 GPU 推理中的效率瓶颈，研究者提出 FastUSP——一种多层级协同加速框架，融合编译级优化（CUDA Graphs 与计算-通信重排）、通信级优化（FP8 量化集体通信）和算子级优化（双缓冲流水线 Ring Attention）。在 FLUX 模型上，FastUSP 相比基线 USP 实现 1.12–1.16 倍端到端加速；分析表明，在现代高带宽 GPU 互联环境下，内核启动开销而非通信延迟是主要瓶颈。",
      "summaryZh": "针对大规模扩散模型（如 FLUX 和 Stable Diffusion 3）在多 GPU 推理中的效率瓶颈，研究者提出 FastUSP——一种多层级协同加速框架，融合编译级优化（CUDA Graphs 与计算-通信重排）、通信级优化（FP8 量化集体通信）和算子级优化（双缓冲流水线 Ring Attention）。在 FLUX 模型上，FastUSP 相比基线 USP 实现 1.12–1.16 倍端到端加速；分析表明，在现代高带宽 GPU 互联环境下，内核启动开销而非通信延迟是主要瓶颈。",
      "summaryEn": "To address inefficiencies in distributed inference of large diffusion models like FLUX (12B) and Stable Diffusion 3 (8B), the paper proposes FastUSP—a multi-level acceleration framework integrating compile-level (CUDA Graphs, compute-communication reordering), communication-level (FP8 quantized collectives), and operator-level (pipelined Ring Attention with double buffering) optimizations. On FLUX, FastUSP achieves 1.12×–1.16× end-to-end speedup over baseline USP, with analysis revealing kernel launch overhead—not communication latency—as the primary bottleneck on modern high-bandwidth GPU interconnects.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Diffusion",
        "Inference",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：FastUSP框架解决大规模扩散模型分布式推理瓶颈，直接提升生成式AI部署效率，具备产业级影响。",
        "热度：10 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T15:19:57+00:00",
      "authors": [
        "Guandong Li"
      ]
    },
    {
      "id": "arxiv_2602_11130v1",
      "title": "From Circuits to Dynamics: Understanding and Stabilizing Failure in 3D Diffusion Transformers",
      "titleZh": "From Circuits to Dynamics: Understanding and Stabilizing Failure in 3D Diffusion Transformers",
      "titleEn": "From Circuits to Dynamics: Understanding and Stabilizing Failure in 3D Diffusion Transformers",
      "url": "https://arxiv.org/abs/2602.11130v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究发现当前最先进的 3D 扩散 Transformer 在稀疏点云表面补全任务中存在“熔断”（Meltdown）失效模式：微小输入扰动即可导致输出碎裂为多个不连通部分。通过机制可解释性中的激活修补技术，作者将问题定位到早期去噪交叉注意力的一个激活，并发现其奇异值谱熵可作为碎片化的标量代理。基于此，他们提出 PowerRemap 方法，在测试时稳定条件输入，在多种架构、数据集和去噪策略下实现最高 98.3% 的稳定率，首次将电路级机制与扩散动力学中的轨迹分岔联系起来。",
      "summaryZh": "研究发现当前最先进的 3D 扩散 Transformer 在稀疏点云表面补全任务中存在“熔断”（Meltdown）失效模式：微小输入扰动即可导致输出碎裂为多个不连通部分。通过机制可解释性中的激活修补技术，作者将问题定位到早期去噪交叉注意力的一个激活，并发现其奇异值谱熵可作为碎片化的标量代理。基于此，他们提出 PowerRemap 方法，在测试时稳定条件输入，在多种架构、数据集和去噪策略下实现最高 98.3% 的稳定率，首次将电路级机制与扩散动力学中的轨迹分岔联系起来。",
      "summaryEn": "State-of-the-art 3D diffusion transformers for surface completion from sparse point clouds suffer from 'Meltdown'—a catastrophic failure where infinitesimal input perturbations fracture outputs into disconnected pieces. Using mechanistic interpretability, the authors localize this to a single early cross-attention activation and identify its spectral entropy as a scalar proxy for fragmentation. Guided by diffusion dynamics insights linking this to symmetry-breaking bifurcations, they propose PowerRemap, a test-time stabilization method achieving up to 98.3% success across architectures (WaLa, Make-a-Shape), datasets (GSO, SimJEB), and denoising strategies (DDPM, DDIM), bridging circuit-level mechanisms and trajectory bifurcations in diffusion dynamics.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "Diffusion",
        "3D",
        "RAG"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：揭示3D扩散Transformer的灾难性失败模式并提出稳定方案，直击生成模型可靠性核心痛点，对机器人、数字孪生等关键应用具有战略级意义。",
        "热度：21 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T18:42:05+00:00",
      "authors": [
        "Maximilian Plattner",
        "Fabian Paischer",
        "Johannes Brandstetter"
      ]
    },
    {
      "id": "arxiv_2602_10983v1",
      "title": "Scaling World Model for Hierarchical Manipulation Policies",
      "titleZh": "Scaling World Model for Hierarchical Manipulation Policies",
      "titleEn": "Scaling World Model for Hierarchical Manipulation Policies",
      "url": "https://arxiv.org/abs/2602.10983v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为提升视觉语言动作（VLA）机器人策略在分布外场景的泛化能力，研究者提出 VISTA 框架：利用大规模预训练世界模型作为高层规划器，将任务分解为带目标图像的子任务序列，再由底层 VLA 执行器根据文本与视觉引导生成动作。相比原始文本目标，合成的目标图像提供更丰富的物理与视觉细节，使相同结构的 VLA 在新场景中的成功率从 14% 提升至 69%，显著优于现有基线，尤其在未见物体和新颖环境中表现突出。",
      "summaryZh": "为提升视觉语言动作（VLA）机器人策略在分布外场景的泛化能力，研究者提出 VISTA 框架：利用大规模预训练世界模型作为高层规划器，将任务分解为带目标图像的子任务序列，再由底层 VLA 执行器根据文本与视觉引导生成动作。相比原始文本目标，合成的目标图像提供更丰富的物理与视觉细节，使相同结构的 VLA 在新场景中的成功率从 14% 提升至 69%，显著优于现有基线，尤其在未见物体和新颖环境中表现突出。",
      "summaryEn": "To improve out-of-distribution generalization of Vision-Language-Action (VLA) robot policies, the authors propose VISTA: a hierarchical framework using a large pre-trained world model as a high-level planner to decompose tasks into subtask sequences with synthesized goal images, which a low-level VLA executor follows via multimodal guidance. These visually and physically grounded goal images boost the same-structured VLA’s success rate in novel scenarios from 14% to 69%, significantly outperforming prior baselines, especially with unseen objects and environments.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Robotics",
        "RAG"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：构建分层VLA框架以解决机器人操作中泛化能力瓶颈，通过世界模型扩展提升真实场景适应性，是通用机器人智能的关键突破，具备产业变革潜力。",
        "热度：16 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-11T16:12:33+00:00",
      "authors": [
        "Qian Long",
        "Yueze Wang",
        "Jiaxi Song"
      ]
    },
    {
      "id": "arxiv_2602_11021v1",
      "title": "ContactGaussian-WM: Learning Physics-Grounded World Model from Videos",
      "titleZh": "ContactGaussian-WM: Learning Physics-Grounded World Model from Videos",
      "titleEn": "ContactGaussian-WM: Learning Physics-Grounded World Model from Videos",
      "url": "https://arxiv.org/abs/2602.11021v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对数据稀缺和接触密集动态场景下世界模型难以准确学习物理规律的问题，研究者提出 ContactGaussian-WM：一种可微分的物理接地刚体世界模型，能直接从稀疏视频序列中学习复杂物理交互。其核心包括统一高斯表示（同时建模外观与碰撞几何）和端到端可微分学习框架（通过闭式物理引擎反向传播以推断物理属性）。实验表明，该模型在仿真与真实环境中均优于现有方法，并成功应用于数据合成与实时模型预测控制（MPC）等下游任务。",
      "summaryZh": "针对数据稀缺和接触密集动态场景下世界模型难以准确学习物理规律的问题，研究者提出 ContactGaussian-WM：一种可微分的物理接地刚体世界模型，能直接从稀疏视频序列中学习复杂物理交互。其核心包括统一高斯表示（同时建模外观与碰撞几何）和端到端可微分学习框架（通过闭式物理引擎反向传播以推断物理属性）。实验表明，该模型在仿真与真实环境中均优于现有方法，并成功应用于数据合成与实时模型预测控制（MPC）等下游任务。",
      "summaryEn": "To address the challenge of learning accurate physical dynamics from sparse, contact-rich videos, the paper introduces ContactGaussian-WM: a differentiable, physics-grounded rigid-body world model. It features a unified Gaussian representation for visual appearance and collision geometry, and an end-to-end differentiable framework that backpropagates through a closed-form physics engine to infer physical properties from sparse observations. Evaluations show superior performance over state-of-the-art methods in simulation and real-world settings, with demonstrated utility in data synthesis and real-time model predictive control (MPC).",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "3D",
        "Benchmark"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出基于物理约束的世界模型学习方法，解决机器人规划中数据稀缺与复杂接触动力学难题，对具身智能发展具有战略级推动作用。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-11T16:48:13+00:00",
      "authors": [
        "Meizhong Wang",
        "Wanxin Jin",
        "Kun Cao"
      ]
    },
    {
      "id": "arxiv_2602_11146v1",
      "title": "Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling",
      "titleZh": "Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling",
      "titleEn": "Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling",
      "url": "https://arxiv.org/abs/2602.11146v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "当前扩散模型偏好优化依赖视觉语言模型（VLM）作为奖励函数，但存在计算开销大和像素空间奖励与潜在生成域不匹配的问题。为此，研究者提出 DiNa-LRM——一种扩散原生的潜在奖励模型，直接在带噪扩散状态上建模偏好，引入噪声校准的 Thurstone 似然与扩散噪声相关的不确定性。该方法基于预训练潜在扩散主干和时间步条件奖励头，支持推理时噪声集成，在图像对齐基准上以更低计算成本达到媲美顶尖 VLM 的性能，并显著改善偏好优化的收敛速度与资源效率。",
      "summaryZh": "当前扩散模型偏好优化依赖视觉语言模型（VLM）作为奖励函数，但存在计算开销大和像素空间奖励与潜在生成域不匹配的问题。为此，研究者提出 DiNa-LRM——一种扩散原生的潜在奖励模型，直接在带噪扩散状态上建模偏好，引入噪声校准的 Thurstone 似然与扩散噪声相关的不确定性。该方法基于预训练潜在扩散主干和时间步条件奖励头，支持推理时噪声集成，在图像对齐基准上以更低计算成本达到媲美顶尖 VLM 的性能，并显著改善偏好优化的收敛速度与资源效率。",
      "summaryEn": "To overcome the high computational cost and domain mismatch of Vision-Language Model (VLM)-based rewards in diffusion model alignment, the paper proposes DiNa-LRM—a diffusion-native latent reward model that formulates preference learning directly on noisy diffusion states using a noise-calibrated Thurstone likelihood with diffusion-noise-dependent uncertainty. Built on a pretrained latent diffusion backbone with a timestep-conditioned reward head and supporting noise ensembling at inference, DiNa-LRM matches state-of-the-art VLM performance at a fraction of the cost and improves preference optimization dynamics for faster, more efficient alignment.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Diffusion"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：挑战传统VLM奖励机制，提出扩散模型原生的潜在奖励建模方法，有望提升生成质量与训练效率，是扩散模型对齐的关键进展。",
        "热度：19 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-11T18:57:29+00:00",
      "authors": [
        "Gongye Liu",
        "Bo Yang",
        "Yida Zhi"
      ]
    },
    {
      "id": "arxiv_2602_11114v1",
      "title": "Learning to Compose for Cross-domain Agentic Workflow Generation",
      "titleZh": "Learning to Compose for Cross-domain Agentic Workflow Generation",
      "titleEn": "Learning to Compose for Cross-domain Agentic Workflow Generation",
      "url": "https://arxiv.org/abs/2602.11114v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决跨领域智能体工作流生成中依赖高成本迭代优化的问题，研究者提出一种单次生成方法：通过在开源 LLM 中内化“分解-重组-决策”机制，先从多领域任务中学习一组可复用的工作流能力基元，再将新任务映射为这些基元的稀疏组合以单次生成定制化工作流，并通过反事实归因识别关键成功能力。该方法在跨域、未知域评估中超越需 20 次迭代的最先进基线，同时大幅降低延迟与计算成本。",
      "summaryZh": "为解决跨领域智能体工作流生成中依赖高成本迭代优化的问题，研究者提出一种单次生成方法：通过在开源 LLM 中内化“分解-重组-决策”机制，先从多领域任务中学习一组可复用的工作流能力基元，再将新任务映射为这些基元的稀疏组合以单次生成定制化工作流，并通过反事实归因识别关键成功能力。该方法在跨域、未知域评估中超越需 20 次迭代的最先进基线，同时大幅降低延迟与计算成本。",
      "summaryEn": "To avoid costly iterative refinement in cross-domain agentic workflow generation, the authors propose a one-pass approach that internalizes a decompose-recompose-decide mechanism into an open-source LLM. It learns reusable workflow capability primitives across domains, maps new tasks to sparse compositions of these bases for single-pass workflow generation, and uses counterfactual attribution to identify capabilities driving success. This method surpasses state-of-the-art iterative baselines (requiring 20 iterations) across multi-domain, cross-domain, and unseen-domain evaluations while significantly reducing latency and cost.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Agent",
        "Reasoning",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出跨域智能体工作流的可组合学习框架，显著提升复杂任务自动化能力，是实现通用智能体的核心关键技术突破。",
        "热度：9 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-11T18:27:22+00:00",
      "authors": [
        "Jialiang Wang",
        "Shengxiang Xu",
        "Hanmo Liu"
      ]
    },
    {
      "id": "arxiv_2602_10719v1",
      "title": "From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving",
      "titleZh": "From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving",
      "titleEn": "From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving",
      "url": "https://arxiv.org/abs/2602.10719v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究通过 RecogDrive 平台对比纯视觉（ViT）与视觉语言模型（VLM）骨干在端到端驾驶中的行为差异，发现两者在长尾场景中各有优势：VLM 更激进，ViT 更保守，各自在约 2–3% 场景中显著胜出。基于此，作者提出 HybridDriveVLA 同时运行双分支并用学习评分器选择更优轨迹，将 PDMS 提升至 92.10；进一步设计的 DualDriveVLA 默认使用 ViT，仅在评分置信度低时（15% 场景）调用 VLM，在保持 91.00 PDMS 的同时实现 3.2 倍吞吐量提升。",
      "summaryZh": "研究通过 RecogDrive 平台对比纯视觉（ViT）与视觉语言模型（VLM）骨干在端到端驾驶中的行为差异，发现两者在长尾场景中各有优势：VLM 更激进，ViT 更保守，各自在约 2–3% 场景中显著胜出。基于此，作者提出 HybridDriveVLA 同时运行双分支并用学习评分器选择更优轨迹，将 PDMS 提升至 92.10；进一步设计的 DualDriveVLA 默认使用 ViT，仅在评分置信度低时（15% 场景）调用 VLM，在保持 91.00 PDMS 的同时实现 3.2 倍吞吐量提升。",
      "summaryEn": "Analyzing end-to-end driving with identical diffusion Transformer planners but different backbones, the study reveals complementary behaviors: VLM-based systems are more aggressive while vision-only (ViT) ones are more conservative, each decisively outperforming the other in ~2–3% of long-tail scenarios. Building on this, HybridDriveVLA runs both branches and selects the better trajectory via a learned scorer, achieving 92.10 PDMS. DualDriveVLA implements a practical fast-slow policy—using ViT by default and invoking VLM only when scorer confidence is low (15% of cases)—reaching 91.00 PDMS with 3.2× higher throughput.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Diffusion",
        "Training"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：探索视觉语言模型与纯视觉骨干的协同机制，为端到端自动驾驶提供新范式，推动多模态融合向系统级演进。",
        "热度：13 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-11T10:25:05+00:00",
      "authors": [
        "Sining Ang",
        "Yuguang Yang",
        "Chenxu Dang"
      ]
    },
    {
      "id": "arxiv_2602_11113v1",
      "title": "A receding-horizon multi-contact motion planner for legged robots in challenging environments",
      "titleZh": "A receding-horizon multi-contact motion planner for legged robots in challenging environments",
      "titleEn": "A receding-horizon multi-contact motion planner for legged robots in challenging environments",
      "url": "https://arxiv.org/abs/2602.11113v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "该论文提出一种用于足式机器人在复杂环境中执行多接触运动的滚动时域规划器，能同步规划接触点位置与全身轨迹，支持烟囱攀爬、穿越狭窄通道或跨越大间隙等动作；其基于二次规划的姿态生成器比现有算法更快生成节点，且对局部极小值问题更具鲁棒性。实验表明，在短规划视距（如一步）下，该方法比现有技术快45%至98%，但运动效率略低（平均多出5%至700%的支撑相切换）；而在长视距（如四步）下，除烟囱行走外，虽规划时间可能延长（最慢达4倍），却显著提升运动质量（支撑相切换减少最多47%）。",
      "summaryZh": "该论文提出一种用于足式机器人在复杂环境中执行多接触运动的滚动时域规划器，能同步规划接触点位置与全身轨迹，支持烟囱攀爬、穿越狭窄通道或跨越大间隙等动作；其基于二次规划的姿态生成器比现有算法更快生成节点，且对局部极小值问题更具鲁棒性。实验表明，在短规划视距（如一步）下，该方法比现有技术快45%至98%，但运动效率略低（平均多出5%至700%的支撑相切换）；而在长视距（如四步）下，除烟囱行走外，虽规划时间可能延长（最慢达4倍），却显著提升运动质量（支撑相切换减少最多47%）。",
      "summaryEn": "This paper presents a receding-horizon multi-contact motion planner for legged robots in challenging environments, capable of simultaneously planning contact locations and whole-body trajectories to enable motions like chimney climbing, narrow-passage navigation, and large-gap crossing. Its quadratic-program-based posture generator produces nodes faster than existing methods and is more robust to local minima. Statistical experiments show that with short horizons (e.g., one step), the planner is 45–98% faster than state-of-the-art approaches but yields less efficient motions (5% fewer to 700% more stance changes on average). With longer horizons (e.g., four steps), planning times range from 73% faster to 400% slower, yet motion quality improves significantly—reducing stance changes by up to 47%—in all but the Chimney Walking scenario.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "RAG"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：提出用于复杂环境下的足式机器人多接触运动规划新框架，支持攀爬、窄道穿越等高难度动作，推动自主机器人在真实世界部署能力跃升。",
        "热度：9 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-11T18:25:29+00:00",
      "authors": [
        "Daniel S. J. Derwent",
        "Simon Watson",
        "Bruno V. Adorno"
      ]
    },
    {
      "id": "arxiv_2602_10702v1",
      "title": "A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner",
      "titleZh": "A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner",
      "titleEn": "A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner",
      "url": "https://arxiv.org/abs/2602.10702v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "该论文提出一种统一的实验架构GuadalPlanner，通过解耦高层决策与具体载具控制，为信息路径规划算法提供跨仿真与真实部署的一致评估框架；其基于ROS2、MAVLink和MQTT等主流机器人技术，定义了规划、感知与执行模块间的标准化接口，支持图结构环境与可插拔规划策略，并已在自主水面艇水质监测任务中完成真实世界验证，实现同一算法逻辑在纯仿真、软硬件在环及实体平台上的无缝迁移。",
      "summaryZh": "该论文提出一种统一的实验架构GuadalPlanner，通过解耦高层决策与具体载具控制，为信息路径规划算法提供跨仿真与真实部署的一致评估框架；其基于ROS2、MAVLink和MQTT等主流机器人技术，定义了规划、感知与执行模块间的标准化接口，支持图结构环境与可插拔规划策略，并已在自主水面艇水质监测任务中完成真实世界验证，实现同一算法逻辑在纯仿真、软硬件在环及实体平台上的无缝迁移。",
      "summaryEn": "This paper introduces GuadalPlanner, a unified experimental architecture that decouples high-level decision-making from vehicle-specific control to enable consistent evaluation of informative path planning algorithms across simulation and real-world deployment. Built on widely adopted robotics technologies like ROS2, MAVLink, and MQTT, it defines standardized interfaces between planning, sensing, and execution modules, supports discrete graph-based environments and interchangeable planning strategies, and has been validated through real-world deployment on an autonomous surface vehicle performing water quality monitoring—demonstrating seamless transfer of identical algorithmic logic from full simulation to physical platforms.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "RAG",
        "Research",
        "Benchmark"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：GuadalPlanner统一路径规划架构实现从仿真到部署的无缝迁移，解决自主系统开发的关键瓶颈，具备行业级推广潜力。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-11T10:02:31+00:00",
      "authors": [
        "Alejandro Mendoza Barrionuevo",
        "Dame Seck Diop",
        "Alejandro Casado Pérez"
      ]
    }
  ],
  "news": [
    {
      "id": "hn_46981058",
      "title": "Anthropic承诺承担数据中心推高电价的全部成本",
      "titleZh": "Anthropic承诺承担数据中心推高电价的全部成本",
      "titleEn": "Anthropic Pledges to Cover Electricity Price Increases Caused by Its Data Centers",
      "url": "https://www.anthropic.com/news/covering-electricity-price-increases",
      "type": "news",
      "source": "Hacker News",
      "summary": "**Anthropic宣布将全额承担其数据中心造成的电网升级成本，并通过采购新增电力、部署需求响应系统等方式抵消对居民电价的推高影响**，此举旨在应对AI算力激增带来的能源压力——单个前沿模型训练未来需吉瓦级电力，美国AI行业数年内需至少50吉瓦新增容量；该公司承诺覆盖基础设施分摊费用、匹配用电需求的新发电量、在用电高峰削减负荷，并投资本地社区创造就业与采用节水冷却技术，同时呼吁联邦层面加快输电审批与并网改革，以确保AI基础设施扩张不转嫁成本给普通用户。",
      "summaryZh": "**Anthropic宣布将全额承担其数据中心造成的电网升级成本，并通过采购新增电力、部署需求响应系统等方式抵消对居民电价的推高影响**，此举旨在应对AI算力激增带来的能源压力——单个前沿模型训练未来需吉瓦级电力，美国AI行业数年内需至少50吉瓦新增容量；该公司承诺覆盖基础设施分摊费用、匹配用电需求的新发电量、在用电高峰削减负荷，并投资本地社区创造就业与采用节水冷却技术，同时呼吁联邦层面加快输电审批与并网改革，以确保AI基础设施扩张不转嫁成本给普通用户。",
      "summaryEn": "Anthropic announced it will fully cover grid infrastructure costs and offset consumer electricity price increases caused by its data centers, addressing the surging energy demands of AI—where training a single frontier model may soon require gigawatts of power and the U.S. AI sector needs at least 50 gigawatts of new capacity in coming years. The company commits to paying 100% of interconnection-related grid upgrade costs, procuring net-new power generation to match its consumption, deploying curtailment systems to reduce peak demand, and investing in local communities through jobs and water-efficient cooling. It also advocates for federal permitting reform and faster transmission development to ensure AI infrastructure expansion doesn’t burden ratepayers.",
      "fullText": "Skip to main content Skip to footer Research Economic Futures Commitments Learn News Try Claude Policy Covering electricity price increases from our data centers Feb 11, 2026 As we continue to invest in American AI infrastructure , Anthropic will cover electricity price increases that consumers face from our data centers. Training a single frontier AI model will soon require gigawatts of power, and the US AI sector will need at least 50 gigawatts of capacity over the next several years. The country needs to build new data centers quickly to maintain its competitiveness on AI and national security—but AI companies shouldn’t leave American ratepayers to pick up the tab. Data centers can raise consumer electricity prices in two main ways. First, connecting data centers to the grid often requires costly new or upgraded infrastructure like transmission lines or substations. Second, new demand tightens the market, pushing up prices. We’re committing to address both. Specifically, we will: Cover grid infrastructure costs . We will pay for 100% of the grid upgrades needed to interconnect our data centers, paid through increases to our monthly electricity charges. This includes the shares of these costs that would otherwise be passed onto consumers. Procure new power and protect consumers from price increases . We will work to bring net-new power generation online to match our data centers’ electricity needs. Where new generation isn’t online, we’ll work with utilities and external experts to estimate and cover demand-driven price effects from our data centers. Reduce strain on the grid . We’re investing in curtailment systems that cut our data centers’ power usage during periods of peak demand, as well as grid optimization tools, both of which help keep prices lower for ratepayers. Invest in local communities. Our current data center projects will create hundreds of permanent jobs and thousands of construction jobs. We’re also committed to being a responsible neighbor—that means addressing environmental impacts, including deploying water-efficient cooling technologies, and partnering with local leaders on initiatives that share AI’s benefits broadly. Where we work with partners to develop data centers for handling our own workloads, we make these commitments directly. Where we lease capacity from existing data centers, we’re exploring further ways to address our own workloads' effects on prices. Of course, company-level action isn't enough. Keeping electricity affordable also requires systemic change. We support federal policies —including permitting reform and efforts to speed up transmission development and grid interconnection—that make it faster and cheaper to bring new energy online for everyone. Done right, AI infrastructure can be a catalyst for the broader energy investment the country needs. These commitments are the beginning of our efforts to address data centers’ impact on energy costs. We have more to do, and we’ll continue to share updates as this work develops. Related content Anthropic is donating $20 million to Public First Action Read more Introducing Claude Opus 4.6 We’re upgrading our smartest model. Across agentic coding, computer use, tool use, search, and finance, Opus 4.6 is an industry-leading model, often by wide margin. Read more Claude is a space to think We’ve made a choice: Claude will remain ad-free. We explain why advertising incentives are incompatible with a genuinely helpful AI assistant, and how we plan to expand access without compromising user trust. Read more Products Claude Claude Code Cowork Claude in Chrome Claude in Excel Claude in PowerPoint Claude in Slack Skills Max plan Team plan Enterprise plan Download app Pricing Log in to Claude Models Opus Sonnet Haiku Solutions AI agents Code modernization Coding Customer support Education Financial services Government Healthcare Life sciences Nonprofits Claude Developer Platform Overview Developer docs Pricing Regional compliance Amazon Bedrock Google Cloud’s Vertex AI Console login Learn Blog Claude partner network Connectors Courses Customer stories Engineering at Anthropic Events Plugins Powered by Claude Service partners Startups program Tutorials Use cases Company Anthropic Careers Economic Futures Research News Claude’s Constitution Responsible Scaling Policy Security and compliance Transparency Help and security Availability Status Support center Terms and policies Privacy policy Consumer health data privacy policy Responsible disclosure policy Terms of service: Commercial Terms of service: Consumer Usage policy © 2026 Anthropic PBC Covering electricity price increases from our data centers \\ Anthropic",
      "imageUrl": "https://www.anthropic.com/api/opengraph-illustration?name=Hand%20HeadBolt&backgroundColor=cactus",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Anthropic宣布承担数据中心电力成本，直面美国AI基础设施扩张的能源与社会成本问题，具有全球产业政策层面的战略意义",
        "热度：121 / 评论 94"
      ],
      "score": 10.97,
      "publishedAt": "2026-02-11T21:12:59+00:00",
      "authors": [
        "ryanhn"
      ]
    },
    {
      "id": "rss_6337705399",
      "title": "Blackwell平台助推理服务商将AI成本最高降10倍",
      "titleZh": "Blackwell平台助推理服务商将AI成本最高降10倍",
      "titleEn": "Inference Providers Slash AI Costs Up to 10x Using Open Models on NVIDIA Blackwell",
      "url": "https://blogs.nvidia.com/blog/inference-open-source-models-blackwell-reduce-cost-per-token/",
      "type": "news",
      "source": "NVIDIA Blog",
      "summary": "**多家领先推理服务商借助NVIDIA Blackwell平台将开源大模型的推理成本降低最高10倍**，通过硬件-软件协同设计、低精度格式（如NVFP4）和优化推理栈，Baseten、DeepInfra、Fireworks AI和Together AI等公司已在医疗、游戏、智能客服等领域实现显著降本：Sully.ai医疗编码成本降90%、Latitude游戏每token成本降至1/4、Sentient Chat多智能体系统成本降25–50%、Decagon语音客服单次交互成本降6倍；这一“更好tokenomics”趋势正推动企业大规模部署AI应用，使医生节省数千万分钟文书时间、玩家获得更流畅体验、用户享受低延迟语音服务。",
      "summaryZh": "**多家领先推理服务商借助NVIDIA Blackwell平台将开源大模型的推理成本降低最高10倍**，通过硬件-软件协同设计、低精度格式（如NVFP4）和优化推理栈，Baseten、DeepInfra、Fireworks AI和Together AI等公司已在医疗、游戏、智能客服等领域实现显著降本：Sully.ai医疗编码成本降90%、Latitude游戏每token成本降至1/4、Sentient Chat多智能体系统成本降25–50%、Decagon语音客服单次交互成本降6倍；这一“更好tokenomics”趋势正推动企业大规模部署AI应用，使医生节省数千万分钟文书时间、玩家获得更流畅体验、用户享受低延迟语音服务。",
      "summaryEn": "Leading inference providers—including Baseten, DeepInfra, Fireworks AI, and Together AI—are cutting AI inference costs by up to 10x using open-source frontier models on NVIDIA’s Blackwell platform, leveraging extreme hardware-software co-design, low-precision formats like NVFP4, and optimized inference stacks. Real-world deployments show Sully.ai reduced healthcare coding costs by 90%, Latitude cut per-token costs to one-fourth in AI gaming, Sentient Chat achieved 25–50% lower costs for multi-agent reasoning, and Decagon slashed per-query voice AI costs by 6x. This improved tokenomics enables scalable AI adoption across industries, returning over 30 million minutes to physicians, enhancing player experiences, and delivering sub-second voice responses—making powerful AI interactions more affordable and accessible.",
      "fullText": "A diagnostic insight in healthcare. A character’s dialogue in an interactive game. An autonomous resolution from a customer service agent. Each of these AI-powered interactions is built on the same unit of intelligence: a token. Scaling these AI interactions requires businesses to consider whether they can afford more tokens. The answer lies in better tokenomics — which at its core is about driving down the cost of each token. This downward trend is unfolding across industries. Recent MIT research found that infrastructure and algorithmic efficiencies are reducing inference costs for frontier-level performance by up to 10x annually. To understand how infrastructure efficiency improves tokenomics, consider the analogy of a high-speed printing press. If the press produces 10x output with incremental investment in ink, energy and the machine itself, the cost to print each individual page drops. In the same way, investments in AI infrastructure can lead to far greater token output compared with the increase in cost — causing a meaningful reduction in the cost per token. When token output outpaces infrastructure cost, the cost of each token drops. That’s why leading inference providers including Baseten, DeepInfra, Fireworks AI and Together AI are using the NVIDIA Blackwell platform, which helps them reduce cost per token by up to 10x compared with the NVIDIA Hopper platform. These providers host advanced open source models, which have now reached frontier-level intelligence. By combining open source frontier intelligence, the extreme hardware-software codesign of NVIDIA Blackwell and their own optimized inference stacks, these providers are enabling dramatic token cost reductions for businesses across every industry. Healthcare — Baseten and Sully.ai Cut AI Inference Costs by 10x In healthcare, tedious, time-consuming tasks like medical coding, documentation and managing insurance forms cut into the time doctors can spend with patients. Sully.ai helps solve this problem by developing “AI employees” that can handle routine tasks like medical coding and note-taking. As the company’s platform scaled, its proprietary, closed source models created three bottlenecks: unpredictable latency in real-time clinical workflows, inference costs that scaled faster than revenue and insufficient control over model quality and updates. Sully.ai builds AI employees that handle routine tasks for physicians. To overcome these bottlenecks, Sully.ai uses Baseten’s Model API, which deploys open source models such as gpt-oss-120b on NVIDIA Blackwell GPUs. Baseten used the low-precision NVFP4 data format, the NVIDIA TensorRT-LLM library and the NVIDIA Dynamo inference framework to deliver optimized inference. The company chose NVIDIA Blackwell to run its Model API after seeing up to 2.5x better throughput per dollar compared with the NVIDIA Hopper platform. As a result, Sully.ai’s inference costs dropped by 90%, representing a 10x reduction compared with the prior closed source implementation, while response times improved by 65% for critical workflows like generating medical notes. The company has now returned over 30 million minutes to physicians, time previously lost to data entry and other manual tasks. Gaming — DeepInfra and Latitude Reduce Cost per Token by 4x Latitude is building the future of AI-native gaming with its AI Dungeon adventure-story game and upcoming AI-powered role-playing gaming platform, Voyage, where players can create or play worlds with the freedom to choose any action and make their own story. The company’s platform uses large language models to respond to players’ actions — but this comes with scaling challenges, as every player action triggers an inference request. Costs scale with engagement, and response times must stay fast enough to keep the experience seamless. Latitude has built a text-based adventure-story game called “AI Dungeon,” which generates both narrative text and imagery in real time as players explore dynamic stories. Latitude runs large open source models on DeepInfra’s inference platform, powered by NVIDIA Blackwell GPUs and TensorRT-LLM. For a large-scale mixture-of-experts (MoE) model, DeepInfra reduced the cost per million tokens from 20 cents on the NVIDIA Hopper platform to 10 cents on Blackwell. Moving to Blackwell’s native low-precision NVFP4 format further cut that cost to just 5 cents — for a total 4x improvement in cost per token — while maintaining the accuracy that customers expect. Running these large-scale MoE models on DeepInfra’s Blackwell-powered platform allows Latitude to deliver fast, reliable responses cost effectively. DeepInfra inference platform delivers this performance while reliably handling traffic spikes, letting Latitude deploy more capable models without compromising player experience. Agentic Chat — Fireworks AI and Sentient Foundation Lower AI Costs by up to 50% Sentient Labs is focused on bringing AI developers together to build powerful reasoning AI systems that are all open source. The goal is to accelerate AI toward solving harder reasoning problems through research in secure autonomy, agentic architecture and continual learning. Its first app, Sentient Chat, orchestrates complex multi-agent workflows and integrates more than a dozen specialized AI agents from the community. Due to this, Sentient Chat has massive compute demands because a single user query could trigger a cascade of autonomous interactions that typically lead to costly infrastructure overhead. To manage this scale and complexity, Sentient uses Fireworks AI’s inference platform running on NVIDIA Blackwell. With Fireworks’ Blackwell-optimized inference stack, Sentient achieved 25-50% better cost efficiency compared with its previous Hopper-based deployment. Sentient Chat orchestrates complex multi-agent workflows and integrates more than a dozen specialized AI agents from the community. This higher throughput per GPU allowed the company to serve significantly more concurrent users for the same cost. The platform’s scalability supported a viral launch of 1.8 million waitlisted users in 24 hours and processed 5.6 million queries in a single week while delivering consistent low latency. Customer Service — Together AI and Decagon Drive Down Cost by 6x Customer service calls with voice AI often end in frustration because even a slight delay can lead users to talk over the agent, hang up or lose trust. Decagon builds AI agents for enterprise customer support, with AI-powered voice being its most demanding channel. Decagon needed infrastructure that could deliver sub-second responses under unpredictable traffic loads with tokenomics that supported 24/7 voice deployments. Decagon builds AI agents for customer support, and voice is its most demanding channel. Together AI runs production inference for Decagon’s multimodel voice stack on NVIDIA Blackwell GPUs. The companies collaborated on several key optimizations: speculative decoding that trains smaller models to generate faster responses while a larger model verifies accuracy in the background, caching repeated conversation elements to speed up responses and building automatic scaling that handles traffic surges without degrading performance. Decagon saw response times under 400 milliseconds even when processing thousands of tokens per query. Cost per query, which is the total cost to complete one voice interaction, dropped by 6x compared with using closed source proprietary models. This was achieved through the combination of Decagon’s multimodel approach (some open source, some trained in house on NVIDIA GPUs), NVIDIA Blackwell’s extreme codesign and Together’s optimized inference stack. Optimizing Tokenomics With Extreme Codesign The dramatic cost savings seen across healthcare, gaming and customer service are driven by the efficiency of NVIDIA Blackwell. The NVIDIA GB200 NVL72 system further scales this impact by delivering a breakthrough 10x reduction in cost per token for reasoning MoE models compared with NVIDIA Hopper. NVIDIA’s extreme codesign across every layer of the stack — spanning compute, networking and software — and its partner ecosystem are unlocking massive reductions in cost per token at scale. This momentum continues with the NVIDIA Rubin platform — integrating six new chips into a single AI supercomputer to deliver 10x performance and 10x lower token cost over Blackwell. Explore NVIDIA’s full-stack inference platform to learn more about how it delivers better tokenomics for AI inference.",
      "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2026/02/inference-press-moe-x-tokenomics-think-smart-blog-4779150-1280x680-1.jpg",
      "tags": [
        "Agent",
        "Inference",
        "Open Source"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：NVIDIA联合开源模型实现推理成本下降10倍，是推动AI规模化落地的关键技术突破，将重塑整个AI商业化生态",
        "热度：0 / 评论 0"
      ],
      "score": 10.1,
      "publishedAt": "2026-02-12T16:00:46+00:00",
      "authors": [
        "Shruti Koparkar"
      ]
    },
    {
      "id": "rss_2229748988",
      "title": "Gemini 3 Deep Think升级，专攻科研与工程难题",
      "titleZh": "Gemini 3 Deep Think升级，专攻科研与工程难题",
      "titleEn": "Gemini 3 Deep Think Updated to Tackle Advanced Science, Research and Engineering Challenges",
      "url": "https://deepmind.google/blog/gemini-3-deep-think-advancing-science-research-and-engineering/",
      "type": "news",
      "source": "DeepMind Blog",
      "summary": "**Google更新Gemini 3的Deep Think模式，专门强化其在现代科学、研究与工程领域的复杂推理能力**，使其能更准确地处理专业问题，这对科研人员和工程师意味着更可靠的AI辅助工具，普通人则可通过该功能获得更深入的技术解答或参与前沿项目协作。",
      "summaryZh": "**Google更新Gemini 3的Deep Think模式，专门强化其在现代科学、研究与工程领域的复杂推理能力**，使其能更准确地处理专业问题，这对科研人员和工程师意味着更可靠的AI辅助工具，普通人则可通过该功能获得更深入的技术解答或参与前沿项目协作。",
      "summaryEn": "Google has updated Gemini 3’s Deep Think mode to enhance its specialized reasoning capabilities for modern scientific, research, and engineering challenges, enabling more accurate handling of complex technical problems. This advancement provides researchers and engineers with a more reliable AI assistant, while offering general users deeper technical insights and opportunities to engage with cutting-edge projects.",
      "fullText": "Gemini 3 Deep Think: Advancing science, research and engineering",
      "imageUrl": "https://lh3.googleusercontent.com/RlrY06Cc3MLbXna5gqMdx9jpY1yDikXD5v5qOFSgfDsnXOR71u3s1_dh6hWimLrEybCkyGyqazG6UF2DWrK4F52tVpdaf9amz5R-ZgJQ7uogoSuo-g=w528-h297-n-nu-rw-lo",
      "tags": [
        "LLM",
        "Reasoning",
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：2 个来源",
        "模型评分：8/10，理由：Gemini 3 Deep Think聚焦科学与工程推理能力提升，是谷歌在专业领域AI应用上的重要进展，具备行业标杆意义",
        "热度：0 / 评论 0"
      ],
      "score": 9.4,
      "publishedAt": "2026-02-12T16:15:09+00:00",
      "authors": []
    },
    {
      "id": "github_google_langextract",
      "title": "Google开源langextract：LLM驱动的结构化信息提取工具",
      "titleZh": "Google开源langextract：LLM驱动的结构化信息提取工具",
      "titleEn": "Google Releases langextract: LLM-Powered Structured Information Extraction with Source Grounding",
      "url": "https://github.com/google/langextract",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Google开源langextract库，利用大语言模型从非结构化文本中提取结构化信息，并支持精确溯源与交互式可视化**，开发者可借此构建高可信度的信息抽取系统，研究人员能验证AI输出依据，普通用户则可通过可视化界面直观理解模型如何从文本中提炼关键数据。",
      "summaryZh": "**Google开源langextract库，利用大语言模型从非结构化文本中提取结构化信息，并支持精确溯源与交互式可视化**，开发者可借此构建高可信度的信息抽取系统，研究人员能验证AI输出依据，普通用户则可通过可视化界面直观理解模型如何从文本中提炼关键数据。",
      "summaryEn": "Google has released langextract, an open-source Python library that uses LLMs to extract structured information from unstructured text with precise source grounding and interactive visualization. Developers can build trustworthy information extraction systems, researchers can audit model outputs against original sources, and end users gain intuitive visual insights into how key data is derived from raw text.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/ab19a0b316dda195c17624dd43928abf61b93364158935b5f184fc2620e47727/google/langextract",
      "tags": [
        "LLM",
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：谷歌开源的结构化信息提取库结合LLM与溯源可视化，具有高实用价值和技术示范意义。",
        "热度：31138 / 评论 0"
      ],
      "score": 9.3,
      "publishedAt": "2026-02-12T18:29:26.914629+00:00",
      "authors": []
    },
    {
      "id": "github_unslothai_unsloth",
      "title": "Unsloth开源：LLM微调提速2倍、显存降70%",
      "titleZh": "Unsloth开源：LLM微调提速2倍、显存降70%",
      "titleEn": "Unsloth Open-Sources LLM Fine-Tuning That’s 2x Faster with 70% Less VRAM",
      "url": "https://github.com/unslothai/unsloth",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Unsloth开源库实现大语言模型微调与强化学习速度提升2倍、显存占用减少70%**，支持gpt-oss、Llama、Qwen等主流模型，开发者可更快迭代模型并降低硬件门槛，研究人员能高效探索新算法，普通用户则有望通过更低成本获得高性能本地AI应用。",
      "summaryZh": "**Unsloth开源库实现大语言模型微调与强化学习速度提升2倍、显存占用减少70%**，支持gpt-oss、Llama、Qwen等主流模型，开发者可更快迭代模型并降低硬件门槛，研究人员能高效探索新算法，普通用户则有望通过更低成本获得高性能本地AI应用。",
      "summaryEn": "The Unsloth open-source library accelerates fine-tuning and reinforcement learning for LLMs by 2x while reducing VRAM usage by 70%, supporting models like gpt-oss, Llama, Qwen, Gemma, and DeepSeek. This enables developers to iterate faster with lower hardware barriers, empowers researchers to efficiently test new algorithms, and paves the way for end users to access high-performance local AI applications at reduced cost.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/626e8958daf2e332cf51d98f84ca4a2b751879c5a25fb00a02204dc65adee11a/unslothai/unsloth",
      "tags": [
        "LLM",
        "Audio",
        "Training",
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Unsloth 提出的高效微调与强化学习方法显著降低训练成本，对主流大模型生态具有全球性技术变革意义。",
        "热度：51991 / 评论 0"
      ],
      "score": 8.4,
      "publishedAt": "2026-02-12T18:29:36.158736+00:00",
      "authors": []
    },
    {
      "id": "rss_3455091418",
      "title": "DGX Spark桌面超算进驻全球高校实验室",
      "titleZh": "DGX Spark桌面超算进驻全球高校实验室",
      "titleEn": "NVIDIA DGX Spark Brings Data-Center-Class AI to University Labs Worldwide",
      "url": "https://blogs.nvidia.com/blog/dgx-spark-higher-education/",
      "type": "news",
      "source": "NVIDIA Blog",
      "summary": "**NVIDIA DGX Spark桌面超算正被全球顶尖高校广泛部署，将数据中心级AI能力带入实验室与课堂**，从南极IceCube中微子观测站到哈佛癫痫研究、NYU放射报告评估、斯坦福生物智能体开发，其高达2000亿参数模型支持能力使研究人员能在本地快速迭代敏感数据项目；学生因此获得工业级工具实践机会，普通人则受益于由此加速产生的医疗诊断、机器人救援等创新成果。",
      "summaryZh": "**NVIDIA DGX Spark桌面超算正被全球顶尖高校广泛部署，将数据中心级AI能力带入实验室与课堂**，从南极IceCube中微子观测站到哈佛癫痫研究、NYU放射报告评估、斯坦福生物智能体开发，其高达2000亿参数模型支持能力使研究人员能在本地快速迭代敏感数据项目；学生因此获得工业级工具实践机会，普通人则受益于由此加速产生的医疗诊断、机器人救援等创新成果。",
      "summaryEn": "NVIDIA’s DGX Spark desktop supercomputer is being deployed across leading global universities—from the IceCube Neutrino Observatory in Antarctica to Harvard, NYU, Stanford, and beyond—bringing data-center-class AI to labs and classrooms. With support for models up to 200 billion parameters and integration with NVIDIA’s professional AI platforms, it enables local, secure iteration on sensitive applications like clinical report evaluation, epilepsy research, and robotic perception. Students gain hands-on access to industry-grade tools, while broader society benefits from accelerated innovations in healthcare, search-and-rescue robotics, and scientific discovery.",
      "fullText": "At leading institutions across the globe, the NVIDIA DGX Spark desktop supercomputer is bringing data‑center‑class AI to lab benches, faculty offices and students’ systems. There’s even a DGX Spark hard at work in the South Pole, at the IceCube Neutrino Observatory run by the University of Wisconsin-Madison. The compact supercomputer’s petaflop‑class performance enables local deployment of large AI applications, from clinical report evaluators to robotics perception systems, all while keeping sensitive data on site and shortening iteration loops for researchers and learners. Powered by the NVIDIA GB10 superchip and the NVIDIA DGX operating system, each DGX Spark unit supports AI models of up to 200 billion parameters and integrates seamlessly with the NVIDIA NeMo, Metropolis, Holoscan and Isaac platforms, giving students access to the same professional-grade tools used across the DGX ecosystem. Read more below on how DGX Spark powers groundbreaking AI work at leading institutions worldwide. IceCube Neutrino Observatory: Studying Particles in the South Pole At the University of Wisconsin-Madison’s IceCube Neutrino Observatory in Antarctica, researchers are using DGX Spark to run AI models for its experiments studying the universe’s most cataclysmic events, using subatomic particles called neutrinos. Traditional astronomy methods, based on detecting light waves, enable observing about 80% of the known universe, according to Benedikt Riedel, computing director at the Wisconsin IceCube Particle Astrophysics Center. A new way to explore the universe — using gravitational waves and particles like neutrinos — unlocks examining the most extreme cosmic environments, including those involving supernovas and dark matter. DGX Spark on a ceremonial South Pole marker. Image courtesy of Tim Bendfelt / NSF. “There’s no hardware store in the South Pole, which is technically a desert, with relative humidity under 5% and an elevation of 10,000 feet, meaning very limited power,” Riedel said. “DGX Spark allows us to deploy AI in a compartmentalized and easy fashion, at low cost and in such an extremely remote environment, to run AI analyses locally on our neutrino observation data.” NYU: Using Agentic AI for Radiology Reports At NYU’s Global AI Frontier Lab, ​the ICARE (Interpretable and Clinically‑Grounded Agent‑Based Report Evaluation) project runs end-to-end on a DGX Spark in the lab. ICARE uses collaborating AI agents and multiple‑choice question generation to evaluate how closely AI‑generated radiology reports align with expert sources, enabling real‑time clinical evaluation and continuous monitoring without sending medical imaging data to the cloud.​ “Being able to run powerful LLMs locally on the DGX Spark has completely changed my workflow,” said Lucius Bynum, data science assistant professor and a faculty fellow at the NYU Center for Data Science. “I have been able to focus my efforts on quickly iterating and improving the research tool I’m developing.” NYU researchers also use DGX Spark to run LLMs locally as part of interactive causal modeling tools that generate and refine semantic causal models — structured, machine‑readable maps of cause‑and‑effect relationships between clinical variables, imaging findings and potential diagnoses. This setup lets teams rapidly design, test and iterate on advanced models without waiting for cluster resources, including for privacy- and security‑sensitive applications such as in healthcare, where data must stay on premises.​​ Harvard: Decoding Epilepsy With AI At Harvard’s Kempner Institute for the Study of Natural and Artificial Intelligence, neuroscientists are using DGX Spark as a compact desktop supercomputer to probe how genetic mutations in the brain drive epilepsy. The system lets researchers run complex analyses in real time without needing to wait for access to large institutional clusters.​ Kempner Institute Co-Director Bernardo Sabatini (left) and Kempner Senior AI Computing Engineer Bala Desinghu (right) use a DGX Spark supercomputer to study how disruptions to neurons in the brain can drive neurological disorders such as epilepsy. Image courtesy of Anna Olivella. The team, led by Kempner Institute Co-Director Bernardo Sabatini, is studying about 6,000 mutations in excitatory and inhibitory neurons, building protein-structure and neuronal-function prediction maps that guide which variants to test next in the lab.​ DGX Spark acts as a bridge between benchtop and cluster‑scale computing at Harvard. Researchers first validate workflows and timing on a single DGX Spark, then scale successful pipelines to large GPU clusters for massive protein screens.​ ASU: Enabling Campus‑Scale Innovation Arizona State University was among the first universities to receive multiple DGX Spark systems, which now support AI research across the campus, spanning initiatives for memory care, transportation safety and sustainable energy.​ ASU doctoral students hold the NVIDIA DGX Spark for the first time. Both students are part of Professor ‘YZ’ Yang’s Active Perception Group laboratory. Image courtesy of Alisha Mendez, ASU. One ASU team led by Yezhou “YZ” Yang, associate professor in the School of Computing and Augmented Intelligence, is using DGX Spark to power advanced perception and robotics research, including for applications such as AI‑enabled, search-and-rescue robotic dogs and assistance tools for visually impaired users. Mississippi State: Empowering Computer Science and Engineering Students In the computer science and engineering department at Mississippi State University, DGX Spark serves as a hands‑on learning platform for the next generation of AI engineers. The enthusiasm around DGX Spark at Mississippi State is captured through lab‑driven outreach, including an unboxing video created by a lab working to advance applied AI, foster AI workforce development and drive real-world AI experimentation across the state. University of Delaware: Transforming Research Across Disciplines When ASUS delivered the school’s first Ascent GX10 — powered by DGX Spark — Sunita Chandrasekaran, professor of computer and information sciences and director of the First State AI Institute, called it “transformative for research,” enabling teams across disciplines like sports analytics and coastal science to run large AI models directly on campus instead of relying on costly cloud resources. Through the ASUS Virtual Lab program, schools can test GX10 performance remotely before deployment. ISTA: Training Big LLMs on a Small Desktop At the Institute of Science and Technology Austria, researchers are using an HP ZGX Nano AI Station — a compact system based on NVIDIA DGX Spark — to train and fine‑tune LLMs right on a desktop. The team’s open source LLMQ software enables working with models of up to 7 billion parameters, making advanced LLM training accessible to more students and researchers. Because the ZGX Nano includes 128GB of unified memory, the entire LLM and its training data can remain on the system, avoiding the complex memory juggling usually required on consumer GPUs. This helps teams move faster and keep sensitive data on premises. Read this research paper on ISTA’s LLMQ software. Stanford: A Pipeline for Prototyping At Stanford University, researchers are using DGX Spark to prototype complete training and evaluation pipelines to run their Biomni biological agent workflows locally before scaling to large GPU clusters. This enables a tight, iterative loop for model development and benchmarking, and automates complex analysis and experimental planning directly in the lab environment. The Stanford research team reported that DGX Spark provides performance similar to big cloud GPU instances — about 80 tokens per second on a 120 billion‑parameter gpt‑oss model at MXFP4 via Ollama — while keeping the entire workload on a desktop. College students from across the globe are invited to participate in Treehacks, a massive student hackathon running Feb. 13-15 at Stanford, which will feature DGX Spark units from ASUS. See how DGX Spark is transforming higher education and student innovation at Stanford by joining this livestream on Friday, Feb. 13, at 9 a.m. PT. Get started with DGX Spark and find purchase options on this webpage.",
      "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2026/02/dgx-spark-higher-ed-featured-1280x680-1.jpg",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：DGX Spark推动高校科研本地化部署，促进AI教育与研究普及，具有显著的学术与产业协同价值",
        "热度：0 / 评论 0"
      ],
      "score": 8.3,
      "publishedAt": "2026-02-12T15:00:23+00:00",
      "authors": [
        "Max Starubinskiy"
      ]
    },
    {
      "id": "hn_46982792",
      "title": "GPT-5法律推理能力超越联邦法官",
      "titleZh": "GPT-5法律推理能力超越联邦法官",
      "titleEn": "GPT-5 Outperforms Federal Judges in Legal Reasoning Test",
      "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012",
      "type": "news",
      "source": "Hacker News",
      "summary": "一项实验显示，**GPT-5在法律推理任务中表现优于联邦法官**，凸显了当前大模型在复杂逻辑与规则应用上的能力跃升；这一结果不仅挑战了人类专家在专业判断领域的传统优势，也引发对AI在司法辅助甚至决策角色中可行性的重新评估；对普通人而言，这意味着未来法律服务可能更高效、可及，但也需警惕算法偏见与透明度缺失带来的公平性风险。",
      "summaryZh": "一项实验显示，**GPT-5在法律推理任务中表现优于联邦法官**，凸显了当前大模型在复杂逻辑与规则应用上的能力跃升；这一结果不仅挑战了人类专家在专业判断领域的传统优势，也引发对AI在司法辅助甚至决策角色中可行性的重新评估；对普通人而言，这意味着未来法律服务可能更高效、可及，但也需警惕算法偏见与透明度缺失带来的公平性风险。",
      "summaryEn": "In a legal reasoning experiment, GPT-5 outperformed federal judges, demonstrating a significant leap in large language models’ ability to handle complex logic and rule-based reasoning. This challenges the traditional dominance of human experts in professional judgment and reopens debate over AI’s potential role in judicial assistance or even decision-making. For the public, it suggests more accessible and efficient legal services ahead—but also raises concerns about algorithmic bias and lack of transparency that could undermine fairness.",
      "fullText": "",
      "imageUrl": "https://tse3.mm.bing.net/th/id/OIP.iy7v_qsGMqkn0jaLyike_AHaJ4?w=1200&h=630&c=7&r=0&o=5&pid=1.7",
      "tags": [
        "LLM",
        "Reasoning"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：GPT-5 outperforming federal judges in legal reasoning suggests a breakthrough in AI's real-world decision-making capability, with major implications for law, governance, and AI trust at scale.",
        "热度：297 / 评论 218"
      ],
      "score": 6.78,
      "publishedAt": "2026-02-11T23:37:11+00:00",
      "authors": [
        "droidjj"
      ]
    },
    {
      "id": "rss_1382051665",
      "title": "AI正被用于全流程自动化网络犯罪，深度伪造诈骗激增",
      "titleZh": "AI正被用于全流程自动化网络犯罪，深度伪造诈骗激增",
      "titleEn": "AI Now Powers End-to-End Cybercrime Automation, Deepfake Scams Surge",
      "url": "https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/",
      "type": "news",
      "source": "MIT Tech Review AI",
      "summary": "**研究人员发现AI正被用于自动化网络犯罪全流程**，从生成恶意代码、识别敏感数据到撰写个性化勒索信，如NYU团队开发的PromptLock虽为实验项目，却揭示了LLM驱动的自适应恶意软件已成现实威胁；这标志着AI正显著降低攻击门槛，使初级黑客也能发起高效率诈骗或勒索；普通用户应警惕日益逼真的AI深度伪造（如语音、视频冒充高管），并加强多因素验证与安全意识，因微软数据显示2025年前一年已拦截价值40亿美元的AI辅助诈骗。",
      "summaryZh": "**研究人员发现AI正被用于自动化网络犯罪全流程**，从生成恶意代码、识别敏感数据到撰写个性化勒索信，如NYU团队开发的PromptLock虽为实验项目，却揭示了LLM驱动的自适应恶意软件已成现实威胁；这标志着AI正显著降低攻击门槛，使初级黑客也能发起高效率诈骗或勒索；普通用户应警惕日益逼真的AI深度伪造（如语音、视频冒充高管），并加强多因素验证与安全意识，因微软数据显示2025年前一年已拦截价值40亿美元的AI辅助诈骗。",
      "summaryEn": "Researchers have found that AI is now being used to automate entire cybercrime operations—from generating malicious code and identifying sensitive data to crafting personalized ransom notes—as demonstrated by PromptLock, an experimental LLM-powered ransomware developed by NYU researchers. Though not a real-world attack, it revealed how generative AI can enable highly adaptive malware, drastically lowering the barrier for less-skilled attackers. For ordinary users, this means heightened risks from increasingly convincing deepfakes (e.g., fake video calls impersonating executives), necessitating stronger multi-factor authentication and vigilance; Microsoft reported blocking $4 billion worth of AI-assisted scams in the year leading up to April 2025.",
      "fullText": "Anton Cherepanov is always on the lookout for something interesting. And in late August last year, he spotted just that. It was a file uploaded to VirusTotal, a site cybersecurity researchers like him use to analyze submissions for potential viruses and other types of malicious software, often known as malware. On the surface it seemed innocuous, but it triggered Cherepanov’s custom malware-detecting measures. Over the next few hours, he and his colleague Peter Strýček inspected the sample and realized they’d never come across anything like it before. The file contained ransomware, a nasty strain of malware that encrypts the files it comes across on a victim’s system, rendering them unusable until a ransom is paid to the attackers behind it. But what set this example apart was that it employed large language models (LLMs). Not just incidentally, but across every stage of an attack. Once it was installed, it could tap into an LLM to generate customized code in real time, rapidly map a computer to identify sensitive data to copy or encrypt, and write personalized ransom notes based on the files’ content. The software could do this autonomously, without any human intervention. And every time it ran, it would act differently, making it harder to detect. Cherepanov and Strýček were confident that their discovery, which they dubbed PromptLock, marked a turning point in generative AI, showing how the technology could be exploited to create highly flexible malware attacks. They published a blog post declaring that they’d uncovered the first example of AI-powered ransomware, which quickly became the object of widespread global media attention. But the threat wasn’t quite as dramatic as it first appeared. The day after the blog post went live, a team of researchers from New York University claimed responsibility, explaining that the malware was not, in fact, a full attack let loose in the wild but a research project, merely designed to prove it was possible to automate each step of a ransomware campaign—which, they said, they had.&nbsp; PromptLock may have turned out to be an academic project, but the real bad guys are using the latest AI tools. Just as software engineers are using artificial intelligence to help write code and check for bugs, hackers are using these tools to reduce the time and effort required to orchestrate an attack, lowering the barriers for less experienced attackers to try something out.&nbsp; The likelihood that cyberattacks will now become more common and more effective over time is not a remote possibility but “a sheer reality,” says Lorenzo Cavallaro, a professor of computer science at University College London.&nbsp; Some in Silicon Valley warn that AI is on the brink of being able to carry out fully automated attacks. But most security researchers say this claim is overblown. “For some reason, everyone is just focused on this malware idea of, like, AI superhackers, which is just absurd,” says Marcus Hutchins, who is principal threat researcher at the security company Expel and famous in the security world for ending a giant global ransomware attack called WannaCry in 2017.&nbsp; Instead, experts argue, we should be paying closer attention to the much more immediate risks posed by AI, which is already speeding up and increasing the volume of scams. Criminals are increasingly exploiting the latest deepfake technologies to impersonate people and swindle victims out of vast sums of money. These AI-enhanced cyberattacks are only set to get more frequent and more destructive, and we need to be ready.&nbsp; Spam and beyond Attackers started adopting generative AI tools almost immediately after ChatGPT exploded on the scene at the end of 2022. These efforts began, as you might imagine, with the creation of spam—and a lot of it. Last year, a report from Microsoft said that in the year leading up to April 2025, the company had blocked $4 billion worth of scams and fraudulent transactions, “many likely aided by AI content.”&nbsp; At least half of spam email is now generated using LLMs, according to estimates by researchers at Columbia University, the University of Chicago, and Barracuda Networks, who analyzed nearly 500,000 malicious messages collected before and after the launch of ChatGPT. They also found evidence that AI is increasingly being deployed in more sophisticated schemes. They looked at targeted email attacks, which impersonate a trusted figure in order to trick a worker within an organization out of funds or sensitive information. By April 2025, they found, at least 14% of those sorts of focused email attacks were generated using LLMs, up from 7.6% in April 2024. In one high-profile case, a worker was tricked into transferring $25 million to criminals via a video call with digital versions of the company’s chief financial officer and other employees. And the generative AI boom has made it easier and cheaper than ever before to generate not only emails but highly convincing images, videos, and audio. The results are much more realistic than even just a few short years ago, and it takes much less data to generate a fake version of someone’s likeness or voice than it used to. Criminals aren’t deploying these sorts of deepfakes to prank people or to simply mess around—they’re doing it because it works and because they’re making money out of it, says Henry Ajder, a generative AI expert. “If there’s money to be made and people continue to be fooled by it, they’ll continue to do it,” he says. In one high-­profile case reported in 2024, a worker at the British engineering firm Arup was tricked into transferring $25 million to criminals via a video call with digital versions of the company’s chief financial officer and other employees. That’s likely only the tip of the iceberg, and the problem posed by convincing deepfakes is only likely to get worse as the technology improves and is more widely adopted.&nbsp; BRIAN STAUFFER Criminals’ tactics evolve all the time, and as AI’s capabilities improve, such people are constantly probing how those new capabilities can help them gain an advantage over victims. Billy Leonard, tech leader of Google’s Threat Analysis Group, has been keeping a close eye on changes in the use of AI by potential bad actors (a widely used term in the industry for hackers and others attempting to use computers for criminal purposes). In the latter half of 2024, he and his team noticed prospective criminals using tools like Google Gemini the same way everyday users do—to debug code and automate bits and pieces of their work—as well as tasking it with writing the odd phishing email. By 2025, they had progressed to using AI to help create new pieces of malware and release them into the wild, he says. The big question now is how far this kind of malware can go. Will it ever become capable enough to sneakily infiltrate thousands of companies’ systems and extract millions of dollars, completely undetected?&nbsp; Most popular AI models have guardrails in place to prevent them from generating malicious code or illegal material, but bad actors still find ways to work around them. For example, Google observed a China-linked actor asking its Gemini AI model to identify vulnerabilities on a compromised system—a request it initially refused on safety grounds. However, the attacker managed to persuade Gemini to break its own rules by posing as a participant in a capture-the-flag competition, a popular cybersecurity game. This sneaky form of jailbreaking led Gemini to hand over information that could have been used to exploit the system. (Google has since adjusted Gemini to deny these kinds of requests.) But bad actors aren’t just focusing on trying to bend the AI giants’ models to their nefarious ends. Going forward, they’re increasingly likely to adopt open-source AI models, as it’s easier to strip out their safeguards and get them to do malicious things, says Ashley Jess, a former tactical specialist at the US Department of Justice and now a senior intelligence analyst at the cybersecurity company Intel 471. “Those are the ones I think that [bad] actors are going to adopt, because they can jailbreak them and tailor them to what they need,” she says. The NYU team used two open-source models from OpenAI in its PromptLock experiment, and the researchers found they didn’t even need to resort to jailbreaking techniques to get the model to do what they wanted. They say that makes attacks much easier. Although these kinds of open-source models are designed with an eye to ethical alignment, meaning that their makers do consider certain goals and values in dictating the way they respond to requests, the models don’t have the same kinds of restrictions as their closed-source counterparts, says Meet Udeshi, a PhD student at New York University who worked on the project. “That is what we were trying to test,” he says. “These LLMs claim that they are ethically aligned—can we still misuse them for these purposes? And the answer turned out to be yes.”&nbsp; It’s possible that criminals have already successfully pulled off covert PromptLock-style attacks and we’ve simply never seen any evidence of them, says Udeshi. If that’s the case, attackers could—in theory—have created a fully autonomous hacking system. But to do that they would have had to overcome the significant barrier that is getting AI models to behave reliably, as well as any inbuilt aversion the models have to being used for malicious purposes—all while evading detection. Which is a pretty high bar indeed. Productivity tools for hackers So, what do we know for sure? Some of the best data we have now on how people are attempting to use AI for malicious purposes comes from the big AI companies themselves. And their findings certainly sound alarming, at least at first. In November, Leonard’s team at Google released a report that found bad actors were using AI tools (including Google’s Gemini) to dynamically alter malware’s behavior; for example, it could self-modify to evade detection. The team wrote that it ushered in “a new operational phase of AI abuse.” However, the five malware families the report dug into (including PromptLock) consisted of code that was easily detected and didn’t actually do any harm, the cybersecurity writer Kevin Beaumont pointed out on social media. “There’s nothing in the report to suggest orgs need to deviate from foundational security programmes—everything worked as it should,” he wrote. It’s true that this malware activity is in an early phase, concedes Leonard. Still, he sees value in making these kinds of reports public if it helps security vendors and others build better defenses to prevent more dangerous AI attacks further down the line. “Cliché to say, but sunlight is the best disinfectant,” he says. “It doesn’t really do us any good to keep it a secret or keep it hidden away. We want people to be able to know about this— we want other security vendors to know about this—so that they can continue to build their own detections.” And it’s not just new strains of malware that would-be attackers are experimenting with—they also seem to be using AI to try to automate the process of hacking targets. In November, Anthropic announced it had disrupted a large-scale cyberattack, the first reported case of one executed without “substantial human intervention.” Although the company didn’t go into much detail about the exact tactics the hackers used, the report’s authors said a Chinese state-sponsored group had used its Claude Code assistant to automate up to 90% of what they called a “highly sophisticated espionage campaign.” “We’re entering an era where the barrier to sophisticated cyber operations has fundamentally lowered, and the pace of attacks will accelerate faster than many organizations are prepared for.” Jacob Klein, head of threat intelligence at Anthropic But, as with the Google findings, there were caveats. A human operator, not AI, selected the targets before tasking C",
      "imageUrl": "https://wp.technologyreview.com/wp-content/uploads/2026/02/opener-final1_social.jpg?resize=1200%2C630",
      "tags": [
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：MIT Tech Review AI",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：首次发现LLM驱动的自主攻击型恶意软件，标志AI已进入主动犯罪工具链，是AI安全领域的历史性转折点。",
        "热度：0 / 评论 0"
      ],
      "score": 5.0,
      "publishedAt": "2026-02-12T11:00:00+00:00",
      "authors": [
        "Rhiannon Williams"
      ]
    },
    {
      "id": "rss_3966977648",
      "title": "美国仲裁协会上线AI仲裁员，专攻建筑纠纷裁决",
      "titleZh": "美国仲裁协会上线AI仲裁员，专攻建筑纠纷裁决",
      "titleEn": "American Arbitration Association Launches AI Arbitrator for Construction Disputes",
      "url": "https://www.theverge.com/podcast/877299/ai-arbitrator-bridget-mccormack-aaa-arbitration-interview",
      "type": "news",
      "source": "The Verge AI",
      "summary": "**美国仲裁协会（AAA）推出AI仲裁员平台，专用于仅凭书面材料裁决的建筑纠纷**，由前密歇根州最高法院首席大法官Bridget McCormack主导；该举措旨在提升争议解决的效率与一致性，回应公众对司法系统信任度降至历史新低的现状；尽管AI尚不能处理涉及证人或情感判断的复杂案件，但其透明展示推理过程的能力或可增强当事人对结果的接受度；普通人若签署含仲裁条款的合同（如就业或消费协议），未来可能直接面对AI辅助甚至主导的裁决流程，需关注其公正性与纠错机制。",
      "summaryZh": "**美国仲裁协会（AAA）推出AI仲裁员平台，专用于仅凭书面材料裁决的建筑纠纷**，由前密歇根州最高法院首席大法官Bridget McCormack主导；该举措旨在提升争议解决的效率与一致性，回应公众对司法系统信任度降至历史新低的现状；尽管AI尚不能处理涉及证人或情感判断的复杂案件，但其透明展示推理过程的能力或可增强当事人对结果的接受度；普通人若签署含仲裁条款的合同（如就业或消费协议），未来可能直接面对AI辅助甚至主导的裁决流程，需关注其公正性与纠错机制。",
      "summaryEn": "The American Arbitration Association (AAA), led by former Michigan Supreme Court Chief Justice Bridget McCormack, has launched an AI Arbitrator platform specifically for construction disputes resolvable solely through written documents. Aimed at improving efficiency and consistency in alternative dispute resolution, this move responds to record-low public trust in the judicial system in 2024. While the AI cannot yet handle cases requiring witness testimony or emotional nuance, its ability to transparently show its reasoning may increase user acceptance of outcomes. Since most people unknowingly agree to arbitration clauses in employment or consumer contracts, they may soon encounter AI-assisted—or even AI-led—decisions, making oversight of fairness and appeal mechanisms critical.",
      "fullText": "Today, we’re going to talk about the role AI might play in deciding legal disputes. Not just drafting memos and doing research — actually deciding who’s right and who’s wrong, and who should pay. My guest today is Bridget McCormack, the former chief justice for the Michigan Supreme Court and now president and CEO of the American Arbitration Association. The AAA has been around for exactly 100 years and is the country’s largest nonprofit arbitrator. You’ve probably heard of arbitration before. It’s is a form of dispute resolution that allows two parties to resolve conflicts outside the formal court system using a third, neutral party — the arbitrator — to negotiate a settlement. Verge subscribers, don&#8217;t forget you get exclusive access to ad-free Decoder wherever you get your podcasts. Head here. Not a subscriber? You can sign up here. You may have never found yourself in arbitration, but you’ve almost certainly signed an arbitration clause, in one of the many contracts and terms-of-service agreements that all of us have to sign all the time. Arbitration can be much faster, cheaper, and easier than going to court, so it’s become a favored way of resolving disputes between businesses. It’s also, as it turns out, how many employers and large corporations defend against lawsuits, because they can sneak an arbitration clause into the agreements for everything from cellphone service to smart washing machine features or even your employment contract, which can protect them down the line from class action claims.&nbsp; Arbitration is everywhere in our legal landscape, so you can see why an organization like the AAA would want to make it faster, cheaper, and more predictable. For the past several years, Bridget and her team have been developing an AI-assisted arbitration platform called the AI Arbitrator, and it’s now available for use in very specific cases — construction disputes that can be resolved entirely on the basis of written documents. As of right now, the AI Arbitrator has officially one case on its docket. I’m obviously fascinated at how all of that might work, but you’ll hear Bridget and me really dig in here on what this kind of automation means not just for arbitration, but also the bigger, more fundamental idea of seeking justice, and whether or not our legal system feels fair.&nbsp; Americans’ trust in the judicial system reached a record low in 2024, and you’ll hear Bridget and me go back and forth on whether a system driven by AI can actually help people trust these systems more simply by making each party feel heard and showing its work, something you often don’t get from a human judge.&nbsp; At the same time, AI systems are AI systems. They’re new, brittle, and hallucinate facts and dates. It feels like there’s real danger in handing this kind of power to such a new, and unpredictable, technology. So you’ll hear Bridget discuss where she thinks the lines should really be drawn, how she’s trying to head off some of the big concerns around AI, and where she sees this going in the future.&nbsp; Again, Bridget was the former chief justice of the Michigan Supreme Court; she was in charge of all the judges in her state. You’ll hear her say several times that people are unreliable. By the way, if you want a broader look at all of this, Verge reporter Lauren Feiner actually published a fantastic feature on AI in the legal system last month, and I highly suggest you go read that if you’re interested in learning even more. Okay: Bridget McCormack, the president and CEO of the American Arbitration Association, on the AI Arbitrator. Here we go. This interview has been lightly edited for length and clarity.&nbsp; Bridget McCormack, you&#8217;re the president and CEO of the American Arbitration Association. You&#8217;re also the former Chief Justice of the Michigan Supreme Court. Welcome to Decoder. It&#8217;s great to be here. Great to see you. You and I were on a panel a while ago. You were talking about rolling out AI in arbitration. You were also talking about your history overseeing judges in Michigan, which was very funny. I&#8217;m very excited to talk about all of that with you.&nbsp; I just want to start at the very beginning. I suspect you and I are going to end up talking a lot about commercial and business disputes. There&#8217;s a lot there to discuss in the context of AI and arbitration. Most people&#8217;s experience of arbitration is that they just sign a contract.&nbsp; You were the Chief Justice in Michigan; you oversaw the literal legal system in that state. American Arbitration Association is 100 years old, so now you oversee a 100-year-old dominant provider of arbitration. Explain to people what the difference is. It&#8217;s a great starting point. The thing about being the Chief Justice of the Michigan Supreme Court is that, like every state Supreme Court, the Supreme Court of Michigan has administrative oversight of all the courts of the state. When you&#8217;re the chief justice, you&#8217;re kind of the CEO of the public dispute resolution system that most people are stuck dealing with, if they need a little justice or if somebody wants a little justice from them. Like other leadership roles, I had a leadership team and another 300 or so staff of folks who reported up to the leadership team. And it was our job to try and figure out how to improve the experience of people across the state of Michigan who had to go to their local courts because of some legal problem. It&#8217;s an enormous change management job for lots of reasons that are not true in my current job. The thing about running the public dispute resolution system, like the state court system, is that your funding isn&#8217;t based on how well you do. You can&#8217;t perform well one year and have extra revenue for R&amp;D. You have to walk over to the legislature and convince some brand-new representative from Leelanau County that online dispute resolution is really going to increase access to justice. You literally have to pick off legislators from around the state to try and fund what you know is going to be a better way of doing business.&nbsp; At the same time, there are the judges across the state in Michigan, and there are approximately 1,000 judicial officers. I say that because in addition to judges, there are magistrates that report up. They&#8217;re all separately elected and they work in counties that have their own funding systems. So they&#8217;re partly funded by the state and they&#8217;re partly funded by their county. The counties across Michigan are differently resourced, right? Some counties have a larger tax base than others, and they have a bigger budget to work with. So convincing separately elected judges with different budgets that we&#8217;re going to do business a certain way going forward is super complicated. It&#8217;s a very fun change management problem.&nbsp; The AAA, on the other hand, is basically a court system, but a private court system, although I should say at the top, the AAA is a nonprofit. We&#8217;re a fee-for-service nonprofit, but we&#8217;re a nonprofit. We&#8217;ve been administering alternative dispute resolution arbitration, but also mediation and any other alternative process parties want, for 100 years as of last Thursday. So we&#8217;ve been doing it for a long time and we have administered over half a million cases a year for the last few years, and not just domestically but also in cross-border disputes. Most of them are B2B commercial disputes, but there are also B2C cases, employment consumer cases, and a growing number of self-represented parties. A lot of small and medium businesses, as I&#8217;m sure you know, can&#8217;t afford legal help. They&#8217;re legally naked. And so arbitration is an easier way for them to manage disputes. I want to talk about the difference between a private dispute resolution system and the public dispute resolution system for one more second. But first, actually, you just said something. I&#8217;m so curious about it. It sounds like, as the Chief Justice, you had a role advocating for the court system with the legislature, inside the justice system.&nbsp; Most people never hear about that and never think about that. What was the split in your time? How often did you have to spend time just saying, &#8220;Hey, can you pay for the courts?&#8221; versus actually being the Chief Justice? I would say the administrative part of the job was significantly more than half compared to the decisional part of the job. It&#8217;s an enormous job. Michigan adjudicates between 3 and 4 million cases a year, and like every other state court, a majority of people who go to court to have cases resolved can&#8217;t afford lawyers. This is the primary place people interact with their government. The kind of justice we deliver, the quality of justice we deliver, it&#8217;s pretty important to, frankly, the rule of law and trust in institutions. I think it&#8217;s one of the most important jobs in government. I&#8217;m curious about that because it feels like the experience you had there really leads to your perspective on how and why AI should enter the legal system.&nbsp; Yep. The reason I&#8217;m starting here with your previous experience and not your current job is—I encounter this on our show and on our site all the time—that people think the legal system is deterministic. Particularly our audience, the tech audience, thinks the legal system is a computer. You can feed it inputs and it&#8217;ll API access the law, and then you&#8217;ll get some predictable outputs. I&#8217;m always trying to convince people that that&#8217;s not the case. Even hearing you talk about the politics of running the legal system underlines for me that the legal system is absolutely not deterministic. Should it be? Yeah. Because you&#8217;re the first person I could just like straightforwardly ask that question to. Should the legal system be more predictable and deterministic? It absolutely should be, at least in a majority of cases. In fact, if it were more deterministic, we would have fewer disputes, right? It&#8217;s because it&#8217;s probabilistic—and I agree with you. It is, for the most part, because it&#8217;s run by humans. You&#8217;ve met humans, right? They&#8217;re flawed.&nbsp; And therefore it isn&#8217;t always predictable. If it were more predictable, we would be a more efficient and effective system. We&#8217;d avoid a lot of disputes because people could plan their business around what, in fact, the rule was going to be, and how it was going to be enforced, and how they could count on it being enforced. In my view, that’s true for most cases for which there is a rule of law, and we know how it&#8217;s been interpreted historically, or at least how it&#8217;s been correctly interpreted historically by the majority of courts. There are always going to be new frontiers in legal. Cases where courts are having to decide how to interpret a new statute. Courts are going to have to figure that out for the first time. That&#8217;s not going to be able to be deterministic. It could get better and better, frankly. I think AI could do a very good job at the front end of statutory drafting, in making sure there was less ambiguity in statutory terms. AI could impact that. But there are even still modern questions about historic provisions in statutes and the constitutions, state and federal, that we have entrusted judges to decide. So I don&#8217;t think it can all be deterministic. I think an awful lot could be, and it would improve the way the law operates. Where do you think that the source of uncertainty in the legal system, as people experience it today, comes from? Is it just that most people can&#8217;t afford a lawyer? Is it that some percentage of judges are just weird old guys? Where does that come from? I don&#8217;t think there&#8217;s a single answer. I do think it’s relevant that 92 percent of Americans can&#8217;t ",
      "imageUrl": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/DCD-Bridget-McCormack_portrait.png?quality=90&strip=all&crop=0%2C10.711631919237%2C100%2C78.576736161526&w=1200",
      "tags": [
        "Research"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：The Verge AI",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：探讨 AI 在司法仲裁中的角色，触及法律与AI融合的关键议题，具有深远社会与制度影响。",
        "热度：0 / 评论 0"
      ],
      "score": 4.8,
      "publishedAt": "2026-02-12T16:22:33+00:00",
      "authors": [
        "Nilay Patel"
      ]
    },
    {
      "id": "github_danielmiessler_Personal_AI_Infrastructure",
      "title": "danielmiessler/Personal_AI_Infrastructure",
      "titleZh": "danielmiessler/Personal_AI_Infrastructure",
      "titleEn": "danielmiessler/Personal_AI_Infrastructure",
      "url": "https://github.com/danielmiessler/Personal_AI_Infrastructure",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "该项目提出一种**以代理（Agentic）架构为核心的个人AI基础设施**，旨在通过自主规划、工具调用与记忆机制放大人类能力；其关键点在于构建可长期运行、自我迭代的AI代理系统，而非仅响应单次指令；这一方法对AI领域的重要性在于推动从被动助手向主动协作者的范式转变；对开发者或技术用户而言，它提供了搭建个性化AI工作流的开源框架，可用于自动化研究、内容创作或知识管理等场景。",
      "summaryZh": "该项目提出一种**以代理（Agentic）架构为核心的个人AI基础设施**，旨在通过自主规划、工具调用与记忆机制放大人类能力；其关键点在于构建可长期运行、自我迭代的AI代理系统，而非仅响应单次指令；这一方法对AI领域的重要性在于推动从被动助手向主动协作者的范式转变；对开发者或技术用户而言，它提供了搭建个性化AI工作流的开源框架，可用于自动化研究、内容创作或知识管理等场景。",
      "summaryEn": "This project proposes a personal AI infrastructure built around agentic architecture—designed to amplify human capabilities through autonomous planning, tool use, and memory. Its key innovation lies in creating self-sustaining, iteratively improving AI agents rather than systems that merely respond to one-off prompts. This approach marks a paradigm shift in AI from passive assistants to proactive collaborators, offering developers and technical users an open-source framework to build personalized AI workflows for tasks like automated research, content creation, or knowledge management.",
      "fullText": "",
      "imageUrl": "https://repository-images.githubusercontent.com/1052845083/986b3f67-e6d2-4ea1-b583-896f53f5331d",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：构建个人AI代理基础设施，聚焦人类能力放大，是当前AI Agent趋势的重要实践方向。",
        "热度：7390 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-12T18:29:25.520795+00:00",
      "authors": []
    },
    {
      "id": "github_rowboatlabs_rowboat",
      "title": "rowboatlabs/rowboat",
      "titleZh": "rowboatlabs/rowboat",
      "titleEn": "rowboatlabs/rowboat",
      "url": "https://github.com/rowboatlabs/rowboat",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Rowboat是一个开源的AI同事工具，具备长期记忆能力**，能记住用户偏好、历史交互和上下文信息以提供连贯协助；其核心在于将记忆模块与语言模型结合，实现跨会话的个性化协作；这对AI领域意味着向真正实用的数字同事迈出一步；普通用户可将其部署为本地或私有化AI助手，用于日常任务自动化，同时避免主流商业模型的数据隐私风险。",
      "summaryZh": "**Rowboat是一个开源的AI同事工具，具备长期记忆能力**，能记住用户偏好、历史交互和上下文信息以提供连贯协助；其核心在于将记忆模块与语言模型结合，实现跨会话的个性化协作；这对AI领域意味着向真正实用的数字同事迈出一步；普通用户可将其部署为本地或私有化AI助手，用于日常任务自动化，同时避免主流商业模型的数据隐私风险。",
      "summaryEn": "Rowboat is an open-source AI coworker equipped with long-term memory, enabling it to retain user preferences, interaction history, and contextual information for coherent, personalized assistance across sessions. By integrating a dedicated memory module with a language model, it represents a step toward practical, persistent digital colleagues. For end users, it offers a privacy-preserving alternative to commercial AI assistants—deployable locally or on private infrastructure—to automate everyday tasks without surrendering data to third parties.",
      "fullText": "",
      "imageUrl": "https://private-user-images.githubusercontent.com/6592213/547591215-fc463b99-01b3-401c-b4a4-044dad480901.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NzA5MjEyNzMsIm5iZiI6MTc3MDkyMDk3MywicGF0aCI6Ii82NTkyMjEzLzU0NzU5MTIxNS1mYzQ2M2I5OS0wMWIzLTQwMWMtYjRhNC0wNDRkYWQ0ODA5MDEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDIxMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAyMTJUMTgyOTMzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZGYxZTM4MTY0Y2U5OTFlZjc5NzU5OWVlY2MyMjAwODg1M2VlODY4ZmQ2ZGVkNDUxZTZkOTMxMGI4OTQ2OTlkNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.y4-VIvh-pym-kKN_5gk_rxbaRCxqiub6Xlf1DiNjxZM",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：开源具备记忆功能的AI同事，推动可持久交互的AI协作范式，具行业变革潜力。",
        "热度：5016 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-12T18:29:33.340020+00:00",
      "authors": []
    }
  ],
  "stats": {
    "total_papers_ingested": 290,
    "total_news_ingested": 68,
    "l1_papers_passed": 116,
    "l1_news_passed": 59,
    "l2_papers_scored": 54,
    "l2_news_scored": 30,
    "l3_papers_selected": 18,
    "l3_news_selected": 11,
    "news_source_counts": {
      "Hacker News": 29,
      "GitHub Trending": 11,
      "TechCrunch AI": 9,
      "The Verge AI": 7,
      "NVIDIA Blog": 3,
      "MIT Tech Review AI": 3,
      "OpenAI Blog": 1,
      "Google AI Blog": 1,
      "DeepMind Blog": 1,
      "Hugging Face Blog": 1,
      "AWS Machine Learning Blog": 1,
      "OpenGVLab (GitHub)": 1
    },
    "rss_source_counts": {
      "TechCrunch AI": 9,
      "The Verge AI": 7,
      "NVIDIA Blog": 3,
      "MIT Tech Review AI": 3,
      "OpenAI Blog": 1,
      "Google AI Blog": 1,
      "DeepMind Blog": 1,
      "Hugging Face Blog": 1,
      "AWS Machine Learning Blog": 1,
      "OpenGVLab (GitHub)": 1
    },
    "news_title_source_counts": {
      "an ai agent published a hit piece on me": 1,
      "gemini 3 deep think": 1,
      "gpt 5 3 codex spark": 1,
      "major european payment processor can t send email to google workspace users": 1,
      "launch hn omnara yc s25 run claude code and codex from anywhere": 1,
      "improving 15 llms at coding in one afternoon only the harness changed": 1,
      "warcraft iii peon voice notifications for claude code": 1,
      "ai dr": 1,
      "show hn 20 claude code agents coordinating on real work open source": 1,
      "lines of code are back and it s worse than before": 1,
      "carl sagan s baloney detection kit tools for thinking critically 2025": 1,
      "ai agent opens a pr write a blogpost to shames the maintainer who closes it": 1,
      "microwave oven failure spontaneously turned on by its led display 2024": 1,
      "show hn agent alcove claude gpt and gemini debate across forums": 1,
      "gpt 5 outperforms federal judges in legal reasoning experiment": 1,
      "covering electricity price increases from our data centers": 1,
      "america s cyber defense agency is burning down and nobody s coming to put it out": 1,
      "training qwen 4b to beat large models on work tasks": 1,
      "private equity s big bet on software was derailed by ai": 1,
      "show hn double blind entropy using drand for verifiably fair randomness": 1,
      "from specification to stress test a weekend with claude": 1,
      "paragon accidentally uploaded a photo of its spyware control panel": 1,
      "u s health officials defend rejection of moderna s flu vaccine": 1,
      "us labels spacex a common carrier by air will regulate firm under railway law": 1,
      "65 lines of markdown a claude code sensation": 1,
      "show hn send claude code tasks to the batch api at 50 off": 1,
      "uk supreme court issues milestone judgment for ai and software patentability": 1,
      "i regret to inform you that the fda is fdaing again": 1,
      "republicans vote to end trump s canada tariffs": 1,
      "tambo ai tambo": 1,
      "danielmiessler personal ai infrastructure": 1,
      "google langextract": 1,
      "chromedevtools chrome devtools mcp": 1,
      "iofficeai aionui": 1,
      "shubhamsaboo awesome llm apps": 1,
      "rowboatlabs rowboat": 1,
      "github gh aw": 1,
      "unslothai unsloth": 1,
      "jeffallan claude skills": 1,
      "handsonllm hands on large language models": 1,
      "introducing gpt 5 3 codex spark": 1,
      "gemini 3 deep think advancing science research and engineering": 2,
      "leading inference providers cut ai costs by up to 10x with open source models on nvidia blackwell": 1,
      "nvidia dgx spark powers big projects in higher education": 1,
      "geforce now turns screens into a gaming machine": 1,
      "good luck have fun don t die is a rollicking parable about this moment in tech": 1,
      "the surprising case for ai judges": 1,
      "bytedance s next gen ai model can generate clips based on text images audio and video": 1,
      "this 7 999 robot will fold some of your laundry": 1,
      "two more xai co founders are among those leaving after the spacex merger": 1,
      "anthropic says it 8217 ll try to keep its data centers from raising electricity costs": 1,
      "apple keeps hitting bumps with its overhauled siri": 1,
      "a new version of openai s codex is powered by a new dedicated chip": 1,
      "xai lays out interplanetary ambitions in public all hands": 1,
      "ai inference startup modal labs in talks to raise at 2 5b valuation sources say": 1,
      "openai disbands mission alignment team": 1,
      "apple s siri revamp reportedly delayed again": 1,
      "uber eats launches ai assistant to help with grocery cart creation": 1,
      "glean s fight to own the ai layer inside every company": 1,
      "who will own your company s ai layer glean s ceo explains": 1,
      "elon musk suggests spate of xai exits have been push not pull": 1,
      "openenv in practice evaluating tool using agents in real world environments": 1,
      "ai is already making online crimes easier it could get much worse": 1,
      "what s next for chinese open source ai": 1,
      "is a secure ai assistant possible": 1,
      "nvidia nemotron 3 nano 30b moe model is now available in amazon sagemaker jumpstart": 1,
      "opengvlab added penghaoyin to opengvlab ummevalkit": 1
    },
    "total_papers_deduped": 290,
    "total_news_deduped": 66,
    "news_recent_filtered": 66
  }
}