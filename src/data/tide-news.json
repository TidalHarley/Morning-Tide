{
  "date": "2026-02-14",
  "generatedAt": "2026-02-14T23:40:45.399780",
  "introduction": "今日AI领域迎来多重突破：字节跳动发布Seed2.0大模型，显著提升复杂任务处理与多模态理解能力；学界聚焦AI可靠性，包括对LLM“心智理论”的质疑、基准测试体系的系统性重构，以及医疗、法律等高风险场景中的对齐与推理机制。同时，开源社区涌现多个具记忆与自主开发能力的AI代理项目。政策层面，印度设立11亿美元深科技基金，而新闻出版业正限制互联网档案馆访问以应对AI抓取风险。这些进展共同勾勒出AI向更可信、更实用、更受监管方向演进的图景。",
  "introductionZh": "今日AI领域迎来多重突破：字节跳动发布Seed2.0大模型，显著提升复杂任务处理与多模态理解能力；学界聚焦AI可靠性，包括对LLM“心智理论”的质疑、基准测试体系的系统性重构，以及医疗、法律等高风险场景中的对齐与推理机制。同时，开源社区涌现多个具记忆与自主开发能力的AI代理项目。政策层面，印度设立11亿美元深科技基金，而新闻出版业正限制互联网档案馆访问以应对AI抓取风险。这些进展共同勾勒出AI向更可信、更实用、更受监管方向演进的图景。",
  "introductionEn": "Today’s AI landscape features major advances in reliability and real-world utility. ByteDance launched Seed2.0, enhancing multimodal understanding and complex task execution. Research critically examines LLMs’ theory of mind, proposes new benchmarks for evaluation integrity, and introduces specialized agents for legal, medical, and robotic applications. Open-source projects like Rowboat and Letta showcase memory-augmented AI coworkers. On the policy front, India approved a $1.1B deep-tech fund, while publishers restrict Internet Archive access over AI scraping concerns—highlighting growing tensions between data access and copyright in the generative era.",
  "longformScript": "今天，AI世界又往前迈了一大步——不是那种炫技式的突破，而是更扎实、更落地的演进。从大厂发布的新模型，到开源社区涌现的记忆型智能体，再到政策与产业对AI风险的重新审视，整个领域正悄悄转向一个新阶段：可信、可用、可管。\n\n字节跳动今天正式推出Seed2.0大模型，算是近期最值得关注的进展之一。它不再只是回答问题或写代码，而是能处理真正复杂的现实任务——比如理解一段科研视频后，自动生成跨学科实验方案；或者在非结构化文档里抽取出关键逻辑，辅助法律或金融决策。更值得注意的是，它在多个专业基准测试中表现顶尖，甚至在某些视频理解任务上超过了人类平均分。现在，普通用户已经能在豆包App里体验它的Pro版本，企业也能通过火山引擎调用API部署生产级应用。这说明，大模型正在从“能说会道”走向“能做实事”，尤其在客服、教育、科研这些高价值场景中，开始展现真正的生产力。\n\n而在这股实用化浪潮中，开源社区也没闲着。今天GitHub上好几个热门项目都指向同一个方向：让AI拥有记忆，并能长期协作。比如Rowboat这个工具，允许开发者把AI嵌入工作流，还能记住之前的对话和上下文，不再是每次都要从零开始解释需求。类似地，Letta推出的编程智能体专门优化了代码记忆机制，解决AI助手在多文件项目中“失忆”的老问题。还有Unstract这样的无代码平台，让业务人员不用写一行代码，就能把PDF、扫描件这类杂乱文档自动转成结构化数据。这些工具看似分散，实则共同推动AI从一次性问答工具，进化为能陪你工作一整天的“数字同事”。它们不追求通用智能，但精准解决了真实工作流中的断点和摩擦。\n\n与此同时，工程基础设施也在快速补位。Chrome DevTools团队今天上线了一个专为AI编程智能体设计的调试工具，这意味着开发者终于可以像调试传统程序一样，观察AI生成的代码逻辑、干预执行路径。过去AI编程常被诟病是“黑盒”，现在有了可观测性，可靠性才可能提升。另一边，SynkraAI发布的AIOS Core v4.0，则试图统一调度模型、工具和数据流，让开发者能一键编排从前端到数据库的全栈AI应用。这些底层工具的成熟，预示着AI原生应用的开发门槛正在系统性降低——未来可能不再需要庞大的工程团队，几个开发者就能快速跑通一个具备自主执行能力的产品原型。\n\n当然，技术越强大，边界就越重要。今天另一条耐人寻味的消息来自新闻出版业：《卫报》《纽约时报》等多家机构开始限制互联网档案馆对其内容的访问，理由很直接——防止AI公司通过Wayback Machine批量抓取版权内容用于训练。这背后其实是个两难：一边是保存网络历史的公益使命，一边是AI时代下内容被无偿“收割”的现实风险。普通用户或许很快会发现，某些历史网页的存档突然打不开了。这件事提醒我们，当AI对数据的渴求日益增长，原有的开放生态可能需要重新协商规则。技术进步不能只靠“拿来主义”，尊重产权和可持续的数据合作机制，才是长期发展的基础。\n\n放眼全球，政策层面也在加速响应。印度政府今天批准了一支11亿美元的国家母基金，专门扶持人工智能、先进制造等深科技初创企业。考虑到当地去年初创融资大幅下滑，这笔钱显然是为了稳住创新基本盘，尤其向二三线城市和硬科技赛道倾斜。而在企业内部，IBM宣布将Z世代初级岗位招聘规模扩大三倍——不是因为AI不够强，恰恰是因为他们意识到，过度依赖自动化会导致人才断层。于是新岗位被重新设计：工程师要更多对接客户需求，HR要监督AI聊天机器人。这透露出一个信号：AI不会简单取代人力，而是重塑“人该做什么”。未来的职场竞争力，或许不在于你会不会用AI，而在于你能否与AI协同创造更高阶的价值。\n\n那么，作为普通用户或从业者，该怎么看待今天的这些变化？首先，别再把AI当成一个遥远的概念——它已经嵌入日常工具、工作流程甚至求职要求中。其次，关注那些“有记忆、可调试、能落地”的项目，它们代表了下一阶段的实用方向。最后，保持对数据伦理和知识产权的敏感度，因为技术红利的背后，往往藏着未被定价的社会成本。\n\n今天的AI世界，少了些喧嚣，多了些沉稳。它不再急于证明自己无所不能，而是开始认真回答一个问题：如何在真实世界里，可靠地帮人做成事。",
  "longformScriptZh": "今天，AI世界又往前迈了一大步——不是那种炫技式的突破，而是更扎实、更落地的演进。从大厂发布的新模型，到开源社区涌现的记忆型智能体，再到政策与产业对AI风险的重新审视，整个领域正悄悄转向一个新阶段：可信、可用、可管。\n\n字节跳动今天正式推出Seed2.0大模型，算是近期最值得关注的进展之一。它不再只是回答问题或写代码，而是能处理真正复杂的现实任务——比如理解一段科研视频后，自动生成跨学科实验方案；或者在非结构化文档里抽取出关键逻辑，辅助法律或金融决策。更值得注意的是，它在多个专业基准测试中表现顶尖，甚至在某些视频理解任务上超过了人类平均分。现在，普通用户已经能在豆包App里体验它的Pro版本，企业也能通过火山引擎调用API部署生产级应用。这说明，大模型正在从“能说会道”走向“能做实事”，尤其在客服、教育、科研这些高价值场景中，开始展现真正的生产力。\n\n而在这股实用化浪潮中，开源社区也没闲着。今天GitHub上好几个热门项目都指向同一个方向：让AI拥有记忆，并能长期协作。比如Rowboat这个工具，允许开发者把AI嵌入工作流，还能记住之前的对话和上下文，不再是每次都要从零开始解释需求。类似地，Letta推出的编程智能体专门优化了代码记忆机制，解决AI助手在多文件项目中“失忆”的老问题。还有Unstract这样的无代码平台，让业务人员不用写一行代码，就能把PDF、扫描件这类杂乱文档自动转成结构化数据。这些工具看似分散，实则共同推动AI从一次性问答工具，进化为能陪你工作一整天的“数字同事”。它们不追求通用智能，但精准解决了真实工作流中的断点和摩擦。\n\n与此同时，工程基础设施也在快速补位。Chrome DevTools团队今天上线了一个专为AI编程智能体设计的调试工具，这意味着开发者终于可以像调试传统程序一样，观察AI生成的代码逻辑、干预执行路径。过去AI编程常被诟病是“黑盒”，现在有了可观测性，可靠性才可能提升。另一边，SynkraAI发布的AIOS Core v4.0，则试图统一调度模型、工具和数据流，让开发者能一键编排从前端到数据库的全栈AI应用。这些底层工具的成熟，预示着AI原生应用的开发门槛正在系统性降低——未来可能不再需要庞大的工程团队，几个开发者就能快速跑通一个具备自主执行能力的产品原型。\n\n当然，技术越强大，边界就越重要。今天另一条耐人寻味的消息来自新闻出版业：《卫报》《纽约时报》等多家机构开始限制互联网档案馆对其内容的访问，理由很直接——防止AI公司通过Wayback Machine批量抓取版权内容用于训练。这背后其实是个两难：一边是保存网络历史的公益使命，一边是AI时代下内容被无偿“收割”的现实风险。普通用户或许很快会发现，某些历史网页的存档突然打不开了。这件事提醒我们，当AI对数据的渴求日益增长，原有的开放生态可能需要重新协商规则。技术进步不能只靠“拿来主义”，尊重产权和可持续的数据合作机制，才是长期发展的基础。\n\n放眼全球，政策层面也在加速响应。印度政府今天批准了一支11亿美元的国家母基金，专门扶持人工智能、先进制造等深科技初创企业。考虑到当地去年初创融资大幅下滑，这笔钱显然是为了稳住创新基本盘，尤其向二三线城市和硬科技赛道倾斜。而在企业内部，IBM宣布将Z世代初级岗位招聘规模扩大三倍——不是因为AI不够强，恰恰是因为他们意识到，过度依赖自动化会导致人才断层。于是新岗位被重新设计：工程师要更多对接客户需求，HR要监督AI聊天机器人。这透露出一个信号：AI不会简单取代人力，而是重塑“人该做什么”。未来的职场竞争力，或许不在于你会不会用AI，而在于你能否与AI协同创造更高阶的价值。\n\n那么，作为普通用户或从业者，该怎么看待今天的这些变化？首先，别再把AI当成一个遥远的概念——它已经嵌入日常工具、工作流程甚至求职要求中。其次，关注那些“有记忆、可调试、能落地”的项目，它们代表了下一阶段的实用方向。最后，保持对数据伦理和知识产权的敏感度，因为技术红利的背后，往往藏着未被定价的社会成本。\n\n今天的AI世界，少了些喧嚣，多了些沉稳。它不再急于证明自己无所不能，而是开始认真回答一个问题：如何在真实世界里，可靠地帮人做成事。",
  "longformScriptEn": "Today’s AI landscape is defined by a pivotal shift: from flashy demos to dependable, integrated tools that solve real problems. We’re seeing models not just talk smarter, but act more reliably—whether in coding, customer service, or scientific research. At the same time, tensions are rising around who owns the data fueling these systems, and how human roles evolve alongside increasingly capable agents. This isn’t just about better algorithms; it’s about building infrastructure, workflows, and policies that make AI truly useful—and sustainable.\n\nLeading this charge is ByteDance with the launch of Seed2.0, a new series of large language models engineered for complex, real-world execution. Unlike earlier models that excel at answering questions, Seed2.0 tackles multi-step tasks like drafting experimental protocols across disciplines or interpreting dense financial charts. It sets new benchmarks on tests like MathVista and MMLongBench, even outperforming humans on EgoTempo—a video understanding challenge that requires tracking objects and actions over time. What’s notable is how ByteDance is deploying it: through its Doubao app and TRAE platform, with APIs on Volcano Engine, making high-accuracy AI accessible for enterprise use cases in education, research, and customer support. This signals a maturation—AI isn’t just a side feature anymore; it’s becoming the engine behind core business functions.\n\nParallel to these commercial advances, open-source projects are redefining how developers interact with AI. Tools like Rowboat and Letta are pioneering “memory-first” agents—AI coworkers that remember past interactions, codebases, and user preferences. Rowboat enables persistent context in collaborative workflows, while Letta’s coding agent stores long-term memory of project structures to avoid the disorientation common in current AI assistants that forget everything after a session ends. These aren’t just productivity hacks; they represent a fundamental redesign of AI from transient helper to continuous collaborator. Meanwhile, Unstract lowers the barrier further by letting non-technical users build document-processing pipelines with a visual interface—turning messy PDFs and scans into structured data with one click. In industries like legal or healthcare, where documents drive decisions, this could democratize AI adoption far beyond engineering teams.\n\nInfrastructure is catching up too. SynkraAI’s AIOS Core v4.0 offers full-stack orchestration, automating everything from frontend design to database schema generation through coordinated AI agents. And critically, debugging is no longer an afterthought: Chrome DevTools has launched a dedicated debugger for AI coding agents, allowing developers to inspect, pause, and correct AI-generated logic just like traditional code. This move toward observability is essential—it transforms AI programming from a black-box gamble into a transparent engineering discipline. Without such tools, scaling AI agents in production would remain risky and opaque.\n\nBut as capabilities grow, so do conflicts over data and labor. Major publishers like The New York Times and The Guardian are now blocking the Internet Archive from crawling their sites, fearing their content is being scraped to train commercial AI models without consent. This pits digital preservation against intellectual property rights, threatening public access to historical web records. On the workforce front, IBM is taking a counterintuitive stance: tripling entry-level hiring for Gen Z despite AI’s automation potential. The company argues that cutting junior roles creates a leadership vacuum down the line. Instead, it’s reshaping jobs—software engineers now engage directly with customers, HR professionals manage AI chatbots—fostering hybrid roles where humans guide, interpret, and ethically steer AI systems. The message is clear: AI augments judgment, not just tasks.\n\nLooking ahead, watch three developments closely. First, whether platforms like OpenAI follow through on building native collaboration environments—potentially disrupting Slack by embedding multi-agent workflows directly into team communication. Second, how regulatory frameworks balance innovation with copyright, especially as archives become battlegrounds. And third, whether memory-augmented agents become standard in developer tooling, shifting expectations from code completion to full project stewardship. The opportunity lies in building systems where AI handles complexity, but humans retain control, context, and creativity.\n\nIn sum, today’s AI story isn’t about bigger models alone—it’s about smarter integration. From ByteDance’s task-executing Seed2.0 to India’s $1.1 billion deep-tech fund fueling the next wave of startups, the focus is shifting from what AI can say to what it can reliably do. As these tools embed themselves into coding, travel planning, and document processing, the winners will be those who design not just intelligent systems, but trustworthy, maintainable, and human-centered ones. The era of AI as a novelty is over. The era of AI as infrastructure has just begun.",
  "audioUrl": "",
  "papers": [
    {
      "id": "arxiv_2602_11674v1",
      "title": "Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs",
      "titleZh": "Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs",
      "titleEn": "Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs",
      "url": "https://arxiv.org/abs/2602.11674v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对大语言模型（LLM）评估基准日益不可靠的问题，研究者提出“基准健康指数”（BHI），通过能力区分度、抗饱和性和影响力三个正交维度，对106个经验证的基准进行系统性审计；该纯数据驱动框架首次在宏观层面量化评估基准的健康状况，为下一代评估协议的动态生命周期管理提供原则性依据。",
      "summaryZh": "针对大语言模型（LLM）评估基准日益不可靠的问题，研究者提出“基准健康指数”（BHI），通过能力区分度、抗饱和性和影响力三个正交维度，对106个经验证的基准进行系统性审计；该纯数据驱动框架首次在宏观层面量化评估基准的健康状况，为下一代评估协议的动态生命周期管理提供原则性依据。",
      "summaryEn": "To address the growing unreliability of benchmarks for Large Language Models (LLMs), researchers propose the Benchmark Health Index (BHI)—a purely data-driven framework that audits 106 validated benchmarks along three orthogonal axes: Capability Discrimination, Anti-Saturation, and Impact. BHI is the first to quantify benchmark health at a macro level, offering a principled foundation for dynamic lifecycle management of next-generation evaluation protocols.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：10/10，理由：构建系统性基准评估框架，直击当前LLM评测体系的信任危机，有望重塑行业评估标准，具有里程碑意义。",
        "热度：11 / 评论 0"
      ],
      "score": 10.0,
      "publishedAt": "2026-02-12T07:47:16+00:00",
      "authors": [
        "Longyuan Zhu",
        "Hairan Hua",
        "Linlin Miao"
      ]
    },
    {
      "id": "arxiv_2602_12150v1",
      "title": "GPT-4o Lacks Core Features of Theory of Mind",
      "titleZh": "GPT-4o Lacks Core Features of Theory of Mind",
      "titleEn": "GPT-4o Lacks Core Features of Theory of Mind",
      "url": "https://arxiv.org/abs/2602.12150v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究基于认知科学中对心理理论（Theory of Mind, ToM）的定义，构建新评估框架检验GPT-4o等大语言模型是否具备因果性、领域通用且一致的心理状态表征；结果表明，尽管模型能在简单任务中模仿人类判断，但在逻辑等价任务中表现不一致，且行为预测与心理状态推断缺乏连贯性，说明其社交能力并非源于真正的ToM机制。",
      "summaryZh": "研究基于认知科学中对心理理论（Theory of Mind, ToM）的定义，构建新评估框架检验GPT-4o等大语言模型是否具备因果性、领域通用且一致的心理状态表征；结果表明，尽管模型能在简单任务中模仿人类判断，但在逻辑等价任务中表现不一致，且行为预测与心理状态推断缺乏连贯性，说明其社交能力并非源于真正的ToM机制。",
      "summaryEn": "Using a cognitively grounded definition of Theory of Mind (ToM), this study evaluates whether LLMs like GPT-4o possess a coherent, domain-general causal model of mental states driving behavior. Despite mimicking human judgments in simple tasks, models fail on logically equivalent variants and show low consistency between action predictions and mental state inferences, indicating their social proficiency does not stem from a genuine ToM.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Inference",
        "Research",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：对GPT-4o是否具备心智理论进行关键质疑，引发关于LLM认知能力的全球性学术与产业讨论，具有战略级影响力。",
        "热度：10 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T16:33:58+00:00",
      "authors": [
        "John Muchovej",
        "Amanda Royka",
        "Shane Lee"
      ]
    },
    {
      "id": "arxiv_2602_11865v1",
      "title": "Intelligent AI Delegation",
      "titleZh": "Intelligent AI Delegation",
      "titleEn": "Intelligent AI Delegation",
      "url": "https://arxiv.org/abs/2602.11865v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为应对AI代理在复杂任务中需安全、动态地向其他AI或人类委派子任务的挑战，研究提出“智能AI委派”框架，将任务分配扩展为包含权限转移、责任界定、意图澄清和信任建立的完整决策序列，适用于人机混合的委派网络，为新兴“代理网络”（agentic web）中的协作协议设计提供理论基础。",
      "summaryZh": "为应对AI代理在复杂任务中需安全、动态地向其他AI或人类委派子任务的挑战，研究提出“智能AI委派”框架，将任务分配扩展为包含权限转移、责任界定、意图澄清和信任建立的完整决策序列，适用于人机混合的委派网络，为新兴“代理网络”（agentic web）中的协作协议设计提供理论基础。",
      "summaryEn": "To enable AI agents to safely and dynamically delegate subtasks to other agents or humans in complex environments, this work proposes an Intelligent AI Delegation framework that treats delegation as a sequence of decisions involving authority transfer, accountability, role boundaries, intent clarity, and trust mechanisms—applicable to both human and AI participants in emerging agentic networks.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：系统性提出智能AI委派范式，解决复杂任务分解与跨主体协作的核心瓶颈，将深刻影响下一代AI代理的发展方向。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T12:11:42+00:00",
      "authors": [
        "Nenad Tomašev",
        "Matija Franklin",
        "Simon Osindero"
      ]
    },
    {
      "id": "arxiv_2602_11860v1",
      "title": "Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models",
      "titleZh": "Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models",
      "titleEn": "Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models",
      "url": "https://arxiv.org/abs/2602.11860v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对车路云一体化动态地图（DM）缺乏自然语言交互接口的问题，研究构建VRCsim仿真框架与VRC-QA问答数据集，并提出Talk2DM模块，通过“提示链”（CoP）机制融合人工规则与大语言模型常识知识，实现高精度（>93%）、低延迟（2–5秒）的自然语言空间查询与推理，已在Qwen3:8B、Gemma3:27B等模型上验证实用性。",
      "summaryZh": "针对车路云一体化动态地图（DM）缺乏自然语言交互接口的问题，研究构建VRCsim仿真框架与VRC-QA问答数据集，并提出Talk2DM模块，通过“提示链”（CoP）机制融合人工规则与大语言模型常识知识，实现高精度（>93%）、低延迟（2–5秒）的自然语言空间查询与推理，已在Qwen3:8B、Gemma3:27B等模型上验证实用性。",
      "summaryEn": "Addressing the lack of natural language interfaces in Vehicle-Road-Cloud (VRC) integrated Dynamic Maps (DM), this work introduces VRCsim for simulating VRC perception data, constructs the VRC-QA dataset, and proposes Talk2DM—a plug-and-play module using a Chain-of-Prompt (CoP) mechanism to integrate human-defined rules with LLM commonsense knowledge. It achieves over 93% query accuracy with 2–5 second response times across models like Qwen3:8B and Gemma3:27B.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "RAG",
        "Reasoning",
        "Research"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：面向车路云协同自动驾驶的动态地图自然语言交互系统，契合中国与日本智能交通战略方向，具重大产业落地潜力。",
        "热度：13 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T12:06:12+00:00",
      "authors": [
        "Lu Tao",
        "Jinxuan Luo",
        "Yousuke Watanabe"
      ]
    },
    {
      "id": "arxiv_2602_12056v1",
      "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
      "titleZh": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
      "titleEn": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
      "url": "https://arxiv.org/abs/2602.12056v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决法律推理中中间步骤无法验证导致错误传播的问题，研究提出LawThinker法律智能体，采用“探索-验证-记忆”策略，在每次知识检索后通过DeepVerifier模块从知识准确性、事实-法律相关性及程序合规性三方面进行原子级验证；在动态司法基准J1-EVAL上较直接推理提升24%，显著改善过程合规性指标。",
      "summaryZh": "为解决法律推理中中间步骤无法验证导致错误传播的问题，研究提出LawThinker法律智能体，采用“探索-验证-记忆”策略，在每次知识检索后通过DeepVerifier模块从知识准确性、事实-法律相关性及程序合规性三方面进行原子级验证；在动态司法基准J1-EVAL上较直接推理提升24%，显著改善过程合规性指标。",
      "summaryEn": "To prevent undetected error propagation in legal reasoning, LawThinker—an autonomous legal agent—adopts an Explore-Verify-Memorize strategy, enforcing atomic verification after each knowledge retrieval via a DeepVerifier module that assesses knowledge accuracy, fact-law relevance, and procedural compliance. It outperforms direct reasoning by 24% on the dynamic J1-EVAL benchmark, with notable gains in process-oriented metrics.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Agent",
        "RAG",
        "Reasoning",
        "Research"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：构建动态环境下的深度法律研究代理，解决法律推理过程可验证性难题，对司法智能化具有战略意义。",
        "热度：12 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T15:19:11+00:00",
      "authors": [
        "Xinyu Yang",
        "Chenlong Deng",
        "Tongyu Wen"
      ]
    },
    {
      "id": "arxiv_2602_12187v1",
      "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
      "titleZh": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
      "titleEn": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
      "url": "https://arxiv.org/abs/2602.12187v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为支持对“搜索增强生成引擎优化”（SAGEO）的现实评估，研究构建SAGEO Arena环境，集成含丰富结构信息（如schema标记）的大规模网页语料与完整生成式搜索流水线；实验发现现有SAGEO方法在真实检索与重排序阶段常失效，而结构信息可缓解此问题，且需针对各流水线阶段定制优化策略。",
      "summaryZh": "为支持对“搜索增强生成引擎优化”（SAGEO）的现实评估，研究构建SAGEO Arena环境，集成含丰富结构信息（如schema标记）的大规模网页语料与完整生成式搜索流水线；实验发现现有SAGEO方法在真实检索与重排序阶段常失效，而结构信息可缓解此问题，且需针对各流水线阶段定制优化策略。",
      "summaryEn": "To enable realistic evaluation of Search-Augmented Generative Engine Optimization (SAGEO), researchers introduce SAGEO Arena—a reproducible environment integrating a full generative search pipeline over a large-scale corpus with rich structural signals like schema markup. Findings show current SAGEO methods often degrade performance in retrieval and reranking, while structural information helps mitigate these issues, necessitating stage-specific optimization strategies.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "RAG",
        "Benchmark"
      ],
      "paperCategory": "General AI",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：构建SAGEO Arena评估搜索增强生成引擎，直面信息检索与生成融合的核心挑战，对下一代搜索引擎发展具有战略意义。",
        "热度：11 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T17:18:00+00:00",
      "authors": [
        "Sunghwan Kim",
        "Wooseok Jeong",
        "Serin Kim"
      ]
    },
    {
      "id": "arxiv_2602_11757v1",
      "title": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
      "titleZh": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
      "titleEn": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
      "url": "https://arxiv.org/abs/2602.11757v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为突破静态3D场景生成局限、实现符合物理规律的4D世界模拟，研究提出Code2Worlds框架，通过双流架构解耦物体生成与环境编排，并引入物理感知闭环机制：由PostProcess Agent编写动力学脚本，VLM-Motion Critic进行自反思迭代优化；在Code4D基准上，其SGS指标提升41%，内容丰富度提高49%，并首次生成具物理一致性的动态行为。",
      "summaryZh": "为突破静态3D场景生成局限、实现符合物理规律的4D世界模拟，研究提出Code2Worlds框架，通过双流架构解耦物体生成与环境编排，并引入物理感知闭环机制：由PostProcess Agent编写动力学脚本，VLM-Motion Critic进行自反思迭代优化；在Code4D基准上，其SGS指标提升41%，内容丰富度提高49%，并首次生成具物理一致性的动态行为。",
      "summaryEn": "To advance beyond static 3D generation toward physically grounded 4D world simulation, Code2Worlds formulates 4D generation as language-to-simulation code synthesis. It employs a dual-stream architecture to disentangle object generation from environmental orchestration and introduces a physics-aware closed-loop mechanism where a PostProcess Agent scripts dynamics and a VLM-Motion Critic iteratively refines code via self-reflection. On the Code4D benchmark, it achieves a 41% SGS gain and 49% higher Richness, uniquely generating physics-consistent dynamics.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Multimodal",
        "Agent",
        "3D"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：将编码LLM扩展至4D世界生成，推动空间智能与物理规律建模融合，具有战略级行业变革潜力。",
        "热度：14 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T09:34:28+00:00",
      "authors": [
        "Yi Zhang",
        "Yunshuang Wang",
        "Zeyu Zhang"
      ]
    },
    {
      "id": "arxiv_2602_12099v1",
      "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "titleZh": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "titleEn": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "url": "https://arxiv.org/abs/2602.12099v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为提升视觉-语言-动作（VLA）模型的长期任务执行能力，研究提出GigaBrain-0.5M*，在已登顶RoboChallenge榜单的GigaBrain-0.5基础上，引入基于世界模型的强化学习方法RAMP；该方法利用视频世界模型的时空预测能力，在衣物折叠、装箱、咖啡制作等任务上性能提升约30%，并在真实机器人部署中实现无失败的长周期复杂操作。",
      "summaryZh": "为提升视觉-语言-动作（VLA）模型的长期任务执行能力，研究提出GigaBrain-0.5M*，在已登顶RoboChallenge榜单的GigaBrain-0.5基础上，引入基于世界模型的强化学习方法RAMP；该方法利用视频世界模型的时空预测能力，在衣物折叠、装箱、咖啡制作等任务上性能提升约30%，并在真实机器人部署中实现无失败的长周期复杂操作。",
      "summaryEn": "Building on GigaBrain-0.5—the current leader on the RoboChallenge benchmark—GigaBrain-0.5M* integrates world model-based reinforcement learning via RAMP (Reinforcement leArning via world Model-conditioned Policy) to enhance Vision-Language-Action (VLA) models. Leveraging spatiotemporal reasoning from video world models, it achieves ~30% performance gains on tasks like Laundry Folding and Espresso Preparation, demonstrating reliable long-horizon execution in real-world robotic deployments without failure.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Multimodal",
        "Robotics",
        "Reasoning"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：GigaBrain-0.5M*通过世界模型强化学习训练VLA，突破传统VLA的场景理解与未来预测瓶颈，代表下一代具身智能关键进展。",
        "热度：15 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T15:55:19+00:00",
      "authors": [
        " GigaBrain Team",
        "Boyuan Wang",
        "Chaojun Ni"
      ]
    },
    {
      "id": "arxiv_2602_11672v1",
      "title": "U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction",
      "titleZh": "U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction",
      "titleEn": "U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction",
      "url": "https://arxiv.org/abs/2602.11672v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究人员提出了一种名为TD-FusionUNet的轻量级深度学习模型，用于次日野火蔓延预测。该模型在U-Net架构中引入可训练的Hadamard变换和离散余弦变换（DCT）层，在正交化潜在空间中捕捉关键“频率”成分，并结合随机边缘裁剪与高斯混合模型等预处理技术，增强对稀疏火灾前掩码的表征能力。在Google Research的Next-Day Wildfire Spread数据集和WildfireSpreadTS数据集上，TD-FusionUNet仅用37万参数即取得0.591的F1分数，优于参数更多的ResNet18编码器U-Net基线，表明其在资源受限环境下兼顾精度与效率，适用于实时野火预测。",
      "summaryZh": "研究人员提出了一种名为TD-FusionUNet的轻量级深度学习模型，用于次日野火蔓延预测。该模型在U-Net架构中引入可训练的Hadamard变换和离散余弦变换（DCT）层，在正交化潜在空间中捕捉关键“频率”成分，并结合随机边缘裁剪与高斯混合模型等预处理技术，增强对稀疏火灾前掩码的表征能力。在Google Research的Next-Day Wildfire Spread数据集和WildfireSpreadTS数据集上，TD-FusionUNet仅用37万参数即取得0.591的F1分数，优于参数更多的ResNet18编码器U-Net基线，表明其在资源受限环境下兼顾精度与效率，适用于实时野火预测。",
      "summaryEn": "Researchers propose TD-FusionUNet, a lightweight deep learning model for next-day wildfire spread prediction that integrates trainable Hadamard and Discrete Cosine Transform (DCT) layers into a U-Net architecture to capture essential frequency components in orthogonalized latent spaces. Coupled with custom preprocessing—including random margin cropping and a Gaussian mixture model—it enhances representation of sparse pre-fire masks. Evaluated on Google Research’s Next-Day Wildfire Spread and WildfireSpreadTS datasets, TD-FusionUNet achieves an F1 score of 0.591 with only 370k parameters, outperforming a ResNet18-based U-Net baseline while using far fewer parameters, demonstrating a favorable balance of accuracy and efficiency for real-time wildfire forecasting in resource-constrained settings.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Multimodal",
        "3D",
        "Industry",
        "Research"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：开发轻量高效的火灾蔓延预测模型，融合变换域特征与卫星数据，直接服务于全球气候与灾害应急管理，具备重大产业影响力。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T07:45:53+00:00",
      "authors": [
        "Yingyi Luo",
        "Shuaiang Rong",
        "Adam Watts"
      ]
    },
    {
      "id": "arxiv_2602_11653v1",
      "title": "GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction",
      "titleZh": "GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction",
      "titleEn": "GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction",
      "url": "https://arxiv.org/abs/2602.11653v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为解决低剂量全身PET成像中因稀疏采样导致的噪声放大与结构模糊问题，研究者提出GR-Diffusion框架，将三维离散高斯表示（GR）与扩散模型相结合。GR从投影数据生成具有物理依据的参考图像，克服传统点或体素方法的低通限制；该参考图像通过分层引导机制——细粒度差异优化局部细节、粗粒度多尺度差异图校正全局偏差——指导扩散过程，从而恢复亚体素信息。在UDPET和临床数据集上的实验表明，GR-Diffusion在图像质量与生理细节保留方面优于现有最先进方法。",
      "summaryZh": "为解决低剂量全身PET成像中因稀疏采样导致的噪声放大与结构模糊问题，研究者提出GR-Diffusion框架，将三维离散高斯表示（GR）与扩散模型相结合。GR从投影数据生成具有物理依据的参考图像，克服传统点或体素方法的低通限制；该参考图像通过分层引导机制——细粒度差异优化局部细节、粗粒度多尺度差异图校正全局偏差——指导扩散过程，从而恢复亚体素信息。在UDPET和临床数据集上的实验表明，GR-Diffusion在图像质量与生理细节保留方面优于现有最先进方法。",
      "summaryEn": "To address noise amplification and structural blurring in low-dose whole-body PET imaging caused by sparse sampling, researchers propose GR-Diffusion, a framework that synergistically combines 3D discrete Gaussian representation (GR) with diffusion models. GR generates a physically grounded reference image from projection data, overcoming the low-pass limitations of conventional point- or voxel-based methods. This reference guides the diffusion process via a hierarchical mechanism: fine-grained differences refine local details, while coarse-grained multi-scale difference maps correct global deviations, enabling sub-voxel information recovery. Experiments on UDPET and clinical datasets show GR-Diffusion outperforms state-of-the-art methods in image quality and physiological detail preservation.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Diffusion",
        "3D",
        "RAG"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：将3D高斯表示与扩散模型结合用于全身体PET重建，显著提升分子影像质量，有望改变核医学成像范式，具备全球医疗科技影响力。",
        "热度：11 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T07:10:38+00:00",
      "authors": [
        "Mengxiao Geng",
        "Zijie Chen",
        "Ran Hong"
      ]
    },
    {
      "id": "arxiv_2602_11564v1",
      "title": "LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts",
      "titleZh": "LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts",
      "titleEn": "LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts",
      "url": "https://arxiv.org/abs/2602.11564v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对超高清（UHR）视频生成中运动建模、语义规划与细节合成的复合挑战，研究团队提出LUVE框架，采用三阶段级联潜空间架构：先生成低分辨率运动一致的潜变量，再直接在潜空间进行视频上采样以降低计算开销，最后通过低频与高频双专家模块联合优化语义连贯性与精细纹理。实验证明LUVE在UHR视频生成中显著提升照片级真实感与内容保真度，项目代码已开源。",
      "summaryZh": "针对超高清（UHR）视频生成中运动建模、语义规划与细节合成的复合挑战，研究团队提出LUVE框架，采用三阶段级联潜空间架构：先生成低分辨率运动一致的潜变量，再直接在潜空间进行视频上采样以降低计算开销，最后通过低频与高频双专家模块联合优化语义连贯性与精细纹理。实验证明LUVE在UHR视频生成中显著提升照片级真实感与内容保真度，项目代码已开源。",
      "summaryEn": "Addressing the compounded challenges of motion modeling, semantic planning, and detail synthesis in ultra-high-resolution (UHR) video generation, researchers propose LUVE, a latent-cascaded framework with dual frequency experts. It employs a three-stage pipeline: low-resolution motion-consistent latent generation, latent-space video upsampling to reduce computational overhead, and high-resolution refinement via low- and high-frequency expert modules that jointly enhance semantic coherence and fine-grained details. Experiments demonstrate LUVE’s superior photorealism and content fidelity in UHR video generation, with code publicly available.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Diffusion",
        "Open Source"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：LUVE在超高清视频生成领域实现关键突破，采用双频专家架构应对运动建模与细节合成难题，有望推动影视、元宇宙等全球产业变革。",
        "热度：8 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T04:35:16+00:00",
      "authors": [
        "Chen Zhao",
        "Jiawei Chen",
        "Hongyu Li"
      ]
    },
    {
      "id": "arxiv_2602_11862v1",
      "title": "LAMP: Implicit Language Map for Robot Navigation",
      "titleZh": "LAMP: Implicit Language Map for Robot Navigation",
      "titleEn": "LAMP: Implicit Language Map for Robot Navigation",
      "url": "https://arxiv.org/abs/2602.11862v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为克服现有语言导航方法在大型环境中因显式存储语言向量导致的内存膨胀与分辨率不足问题，研究者提出LAMP（Language Map），一种基于隐式神经语言场的机器人导航框架。LAMP将语言特征编码为连续隐式场而非离散网格，并结合稀疏图实现粗路径规划，再通过梯度优化在隐式场中精调目标附近姿态；其贝叶斯不确定性建模（基于von Mises-Fisher分布）提升对未见区域的泛化能力，图采样策略则大幅降低计算开销。在仿真与真实多楼层建筑中的实验表明，LAMP在内存效率和精细目标到达精度上均优于现有方法。",
      "summaryZh": "为克服现有语言导航方法在大型环境中因显式存储语言向量导致的内存膨胀与分辨率不足问题，研究者提出LAMP（Language Map），一种基于隐式神经语言场的机器人导航框架。LAMP将语言特征编码为连续隐式场而非离散网格，并结合稀疏图实现粗路径规划，再通过梯度优化在隐式场中精调目标附近姿态；其贝叶斯不确定性建模（基于von Mises-Fisher分布）提升对未见区域的泛化能力，图采样策略则大幅降低计算开销。在仿真与真实多楼层建筑中的实验表明，LAMP在内存效率和精细目标到达精度上均优于现有方法。",
      "summaryEn": "To overcome memory bloat and limited resolution in large-scale language-guided navigation, researchers introduce LAMP (Language Map), a neural implicit language field framework. Instead of explicitly storing language vectors on grids, LAMP encodes them as a continuous implicit field, enabling coarse path planning via a sparse graph followed by gradient-based pose refinement near goals. A Bayesian uncertainty model based on the von Mises-Fisher distribution improves generalization to unobserved regions, while a graph sampling strategy prioritizing spatial coverage and embedding confidence reduces computational overhead. Experiments in NVIDIA Isaac Sim and a real multi-floor building show LAMP outperforms explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "LLM",
        "Vision",
        "Multimodal",
        "Robotics"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出隐式语言地图实现大规模零样本导航，突破现有显式地图的可扩展性瓶颈，具备行业变革潜力。",
        "热度：17 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T12:09:03+00:00",
      "authors": [
        "Sibaek Lee",
        "Hyeonwoo Yu",
        "Giseop Kim"
      ]
    },
    {
      "id": "arxiv_2602_11934v1",
      "title": "Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control",
      "titleZh": "Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control",
      "titleEn": "Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control",
      "url": "https://arxiv.org/abs/2602.11934v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "研究者指出当前视觉骨干网络因追求语义不变性而缺乏几何敏感性，难以支持毫米级精准的机器人操作。为此提出Robot-DIFT框架，通过流形蒸馏将冻结的扩散模型教师网络中的几何先验知识迁移到确定性的空间-语义特征金字塔网络（S2-FPN）中，在保留生成模型丰富几何结构的同时确保时序稳定性、实时推理与抗微调漂移能力。在DROID大规模数据集上预训练后，Robot-DIFT在几何一致性与控制性能上超越主流判别式基线，验证了“如何看”直接影响“如何行动”的观点。",
      "summaryZh": "研究者指出当前视觉骨干网络因追求语义不变性而缺乏几何敏感性，难以支持毫米级精准的机器人操作。为此提出Robot-DIFT框架，通过流形蒸馏将冻结的扩散模型教师网络中的几何先验知识迁移到确定性的空间-语义特征金字塔网络（S2-FPN）中，在保留生成模型丰富几何结构的同时确保时序稳定性、实时推理与抗微调漂移能力。在DROID大规模数据集上预训练后，Robot-DIFT在几何一致性与控制性能上超越主流判别式基线，验证了“如何看”直接影响“如何行动”的观点。",
      "summaryEn": "Researchers argue that current vision backbones, optimized for semantic invariance, lack the geometric sensitivity needed for millimeter-precise robot manipulation. They propose Robot-DIFT, which uses manifold distillation to transfer geometric priors from a frozen diffusion teacher into a deterministic Spatial-Semantic Feature Pyramid Network (S2-FPN). This preserves the generative model’s dense spatial structure while ensuring temporal stability, real-time inference, and robustness to representation drift. Pretrained on the large-scale DROID dataset, Robot-DIFT surpasses leading discriminative baselines in geometric consistency and control performance, supporting the view that how a model learns to see directly dictates how well it can act.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Robotics",
        "Diffusion",
        "Training"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：提出将扩散特征蒸馏用于视觉-运动控制，解决视觉骨干与物理闭环控制之间的结构不匹配问题，是当前具身智能领域的关键突破。",
        "热度：17 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T13:30:24+00:00",
      "authors": [
        "Yu Deng",
        "Yufeng Jin",
        "Xiaogang Jia"
      ]
    },
    {
      "id": "arxiv_2602_12246v1",
      "title": "6G Empowering Future Robotics: A Vision for Next-Generation Autonomous Systems",
      "titleZh": "6G Empowering Future Robotics: A Vision for Next-Generation Autonomous Systems",
      "titleEn": "6G Empowering Future Robotics: A Vision for Next-Generation Autonomous Systems",
      "url": "https://arxiv.org/abs/2602.12246v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "论文系统探讨6G（IMT-2030）如何赋能未来机器人系统，将6G关键性能指标映射到机器人感知、认知、执行与自学习等核心功能模块，并提出融合机器人、智能与网络服务平面的高层架构。作为应用示例，作者展示了基于6G能力的实时动态安全框架，可在人机共享空间中实现高效协作，凸显6G对构建下一代自主系统的基础设施作用。",
      "summaryZh": "论文系统探讨6G（IMT-2030）如何赋能未来机器人系统，将6G关键性能指标映射到机器人感知、认知、执行与自学习等核心功能模块，并提出融合机器人、智能与网络服务平面的高层架构。作为应用示例，作者展示了基于6G能力的实时动态安全框架，可在人机共享空间中实现高效协作，凸显6G对构建下一代自主系统的基础设施作用。",
      "summaryEn": "This paper systematically explores how 6G (IMT-2030) empowers future robotics by mapping its key performance indicators to core robotic functional blocks—sensing, perception, cognition, actuation, and self-learning—and proposes a high-level architecture integrating robotic, intelligent, and network service planes. As a use case, the authors demonstrate a real-time dynamic safety framework enabled by 6G capabilities for efficient human-robot collaboration in shared spaces, highlighting 6G’s foundational role in next-generation autonomous systems.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Vision",
        "Robotics",
        "Research"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：前瞻性探讨6G与机器人融合的未来愿景，为下一代自主系统提供通信基础设施蓝图，具有全球战略意义和产业引领性。",
        "热度：10 / 评论 0"
      ],
      "score": 9.0,
      "publishedAt": "2026-02-12T18:31:24+00:00",
      "authors": [
        "Mona Ghassemian",
        "Andrés Meseguer Valenzuela",
        "Ana Garcia Armada"
      ]
    },
    {
      "id": "arxiv_2602_11919v1",
      "title": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target",
      "titleZh": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target",
      "titleEn": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target",
      "url": "https://arxiv.org/abs/2602.11919v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对现有手-物交互（HOI）基准多聚焦静态物体、忽视动态目标协调的局限，研究者发布DynaHOI-Gym平台及DynaHOI-10M大规模基准数据集，包含1000万帧、18万条手部轨迹，覆盖8大类22子类动态目标运动。同时提出ObAct基线方法，通过时空注意力融合短期观测与当前帧，在位置成功率上提升8.1%，为动态HOI研究提供统一评估标准与新起点。",
      "summaryZh": "针对现有手-物交互（HOI）基准多聚焦静态物体、忽视动态目标协调的局限，研究者发布DynaHOI-Gym平台及DynaHOI-10M大规模基准数据集，包含1000万帧、18万条手部轨迹，覆盖8大类22子类动态目标运动。同时提出ObAct基线方法，通过时空注意力融合短期观测与当前帧，在位置成功率上提升8.1%，为动态HOI研究提供统一评估标准与新起点。",
      "summaryEn": "Addressing the limitation of existing hand-object interaction (HOI) benchmarks that focus on static objects and neglect dynamic targets, researchers introduce DynaHOI-Gym—a unified closed-loop platform—and release DynaHOI-10M, a large-scale benchmark with 10 million frames and 180K hand trajectories across 8 major categories and 22 fine-grained subcategories of dynamic target motions. They also propose ObAct, a simple baseline that integrates short-term observations with the current frame via spatiotemporal attention, achieving an 8.1% improvement in location success rate, establishing a new foundation for dynamic HOI research.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Benchmark"
      ],
      "paperCategory": "Computer Vision",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：构建首个面向动态目标的手-物交互生成基准，填补了人机交互中动态协调评估的空白，推动具身智能发展。",
        "热度：10 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-12T13:19:41+00:00",
      "authors": [
        "BoCheng Hu",
        "Zhonghan Zhao",
        "Kaiyue Zhou"
      ]
    },
    {
      "id": "arxiv_2602_11758v1",
      "title": "HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model",
      "titleZh": "HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model",
      "titleEn": "HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model",
      "url": "https://arxiv.org/abs/2602.11758v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对人形机器人与欠驱动物体（如滑板、手推车）交互时因独立动力学与非完整约束带来的控制难题，研究者提出HAIC框架，无需外部状态估计即可实现鲁棒操作。其核心是仅基于本体感知历史的动力学预测器，可估计物体高阶状态（速度、加速度），并结合几何先验生成动态占据地图，使策略能推断遮挡区域的碰撞边界与接触可能性；通过世界模型与策略的不对称微调，HAIC在滑板、负重推拉及跨地形搬运等任务中表现出高成功率，验证了其对复杂物体动力学的主动补偿能力。",
      "summaryZh": "针对人形机器人与欠驱动物体（如滑板、手推车）交互时因独立动力学与非完整约束带来的控制难题，研究者提出HAIC框架，无需外部状态估计即可实现鲁棒操作。其核心是仅基于本体感知历史的动力学预测器，可估计物体高阶状态（速度、加速度），并结合几何先验生成动态占据地图，使策略能推断遮挡区域的碰撞边界与接触可能性；通过世界模型与策略的不对称微调，HAIC在滑板、负重推拉及跨地形搬运等任务中表现出高成功率，验证了其对复杂物体动力学的主动补偿能力。",
      "summaryEn": "To tackle control challenges in humanoid interaction with underactuated objects (e.g., skateboards, carts) governed by independent dynamics and non-holonomic constraints, researchers propose HAIC, a framework that achieves robust manipulation without external state estimation. Its core is a dynamics predictor that estimates high-order object states (velocity, acceleration) solely from proprioceptive history; these are projected onto geometric priors to form a dynamic occupancy map, enabling the policy to infer collision boundaries and contact affordances in occluded regions. Using asymmetric fine-tuning between a world model and policy, HAIC demonstrates high success rates in agile tasks like skateboarding and cart pushing/pulling under varying loads, as well as long-horizon multi-object tasks such as box carrying across uneven terrain, showcasing proactive compensation for inertial perturbations.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "Training"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：针对非完整驱动物体的具身控制问题提出动态感知世界模型，推动人形机器人在复杂交互中的能力边界。",
        "热度：11 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-12T09:34:35+00:00",
      "authors": [
        "Dongting Li",
        "Xingyu Chen",
        "Qianyang Wu"
      ]
    },
    {
      "id": "arxiv_2602_11468v1",
      "title": "Effective Task Planning with Missing Objects using Learning-Informed Object Search",
      "titleZh": "Effective Task Planning with Missing Objects using Learning-Informed Object Search",
      "titleEn": "Effective Task Planning with Missing Objects using Learning-Informed Object Search",
      "url": "https://arxiv.org/abs/2602.11468v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "针对移动机器人任务规划中常因关键物体位置未知而失效的问题，该研究提出一种融合学习驱动对象搜索的规划框架，引入新型基于模型的LIOS动作（每个动作对应一个用于查找并取回单一物体的策略），在高层规划中将其视为确定性操作，并结合预期成本计算，生成能交错执行搜索与任务动作的完整计划；该方法在保持与现有全知求解器兼容的同时，有效处理环境不确定性，在ProcTHOR仿真家庭和真实世界中的物品取回与备餐任务上均优于非学习及学习型基线。",
      "summaryZh": "针对移动机器人任务规划中常因关键物体位置未知而失效的问题，该研究提出一种融合学习驱动对象搜索的规划框架，引入新型基于模型的LIOS动作（每个动作对应一个用于查找并取回单一物体的策略），在高层规划中将其视为确定性操作，并结合预期成本计算，生成能交错执行搜索与任务动作的完整计划；该方法在保持与现有全知求解器兼容的同时，有效处理环境不确定性，在ProcTHOR仿真家庭和真实世界中的物品取回与备餐任务上均优于非学习及学习型基线。",
      "summaryEn": "Addressing the failure of mobile robot task planners when critical object locations are unknown, this work introduces a planning framework integrating learning-driven object search via novel model-based LIOS actions—each a policy to find and retrieve a single object. High-level planning treats LIOS actions as deterministic and interleaves search with execution based on expected cost estimates, enabling sound, complete, and effective task planning under uncertainty while remaining compatible with full-knowledge solvers. The approach outperforms both non-learned and learned baselines in retrieval and meal-prep tasks in simulated ProcTHOR homes and real-world settings.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "RAG"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：融合学习驱动搜索与任务规划，解决未知物体下的任务执行难题，对移动机器人自主性有实质性提升。",
        "热度：11 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-12T00:56:35+00:00",
      "authors": [
        "Raihan Islam Arnob",
        "Max Merlin",
        "Abhishek Paudel"
      ]
    },
    {
      "id": "arxiv_2602_12012v1",
      "title": "Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario",
      "titleZh": "Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario",
      "titleEn": "Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario",
      "url": "https://arxiv.org/abs/2602.12012v1",
      "type": "paper",
      "source": "arXiv",
      "summary": "为提升海上环境中自主空中-水面机器人团队对漂浮集装箱的感知能力，该研究提出一种去中心化多机器人检测与跟踪框架：各无人机采用YOLOv8与立体视差进行视觉检测，并通过面向对象的扩展卡尔曼滤波器（EKF）实现不确定性感知的数据关联；系统通过协方差交集保守融合各机传输的紧凑轨迹摘要以应对通信受限与未知相关性，并引入信息驱动的目标分配机制，在降低飞行能耗与保障安全间距的同时优化观测视角；仿真结果表明，该方法在保持低通信开销的前提下显著提升了覆盖范围、定位精度与跟踪一致性。",
      "summaryZh": "为提升海上环境中自主空中-水面机器人团队对漂浮集装箱的感知能力，该研究提出一种去中心化多机器人检测与跟踪框架：各无人机采用YOLOv8与立体视差进行视觉检测，并通过面向对象的扩展卡尔曼滤波器（EKF）实现不确定性感知的数据关联；系统通过协方差交集保守融合各机传输的紧凑轨迹摘要以应对通信受限与未知相关性，并引入信息驱动的目标分配机制，在降低飞行能耗与保障安全间距的同时优化观测视角；仿真结果表明，该方法在保持低通信开销的前提下显著提升了覆盖范围、定位精度与跟踪一致性。",
      "summaryEn": "To enhance perception for autonomous aerial-surface robot teams monitoring maritime environments, this work presents a decentralized multi-robot framework for detecting and tracking floating containers. Each UAV uses YOLOv8 and stereo disparity for visual detection and tracks objects with per-object EKFs via uncertainty-aware data association. Compact track summaries are conservatively fused using covariance intersection to handle unknown correlations under limited communication. An information-driven assignment module optimizes UAV hover viewpoints by balancing expected uncertainty reduction against travel cost and safety separation. Simulations show improved coverage, localization accuracy, and tracking consistency with modest communication requirements.",
      "fullText": "",
      "imageUrl": "",
      "tags": [
        "Robotics",
        "RAG"
      ],
      "paperCategory": "Robotics",
      "signalReasons": [
        "来源：arXiv",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：基于AIS数据的轨迹补全方法，为海事安全与物流优化提供关键技术支持，具备全球应用前景。",
        "热度：8 / 评论 0"
      ],
      "score": 8.0,
      "publishedAt": "2026-02-12T14:42:17+00:00",
      "authors": [
        "Muhammad Farhan Ahmed",
        "Vincent Frémont"
      ]
    }
  ],
  "news": [
    {
      "id": "hn_47012187",
      "title": "字节跳动发布Seed2.0大模型，突破复杂现实任务执行能力",
      "titleZh": "字节跳动发布Seed2.0大模型，突破复杂现实任务执行能力",
      "titleEn": "ByteDance Launches Seed2.0 LLM Series, Breaking New Ground in Complex Real-World Task Execution",
      "url": "https://seed.bytedance.com/en/blog/seed2-0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83",
      "type": "news",
      "source": "Hacker News",
      "summary": "**字节跳动Seed团队正式发布Seed2.0大模型系列**，该系列通过强化多模态理解、复杂指令遵循与长程任务执行能力，显著提升在真实复杂场景（如科研探索、软件开发、非结构化文档处理）中的表现；Seed2.0在MathVista、ChartQAPro、MMLongBench等数十项基准测试中达到业界顶尖水平，甚至在EgoTempo视频理解任务中超越人类分数，并能生成具备可执行性的跨学科实验方案；其Pro与Code版本已在豆包App和TRAE上线，API同步开放于火山引擎，**普通用户可通过指定入口体验其在客服、教育、科研辅助等高价值任务中的能力，同时企业可利用其低成本、高精度特性部署生产级AI应用**。",
      "summaryZh": "**字节跳动Seed团队正式发布Seed2.0大模型系列**，该系列通过强化多模态理解、复杂指令遵循与长程任务执行能力，显著提升在真实复杂场景（如科研探索、软件开发、非结构化文档处理）中的表现；Seed2.0在MathVista、ChartQAPro、MMLongBench等数十项基准测试中达到业界顶尖水平，甚至在EgoTempo视频理解任务中超越人类分数，并能生成具备可执行性的跨学科实验方案；其Pro与Code版本已在豆包App和TRAE上线，API同步开放于火山引擎，**普通用户可通过指定入口体验其在客服、教育、科研辅助等高价值任务中的能力，同时企业可利用其低成本、高精度特性部署生产级AI应用**。",
      "summaryEn": "ByteDance’s Seed team has officially launched the Seed2.0 large language model series, which significantly enhances performance in real-world complex tasks—including scientific research, software development, and unstructured document processing—through improved multimodal understanding, complex instruction following, and long-horizon task execution. Seed2.0 achieves state-of-the-art results across dozens of benchmarks such as MathVista, ChartQAPro, and MMLongBench, even surpassing human scores on the EgoTempo video understanding task, and can generate executable cross-disciplinary experimental protocols. The Pro and Code variants are now available in the Doubao app and TRAE, with APIs accessible via Volcano Engine, enabling users to experience its capabilities in high-value scenarios like customer service, education, and research assistance, while enterprises can deploy production-grade AI applications leveraging its low cost and high accuracy.",
      "fullText": "Seed News - ByteDance Seed Team Home Models Blog & Publication Join Us EN 中文 Home Models Blog & Publication Join Us Seed2.0 正式发布 Seed2.0 正式发布 Date 2026-02-14 Category Models 大语言模型驱动的产品已深刻融入我们的生活。过去一年多，Seed 开发的 LLM 模 型系列已支持豆包等拥有上亿用户的 C 端产品，同时，我们也注意到，随着 Agent 时代到来，LLM 将在现实世界的复杂任务中发挥更大作用：比如参与科学研究， 支持复杂软件开发，LLM 甚至可以基于上下文自主学习，完成各类具有经济价值的任务。 在这个关键节点，我们很荣幸地介绍 最新 Seed2.0 系列 ，它们围绕大规模生产环境下的使用需求做了系统性优化， 旨在帮助突破真实世界中的复杂任务 。 通过分析 Seed 通用模型在 MaaS 服务中的调用情况，我们发现，最高比例的需求为处理混杂图表、文档等非 结构化信息的知识内容，企业往往要求模型先做“读得多、想得多”的任务，再进入复杂且专业的 流程型工作 ，对模型的长内容理解和多步任务执行能力要求越来越高。 Seed 通用模型 MaaS 服务在中国陆的调用场景分布，数据来自“火山方舟协作奖励计划”，相关用户已签署授权协议 基于真实使用场景，Seed2.0 系列重点在以下方面进行了优化： 更稳健的视觉与多 模态 理解： Seed2.0 强化了视觉感知与推理能力，对复杂文档、表格、图形、视频内容的解析水平显著提升，视觉信息处理更精准。 更可靠的复杂指令执行： Seed2.0 提升了指令遵循和推理表现，并强化了对多约束、多步骤、长链路任务的理解与执行能力，已具备支撑高价值任务的能力基础。 更快速、更灵活的推理选择： Seed2.0 提供 Pro、Lite、Mini 三款不同尺寸的通用 Agent 模型，以及专门的 Code 模型，覆盖不同的场景需求，供企业和开发者选择。 除了更好地支持生产级需求，Seed2.0 还致力于提升模型智能上限。 目前，Seed2.0 已能从解决奥林匹克竞赛类问题迈向支持研究级的推理任务。比如， Seed2.0 可尝试探索埃尔德什级别的数学问题，也可完成部分科学相关任务的编程工作，进一步突破机器智能的边界。 Seed2.0 Pro 和 Code 模型已分别在豆包 App 和 TRAE 上线，同时，Seed2.0 全系列模型 API 已同步上线火山引擎，欢迎大家体验、反馈。 项目主页（含Model Card）： https://seed.bytedance.com/zh/seed2 体验入口： 1）豆包App-选择“专家”模式-开启对话； 2）TRAE-在“内置模型”中选择“Doubao-Seed-2.0-Code”。 多 模态 理解能力全面升级 大部分基准达 SOTA 水 平 Seed2.0 全面升级了多模态能力， 在各类视觉理解任务上均达到业界顶尖水平 ，其视觉推理、感知能力、空间推理与长上下文理解能力表现尤为突出，Seed2.0 Pro 在大多数相关基准测试中取得了最高分数。 在数学与视觉推理方面，Seed2.0 Pro 在 MathVista、MathVision、MathKangaroo、MathCanvas 等数学推理基准上达到业界最优水平。同时，在 LogicVista、VisuLogic 等视觉解谜与逻辑推理基准上，Seed2.0 Pro 得分较 Seed1.8 显著提升。 标注 * 的数据引自公开技术报告 Seed2.0 的视觉感知能力进一步升级。在 VLMsAreBiased、VLMsAreBlind、BabyVision 等基准中，Seed2.0 取得了业界最高分，说明它在面对不同类型的视觉输入时，仍能保持准确且可信的感知和判断能力。 标注 * 的数据引自公开技术报告 视觉理解基础能力的进步，让 Seed2.0 在真实应用场景中的表现大幅提升。在文档理解中，模型面对的往往不是标准的数据输入，而是复杂版式混排的原始材料。相比 Seed1.8，Seed2.0 处理非结构化信息的能力显著强化，其在 ChartQAPro 与 OmniDocBench 1.5 基准上达到顶尖模型水准。 同时，在长上下文理解方面，Seed2.0 在 DUDE、MMLongBench 与 MMLongBench‑Doc 上均取得业界最佳分数。 标注 * 的数据引自公开技术报告 面对视频场景，Seed2.0 强化了对时间序列与运动感知的理解能力，在 TVBench、TempCompass、MotionBench 等关键测评中处于领先位置，且在 EgoTempo 基准上超过了人类分数，表明它对“变化、动作、节奏”这类信息的捕捉更为稳定，在工程侧可用性更高。 标注 * 的数据引自公开技术报告 长视频场景中，Seed2.0 在大部分评测上超越了其他顶尖模型。其可以高效准确地处理小时级别的长视频，此外，视频工具 VideoCut 进一步提高了长视频处理的时长范围，并提升了推理精度。 在视频长、信息杂的企业真实部署场景中，Seed2.0 可帮助快速捕捉视频关键信息，准确地输出用于下游决策的结论。 同时，Seed2.0 在多个流式实时问答视频基准测试中表现优异，能作为 AI 助手完成实时视频流分析、环境感知、主动纠错与情感陪伴，实现从被动问答到主动指导的交互升级，可应用于健身、穿搭等陪伴场景。 标注 * 的数据引自公开技术报告 LLM 与 Agent 表现大幅强化 真实长程任务执行能力提升 Seed 团队观察到一个典型失衡：语言模型已经可以顺利解决竞赛难题，但放在真实世界中，它们依然很难端到端地完成实际任务——比如一次性构建一个设计精良、功能完整的小程序。 LLM 和 Agent 为什么在处理现实问题时屡屡碰壁？我们认为，原因主要来自两点： 真实世界任务往往跨越更长时间尺度、包含多个阶段，而现有 LLM Agent 难以自主构建高效工作流，并在长时间跨度中积累经验； 真实世界知识具有很强的领域壁垒且呈长尾分布，各行业的经验不在训练语料的高频区，导致即便模型擅长数学与代码，其在专业场景中往往价值有限。 Seed2.0 首先通过 系统性加强长尾领域知识 来应对这一难题。Seed2.0 Pro 在 SuperGPQA 上分数超过 GPT-5.2，其在科学领域的整体成绩与 Gemini 3 Pro 和 GPT-5.2 保持相当水平。 此外，Seed2.0 Pro 在跨学科知识应用上的能力显著增强，其在 FrontierSci 等 STEM 基准测试中表现突出，部分场景得分超过 Gemini 3 Pro。同时，Seed2.0 Pro 在 ICPC、IMO、 CMO 测试中均获得金牌成绩，说明模型在数学、代码及推理智能方面进一步提升。 Seed2.0 还重点强化了指令遵循能力。相关评测显示，Seed2.0 可保持较强的一致性与可控性，这为其作为 Agent 模型在长链路、多步骤任务中严格按约束条件执行奠定基础。 从基础 Agent 能力的得分来看， Seed2.0 在长链路任务中表现突出 ，尤其擅长连续完成“找资料、做归纳、写结论”等连续工作流。 搜索与深度研究任务中，Seed2.0 在 BrowseComp-zh、HLE-text 等七项评测上均取得较高分数，展现出在研究型任务里的推进能力与稳定性。 在复杂 Agent 能力评估中，Seed2.0 达到业界第一梯队水平。比如，在具备直接经济价值的现实任务评测中，Seed2.0 在客服问答、信息抽取、意图识别、中小学阶段问题解答等高频用户场景上表现稳定；在 GDPVal-Diamond、XPert Bench 等复杂专业任务基准上，模型同样取得了有竞争力的结果，说明它可以胜任长链路、多约束查询任务。 同时，Seed2.0 Pro 在 FrontierSci‑research 等前沿科研基准上表现强劲，并在 AInstein Bench 上领先，体现出在科学发现场景中较强的假设驱动式推理能力。 此外，Seed2.0 还能把“研究想法”推进到“形成可落地的实验方案”。 以高尔基体蛋白分析为例，它不仅能给出总体实验路线，还能把基因工程、小鼠模型构建、亚细胞分离与多组学分析串成一条完整流程，细化到关键环节怎么做、用什么进行对照以排除污染、用哪些指标评估纯度。相关领域专家表示，Seed2.0 给出的方案，在跨学科的实验细节与步骤化表达上，超出了他们对大模型的预期，其回答不止停留在策略层面，而是能产出结构清晰、科学上相对可靠，且具有可执行性的实验草案。 在提升了长程任务执行能力的同时，Seed2.0 还进一步降低了推理成本。 其模型效果与业界顶尖大模型相当，同时 token 定价降低了约一个数量级。在现实世界的复杂任务中，由于大规模推理与长链路生成将消耗大量 token，这一成本优势将变得更为关键。 *关于评测基准的详细介绍，以及 Seed2.0 的更多真实用例，可以参见模型 Model Card。 总结与展望 针对企业与用户的真实需求及使用场景，我们筛选和搭建了一系列评测基准，用于构建适用于大语言模型的评估体系。 依托这套可靠且具有前瞻性的评估体系，Seed2.0 强化了多模态理解与推理能力，并致力于解决长尾知识与复杂指令遵循问题，从而提升模型在复杂、长周期现实任务中的可靠性。在针对真实应用场景中的评测中，Seed2.0 表现出色，达到业界第一梯队水平，且已表现出支持科学研究级任务的潜力。 同时，我们也观察到，Seed2.0 在端到端整体代码生成、上下文学习方面取得了明显进步，不过在部分高难基准上，其与国际领先模型相比仍有提升空间。未来，我们将继续面向真实场景迭代 Seed 语言模型，不断提高其智能上限。 Models Seed1.8 Seed1.5-VL Seedance 1.5 pro Seedream 4.5 Seed LiveInterpret 2.0 Seed Realtime Voice Seed Music Teams LLM Infrastructures Vision Speech Multimodal Interaction & World Model AI for Science Robotics Responsible AI Learn More Models Research Join Us Top Seed Seed Edge Models Seed1.8 Seed1.5-VL Seedance 1.5 pro Seedream 4.5 Seed LiveInterpret 2.0 Seed Realtime Voice Seed Music Teams LLM Infrastructures Vision Speech Multimodal Interaction & World Model AI for Science Robotics Responsible AI Learn More Models Research Join Us Top Seed Seed Edge Advancing the frontier of intelligence, in service of humanity Join ByteDance Seed Copyright © 2026 Bytedance Seed Disclaimer Contact us : seed.feedback@bytedance.com Join ByteDance Seed Copyright © 2026 Bytedance Seed Disclaimer",
      "imageUrl": "https://lf3-static.bytednsdoc.com/obj/eden-cn/lapzild-tss/ljhwZthlaukjlkulzlp/user-upload/4og2ymllvgeeg.jpg",
      "tags": [
        "LLM"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源权威：官方/白名单",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：Seed2.0 系列针对真实世界复杂任务的多模态理解与长链推理能力实现系统性突破，具备全球产业级应用潜力，推动 Agent 时代落地，符合战略级影响力标准。",
        "热度：11 / 评论 8"
      ],
      "score": 8.09,
      "publishedAt": "2026-02-14T06:34:01+00:00",
      "authors": [
        "cyp0633"
      ]
    },
    {
      "id": "github_rowboatlabs_rowboat",
      "title": "开源AI协作者Rowboat上线，支持长期记忆交互",
      "titleZh": "开源AI协作者Rowboat上线，支持长期记忆交互",
      "titleEn": "Open-Source AI Coworker Rowboat Launches with Persistent Memory",
      "url": "https://github.com/rowboatlabs/rowboat",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**开源项目rowboatlabs/rowboat推出了一款具备记忆能力的AI协作者工具**，允许开发者将AI集成到工作流中并保留上下文记忆，从而支持更连贯、个性化的协作体验；该项目的意义在于推动AI从一次性问答工具向长期交互式智能体演进，**普通开发者可直接部署该工具以构建具有记忆功能的自动化助手，提升日常编码或任务管理效率**。",
      "summaryZh": "**开源项目rowboatlabs/rowboat推出了一款具备记忆能力的AI协作者工具**，允许开发者将AI集成到工作流中并保留上下文记忆，从而支持更连贯、个性化的协作体验；该项目的意义在于推动AI从一次性问答工具向长期交互式智能体演进，**普通开发者可直接部署该工具以构建具有记忆功能的自动化助手，提升日常编码或任务管理效率**。",
      "summaryEn": "The open-source project rowboatlabs/rowboat introduces an AI coworker with memory, enabling developers to integrate AI into workflows while retaining contextual memory for more coherent and personalized collaboration. This advancement marks a shift from one-off AI assistants toward persistent, interactive agents. Developers can directly deploy this tool to build memory-enabled automation assistants, enhancing productivity in coding and task management.",
      "fullText": "",
      "imageUrl": "https://private-user-images.githubusercontent.com/6592213/547591215-fc463b99-01b3-401c-b4a4-044dad480901.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NzExMTIyOTksIm5iZiI6MTc3MTExMTk5OSwicGF0aCI6Ii82NTkyMjEzLzU0NzU5MTIxNS1mYzQ2M2I5OS0wMWIzLTQwMWMtYjRhNC0wNDRkYWQ0ODA5MDEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDIxNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAyMTRUMjMzMzE5WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NzdkOWFjZTEzMGE1Y2UxNTQ4NmRjYTUwYWJmZjFhZDViMzg5MWVmZjYyZGRlMTM3OTAxOTgwMWNjM2YwZDkwMSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.dfVzPjv0uWx5sUW-3IN6vJUadFVVxyjP54IBWeTqR_A",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：开源带记忆的AI协作者，代表AI Agent向自主工作流演进的关键一步，具备行业变革潜力，已获广泛社区关注。",
        "热度：5994 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-14T23:33:19.376317+00:00",
      "authors": []
    },
    {
      "id": "github_Zipstack_unstract",
      "title": "Unstract推出无代码平台，一键结构化非结构化文档",
      "titleZh": "Unstract推出无代码平台，一键结构化非结构化文档",
      "titleEn": "Unstract Launches No-Code Platform to Structure Unstructured Documents with One Click",
      "url": "https://github.com/Zipstack/unstract",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Zipstack/unstract发布了一个无代码LLM平台，允许用户通过图形界面快速构建API和ETL流水线，用于结构化处理非结构化文档（如PDF、扫描件等）**；该工具降低了企业利用大模型处理文档数据的技术门槛，**普通业务人员无需编程即可将杂乱文档转化为结构化数据，加速信息提取与决策流程**，对金融、法律、医疗等文档密集型行业具有实用价值。",
      "summaryZh": "**Zipstack/unstract发布了一个无代码LLM平台，允许用户通过图形界面快速构建API和ETL流水线，用于结构化处理非结构化文档（如PDF、扫描件等）**；该工具降低了企业利用大模型处理文档数据的技术门槛，**普通业务人员无需编程即可将杂乱文档转化为结构化数据，加速信息提取与决策流程**，对金融、法律、医疗等文档密集型行业具有实用价值。",
      "summaryEn": "Zipstack/unstract has released a no-code LLM platform that enables users to visually build APIs and ETL pipelines to structure unstructured documents like PDFs and scanned files. By lowering the technical barrier for enterprises to leverage LLMs in document processing, the tool empowers non-technical staff to convert messy documents into structured data without coding, accelerating information extraction and decision-making—particularly valuable in document-intensive sectors like finance, legal, and healthcare.",
      "fullText": "",
      "imageUrl": "https://repository-images.githubusercontent.com/761150311/9bd8d8f4-848f-4aeb-8fd1-6d917ba89943",
      "tags": [
        "LLM"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：无代码LLM平台实现文档结构化自动化，极大降低企业数据处理门槛，具备广泛商业应用前景和行业颠覆潜力。",
        "热度：6295 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-14T23:33:22.817152+00:00",
      "authors": []
    },
    {
      "id": "github_letta-ai_letta-code",
      "title": "Letta推出记忆优先的AI编程智能体",
      "titleZh": "Letta推出记忆优先的AI编程智能体",
      "titleEn": "Letta Launches Memory-First AI Coding Agent",
      "url": "https://github.com/letta-ai/letta-code",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Letta-AI推出‘memory-first coding agent’（letta-ai/letta-code）**，该智能体优先利用长期记忆存储和复用代码上下文，以提升在复杂软件开发任务中的连贯性与准确性；这一设计有助于解决当前AI编程助手在多文件、长周期项目中上下文丢失的问题，**开发者可将其集成到IDE中，获得更稳定、上下文感知的代码生成与调试支持**，推动AI编程从片段补全迈向全流程辅助。",
      "summaryZh": "**Letta-AI推出‘memory-first coding agent’（letta-ai/letta-code）**，该智能体优先利用长期记忆存储和复用代码上下文，以提升在复杂软件开发任务中的连贯性与准确性；这一设计有助于解决当前AI编程助手在多文件、长周期项目中上下文丢失的问题，**开发者可将其集成到IDE中，获得更稳定、上下文感知的代码生成与调试支持**，推动AI编程从片段补全迈向全流程辅助。",
      "summaryEn": "Letta-AI has introduced 'letta-ai/letta-code', a memory-first coding agent that prioritizes storing and reusing code context in long-term memory to improve coherence and accuracy in complex software development tasks. This design addresses the common issue of context loss in multi-file, long-horizon projects faced by current AI coding assistants. Developers can integrate it into their IDEs to gain more stable, context-aware code generation and debugging support, advancing AI programming from snippet completion toward full workflow assistance.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/13c8eb484bc35ca5dabe0199bf0a11e09896b0213c1d622258d5f1e059c18b95/letta-ai/letta-code",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：以记忆为核心的编程Agent，标志着AI从辅助工具向可长期协作的智能体演进，对软件开发范式有深远影响。",
        "热度：1199 / 评论 0"
      ],
      "score": 7.8,
      "publishedAt": "2026-02-14T23:33:24.258298+00:00",
      "authors": []
    },
    {
      "id": "github_SynkraAI_aios-core",
      "title": "SynkraAI发布AIOS Core v4.0，支持全栈AI应用自动编排",
      "titleZh": "SynkraAI发布AIOS Core v4.0，支持全栈AI应用自动编排",
      "titleEn": "SynkraAI Releases AIOS Core v4.0 for Full-Stack AI Application Orchestration",
      "url": "https://github.com/SynkraAI/aios-core",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**SynkraAI发布AIOS Core v4.0——一个面向全栈开发的AI编排系统核心框架**，旨在通过统一调度AI模型、工具与数据流，自动化前端、后端、数据库等全链路开发任务；该框架为构建端到端AI原生应用提供基础设施，**开发者可基于此快速搭建具备自主规划与执行能力的AI应用，显著缩短产品原型到部署的周期**，标志着AI工程化向系统级集成迈出关键一步。",
      "summaryZh": "**SynkraAI发布AIOS Core v4.0——一个面向全栈开发的AI编排系统核心框架**，旨在通过统一调度AI模型、工具与数据流，自动化前端、后端、数据库等全链路开发任务；该框架为构建端到端AI原生应用提供基础设施，**开发者可基于此快速搭建具备自主规划与执行能力的AI应用，显著缩短产品原型到部署的周期**，标志着AI工程化向系统级集成迈出关键一步。",
      "summaryEn": "SynkraAI has released AIOS Core v4.0, a core framework for an AI-orchestrated system designed to automate full-stack development—including frontend, backend, and database tasks—by unifying the scheduling of AI models, tools, and data flows. This infrastructure enables end-to-end AI-native application development, allowing developers to rapidly build AI applications with autonomous planning and execution capabilities, drastically shortening the path from prototype to deployment and marking a key step toward system-level AI engineering.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/23e436a55e28934c4c42bd1cc56378c98a57004cbb75bf0c78f524c83b029ef0/SynkraAI/aios-core",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：AI驱动全栈开发框架v4.0发布，体现AI工程化能力跃升，具备显著技术进步和主流开发者关注潜力。",
        "热度：596 / 评论 0"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-14T23:33:17.813266+00:00",
      "authors": []
    },
    {
      "id": "github_ChromeDevTools_chrome-devtools-mcp",
      "title": "Chrome DevTools推出AI编程智能体专用调试工具",
      "titleZh": "Chrome DevTools推出AI编程智能体专用调试工具",
      "titleEn": "Chrome DevTools Launches Dedicated Debugger for AI Coding Agents",
      "url": "https://github.com/ChromeDevTools/chrome-devtools-mcp",
      "type": "news",
      "source": "GitHub Trending",
      "summary": "**Chrome DevTools团队推出专为AI编程智能体设计的调试工具chrome-devtools-mcp**，使开发者能像调试传统程序一样监控、干预和优化AI代理的代码生成与执行过程；该工具填补了AI Agent开发中可观测性与可控性的空白，**普通开发者未来可在浏览器中直接调试AI生成的代码逻辑，提升智能体的可靠性与可维护性**，推动AI编程从黑盒走向透明化工程实践。",
      "summaryZh": "**Chrome DevTools团队推出专为AI编程智能体设计的调试工具chrome-devtools-mcp**，使开发者能像调试传统程序一样监控、干预和优化AI代理的代码生成与执行过程；该工具填补了AI Agent开发中可观测性与可控性的空白，**普通开发者未来可在浏览器中直接调试AI生成的代码逻辑，提升智能体的可靠性与可维护性**，推动AI编程从黑盒走向透明化工程实践。",
      "summaryEn": "The Chrome DevTools team has launched chrome-devtools-mcp, a debugging tool specifically designed for AI coding agents, enabling developers to monitor, intervene, and optimize AI-generated code execution just as they would with traditional programs. This tool addresses the critical gap in observability and controllability in AI agent development. In the future, developers will be able to debug AI-generated code logic directly in the browser, improving agent reliability and maintainability and advancing AI programming from black-box experimentation toward transparent engineering practices.",
      "fullText": "",
      "imageUrl": "https://opengraph.githubassets.com/6ccea82f934633aefbad433e1010ad76c7b937c1d6b0a79420f8f763de48d85e/ChromeDevTools/chrome-devtools-mcp",
      "tags": [
        "Agent"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：GitHub Trending",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：Chrome DevTools集成AI编码代理，将AI能力深度嵌入开发环境，是开发者体验升级的重要里程碑。",
        "热度：25072 / 评论 0"
      ],
      "score": 7.2,
      "publishedAt": "2026-02-14T23:33:20.680647+00:00",
      "authors": []
    },
    {
      "id": "hn_47017138",
      "title": "多家新闻机构限制互联网档案馆访问以防AI抓取",
      "titleZh": "多家新闻机构限制互联网档案馆访问以防AI抓取",
      "titleEn": "News Publishers Restrict Internet Archive Access Over AI Scraping Fears",
      "url": "https://www.niemanlab.org/2026/01/news-publishers-limit-internet-archive-access-due-to-ai-scraping-concerns/",
      "type": "news",
      "source": "Hacker News",
      "summary": "《卫报》《纽约时报》等多家新闻出版商正限制互联网档案馆（Internet Archive）对其内容的抓取，以防止AI公司通过其Wayback Machine或API批量获取受版权保护的新闻内容用于模型训练；此举凸显了在AI训练数据需求激增背景下，传统媒体对知识产权保护的紧迫性，也使本意为保存网络历史的非营利数字图书馆陷入“被滥用”困境；普通用户未来可能面临历史网页存档减少的问题，而出版商则需在开放存档与内容安全之间重新权衡。",
      "summaryZh": "《卫报》《纽约时报》等多家新闻出版商正限制互联网档案馆（Internet Archive）对其内容的抓取，以防止AI公司通过其Wayback Machine或API批量获取受版权保护的新闻内容用于模型训练；此举凸显了在AI训练数据需求激增背景下，传统媒体对知识产权保护的紧迫性，也使本意为保存网络历史的非营利数字图书馆陷入“被滥用”困境；普通用户未来可能面临历史网页存档减少的问题，而出版商则需在开放存档与内容安全之间重新权衡。",
      "summaryEn": "Major news publishers including The Guardian and The New York Times are restricting the Internet Archive’s access to their content to prevent AI companies from scraping copyrighted articles via its Wayback Machine or APIs for model training. This move highlights growing tensions between digital preservation and intellectual property protection in the age of AI, turning a public-good archive into an unintended conduit for data extraction. While publishers aim to safeguard their IP, the public may face reduced access to historical web records, forcing a reevaluation of how open archives coexist with commercial AI development.",
      "fullText": "News publishers limit Internet Archive access due to AI scraping concerns | Nieman Journalism Lab Fellowships Reports Lab Storyboard Nieman Foundation at Harvard HOME About Subscribe Archives Foundation Reports Storyboard LATEST STORY Washington Post layoffs disproportionately affected union members of color, preliminary Guild data shows Business Models Mobile & Apps Audience & Social Aggregation & Discovery Reporting & Production ABOUT SUBSCRIBE Business Models Mobile & Apps Audience & Social Aggregation & Discovery Reporting & Production Translations Jan. 28, 2026, 3:09 p.m. Aggregation & Discovery Business Models News publishers limit Internet Archive access due to AI scraping concerns Outlets like The Guardian and The New York Times are scrutinizing digital archives as potential backdoors for AI crawlers. By Andrew Deck and Hanaa' Tameez Jan. 28, 2026, 3:09 p.m. Jan. 28, 2026, 3:09 p.m. As part of its mission to preserve the web, the Internet Archive operates crawlers that capture webpage snapshots. Many of these snapshots are accessible through its public-facing tool, the Wayback Machine . But as AI bots scavenge the web for training data to feed their models, the Internet Archive’s commitment to free information access has turned its digital library into a potential liability for some news publishers. When The Guardian took a look at who was trying to extract its content, access logs revealed that the Internet Archive was a frequent crawler, said Robert Hahn , head of business affairs and licensing. The publisher decided to limit the Internet Archive’s access to published articles, minimizing the chance that AI companies might scrape its content via the nonprofit’s repository of over one trillion webpage snapshots. RELATED ARTICLE The Wayback Machine’s snapshots of news homepages plummet after a “breakdown” in archiving projects Andrew Deck October 21, 2025 Specifically, Hahn said The Guardian has taken steps to exclude itself from the Internet Archive’s APIs and filter out its article pages from the Wayback Machine’s URLs interface. The Guardian’s regional homepages, topic pages, and other landing pages will continue to appear in the Wayback Machine. In particular, Hahn expressed concern about the Internet Archive’s APIs . “A lot of these AI businesses are looking for readily available, structured databases of content,” he said. “The Internet Archive’s API would have been an obvious place to plug their own machines into and suck out the IP.” (He admits the Wayback Machine itself is “less risky,” since the data is not as well-structured.) As news publishers try to safeguard their contents from AI companies, the Internet Archive is also getting caught in the crosshairs. The Financial Times, for example, blocks any bot that tries to scrape its paywalled content, including bots from OpenAI, Anthropic, Perplexity, and the Internet Archive. The majority of FT stories are paywalled, according to director of global public policy and platform strategy Matt Rogerson . As a result, usually only unpaywalled FT stories appear in the Wayback Machine because those are meant to be available to the wider public anyway. “Common Crawl and Internet Archive are widely considered to be the ‘good guys’ and are used by ‘the bad guys’ like OpenAI,” said Michael Nelson , a computer scientist and professor at Old Dominion University. “In everyone’s aversion to not be controlled by LLMs, I think the good guys are collateral damage.” RELATED ARTICLE To preserve their work — and drafts of history — journalists take archiving into their own hands Hanaa' Tameez July 31, 2024 The Guardian hasn’t documented specific instances of its webpages being scraped by AI companies via the Wayback Machine. Instead, it’s taking these measures proactively and is working directly with the Internet Archive to implement the changes. Hahn says the organization has been receptive to The Guardian’s concerns. The outlet stopped short of an all-out block on the Internet Archive’s crawlers, Hahn said, because it supports the nonprofit’s mission to democratize information, though that position remains under review as part of its routine bot management. “[The decision] was much more about compliance and a backdoor threat to our content,” he said. When asked about The Guardian’s decision, Internet Archive founder Brewster Kahle said that “if publishers limit libraries, like the Internet Archive, then the public will have less access to the historical record.” It’s a prospect, he implied, that could undercut the organization’s work countering “ information disorder .” RELATED ARTICLE After 25 years, Brewster Kahle and the Internet Archive are still working to democratize knowledge Joshua Benton March 24, 2022 The Guardian isn’t alone in reevaluating its relationship to the Internet Archive. The New York Times confirmed to Nieman Lab that it’s actively “hard blocking” the Internet Archive’s crawlers. At the end of 2025 , the Times also added one of those crawlers — archive.org_bot — to its robots.txt file , disallowing access to its content. “We believe in the value of The New York Times’s human-led journalism and always want to ensure that our IP is being accessed and used lawfully,” said a Times spokesperson. “We are blocking the Internet Archive’s bot from accessing the Times because the Wayback Machine provides unfettered access to Times content — including by AI companies — without authorization.” Last August, Reddit announced that it would block the Internet Archive, whose digital libraries include countless archived Reddit forums, comments sections, and profiles. This content is not unlike what Reddit now licenses to Google as AI training data for tens of millions of dollars . “[The] Internet Archive provides a service to the open web, but we’ve been made aware of instances where AI companies violate platform policies, including ours, and scrape data from the Wayback Machine,” a Reddit spokesperson told The Verge at the time. “Until they’re able to defend their site and comply with platform policies…we’re limiting some of their access to Reddit data to protect redditors.” Kahle has also alluded to steps the Internet Archive is taking to restrict bulk access to its libraries. In a Mastodon post last fall, he wrote that “there are many collections that are available to users but not for bulk downloading. We use internal rate-limiting systems, filtering mechanisms, and network security services such as Cloudflare.” Currently, however, the Internet Archive does not disallow any specific crawlers through its robots.txt file, including those of major AI companies. As of January 12, the robots.txt file for archive.org read: “​​Welcome to the Archive! Please crawl our files. We appreciate it if you can crawl responsibly. Stay open!” Shortly after we inquired about this language, it was changed. The file now reads, simply, “Welcome to the Internet Archive!” There is evidence that the Wayback Machine, generally speaking, has been used to train LLMs in the past. An analysis of Google’s C4 dataset by the Washington Post in 2023 showed that the Internet Archive was among millions of websites in the training data used to build Google’s T5 model and Meta’s Llama models. Out of the 15 million domains in the C4 dataset, the domain for the Wayback Machine ( web.archive.org ) was ranked as the 187th most present. RELATED ARTICLE Hundreds of thousands of videos from news publishers like The New York Times and Vox were used to train AI models Andrew Deck October 30, 2025 In May 2023, the Internet Archive went offline temporarily after an AI company caused a server overload, Wayback Machine director Mark Graham told Nieman Lab this past fall. The company sent tens of thousands of requests per second from virtual hosts on Amazon Web Services to extract text data from the nonprofit’s public domain archives. The Internet Archive blocked the hosts twice before putting out a public call to “respectfully” scrape its site. “We got in contact with them. They ended up giving us a donation,” Graham said. “They ended up saying that they were sorry and they stopped doing it.” “Those wanting to use our materials in bulk should start slowly, and ramp up,” wrote Kahle in a blog post shortly after the incident. “Also, if you are starting a large project please contact us …we are here to help.” The Guardian’s moves to limit the Internet Archive’s access made us wonder whether other news publishers were taking similar actions. We looked at publishers’ robots.txt pages as a way to measure potential concern over the Internet Archive’s crawling. A website’s robots.txt page tells bots which parts of the site they can crawl, acting like a “ doorman ,” telling visitors who is and isn’t allowed in the house and which parts are off limits. Robots.txt pages aren’t legally binding, so the companies running crawling bots aren’t obligated to comply with them, but they indicate where the Internet Archive is unwelcome. For example, in addition to “hard blocking,” The New York Times and The Athletic include the archive.org_bot in their robots.txt file, though they do not currently disallow other bots operated by the Internet Archive. To explore this issue, Nieman Lab used journalist Ben Welsh ‘s database of 1,167 news websites as a starting point. As part of a larger side project to archive news sites’ homepages, Welsh runs crawlers that regularly scrape the robots.txt files of the outlets in his database. In late December, we downloaded a spreadsheet from Welsh’s site that displayed all the bots disallowed in the robots.txt files of those sites. We identified four bots that the AI user agent watchdog service Dark Visitors has associated with the Internet Archive. (The Internet Archive did not respond to requests to confirm its ownership of these bots.) This data is not comprehensive, but exploratory. It does not represent global, industry-wide trends — 76% of sites in the Welsh’s publisher list are based in the U.S., for example — but instead begins to shed light on which publishers are less eager to have their content crawled by the Internet Archive. In total, 241 news sites from nine countries explicitly disallow at least one out of the four Internet Archive crawling bots. Most of those sites (87%) are owned by USA Today Co., the largest newspaper conglomerate in the United States formerly known as Gannett. (Gannett sites only make up 18% of Welsh’s original publishers list.) Each Gannett-owned outlet in our dataset disallows the same two bots: “archive.org_bot” and “ia_archiver-web.archive.org”. These bots were added to the robots.txt files of Gannett-owned publications in 2025. Some Gannett sites have also taken stronger measures to guard their contents from Internet Archive crawlers. URL searches for the Des Moines Register in the Wayback Machine return a message that says, “Sorry. This URL has been excluded from the Wayback Machine.” “USA Today Co. has consistently emphasized the importance of safeguarding our content and intellectual property,” a company spokesperson said via email. “Last year, we introduced new protocols to deter unauthorized data collection and scraping, redirecting such activity to a designated page outlining our licensing requirements.” Gannett declined to comment further on its relationship with the Internet Archive. In an October 2025 earnings call , CEO Mike Reed spoke to the company’s anti-scraping measures. “In September alone, we blocked 75 million AI bots across our local and USA Today platforms, the vast majority of which were seeking to scrape our local content,” Reed said on that call. “About 70 million of those came from OpenAI.” ( Gannett signed a content licensing agreement with Perplexity in July 2025 .) About 93% (226 sites) of publishers in our dataset disallow two out of the four Internet Archive bots we identified. Three news sites in the sample disallow three Internet Archive crawlers: Le Huffington Post, Le Monde, and Le ",
      "imageUrl": "https://www.niemanlab.org/images/internt-archive-stock-2.jpg",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：新闻出版商限制互联网档案馆访问，反映全球AI训练数据合规性与版权博弈的深层转折，具有重大产业政策与法律影响。",
        "热度：300 / 评论 181"
      ],
      "score": 6.8,
      "publishedAt": "2026-02-14T18:46:32+00:00",
      "authors": [
        "ninjagoo"
      ]
    },
    {
      "id": "hn_47012553",
      "title": "OpenAI应自建AI原生协作平台挑战Slack",
      "titleZh": "OpenAI应自建AI原生协作平台挑战Slack",
      "titleEn": "OpenAI Should Build an AI-Native Collaboration Platform to Challenge Slack",
      "url": "https://www.latent.space/p/ainews-why-openai-should-build-slack",
      "type": "news",
      "source": "Hacker News",
      "summary": "科技评论员swyx撰文呼吁OpenAI应自建类似Slack的企业协作平台，理由是当前Slack在AI功能、开发者体验和价格上已显疲态，而OpenAI凭借其强大的聊天AI、多智能体交互能力及新聘前Slack高管Denise Dresser，有机会打造深度集成AI代理的原生工作空间；此举不仅能巩固其在企业市场的护城河，还可为编码智能体提供真正的多人协作环境，从而超越Anthropic等竞争对手的桌面整合策略；对开发者而言，这可能意味着未来更无缝、上下文感知的AI工作流工具。",
      "summaryZh": "科技评论员swyx撰文呼吁OpenAI应自建类似Slack的企业协作平台，理由是当前Slack在AI功能、开发者体验和价格上已显疲态，而OpenAI凭借其强大的聊天AI、多智能体交互能力及新聘前Slack高管Denise Dresser，有机会打造深度集成AI代理的原生工作空间；此举不仅能巩固其在企业市场的护城河，还可为编码智能体提供真正的多人协作环境，从而超越Anthropic等竞争对手的桌面整合策略；对开发者而言，这可能意味着未来更无缝、上下文感知的AI工作流工具。",
      "summaryEn": "In an editorial, technologist swyx argues OpenAI should build its own Slack-like collaboration platform, citing Slack’s stagnation in AI features, poor developer experience, and rising costs. With its superior chat AI, multi-agent capabilities, and recent hire of former Slack CEO Denise Dresser, OpenAI is uniquely positioned to create an AI-native workspace that deeply integrates agents into team communication and coding workflows. Such a move would strengthen OpenAI’s enterprise moat and enable truly collaborative AI coding—surpassing Anthropic’s unified desktop approach—and could deliver more contextual, seamless productivity tools for developers and organizations.",
      "fullText": "[AINews] Why OpenAI Should Build Slack - by swyx (Shawn) Subscribe Sign in AINews: Weekday Roundups [AINews] Why OpenAI Should Build Slack a quiet day lets us answer a Sam Altman question swyx (Shawn) Feb 14, 2026 ∙ Paid 29 2 2 Share We’re still not over the Sam Altman town hall ; at the town hall he said “ tell us what we should build, we’ll probably build it! ” and today at Stanford Treehacks he said a variant of the same thing: he thinks of himself as having made a career out of doing things people think are hard, but would be a big deal if it came true. well okay, Sam: You Should Build Slack. It fits your criteria: it is hard for anyone else without the clout of OpenAI to pull off, it will be very well received by the tech community, and it is an obvious progression of ChatGPT for both your Enterprise -and- your Coding push and build permanent entrenchment in your customers. Slack rejected developer community and went upmarket in 2019, then Salesforce bought it for $27.7B in 2021 , and ever since then Slack has been on a slow rachet up in prices and has struggled to introduce compelling new AI features ( Slack AI is occasionally useful but impossible to discover/learn/personalize) while facing constant outages . NPS feels low, and yet every organization in tech uses it. Everything could be better . Developers routinely complain about Slack’s API costs and permissions (even 3rd or 4th Uber investor and famed vibe coder Jason Calacanis complained on the latest All In podcast ). Founders routinely complain about the pricing. Slack users complain about channel fatigue and find the Recap tooling and notifications spam woefully inadequate. Huddles could offer far better realtime multimodal AI features. Slack Connect is great though, definitely just clone that. Sure, ChatGPT launched group chats 3 months ago and probably the usage isn’t great outside of OpenAI. It’d be a mistake to think that repeated half hearted attempts in consumer social AI means that you can’t build a successful business social network if you took it as seriously as you do everything else. Microsoft did, and Teams is by all reports a solid success (after a rocky start ). In the desktop wars, Anthropic has pursued a far more cohesive strategy than OpenAI: one app for Chat, Cowork, and Claude Code, with optional control of the browser via Claude in Chrome. By contrast, OpenAI has shipped the org chart to every user’s desktop: get our chat app here , get our browser app here, get our coding app there. Log in fresh every single time. Even doing a unification at some point probably still leaves you behind; you need to lead, not be a slow follower of what Anthropic already did. “OpenAI Slack” is your chance to retake the initiative. Of course you’re going to be good at chat AI. Of course you care about the multiagent UX of the future. Why not build your own version of the existing multiagent UX we all know to work between humans? Heck, forgot you even hired Slack CEO Denise Dresser in Dec . Great! The killer part of course is that this could also be the coding agent interface you always wanted anyway. The main remaining thing missing from the admittedly very good Codex app is the ability to be truly multiplayer. You haven’t felt the AGI until you have given your designer access to your coding agent and let him rip all night with you occasionally chiming in to guide things. You can see swarms of humans and swarms of agents all working together in God’s given orchestration interface: chat . Put another way, it is now time to layer a customer organization’s social graph and work graph onto ChatGPT, and then lather every interface with agents and AI in the way that OpenAI does best. The network effect makes it 10000x harder to leave you for a competitor, and sure, you could do it atop Slack as you currently do, but it’s easy to switch and won’t give you access to reinvent with as much freedom. To recap: Is it hard to do? yes for almost everyone except you Is it a big deal if you get it right? yes for us users, but an even bigger deal for your business Will you have lots of low hanging fruit to build new agentic interfaces and a context graph /system of record to power Frontier and everything else you do in SMB and Enterprise? yeah. /fin Feb 14 update: This header is usually at the start of the post, but since it is causing some confusion on HN and Twitter , I am moving it down. The editorial written above is always human written, the recaps below are human reviewed. AI News — Feb 13, 2026 AI News for 2/12/2026-2/13/2026. We checked 12 subreddits, 544 Twitters and 24 Discords ( 256 channels, and 7993 messages) for you. Estimated reading time saved (at 200wpm): 675 minutes. AINews’ website lets you search all past issues. As a reminder, AINews is now a section of Latent Space . You can opt in/out of email frequencies! It’s a pretty quiet day — the new Dwarkesh-Dario pod is worthwhile but hasn’t generated much new conversation on day 1, and OpenAI claimed a big result in theoretical physics that is mostly getting questioned by some physicists. This means we get to go back to our backlog of mini-editorial ideas for AINews subscribers! AI Twitter Recap MiniMax M2.5 open-sourcing: agent-native RL, speed/cost, and rapid ecosystem uptake MiniMax-M2.5 is now open source : MiniMax released MiniMax-M2.5 weights + code, positioning it as an “agent-native” model trained with RL across hundreds of thousands of real-world environments for coding, tool use, search, and office workflows ( MiniMax announcement ). vLLM highlights day‑0 support and reports key benchmark numbers: 80.2% SWE‑Bench Verified , 76.3% BrowseComp , plus claims around training scale (200k+ RL environments) and speed/cost characteristics ( vLLM ). SGLang similarly ships day‑0 support and frames the model as production-grade for “always-on” agents ( lmsys ). The practical headline is economics + throughput, not just score : MiniMax repeatedly markets “$1 per hour at 100 tps” (interpretable as a “long-horizon agent budget”), which shows up both in their own posts ( MiniMax ) and in community recaps emphasizing that low activated-parameter count makes self-hosting plausible ( omarsar0 ). Early local runs suggest unusually strong on-device viability for its class: MLX users report ~ 50 tok/s shortly after release ( pcuenq ), and a single M3 Ultra 512GB run at 6‑bit reports ~ 40 tok/s with ~ 186GB peak memory ( ivanfioravanti ). Forge RL training system details leak into the narrative : A Zhihu-derived writeup summarizes MiniMax’s “Forge” RL stack as still CISPO-like , using process reward + completion-time reward , with infrastructure tricks like multi-level prefix cache and high rollout compute share (claimed ~60% of compute) generating millions of trajectories/day ( YouJiacheng ). MiniMax leadership explicitly answers parameterization tradeoffs (“ 10B active intentional”), claims proximity to “ infinite agent scaling ” with knowledge capacity as the limiter, and teases structural + pretraining innovation focus for M3 ( MiniMax reply ). Independent reviews: “viable for multi-turn work” but token-hungry : A Chinese review thread claims M2.5 corrects M2.1’s imbalance (coding up, logic down), with overall improvements and better stability; it notes high token usage (nearly 2× Sonnet in one comparison) but frames pricing/compute as making it usable day-to-day ( ZhihuFrontier ). Another summary calls it “≤Sonnet for coding, but close,” and emphasizes multi-turn viability as the key break from “toy” open models ( teortaxesTex ). Ecosystem uptake is immediate : weights mirrored and packaged across tooling (Hugging Face release pings, GGUF/quant drops, etc.), including Intel-hosted quantized artifacts like a 2‑bit GGUF for MiniMax‑M2 and INT4 for Qwen3‑Coder‑Next ( HaihaoShen ). GLM‑5 and the “near-frontier” open model wave: performance, infra constraints, and eval chatter GLM‑5 positioning : Together markets GLM‑5 as best-in-class open-source for long-horizon agents and systems engineering, quoting metrics like 77.8% SWE‑Bench Verified , 50.4% HLE w/ tools , and a MoE efficiency story with “DeepSeek Sparse Attention” (as described in the tweet) ( Together ). W&B promotes an interview claiming 744B params , a “new RL framework,” and “fully open source under MIT” (as stated in the post) ( W&B ). Community members also notice dataset fingerprints like “truthy‑dpo” appearing in GLM‑5 outputs ( jon_durbin ). GLM‑5 qualitative review highlights : A detailed Zhihu-based comparison frames GLM‑5 as a substantial improvement over GLM‑4.7, especially on hallucination control, programming fundamentals, and character processing—but also more verbose/token-expensive and prone to “overthinking,” suggesting a trade between long-horizon reasoning and compute burn ( ZhihuFrontier on GLM‑5 ). Benchmarks as a moving target : There’s persistent meta-discussion about whether leaderboards/evals are saturated or misleading. Examples: concerns that tokens/latency tradeoffs hide true capability; skepticism about inferring model size from TPS; and the observation that past “SWE‑bench saturation” claims were premature ( jyangballin , teortaxesTex ). Cross-checking with alternative evals : SWE‑rebench is cited as “brutal” for some recent releases and shows different relative rankings than SWE‑bench Verified; a caution is made to treat it as “additional signal” ( maximelabonne ). Agent engineering in practice: file-based coordination, terminal-first workflows, and “agent OS” framing Claude Code “Agent Teams” internals are surprisingly simple : A reverse-engineering summary claims Claude Code’s multi-agent comms use JSON files on disk (inboxes under ~/.claude/teams/inboxes/{agent}.json ), with polling between turns and JSON-in-JSON protocol messages; the argument is that this is a pragmatic CLI design (no Redis/queues) and improves observability at the cost of atomicity/backpressure ( peter6759 ). Terminal agents are becoming the default UX : Cline launches Cline CLI 2.0 , an open-source terminal coding agent featuring a redesigned interactive TUI, parallel agents with isolated state, headless CI/CD mode, and broad editor support (ACP for Zed/Neovim/Emacs) ( cline , cline details ). Community framing: “open-source strikes back” due to free/low-barrier access to strong models ( testingcatalog , dr_cintas ). One Cline team member describes a full rewrite (Go → TypeScript) driven by architecture/UX pain and the need to run evals reliably ( arafatkatze ). Agent scaffolds may matter less than expected (for some horizons) : METR-related discussion suggests Claude Code / Codex scaffolds don’t strongly outperform METR’s “simple OS scaffolds” on measured time horizons so far ( nikolaj2030 ), with Ajeya Cotra noting surprise at the small delta ( ajeya_cotra ). In contrast, others note that for longer, harder tasks, scaffold choice can matter materially (e.g., ~10% success swings) ( gneubig ). “Agents as OS / filesystem as substrate” : Several posts converge on the idea that file systems are the natural environment for agents (observability, unstructured data manipulation). Box announces integration as a “cloud filesystem” into LangChain deepagents ( levie ). WebMCP pushes “browser is the API” for web automation without UI perception, with a DoorDash-like starter template ( skirano ). Key operational lesson: make codebases “agent-ready” : A crisp observation is that agents have “zero tolerance” for entropy humans route around; they treat dead code/outdated docs literally, forcing engineering hygiene that humans always needed but often deferred ( dok2001 ). RL/post-training research themes: process rewards, exploration, and rubric-based evaluation Length-Incentivized Exploration (LIE) for reasoning : A research summary introduces the “Shallow Exploration Trap” (long reasoning trajectories become exponentially unlikely under AR sampling), and proposes LIE: a length reward + redundancy penalty to encourage broa",
      "imageUrl": "https://substackcdn.com/image/fetch/$s_!XQAE!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ee056a-0ea2-4473-8e1c-9b21f034c717_1474x2116.png",
      "tags": [
        "Industry"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：建议OpenAI构建Slack，直指企业级AI融合痛点，具备平台级战略潜力，影响未来办公生态。",
        "热度：81 / 评论 89"
      ],
      "score": 6.45,
      "publishedAt": "2026-02-14T07:50:13+00:00",
      "authors": [
        "swyx"
      ]
    },
    {
      "id": "rss_4934004585",
      "title": "印度批准11亿美元国家母基金力挺深科技创业",
      "titleZh": "印度批准11亿美元国家母基金力挺深科技创业",
      "titleEn": "India Approves $1.1B State-Backed Fund to Boost Deep-Tech Startups",
      "url": "https://techcrunch.com/2026/02/14/india-doubles-down-on-state-backed-venture-capital-approving-1-1b-fund/",
      "type": "news",
      "source": "TechCrunch AI",
      "summary": "印度政府批准设立11亿美元的国家级母基金，通过投资私营风投机构重点支持人工智能、先进制造等深科技初创企业；该计划延续2016年首期基金模式，但更聚焦长周期、高资本需求领域，并旨在扶持中小风投、扩大地域覆盖；在2025年印度初创融资总额下降17%、交易数锐减近四成的背景下，此举意在缓解深科技企业融资难问题，配合近期延长初创认定年限至20年等政策，强化本土创新生态；对创业者而言，这意味着在Tier-2城市或硬科技赛道将有更多政府引导资金可触达。",
      "summaryZh": "印度政府批准设立11亿美元的国家级母基金，通过投资私营风投机构重点支持人工智能、先进制造等深科技初创企业；该计划延续2016年首期基金模式，但更聚焦长周期、高资本需求领域，并旨在扶持中小风投、扩大地域覆盖；在2025年印度初创融资总额下降17%、交易数锐减近四成的背景下，此举意在缓解深科技企业融资难问题，配合近期延长初创认定年限至20年等政策，强化本土创新生态；对创业者而言，这意味着在Tier-2城市或硬科技赛道将有更多政府引导资金可触达。",
      "summaryEn": "India has approved a $1.1 billion state-backed fund-of-funds to invest in deep-tech and advanced manufacturing startups through private venture capital firms. Building on a 2016 initiative, this targeted program aims to support early-stage founders, bolster smaller VC funds, and expand investment beyond major cities. Amid a 17% decline in total startup funding and a 39% drop in deal count in 2025, the move addresses growing financing gaps for capital-intensive deep-tech ventures. Complemented by policy changes—such as extending the official startup status period to 20 years—it strengthens India’s domestic innovation ecosystem, offering new opportunities for entrepreneurs outside metropolitan hubs.",
      "fullText": "India doubles down on state-backed venture capital, approving $1.1B fund | TechCrunch TechCrunch Desktop Logo TechCrunch Mobile Logo Latest Startups Venture Apple Security AI Apps Events Podcasts Newsletters Search Submit Site Search Toggle Mega Menu Toggle Topics Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture More from TechCrunch Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us Image Credits: Jagmeet Singh / TechCrunch Startups India doubles down on state-backed venture capital, approving $1.1B fund Jagmeet Singh 8:23 AM PST · February 14, 2026 India has cleared a $1.1 billion state-backed venture capital program that will channel government money into startups through private investors, doubling down on its effort to finance high-risk areas such as artificial intelligence, advanced manufacturing and other sectors broadly referred to by the industry as deep tech. First outlined in the January 2025 budget speech by India’s finance minister, the ₹100 billion fund won cabinet approval this week (more than a year after the speech), allowing the government to move ahead with deployment. A previous iteration of the program, launched in 2016, committed ₹100 billion to 145 private funds that have invested more than ₹255 billion (about $2.8 billion) in over 1,370 startups, according to official data released on Saturday. The program is structured as a fund of funds, a common venture capital model in which governments back startups indirectly by committing capital to private investment firms. It is designed to take a more targeted approach than its 2016 counterpart, focusing on deep-tech and manufacturing startups that typically require longer time horizons and larger amounts of capital, while also backing early-stage founders, expanding investment beyond major cities and strengthening India’s domestic venture capital industry, particularly smaller funds, per the Indian government. At the announcement on Saturday, IT minister Ashwini Vaishnaw highlighted the scale of India’s startup expansion, pointing to figures shown on a presentation slide indicating the number of startups has grown from fewer than 500 in 2016 to more than 200,000 today. The slide said more than 49,000 startups were registered in 2025 alone, the highest annual total on record. The cabinet approval follows recent changes to India’s startup rules aimed at easing pressure on deep-tech companies . New Delhi doubled the period for which such firms are classified as startups to 20 years and raised the revenue threshold for startup-specific tax, grant and regulatory benefits to ₹3 billion, or about $33 million, up from ₹1 billion previously. The approval comes just ahead of the government-backed India AI Impact Summit , where global AI companies including OpenAI, Anthropic, Google, Meta, Microsoft, and Nvidia are set to participate alongside Indian corporates such as Reliance Industries and Tata Group. India, the world’s most populous country and one of its largest internet markets with more than a billion online users, has become an increasingly attractive arena for global tech companies looking to expand their user base. At the same time, private capital has become harder to secure. India’s startup ecosystem raised $10.5 billion in 2025 , down just over 17% from a year earlier, even as investors grew more selective and sharply reduced the number of deals. The number of funding rounds fell nearly 39% to 1,518 transactions, according to data from Tracxn. Techcrunch event TechCrunch Founder Summit 2026: Tickets Live On June 23 in Boston , more than 1,100 founders come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately Save up to $300 on your pass or save up to 30% with group tickets for teams of four or more. TechCrunch Founder Summit: Tickets Live On June 23 in Boston , more than 1,100 founders come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately Save up to $300 on your pass or save up to 30% with group tickets for teams of four or more. Boston, MA | June 23, 2026 REGISTER NOW Vaishnaw said the new venture capital program would remain flexible, adding that “extensive consultations have taken place with all stakeholders.” Topics AI , deep tech , India , Startups , Venture Jagmeet Singh Reporter Jagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV. You can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com . View Bio October 13-15 San Francisco, CA Tickets are live at the lowest rates of the year. Save up to $680 on your pass now. Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders , dive into 200+ sessions , and explore 300+ startups building what’s next. Don’t miss these one-time savings. REGISTER NOW Most Popular A Stanford grad student created an algorithm to help his classmates find love; now, Date Drop is the basis of his new startup Amanda Silberling Spotify says its best developers haven’t written a line of code since December, thanks to AI Sarah Perez The first signs of burnout are coming from the people who embrace AI the most Connie Loizos MrBeast’s company buys Gen Z-focused fintech app Step Amanda Silberling YouTube TV introduces cheaper bundles, including a $65/month sports package Sarah Perez Discord to roll out age verification next month Aisha Malik From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads Lauren Forristal Loading the next article Error loading the next article X LinkedIn Facebook Instagram youTube Mastodon Threads Bluesky TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Terms of Service Privacy Policy RSS Terms of Use Code of Conduct Epstein Kindle Scribe Reddit TikTok GPT-4o Tech Layoffs ChatGPT © 2025 TechCrunch Media LLC.",
      "imageUrl": "https://techcrunch.com/wp-content/uploads/2025/09/india-flag.jpg?resize=1200%2C630",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：TechCrunch AI",
        "跨源重复：1 个来源",
        "模型评分：9/10，理由：印度批准11亿美元国家基金支持AI与先进制造，是国家级战略级投入，将显著影响全球科技生态布局。",
        "热度：0 / 评论 0"
      ],
      "score": 5.4,
      "publishedAt": "2026-02-14T16:23:22+00:00",
      "authors": [
        "Jagmeet Singh"
      ]
    },
    {
      "id": "hn_47009327",
      "title": "IBM三倍扩招Z世代员工，重写AI时代初级岗位",
      "titleZh": "IBM三倍扩招Z世代员工，重写AI时代初级岗位",
      "titleEn": "IBM Triples Entry-Level Hiring for Gen Z, Redefining Roles in the AI Era",
      "url": "https://fortune.com/2026/02/13/tech-giant-ibm-tripling-gen-z-entry-level-hiring-according-to-chro-rewriting-jobs-ai-era/",
      "type": "news",
      "source": "Hacker News",
      "summary": "IBM宣布将面向Z世代的初级岗位招聘规模扩大三倍，尽管AI已能自动化部分基础任务，但公司发现过度依赖AI会导致人才断层，因此重写岗位职责——如让软件工程师更侧重客户交互、HR人员监督AI聊天机器人；此举旨在培养具备AI协同能力的长期人才梯队，避免未来中层管理真空；对求职者而言，展示AI素养与主动性将成为突破紧缩就业市场的关键，也印证了AI并非取代人力而是重塑技能需求。",
      "summaryZh": "IBM宣布将面向Z世代的初级岗位招聘规模扩大三倍，尽管AI已能自动化部分基础任务，但公司发现过度依赖AI会导致人才断层，因此重写岗位职责——如让软件工程师更侧重客户交互、HR人员监督AI聊天机器人；此举旨在培养具备AI协同能力的长期人才梯队，避免未来中层管理真空；对求职者而言，展示AI素养与主动性将成为突破紧缩就业市场的关键，也印证了AI并非取代人力而是重塑技能需求。",
      "summaryEn": "IBM is tripling its entry-level hiring for Gen Z talent, reversing the trend of cutting junior roles despite AI’s ability to automate routine tasks. Recognizing that over-reliance on AI risks a future leadership gap, IBM has redesigned roles—e.g., shifting software engineers toward customer interaction and HR staff toward overseeing AI chatbots—to build durable, AI-fluent teams. This strategy prioritizes long-term organizational health over short-term cost savings. For job seekers, especially young graduates, demonstrating AI literacy and initiative is becoming essential to stand out in a tight labor market, underscoring that AI augments rather than replaces human potential.",
      "fullText": "IBM is tripling the number of Gen Z entry-level jobs after finding the limits of AI adoption | Fortune Search Subscribe Home Latest Fortune 500 Finance Tech Leadership Lifestyle Rankings Multimedia Success Careers IBM is tripling the number of Gen Z entry-level jobs after finding the limits of AI adoption By Preston Fore Preston Fore Success Reporter Down Arrow Button Icon By Preston Fore Preston Fore Success Reporter Down Arrow Button Icon February 13, 2026, 11:43 AM ET Add us on Gen Z jobs aren’t dead yet: $240 billion tech giant IBM says it’s rewriting entry-level jobs—and tripling down on its hiring of young talent. Dragos Condrea—Getty Images The job market has been a sore subject for Gen Z . The unemployment rate among young college grads sits at 5.6%, hovering near its highest level in more than a decade outside the pandemic. Meanwhile, prominent executives—from Anthropic’s Dario Amodei to Ford’s Jim Farley —have warned that artificial intelligence will slash corporate entry-level jobs. Recommended Video But some companies are realizing that cutting young workers out of the pipeline isn’t a sustainable long-term strategy: $240 billion tech giant IBM just revealed it’s ramping up hiring of Gen Z. “The companies three to five years from now that are going to be the most successful are those companies that doubled down on entry-level hiring in this environment,” Nickle LaMoreaux , IBM’s chief human resources officer, said this week. “We are tripling our entry-level hiring, and yes, that is for software developers and all these jobs we’re being told AI can do.” While she admitted that many of the responsibilities that previously defined entry-level jobs can now be automated, IBM has since rewritten its roles across sectors to account for AI fluency. For example, software engineers will spend less time on routine coding—and more on interacting with customers, and HR staffers will work more on intervening with chatbots, rather than having to answer every question. The shift, LaMoreaux said, builds more durable skills for workers while creating greater long-term value for the company. With job market conditions likely to stay tight for young candidates in 2026, applicants who show initiative and comfort with AI may be the ones who break through at companies like IBM. According to LinkedIn , AI literacy is now the fastest-growing skill in the U.S. Cutting entry-level talent could backfire in the long term, according to IBM’s HR head As AI increases pressure on companies to be leaner and more productive, early-career hiring has often looked like the simplest place to cut. A report from Korn Ferry found that 37% of organizations plan to replace early career roles with AI. But while that strategy might be helpful with short-term financials, LaMoreaux argued, it could cause havoc in the future. Reducing junior headcount risks creating an eventual shortage of mid-level managers. Attempting to poach talent from competitors is likely to be costlier, and outside hires tend to take longer to adapt to internal systems and culture. That’s why, she said, HR leaders need to push back. “Entry-level hires—it is your responsibility to make the case for that,” she said. “Build the business case now; even though it may not seem so obvious to your leaders, because AI is going to make your job easier three years from now.” IBM CEO Arvind Krishna has already heard LaMoreaux’s plea and rejected the idea that AI should translate into fewer opportunities for graduates. “People are talking about either layoffs or freezing hiring, but I actually want to say that we are the opposite,” Krishna told CNN in October. “I expect we are probably going to hire more people out of college over the next 12 months than we have in the past few years, so you’re going to see that.” Just a week after his comments, however, IBM announced it would cut thousands of workers by the end of the year as it shifts focus to high-growth software and AI areas. A company spokesperson told Fortune at the time that the round of layoffs would impact a relatively low single-digit percentage of the company’s global workforce, and when combined with new hiring, would leave IBM’s U.S. headcount roughly flat. Fortune reached out to IBM for further comment. Like IBM, some tech companies are rethinking talent pipelines—and embracing Gen Z IBM isn’t alone in betting that younger workers may actually accelerate AI adoption. In fact, according to Melanie Rosenwasser, chief people officer at Dropbox , Gen Z are actually coming to work equipped with better AI skills than their older peers. “It’s like they’re biking in the Tour de France and the rest of us still have training wheels,” Rosenwasser told Bloomberg . “Honestly, that’s how much they’re lapping us in proficiency.” The file-sharing company is set to expand its internship and new graduate programs by 25% to capitalize on the AI fluency of younger workers. Ravi Kumar S, CEO of IT firm Cognizant, similarly told Fortune last year that he would be creating more entry-level jobs owing to his bullish view of Gen Z. “So many companies have a pyramid with the bottom where school graduates are. That pyramid is going to be broader and shorter, and the path to expertise is going to be faster,” he said. “This year, we are hiring more school graduates than ever before. I can take a school graduate and give them the tooling so they can actually punch above their weight. AI is an amplifier of human potential. It’s not a displacement strategy.” Join us at the Fortune Workplace Innovation Summit May 19–20, 2026, in Atlanta. The next era of workplace innovation is here—and the old playbook is being rewritten. At this exclusive, high-energy event, the world’s most innovative leaders will convene to explore how AI, humanity, and strategy converge to redefine, again, the future of work. Register now . About the Author By Preston Fore Success Reporter LinkedIn icon Twitter icon Preston Fore is a reporter on Fortune 's Success team. See full bio Right Arrow Button Icon Latest in Success Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Most Popular Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Finance Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam By Fortune Editors October 20, 2025 Rankings 100 Best Companies Fortune 500 Global 500 Fortune 500 Europe Most Powerful Women Future 50 World’s Most Admired Companies See All Rankings Sections Finance Leadership Success Tech Asia Europe Environment Fortune Crypto Health Retail Lifestyle Politics Newsletters Magazine Features Commentary Mpw CEO Initiative Conferences Personal Finance Education Customer Support Frequently Asked Questions Customer Service Portal Privacy Policy Terms Of Use Single Issues For Purchase International Print Commercial Services Advertising Fortune Brand Studio Fortune Analytics Fortune Conferences Business Development About Us About Us Editorial Calendar Press Center Work At Fortune Diversity And Inclusion Terms And Conditions Site Map Facebook icon Twitter icon LinkedIn icon Instagram icon Pinterest icon Latest in Success Arts & Entertainment Valentine's Day Victorian-era ‘vinegar valentines’ show that trolling existed long before social media or the internet By Melissa Chan and The Conversation February 14, 2026 7 hours ago Economy Coffee Americans wake up and smell the coffee price surge—skipping Starbucks, brewing at home, and drinking Diet Coke for caffeine By Matt Sedensky and The Associated Press February 14, 2026 7 hours ago Commentary private equity Private equity’s playbook to shake off the zombies: meet the continuation vehicle By Sunaina Sinha Haldea February 14, 2026 10 hours ago Success MacKenzie Scott MacKenzie Scott says her college roommate loaned her $1,000 so she wouldn’t have to drop out—and is now inspiring her to give away billions By Sydney Lake February 14, 2026 10 hours ago Cybersecurity fraud Romance scam from the front lines of the $16 billion fraud crisis: 6 dead dogs, a missing $39,000, and a wronged widow By Amanda Gerut February 14, 2026 10 hours ago Success Careers ‘America’s Got Talent’ creator Simon Cowell has given up working on Fridays because ‘it’s pointless’—and research shows he’s right By Orianna Rosa Royle February 14, 2026 10 hours ago Most Popular AI Microsoft AI chief gives it 18 months—for all white-collar work to be automated by AI By Jake Angelo February 13, 2026 1 day ago Success MacKenzie Scott says her college roommate loaned her $1,000 so she wouldn't have to drop out—and is now inspiring her to give away billions By Sydney Lake February 14, 2026 10 hours ago Economy Some folks on Wall Street think yesterday’s U.S. jobs number is ‘implausible’ and thus due for a downward correction By Jim Edwards February 12, 2026 2 days ago Success Actress Jennifer Garner just took her $724 million organic food empire public. She started her career making just $150 weekly as a ‘broke’ understudy By Emma Burleigh February 13, 2026 1 day ago North America ‘I gave another girl to Kimbal’: Inside Jeffrey Epstein’s honey-trap plan targeting Elon Musk through his brother By Eva Roytburg and Jessica Mathews February 13, 2026 1 day ago Big Tech Analog-obsessed Gen Zers are buying $40 app blockers to limit their social media use and take a break from the ‘slot machine in your pocket’ By Marco Quiroz-Gutierrez February 13, 2026 1 day ago © 2026 Fortune Media IP Limited. All Rights Reserved. Use of this site constitutes acceptance of our Terms of Use and Privacy Policy | CA Notice at Collection and Privacy Notice | Do Not Sell/Share My Personal Information FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
      "imageUrl": "https://fortune.com/img-assets/wp-content/uploads/2026/02/GettyImages-2215326599-e1771000637949.jpg?resize=1200%2C630",
      "tags": [],
      "paperCategory": "",
      "signalReasons": [
        "来源：Hacker News",
        "跨源重复：1 个来源",
        "模型评分：8/10，理由：IBM扩大青年招聘反映AI对人力结构的反向修正，预示企业战略调整，影响全球科技人才市场走向。",
        "热度：133 / 评论 52"
      ],
      "score": 4.86,
      "publishedAt": "2026-02-13T23:34:09+00:00",
      "authors": [
        "WhatsTheBigIdea"
      ]
    },
    {
      "id": "rss_1178301099",
      "title": "Airbnb全面拥抱AI：自然语言搜索、语音客服与智能推荐",
      "titleZh": "Airbnb全面拥抱AI：自然语言搜索、语音客服与智能推荐",
      "titleEn": "Airbnb Bakes AI into Core Features: Natural Language Search, Voice Support, and Smart Recommendations",
      "url": "https://techcrunch.com/2026/02/13/airbnb-plans-to-bake-in-ai-features-for-search-discovery-and-support/",
      "type": "news",
      "source": "TechCrunch AI",
      "summary": "Airbnb计划深度集成大语言模型，打造“AI原生”体验：用户可通过自然语言搜索房源并规划全程旅行，房东获得AI辅助运营，客服系统将从文字扩展至语音并覆盖更多语言；目前其AI客服已处理北美三分之一的用户问题，目标是一年后显著提升自动化比例；新任CTO（前Meta Llama团队成员）将利用平台身份与评论数据优化个性化推荐；对用户而言，未来搜索将更直观智能，但也可能引入AI驱动的赞助房源广告，需留意推荐透明度。",
      "summaryZh": "Airbnb计划深度集成大语言模型，打造“AI原生”体验：用户可通过自然语言搜索房源并规划全程旅行，房东获得AI辅助运营，客服系统将从文字扩展至语音并覆盖更多语言；目前其AI客服已处理北美三分之一的用户问题，目标是一年后显著提升自动化比例；新任CTO（前Meta Llama团队成员）将利用平台身份与评论数据优化个性化推荐；对用户而言，未来搜索将更直观智能，但也可能引入AI驱动的赞助房源广告，需留意推荐透明度。",
      "summaryEn": "Airbnb is embedding large language models deeply into its platform to create an 'AI-native' experience: guests can use natural language to search listings and plan entire trips, hosts receive AI-powered operational support, and customer service will expand from text to voice across more languages. Already handling one-third of support tickets in North America without human intervention, Airbnb aims to significantly increase AI resolution rates within a year. Leveraging its rich identity and review data under new CTO Ahmad Al-Dahle (ex-Meta Llama), the company also plans to test conversational sponsored listings. For users, this means more intuitive travel planning—but also potential exposure to AI-curated ads requiring greater transparency.",
      "fullText": "Airbnb plans to bake in AI features for search, discovery and support | TechCrunch TechCrunch Desktop Logo TechCrunch Mobile Logo Latest Startups Venture Apple Security AI Apps Events Podcasts Newsletters Search Submit Site Search Toggle Mega Menu Toggle Topics Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture More from TechCrunch Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us Image Credits: Gerald Matzka / Stringer (opens in a new window) / Getty Images Apps Airbnb plans to bake in AI features for search, discovery and support Ivan Mehta 6:40 PM PST · February 13, 2026 Airbnb has taken its time to launch AI features within the app, but CEO Brian Chesky on Friday said the company is now planning to bake in features powered by large language models that would help users search for listings, plan their trips, and aid hosts in managing their properties. Speaking at the company’s fourth-quarter conference call, Chesky said the company wants to increase its use of large language models for customer discovery, support and engineering. “We are building an AI-native experience where the app does not just search for you. It knows you. It will help guests plan their entire trip, help hosts better run their businesses, and help the company operate more efficiently at scale,” he said. The company separately said it is testing a new feature that lets users search and ask questions about properties and locations using natural language queries. Currently, Airbnb offers an LLM-powered customer service bot, for some personalization, and communications. The new AI search feature is expected to “evolve into a more comprehensive and intuitive search experience that extends through the trip.” Questioned by analyst whether Airbnb would roll out sponsored property slots within AI search, Chesky said the company wants to get the design and user experience right first. “AI search is live to a very small percentage of traffic right now. We are doing a lot of experimentation. Over time, we are gonna be experimenting with making AI search more conversational, integrating it into more than the trip, and, eventually, we will be looking at sponsor listings as a result of that,” Chesky said, adding that Airbnb would consider designing an ad unit that fits the conversational search flow. Techcrunch event TechCrunch Founder Summit 2026: Tickets Live On June 23 in Boston , more than 1,100 founders come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately Save up to $300 on your pass or save up to 30% with group tickets for teams of four or more. TechCrunch Founder Summit: Tickets Live On June 23 in Boston , more than 1,100 founders come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately Save up to $300 on your pass or save up to 30% with group tickets for teams of four or more. Boston, MA | June 23, 2026 REGISTER NOW Chesky said Airbnb plans to tap the AI expertise of its new CTO, Ahmad Al-Dahle (he worked on Meta’s Llama models previously), to use its trove of identity and review data to make the app more useful. Airbnb claimed its AI-powered customer support bot, launched in North America last year, now handles a third of customer problems without needing any human intervention. Chesky noted there are plans to enable customers to call the AI bot for support, and expand language coverage to customer support as well. “A year from now, if we are successful, significantly more than 30% of tickets will be handled by a custom service agent, in many more languages, in all the languages where we have live agents. AI customer service will not only be chat, it will be voice,” he said. The company is also thinking about increasing AI usage internally. Airbnb said 80% of its engineers use AI tools, but the goal is to get to 100%. Airbnb reported better-than-expected revenue of $2.78 billion in the fourth quarter, up 12% from a year earlier. Topics AI , AI search , Airbnb , Apps , travel apps Ivan Mehta Ivan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web. You can contact or verify outreach from Ivan by emailing im@ivanmehta.com or via encrypted message at ivan.42 on Signal. View Bio October 13-15 San Francisco, CA Tickets are live at the lowest rates of the year. Save up to $680 on your pass now. Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders , dive into 200+ sessions , and explore 300+ startups building what’s next. Don’t miss these one-time savings. REGISTER NOW Most Popular A Stanford grad student created an algorithm to help his classmates find love; now, Date Drop is the basis of his new startup Amanda Silberling Spotify says its best developers haven’t written a line of code since December, thanks to AI Sarah Perez The first signs of burnout are coming from the people who embrace AI the most Connie Loizos MrBeast’s company buys Gen Z-focused fintech app Step Amanda Silberling YouTube TV introduces cheaper bundles, including a $65/month sports package Sarah Perez Discord to roll out age verification next month Aisha Malik From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads Lauren Forristal Loading the next article Error loading the next article X LinkedIn Facebook Instagram youTube Mastodon Threads Bluesky TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Terms of Service Privacy Policy RSS Terms of Use Code of Conduct Epstein Kindle Scribe Reddit TikTok GPT-4o Tech Layoffs ChatGPT © 2025 TechCrunch Media LLC.",
      "imageUrl": "https://techcrunch.com/wp-content/uploads/2025/08/brian-chesky-GettyImages-2217178973.jpg?w=1024",
      "tags": [
        "LLM"
      ],
      "paperCategory": "",
      "signalReasons": [
        "来源：TechCrunch AI",
        "跨源重复：1 个来源",
        "模型评分：7/10，理由：Airbnb推进LLM深度集成，代表主流平台规模化落地AI，具备行业示范效应，但非突破性创新。",
        "热度：0 / 评论 0"
      ],
      "score": 4.2,
      "publishedAt": "2026-02-14T02:40:42+00:00",
      "authors": [
        "Ivan Mehta"
      ]
    }
  ],
  "stats": {
    "total_papers_ingested": 335,
    "total_news_ingested": 31,
    "l1_papers_passed": 156,
    "l1_news_passed": 25,
    "l2_papers_scored": 51,
    "l2_news_scored": 17,
    "l3_papers_selected": 18,
    "l3_news_selected": 11,
    "news_source_counts": {
      "Hacker News": 20,
      "GitHub Trending": 6,
      "TechCrunch AI": 4,
      "The Verge AI": 1
    },
    "rss_source_counts": {
      "TechCrunch AI": 4,
      "The Verge AI": 1
    },
    "news_title_source_counts": {
      "news publishers limit internet archive access due to ai scraping concerns": 1,
      "my smart sleep mask broadcasts users brainwaves to an open mqtt broker": 1,
      "ibm tripling entry level jobs after finding the limits of ai adoption": 1,
      "colored petri nets llms and distributed applications": 1,
      "a review of m disc archival capability with long term testing results 2016": 1,
      "an ai agent published a hit piece on me more things have happened": 1,
      "openai should build slack": 1,
      "youtube as storage": 1,
      "you can t trust the internet anymore": 1,
      "verizon imposes new roadblock on users trying to unlock paid off phones": 1,
      "dune ii written in html5 js": 1,
      "gemini 3 deep think drew me a good svg of a pelican riding a bicycle": 1,
      "ai agent lands prs in major oss projects targets maintainers via cold outreach": 1,
      "dr oz pushes ai avatars as a fix for rural health care": 1,
      "taste for makers": 1,
      "show hn prompt to planet generate procedural 3d planets from text": 1,
      "just 5 weeks of brain training may protect against dementia for 20 years": 1,
      "bytedance seed2 0 llm breakthrough in complex real world tasks": 1,
      "pentagon used claude in maduro venezuela raid": 1,
      "we urgently need a federal law forbidding ai from impersonating humans": 1,
      "tambo ai tambo": 1,
      "synkraai aios core": 1,
      "rowboatlabs rowboat": 1,
      "chromedevtools chrome devtools mcp": 1,
      "zipstack unstract": 1,
      "letta ai letta code": 1,
      "my uncanny ai valentines": 1,
      "is safety is dead at xai": 1,
      "hollywood isn t happy about the new seedance 2 0 video generator": 1,
      "india doubles down on state backed venture capital approving 1 1b fund": 1,
      "airbnb plans to bake in ai features for search discovery and support": 1
    },
    "total_papers_deduped": 335,
    "total_news_deduped": 31,
    "news_recent_filtered": 31
  }
}